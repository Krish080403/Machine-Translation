2025-04-03 05:03:47 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 2, 'log_format': 'simple', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 222, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 3600, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 3600, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 40000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [2], 'lr': [3e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': '/home/krish/content/1.2B_last_checkpoint.pt', 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 5000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': 10, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=2, log_format='simple', log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=222, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', scoring='bleu', task='translation_multi_simple_epoch', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=3600, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=3600, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='transformer_wmt_en_de_big', max_epoch=0, max_update=40000, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[2], lr=[3e-05], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='/home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model='/home/krish/content/1.2B_last_checkpoint.pt', reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=5000, keep_interval_updates=10, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=10, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, source_lang=None, target_lang=None, lang_pairs='mr-hi', keep_inference_langtok=False, sampling_method='temperature', sampling_temperature=1.5, data='/home/krish/content/old_files/Version3/wmt22_spm/wmt22_bin', langs=['hi', 'mr'], lang_dict=None, source_dict=None, target_dict=None, lang_tok_style='multilingual', load_alignments=False, left_pad_source='True', left_pad_target='False', upsample_primary=1, truncate_source=False, encoder_langtok='src', decoder_langtok=True, lang_tok_replacing_bos_eos=False, enable_lang_ids=False, enable_reservsed_directions_shared_datasets=False, extra_data=None, extra_lang_pairs=None, fixed_dictionary=None, langtoks_specs=['main'], langtoks=None, sampling_weights_from_file=None, sampling_weights=None, virtual_epoch_size=None, virtual_data_size=None, label_smoothing=0.2, report_accuracy=False, ignore_prefix_size=0, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.0, use_old_adam=False, fp16_adam_stats=False, warmup_updates=2500, warmup_init_lr=-1, pad=1, eos=2, unk=3, encoder_normalize_before=True, decoder_normalize_before=True, dropout=0.3, attention_dropout=0.1, encoder_layers=24, decoder_layers=24, encoder_ffn_embed_dim=8192, decoder_ffn_embed_dim=8192, encoder_layerdrop=0.05, decoder_layerdrop=0.05, share_decoder_input_output_embed=True, share_all_embeddings=True, no_seed_provided=False, encoder_embed_dim=1024, encoder_attention_heads=16, decoder_embed_dim=1024, decoder_attention_heads=16, encoder_embed_path=None, encoder_learned_pos=False, decoder_embed_path=None, decoder_learned_pos=False, activation_dropout=0.0, activation_fn='relu', adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, no_token_positional_embeddings=False, adaptive_input=False, no_cross_attention=False, cross_self_attention=False, decoder_output_dim=1024, decoder_input_dim=1024, no_scale_embedding=False, layernorm_embedding=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, _name='transformer_wmt_en_de_big'), 'task': Namespace(no_progress_bar=False, log_interval=2, log_format='simple', log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=222, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', scoring='bleu', task='translation_multi_simple_epoch', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=3600, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=3600, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='transformer_wmt_en_de_big', max_epoch=0, max_update=40000, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[2], lr=[3e-05], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='/home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model='/home/krish/content/1.2B_last_checkpoint.pt', reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=5000, keep_interval_updates=10, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=10, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, source_lang=None, target_lang=None, lang_pairs='mr-hi', keep_inference_langtok=False, sampling_method='temperature', sampling_temperature=1.5, data='/home/krish/content/old_files/Version3/wmt22_spm/wmt22_bin', langs=['hi', 'mr'], lang_dict=None, source_dict=None, target_dict=None, lang_tok_style='multilingual', load_alignments=False, left_pad_source='True', left_pad_target='False', upsample_primary=1, truncate_source=False, encoder_langtok='src', decoder_langtok=True, lang_tok_replacing_bos_eos=False, enable_lang_ids=False, enable_reservsed_directions_shared_datasets=False, extra_data=None, extra_lang_pairs=None, fixed_dictionary=None, langtoks_specs=['main'], langtoks=None, sampling_weights_from_file=None, sampling_weights=None, virtual_epoch_size=None, virtual_data_size=None, label_smoothing=0.2, report_accuracy=False, ignore_prefix_size=0, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.0, use_old_adam=False, fp16_adam_stats=False, warmup_updates=2500, warmup_init_lr=-1, pad=1, eos=2, unk=3, encoder_normalize_before=True, decoder_normalize_before=True, dropout=0.3, attention_dropout=0.1, encoder_layers=24, decoder_layers=24, encoder_ffn_embed_dim=8192, decoder_ffn_embed_dim=8192, encoder_layerdrop=0.05, decoder_layerdrop=0.05, share_decoder_input_output_embed=True, share_all_embeddings=True, no_seed_provided=False, encoder_embed_dim=1024, encoder_attention_heads=16, decoder_embed_dim=1024, decoder_attention_heads=16, encoder_embed_path=None, encoder_learned_pos=False, decoder_embed_path=None, decoder_learned_pos=False, activation_dropout=0.0, activation_fn='relu', adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, no_token_positional_embeddings=False, adaptive_input=False, no_cross_attention=False, cross_self_attention=False, decoder_output_dim=1024, decoder_input_dim=1024, no_scale_embedding=False, layernorm_embedding=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, max_source_positions=1024, max_target_positions=1024, _name='translation_multi_simple_epoch'), 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.2, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [3e-05]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 2500, 'warmup_init_lr': -1.0, 'lr': [3e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2025-04-03 05:03:47 | INFO | fairseq.data.multilingual.multilingual_data_manager | parsed the language list as they are ordered in the option: ['hi', 'mr']
2025-04-03 05:03:47 | INFO | fairseq.data.multilingual.multilingual_data_manager | [mr] dictionary: 128112 types
2025-04-03 05:03:47 | INFO | fairseq.data.multilingual.multilingual_data_manager | [hi] dictionary: 128112 types
2025-04-03 05:03:55 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(128112, 1024, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): LayerDropModuleList(
      (0-22): 23 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=8192, bias=True)
        (fc2): Linear(in_features=8192, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(128112, 1024, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): LayerDropModuleList(
      (0-20): 21 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=8192, bias=True)
        (fc2): Linear(in_features=8192, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=1024, out_features=128112, bias=False)
  )
)
2025-04-03 05:03:55 | INFO | fairseq_cli.train | task: TranslationMultiSimpleEpochTask
2025-04-03 05:03:55 | INFO | fairseq_cli.train | model: TransformerModel
2025-04-03 05:03:55 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2025-04-03 05:03:55 | INFO | fairseq_cli.train | num. shared model params: 1,743,106,048 (num. trained: 1,743,106,048)
2025-04-03 05:03:55 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2025-04-03 05:03:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | loading data for valid epoch=1/None
2025-04-03 05:03:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=10618.15234375Mb; avail=244482.921875Mb
2025-04-03 05:03:55 | INFO | fairseq.data.multilingual.multilingual_data_manager | langtoks settings: {'main': ('src', 'tgt')}
2025-04-03 05:03:55 | INFO | fairseq.data.multilingual.multilingual_data_manager | [valid] num of shards: {'main:mr-hi': 1}
2025-04-03 05:03:55 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:mr-hi src_langtok: 128063; tgt_langtok: 128036
2025-04-03 05:03:55 | INFO | fairseq.data.data_utils | loaded 3,313 examples from: /home/krish/content/old_files/Version3/wmt22_spm/wmt22_bin/valid.hi-mr.mr
2025-04-03 05:03:55 | INFO | fairseq.data.data_utils | loaded 3,313 examples from: /home/krish/content/old_files/Version3/wmt22_spm/wmt22_bin/valid.hi-mr.hi
2025-04-03 05:03:55 | INFO | fairseq.data.multilingual.multilingual_data_manager | /home/krish/content/old_files/Version3/wmt22_spm/wmt22_bin valid mr-hi 3313 examples
2025-04-03 05:03:56 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2025-04-03 05:03:56 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2025-04-03 05:03:56 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2025-04-03 05:03:56 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
2025-04-03 05:03:56 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2025-04-03 05:03:56 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2025-04-03 05:03:56 | INFO | fairseq_cli.train | max tokens per device = 3600 and max sentences per device = None
2025-04-03 05:03:56 | INFO | fairseq.checkpoint_utils | loading pretrained model from /home/krish/content/1.2B_last_checkpoint.pt: optimizer, lr scheduler, meters, dataloader will be reset
2025-04-03 05:03:56 | INFO | fairseq.trainer | Preparing to load checkpoint /home/krish/content/1.2B_last_checkpoint.pt
2025-04-03 05:04:05 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2025-04-03 05:04:05 | INFO | fairseq.trainer | Loaded checkpoint /home/krish/content/1.2B_last_checkpoint.pt (epoch 81 @ 0 updates)
2025-04-03 05:04:06 | INFO | fairseq.trainer | loading train data for epoch 1
2025-04-03 05:04:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | loading data for train epoch=1/None
2025-04-03 05:04:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=6939.6640625Mb; avail=248153.41015625Mb
2025-04-03 05:04:06 | INFO | fairseq.data.multilingual.multilingual_data_manager | langtoks settings: {'main': ('src', 'tgt')}
2025-04-03 05:04:06 | INFO | fairseq.data.multilingual.multilingual_data_manager | [train] num of shards: {'main:mr-hi': 1}
2025-04-03 05:04:06 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:mr-hi src_langtok: 128063; tgt_langtok: 128036
2025-04-03 05:04:06 | INFO | fairseq.data.data_utils | loaded 31,849 examples from: /home/krish/content/old_files/Version3/wmt22_spm/wmt22_bin/train.hi-mr.mr
2025-04-03 05:04:06 | INFO | fairseq.data.data_utils | loaded 31,849 examples from: /home/krish/content/old_files/Version3/wmt22_spm/wmt22_bin/train.hi-mr.hi
2025-04-03 05:04:06 | INFO | fairseq.data.multilingual.multilingual_data_manager | /home/krish/content/old_files/Version3/wmt22_spm/wmt22_bin train mr-hi 31849 examples
2025-04-03 05:04:06 | INFO | fairseq.data.multilingual.multilingual_data_manager | estimated total data sizes of all shards used in sampling ratios: [('main:mr-hi', 31849)]. Note that if the data a shard has not been loaded yet, use the max known data size to approximate
2025-04-03 05:04:06 | INFO | fairseq.data.multilingual.sampling_method | selected sampler: temperature
2025-04-03 05:04:06 | INFO | fairseq.data.multilingual.multilingual_data_manager | | Upsample ratios: [('main:mr-hi', 1.0)]
2025-04-03 05:04:06 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:mr-hi': 31849}; raw total size: 31849
2025-04-03 05:04:06 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:mr-hi': 31849}; resampled total size: 31849
2025-04-03 05:04:06 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:mr-hi': 1.0}
2025-04-03 05:04:06 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001044
2025-04-03 05:04:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=6939.6640625Mb; avail=248153.41015625Mb
2025-04-03 05:04:06 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000313
2025-04-03 05:04:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003360
2025-04-03 05:04:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=6939.6640625Mb; avail=248153.41015625Mb
2025-04-03 05:04:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000101
2025-04-03 05:04:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=6939.6640625Mb; avail=248153.41015625Mb
2025-04-03 05:04:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.002501
2025-04-03 05:04:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.006360
2025-04-03 05:04:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=6939.6640625Mb; avail=248153.41015625Mb
2025-04-03 05:04:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 126
2025-04-03 05:04:06 | INFO | fairseq.trainer | begin training epoch 1
2025-04-03 05:04:06 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-03 05:04:11 | INFO | train_inner | epoch 001:      2 / 126 loss=8.729, nll_loss=5.85, ppl=57.69, wps=1784.5, ups=0.37, wpb=4601.5, bsz=328, num_updates=2, lr=2.4e-08, gnorm=6.545, train_wall=6, gb_free=14.7, wall=15
2025-04-03 05:04:16 | INFO | train_inner | epoch 001:      4 / 126 loss=8.764, nll_loss=5.897, ppl=59.6, wps=1864.1, ups=0.39, wpb=4753.5, bsz=272, num_updates=4, lr=4.8e-08, gnorm=5.914, train_wall=5, gb_free=13.8, wall=20
2025-04-03 05:04:20 | INFO | train_inner | epoch 001:      6 / 126 loss=8.942, nll_loss=6.12, ppl=69.53, wps=1444.5, ups=0.48, wpb=3007, bsz=176.5, num_updates=6, lr=7.2e-08, gnorm=6.442, train_wall=4, gb_free=14.2, wall=25
2025-04-03 05:04:26 | INFO | train_inner | epoch 001:      8 / 126 loss=8.834, nll_loss=5.983, ppl=63.26, wps=1685.5, ups=0.36, wpb=4707, bsz=200, num_updates=8, lr=9.6e-08, gnorm=5.319, train_wall=6, gb_free=10.7, wall=30
2025-04-03 05:04:31 | INFO | train_inner | epoch 001:     10 / 126 loss=8.807, nll_loss=5.944, ppl=61.58, wps=1659.5, ups=0.37, wpb=4439, bsz=244, num_updates=10, lr=1.2e-07, gnorm=6.102, train_wall=5, gb_free=10.5, wall=35
2025-04-03 05:04:37 | INFO | train_inner | epoch 001:     12 / 126 loss=8.69, nll_loss=5.802, ppl=55.81, wps=1571, ups=0.36, wpb=4322, bsz=284, num_updates=12, lr=1.44e-07, gnorm=6.215, train_wall=5, gb_free=13.9, wall=41
2025-04-03 05:04:43 | INFO | train_inner | epoch 001:     14 / 126 loss=8.858, nll_loss=6.02, ppl=64.91, wps=1634, ups=0.35, wpb=4648.5, bsz=184, num_updates=14, lr=1.68e-07, gnorm=5.1, train_wall=6, gb_free=12.6, wall=47
2025-04-03 05:04:48 | INFO | train_inner | epoch 001:     16 / 126 loss=8.729, nll_loss=5.851, ppl=57.72, wps=1487.5, ups=0.37, wpb=4018, bsz=212, num_updates=16, lr=1.92e-07, gnorm=6.141, train_wall=5, gb_free=10.9, wall=52
2025-04-03 05:04:53 | INFO | train_inner | epoch 001:     18 / 126 loss=8.86, nll_loss=6.018, ppl=64.8, wps=1457.4, ups=0.38, wpb=3857, bsz=196, num_updates=18, lr=2.16e-07, gnorm=5.664, train_wall=5, gb_free=13.9, wall=57
2025-04-03 05:04:58 | INFO | train_inner | epoch 001:     20 / 126 loss=8.697, nll_loss=5.815, ppl=56.29, wps=1841.2, ups=0.4, wpb=4654.5, bsz=288, num_updates=20, lr=2.4e-07, gnorm=5.305, train_wall=5, gb_free=12.3, wall=62
2025-04-03 05:05:04 | INFO | train_inner | epoch 001:     22 / 126 loss=8.783, nll_loss=5.92, ppl=60.55, wps=1542.3, ups=0.37, wpb=4177.5, bsz=268, num_updates=22, lr=2.64e-07, gnorm=5.853, train_wall=5, gb_free=12.3, wall=68
2025-04-03 05:05:10 | INFO | train_inner | epoch 001:     24 / 126 loss=8.855, nll_loss=6.016, ppl=64.7, wps=1385.4, ups=0.35, wpb=3995.5, bsz=188, num_updates=24, lr=2.88e-07, gnorm=5.26, train_wall=6, gb_free=8.8, wall=74
2025-04-03 05:05:15 | INFO | train_inner | epoch 001:     26 / 126 loss=8.591, nll_loss=5.691, ppl=51.65, wps=1675.3, ups=0.36, wpb=4679, bsz=232, num_updates=26, lr=3.12e-07, gnorm=4.969, train_wall=6, gb_free=10.3, wall=79
2025-04-03 05:05:21 | INFO | train_inner | epoch 001:     28 / 126 loss=8.466, nll_loss=5.534, ppl=46.32, wps=1573.8, ups=0.36, wpb=4423, bsz=268, num_updates=28, lr=3.36e-07, gnorm=4.773, train_wall=6, gb_free=13.5, wall=85
2025-04-03 05:05:27 | INFO | train_inner | epoch 001:     30 / 126 loss=8.33, nll_loss=5.353, ppl=40.87, wps=1533.2, ups=0.34, wpb=4474.5, bsz=260, num_updates=30, lr=3.6e-07, gnorm=5.017, train_wall=6, gb_free=8.5, wall=91
2025-04-03 05:05:32 | INFO | train_inner | epoch 001:     32 / 126 loss=8.545, nll_loss=5.634, ppl=49.67, wps=1745, ups=0.34, wpb=5074.5, bsz=232, num_updates=32, lr=3.84e-07, gnorm=4.21, train_wall=6, gb_free=13.1, wall=96
2025-04-03 05:05:38 | INFO | train_inner | epoch 001:     34 / 126 loss=8.471, nll_loss=5.544, ppl=46.64, wps=1789.9, ups=0.36, wpb=5026.5, bsz=272, num_updates=34, lr=4.08e-07, gnorm=4.645, train_wall=6, gb_free=12.6, wall=102
2025-04-03 05:05:43 | INFO | train_inner | epoch 001:     36 / 126 loss=8.612, nll_loss=5.719, ppl=52.67, wps=1628, ups=0.37, wpb=4404.5, bsz=264, num_updates=36, lr=4.32e-07, gnorm=4.603, train_wall=5, gb_free=13.5, wall=108
2025-04-03 05:05:49 | INFO | train_inner | epoch 001:     38 / 126 loss=8.442, nll_loss=5.508, ppl=45.51, wps=1649.7, ups=0.33, wpb=4966.5, bsz=260, num_updates=38, lr=4.56e-07, gnorm=4.293, train_wall=6, gb_free=10, wall=114
2025-04-03 05:05:55 | INFO | train_inner | epoch 001:     40 / 126 loss=8.5, nll_loss=5.59, ppl=48.18, wps=1712.5, ups=0.39, wpb=4421.5, bsz=264, num_updates=40, lr=4.8e-07, gnorm=4.304, train_wall=5, gb_free=12.5, wall=119
2025-04-03 05:06:00 | INFO | train_inner | epoch 001:     42 / 126 loss=8.456, nll_loss=5.525, ppl=46.05, wps=1551.6, ups=0.37, wpb=4224, bsz=236, num_updates=42, lr=5.04e-07, gnorm=4.221, train_wall=5, gb_free=13, wall=124
2025-04-03 05:06:06 | INFO | train_inner | epoch 001:     44 / 126 loss=8.451, nll_loss=5.524, ppl=46.02, wps=1636.7, ups=0.35, wpb=4681.5, bsz=192, num_updates=44, lr=5.28e-07, gnorm=3.741, train_wall=6, gb_free=13.7, wall=130
2025-04-03 05:06:12 | INFO | train_inner | epoch 001:     46 / 126 loss=8.279, nll_loss=5.311, ppl=39.69, wps=1832.2, ups=0.35, wpb=5261, bsz=312, num_updates=46, lr=5.52e-07, gnorm=3.866, train_wall=6, gb_free=12.2, wall=136
2025-04-03 05:06:17 | INFO | train_inner | epoch 001:     48 / 126 loss=8.483, nll_loss=5.568, ppl=47.45, wps=1477.5, ups=0.36, wpb=4106, bsz=192, num_updates=48, lr=5.76e-07, gnorm=3.534, train_wall=6, gb_free=10.4, wall=141
2025-04-03 05:06:23 | INFO | train_inner | epoch 001:     50 / 126 loss=8.317, nll_loss=5.359, ppl=41.05, wps=1627.3, ups=0.37, wpb=4423, bsz=312, num_updates=50, lr=6e-07, gnorm=3.7, train_wall=5, gb_free=11.6, wall=147
2025-04-03 05:06:28 | INFO | train_inner | epoch 001:     52 / 126 loss=8.029, nll_loss=4.998, ppl=31.95, wps=1888.1, ups=0.34, wpb=5584, bsz=384, num_updates=52, lr=6.24e-07, gnorm=3.634, train_wall=6, gb_free=10.4, wall=153
2025-04-03 05:06:34 | INFO | train_inner | epoch 001:     54 / 126 loss=8.301, nll_loss=5.349, ppl=40.77, wps=1563.4, ups=0.35, wpb=4516, bsz=268, num_updates=54, lr=6.48e-07, gnorm=3.487, train_wall=6, gb_free=8.9, wall=158
2025-04-03 05:06:39 | INFO | train_inner | epoch 001:     56 / 126 loss=8.523, nll_loss=5.629, ppl=49.49, wps=1539, ups=0.39, wpb=3968, bsz=288, num_updates=56, lr=6.72e-07, gnorm=3.87, train_wall=5, gb_free=14.3, wall=163
2025-04-03 05:06:45 | INFO | train_inner | epoch 001:     58 / 126 loss=8.258, nll_loss=5.297, ppl=39.31, wps=1754.3, ups=0.34, wpb=5149, bsz=272, num_updates=58, lr=6.96e-07, gnorm=3.155, train_wall=6, gb_free=12.4, wall=169
2025-04-03 05:06:51 | INFO | train_inner | epoch 001:     60 / 126 loss=8.175, nll_loss=5.188, ppl=36.45, wps=1775.1, ups=0.37, wpb=4813, bsz=332, num_updates=60, lr=7.2e-07, gnorm=3.291, train_wall=5, gb_free=10.4, wall=175
2025-04-03 05:06:56 | INFO | train_inner | epoch 001:     62 / 126 loss=8.012, nll_loss=4.992, ppl=31.82, wps=1902.2, ups=0.35, wpb=5408, bsz=336, num_updates=62, lr=7.44e-07, gnorm=3.129, train_wall=6, gb_free=13, wall=180
2025-04-03 05:07:02 | INFO | train_inner | epoch 001:     64 / 126 loss=8.27, nll_loss=5.312, ppl=39.74, wps=1557.2, ups=0.33, wpb=4785, bsz=272, num_updates=64, lr=7.68e-07, gnorm=2.762, train_wall=6, gb_free=9.7, wall=187
2025-04-03 05:07:08 | INFO | train_inner | epoch 001:     66 / 126 loss=8.287, nll_loss=5.347, ppl=40.7, wps=1660.1, ups=0.35, wpb=4791.5, bsz=232, num_updates=66, lr=7.92e-07, gnorm=3.036, train_wall=6, gb_free=12.8, wall=192
2025-04-03 05:07:14 | INFO | train_inner | epoch 001:     68 / 126 loss=8.147, nll_loss=5.169, ppl=35.98, wps=1782.6, ups=0.37, wpb=4827.5, bsz=324, num_updates=68, lr=8.16e-07, gnorm=2.771, train_wall=5, gb_free=13.9, wall=198
2025-04-03 05:07:19 | INFO | train_inner | epoch 001:     70 / 126 loss=8.35, nll_loss=5.418, ppl=42.76, wps=1572, ups=0.38, wpb=4143, bsz=200, num_updates=70, lr=8.4e-07, gnorm=3.054, train_wall=5, gb_free=12.9, wall=203
2025-04-03 05:07:25 | INFO | train_inner | epoch 001:     72 / 126 loss=8.172, nll_loss=5.205, ppl=36.89, wps=1583.2, ups=0.35, wpb=4544.5, bsz=260, num_updates=72, lr=8.64e-07, gnorm=2.702, train_wall=6, gb_free=13.2, wall=209
2025-04-03 05:07:30 | INFO | train_inner | epoch 001:     74 / 126 loss=8.307, nll_loss=5.378, ppl=41.57, wps=1694.6, ups=0.39, wpb=4317, bsz=224, num_updates=74, lr=8.88e-07, gnorm=3.272, train_wall=5, gb_free=12.8, wall=214
2025-04-03 05:07:35 | INFO | train_inner | epoch 001:     76 / 126 loss=8.144, nll_loss=5.166, ppl=35.9, wps=1680, ups=0.35, wpb=4741.5, bsz=284, num_updates=76, lr=9.12e-07, gnorm=2.726, train_wall=6, gb_free=10.1, wall=220
2025-04-03 05:07:41 | INFO | train_inner | epoch 001:     78 / 126 loss=8.253, nll_loss=5.308, ppl=39.63, wps=1696.1, ups=0.37, wpb=4589.5, bsz=224, num_updates=78, lr=9.36e-07, gnorm=2.704, train_wall=5, gb_free=12.7, wall=225
2025-04-03 05:07:46 | INFO | train_inner | epoch 001:     80 / 126 loss=8.072, nll_loss=5.078, ppl=33.79, wps=1689.9, ups=0.37, wpb=4595.5, bsz=328, num_updates=80, lr=9.6e-07, gnorm=2.576, train_wall=5, gb_free=12.2, wall=230
2025-04-03 05:07:52 | INFO | train_inner | epoch 001:     82 / 126 loss=8.093, nll_loss=5.114, ppl=34.62, wps=1784.8, ups=0.35, wpb=5089, bsz=284, num_updates=82, lr=9.84e-07, gnorm=2.828, train_wall=6, gb_free=10.7, wall=236
2025-04-03 05:07:58 | INFO | train_inner | epoch 001:     84 / 126 loss=8.188, nll_loss=5.236, ppl=37.69, wps=1734.5, ups=0.35, wpb=4898, bsz=308, num_updates=84, lr=1.008e-06, gnorm=2.418, train_wall=6, gb_free=12.1, wall=242
2025-04-03 05:08:03 | INFO | train_inner | epoch 001:     86 / 126 loss=8.085, nll_loss=5.106, ppl=34.45, wps=1847.1, ups=0.36, wpb=5095.5, bsz=280, num_updates=86, lr=1.032e-06, gnorm=2.35, train_wall=6, gb_free=12.1, wall=247
2025-04-03 05:08:09 | INFO | train_inner | epoch 001:     88 / 126 loss=8.088, nll_loss=5.115, ppl=34.66, wps=1793.3, ups=0.36, wpb=4936, bsz=292, num_updates=88, lr=1.056e-06, gnorm=2.453, train_wall=5, gb_free=12.6, wall=253
2025-04-03 05:08:14 | INFO | train_inner | epoch 001:     90 / 126 loss=8.039, nll_loss=5.051, ppl=33.16, wps=1734.7, ups=0.36, wpb=4817.5, bsz=232, num_updates=90, lr=1.08e-06, gnorm=2.449, train_wall=6, gb_free=12.5, wall=258
2025-04-03 05:08:20 | INFO | train_inner | epoch 001:     92 / 126 loss=8.11, nll_loss=5.14, ppl=35.25, wps=1573.9, ups=0.34, wpb=4572, bsz=232, num_updates=92, lr=1.104e-06, gnorm=2.733, train_wall=6, gb_free=9.1, wall=264
2025-04-03 05:08:26 | INFO | train_inner | epoch 001:     94 / 126 loss=8.262, nll_loss=5.336, ppl=40.41, wps=1578.1, ups=0.34, wpb=4665, bsz=160, num_updates=94, lr=1.128e-06, gnorm=2.623, train_wall=6, gb_free=9.1, wall=270
2025-04-03 05:08:31 | INFO | train_inner | epoch 001:     96 / 126 loss=8.084, nll_loss=5.106, ppl=34.44, wps=1682.7, ups=0.38, wpb=4464.5, bsz=316, num_updates=96, lr=1.152e-06, gnorm=2.419, train_wall=5, gb_free=15, wall=275
2025-04-03 05:08:36 | INFO | train_inner | epoch 001:     98 / 126 loss=8.178, nll_loss=5.234, ppl=37.63, wps=1738.4, ups=0.39, wpb=4503.5, bsz=276, num_updates=98, lr=1.176e-06, gnorm=2.444, train_wall=5, gb_free=14.7, wall=281
2025-04-03 05:08:42 | INFO | train_inner | epoch 001:    100 / 126 loss=8.205, nll_loss=5.269, ppl=38.56, wps=1484.8, ups=0.35, wpb=4194.5, bsz=220, num_updates=100, lr=1.2e-06, gnorm=2.429, train_wall=6, gb_free=13.2, wall=286
2025-04-03 05:08:47 | INFO | train_inner | epoch 001:    102 / 126 loss=8.087, nll_loss=5.114, ppl=34.64, wps=1636.7, ups=0.38, wpb=4323, bsz=164, num_updates=102, lr=1.224e-06, gnorm=2.738, train_wall=5, gb_free=17, wall=291
2025-04-03 05:08:53 | INFO | train_inner | epoch 001:    104 / 126 loss=8.305, nll_loss=5.4, ppl=42.21, wps=1443, ups=0.34, wpb=4276, bsz=140, num_updates=104, lr=1.248e-06, gnorm=2.608, train_wall=6, gb_free=8.7, wall=297
2025-04-03 05:08:59 | INFO | train_inner | epoch 001:    106 / 126 loss=8.207, nll_loss=5.278, ppl=38.81, wps=1443.2, ups=0.35, wpb=4086, bsz=256, num_updates=106, lr=1.272e-06, gnorm=2.59, train_wall=6, gb_free=11.7, wall=303
2025-04-03 05:09:05 | INFO | train_inner | epoch 001:    108 / 126 loss=7.976, nll_loss=4.979, ppl=31.53, wps=1726.9, ups=0.34, wpb=5102, bsz=248, num_updates=108, lr=1.296e-06, gnorm=2.231, train_wall=6, gb_free=12.1, wall=309
2025-04-03 05:09:10 | INFO | train_inner | epoch 001:    110 / 126 loss=8.266, nll_loss=5.355, ppl=40.92, wps=1465.4, ups=0.42, wpb=3511, bsz=180, num_updates=110, lr=1.32e-06, gnorm=2.666, train_wall=5, gb_free=18.8, wall=314
2025-04-03 05:09:15 | INFO | train_inner | epoch 001:    112 / 126 loss=8.118, nll_loss=5.159, ppl=35.74, wps=1668.7, ups=0.36, wpb=4660, bsz=244, num_updates=112, lr=1.344e-06, gnorm=2.601, train_wall=6, gb_free=13.6, wall=319
2025-04-03 05:09:20 | INFO | train_inner | epoch 001:    114 / 126 loss=8.244, nll_loss=5.324, ppl=40.05, wps=1620.1, ups=0.38, wpb=4266.5, bsz=200, num_updates=114, lr=1.368e-06, gnorm=2.46, train_wall=5, gb_free=11.9, wall=325
2025-04-03 05:09:26 | INFO | train_inner | epoch 001:    116 / 126 loss=7.918, nll_loss=4.915, ppl=30.17, wps=1781.2, ups=0.34, wpb=5171, bsz=256, num_updates=116, lr=1.392e-06, gnorm=2.409, train_wall=6, gb_free=12.3, wall=330
2025-04-03 05:09:32 | INFO | train_inner | epoch 001:    118 / 126 loss=8.16, nll_loss=5.226, ppl=37.43, wps=1564.7, ups=0.35, wpb=4416, bsz=212, num_updates=118, lr=1.416e-06, gnorm=2.304, train_wall=6, gb_free=11.9, wall=336
2025-04-03 05:09:37 | INFO | train_inner | epoch 001:    120 / 126 loss=8.089, nll_loss=5.131, ppl=35.05, wps=1763.7, ups=0.38, wpb=4619.5, bsz=332, num_updates=120, lr=1.44e-06, gnorm=2.577, train_wall=5, gb_free=13.3, wall=341
2025-04-03 05:09:43 | INFO | train_inner | epoch 001:    122 / 126 loss=7.974, nll_loss=4.995, ppl=31.89, wps=1795.6, ups=0.37, wpb=4913, bsz=324, num_updates=122, lr=1.464e-06, gnorm=2.178, train_wall=5, gb_free=14, wall=347
2025-04-03 05:09:48 | INFO | train_inner | epoch 001:    124 / 126 loss=8.121, nll_loss=5.176, ppl=36.15, wps=1564.4, ups=0.36, wpb=4369.5, bsz=220, num_updates=124, lr=1.488e-06, gnorm=2.246, train_wall=6, gb_free=13.4, wall=352
2025-04-03 05:09:52 | INFO | train_inner | epoch 001:    126 / 126 loss=8.004, nll_loss=5.027, ppl=32.61, wps=1674, ups=0.47, wpb=3563, bsz=184, num_updates=126, lr=1.512e-06, gnorm=2.699, train_wall=4, gb_free=14.7, wall=357
2025-04-03 05:09:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-03 05:09:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=7572.19921875Mb; avail=247512.8828125Mb
2025-04-03 05:09:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000622
2025-04-03 05:09:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=7572.19921875Mb; avail=247512.8828125Mb
2025-04-03 05:09:53 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.013227
2025-04-03 05:09:53 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=7572.19921875Mb; avail=247512.8828125Mb
2025-04-03 05:09:53 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.011103
2025-04-03 05:09:53 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.025310
2025-04-03 05:09:53 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=7572.19921875Mb; avail=247512.8828125Mb
2025-04-03 05:10:07 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 7.737 | nll_loss 4.524 | ppl 23.01 | wps 3870.5 | wpb 2070.5 | bsz 122.7 | num_updates 126
2025-04-03 05:10:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 126 updates
2025-04-03 05:10:07 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 05:10:40 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 05:10:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt (epoch 1 @ 126 updates, score 7.737) (writing took 48.69911129097454 seconds)
2025-04-03 05:10:55 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2025-04-03 05:10:55 | INFO | train | epoch 001 | loss 8.332 | nll_loss 5.395 | ppl 42.07 | wps 1397.7 | ups 0.31 | wpb 4549.7 | bsz 252.8 | num_updates 126 | lr 1.512e-06 | gnorm 3.641 | train_wall 346 | gb_free 14.7 | wall 420
2025-04-03 05:10:55 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:mr-hi': 31849}; raw total size: 31849
2025-04-03 05:10:55 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:mr-hi': 31849}; resampled total size: 31849
2025-04-03 05:10:55 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:mr-hi': 1.0}
2025-04-03 05:10:55 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001197
2025-04-03 05:10:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13150.8046875Mb; avail=241934.2421875Mb
2025-04-03 05:10:55 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000404
2025-04-03 05:10:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003118
2025-04-03 05:10:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13150.8046875Mb; avail=241934.2421875Mb
2025-04-03 05:10:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000095
2025-04-03 05:10:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13150.8046875Mb; avail=241934.2421875Mb
2025-04-03 05:10:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001127
2025-04-03 05:10:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.004643
2025-04-03 05:10:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13150.8046875Mb; avail=241934.2421875Mb
2025-04-03 05:10:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 126
2025-04-03 05:10:56 | INFO | fairseq.trainer | begin training epoch 2
2025-04-03 05:10:56 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-03 05:11:01 | INFO | train_inner | epoch 002:      2 / 126 loss=8.18, nll_loss=5.258, ppl=38.26, wps=126, ups=0.03, wpb=4315.5, bsz=256, num_updates=128, lr=1.536e-06, gnorm=2.362, train_wall=5, gb_free=8.4, wall=425
2025-04-03 05:11:07 | INFO | train_inner | epoch 002:      4 / 126 loss=7.849, nll_loss=4.834, ppl=28.52, wps=1744.2, ups=0.34, wpb=5076.5, bsz=292, num_updates=130, lr=1.56e-06, gnorm=2.035, train_wall=6, gb_free=11, wall=431
2025-04-03 05:11:12 | INFO | train_inner | epoch 002:      6 / 126 loss=8.202, nll_loss=5.268, ppl=38.53, wps=1518.1, ups=0.38, wpb=3966.5, bsz=88, num_updates=132, lr=1.584e-06, gnorm=2.786, train_wall=5, gb_free=14.2, wall=436
2025-04-03 05:11:18 | INFO | train_inner | epoch 002:      8 / 126 loss=7.964, nll_loss=4.989, ppl=31.75, wps=1738.7, ups=0.36, wpb=4811, bsz=292, num_updates=134, lr=1.608e-06, gnorm=2.179, train_wall=6, gb_free=13.7, wall=442
2025-04-03 05:11:23 | INFO | train_inner | epoch 002:     10 / 126 loss=7.896, nll_loss=4.887, ppl=29.59, wps=1827.4, ups=0.36, wpb=5133.5, bsz=284, num_updates=136, lr=1.632e-06, gnorm=2.769, train_wall=6, gb_free=10.9, wall=447
2025-04-03 05:11:29 | INFO | train_inner | epoch 002:     12 / 126 loss=7.856, nll_loss=4.845, ppl=28.73, wps=1851.1, ups=0.36, wpb=5173.5, bsz=276, num_updates=138, lr=1.656e-06, gnorm=2.298, train_wall=6, gb_free=12.7, wall=453
2025-04-03 05:11:34 | INFO | train_inner | epoch 002:     14 / 126 loss=7.942, nll_loss=4.944, ppl=30.79, wps=1627.6, ups=0.4, wpb=4034, bsz=188.5, num_updates=140, lr=1.68e-06, gnorm=2.825, train_wall=5, gb_free=11.6, wall=458
2025-04-03 05:11:39 | INFO | train_inner | epoch 002:     16 / 126 loss=8.1, nll_loss=5.163, ppl=35.83, wps=1636.3, ups=0.38, wpb=4321, bsz=292, num_updates=142, lr=1.704e-06, gnorm=2.416, train_wall=5, gb_free=14.4, wall=463
2025-04-03 05:11:45 | INFO | train_inner | epoch 002:     18 / 126 loss=7.945, nll_loss=4.959, ppl=31.1, wps=1748.6, ups=0.34, wpb=5087, bsz=312, num_updates=144, lr=1.728e-06, gnorm=2.162, train_wall=6, gb_free=12.1, wall=469
2025-04-03 05:11:50 | INFO | train_inner | epoch 002:     20 / 126 loss=7.814, nll_loss=4.793, ppl=27.72, wps=1528.7, ups=0.36, wpb=4196.5, bsz=272, num_updates=146, lr=1.752e-06, gnorm=2.704, train_wall=5, gb_free=12.7, wall=474
2025-04-03 05:11:56 | INFO | train_inner | epoch 002:     22 / 126 loss=8.022, nll_loss=5.056, ppl=33.26, wps=1468.6, ups=0.36, wpb=4110.5, bsz=252, num_updates=148, lr=1.776e-06, gnorm=2.676, train_wall=6, gb_free=10.6, wall=480
2025-04-03 05:12:02 | INFO | train_inner | epoch 002:     24 / 126 loss=7.76, nll_loss=4.725, ppl=26.45, wps=1773.9, ups=0.32, wpb=5475, bsz=388, num_updates=150, lr=1.8e-06, gnorm=2.269, train_wall=6, gb_free=9, wall=486
2025-04-03 05:12:07 | INFO | train_inner | epoch 002:     26 / 126 loss=7.855, nll_loss=4.856, ppl=28.96, wps=1830.5, ups=0.37, wpb=4899, bsz=380, num_updates=152, lr=1.824e-06, gnorm=2.009, train_wall=5, gb_free=12.7, wall=492
2025-04-03 05:12:13 | INFO | train_inner | epoch 002:     28 / 126 loss=8.193, nll_loss=5.288, ppl=39.06, wps=1585.7, ups=0.37, wpb=4290.5, bsz=240, num_updates=154, lr=1.848e-06, gnorm=2.204, train_wall=5, gb_free=10.2, wall=497
2025-04-03 05:12:18 | INFO | train_inner | epoch 002:     30 / 126 loss=8.127, nll_loss=5.203, ppl=36.83, wps=1548.8, ups=0.36, wpb=4297.5, bsz=192, num_updates=156, lr=1.872e-06, gnorm=2.434, train_wall=6, gb_free=11, wall=503
2025-04-03 05:12:24 | INFO | train_inner | epoch 002:     32 / 126 loss=7.902, nll_loss=4.917, ppl=30.2, wps=1687.4, ups=0.35, wpb=4770.5, bsz=268, num_updates=158, lr=1.896e-06, gnorm=2.313, train_wall=6, gb_free=13.6, wall=508
2025-04-03 05:12:29 | INFO | train_inner | epoch 002:     34 / 126 loss=8.033, nll_loss=5.083, ppl=33.89, wps=1649.7, ups=0.38, wpb=4398.5, bsz=212, num_updates=160, lr=1.92e-06, gnorm=2.268, train_wall=5, gb_free=14.3, wall=514
2025-04-03 05:12:35 | INFO | train_inner | epoch 002:     36 / 126 loss=7.794, nll_loss=4.776, ppl=27.4, wps=1709.4, ups=0.35, wpb=4852, bsz=284, num_updates=162, lr=1.944e-06, gnorm=2.095, train_wall=6, gb_free=10.3, wall=519
2025-04-03 05:12:41 | INFO | train_inner | epoch 002:     38 / 126 loss=8.008, nll_loss=5.04, ppl=32.91, wps=1736.4, ups=0.37, wpb=4707, bsz=228, num_updates=164, lr=1.968e-06, gnorm=2.261, train_wall=5, gb_free=14.7, wall=525
2025-04-03 05:12:46 | INFO | train_inner | epoch 002:     40 / 126 loss=8.08, nll_loss=5.133, ppl=35.09, wps=1423.1, ups=0.36, wpb=3965.5, bsz=204, num_updates=166, lr=1.992e-06, gnorm=2.407, train_wall=6, gb_free=8.8, wall=530
2025-04-03 05:12:52 | INFO | train_inner | epoch 002:     42 / 126 loss=7.968, nll_loss=5.005, ppl=32.1, wps=1599.6, ups=0.36, wpb=4423, bsz=268, num_updates=168, lr=2.016e-06, gnorm=2.019, train_wall=6, gb_free=10.6, wall=536
2025-04-03 05:12:57 | INFO | train_inner | epoch 002:     44 / 126 loss=7.72, nll_loss=4.675, ppl=25.54, wps=1800.4, ups=0.34, wpb=5296.5, bsz=328, num_updates=170, lr=2.04e-06, gnorm=2.027, train_wall=6, gb_free=9.5, wall=542
2025-04-03 05:13:03 | INFO | train_inner | epoch 002:     46 / 126 loss=8.119, nll_loss=5.197, ppl=36.69, wps=1406.6, ups=0.36, wpb=3918, bsz=236, num_updates=172, lr=2.064e-06, gnorm=2.429, train_wall=6, gb_free=9.2, wall=547
2025-04-03 05:13:08 | INFO | train_inner | epoch 002:     48 / 126 loss=8.145, nll_loss=5.218, ppl=37.21, wps=1602.5, ups=0.37, wpb=4290, bsz=180, num_updates=174, lr=2.088e-06, gnorm=2.524, train_wall=5, gb_free=10.7, wall=553
2025-04-03 05:13:14 | INFO | train_inner | epoch 002:     50 / 126 loss=7.786, nll_loss=4.763, ppl=27.15, wps=1674, ups=0.36, wpb=4639, bsz=300, num_updates=176, lr=2.112e-06, gnorm=2.418, train_wall=6, gb_free=9.3, wall=558
2025-04-03 05:13:19 | INFO | train_inner | epoch 002:     52 / 126 loss=7.897, nll_loss=4.919, ppl=30.25, wps=1643.7, ups=0.37, wpb=4440, bsz=280, num_updates=178, lr=2.136e-06, gnorm=2.229, train_wall=5, gb_free=11.2, wall=563
2025-04-03 05:13:25 | INFO | train_inner | epoch 002:     54 / 126 loss=7.909, nll_loss=4.919, ppl=30.24, wps=1659.3, ups=0.35, wpb=4713, bsz=240, num_updates=180, lr=2.16e-06, gnorm=2.125, train_wall=6, gb_free=13.3, wall=569
2025-04-03 05:13:30 | INFO | train_inner | epoch 002:     56 / 126 loss=8.022, nll_loss=5.07, ppl=33.6, wps=1362.4, ups=0.38, wpb=3581, bsz=224, num_updates=182, lr=2.184e-06, gnorm=2.488, train_wall=5, gb_free=9.2, wall=574
2025-04-03 05:13:36 | INFO | train_inner | epoch 002:     58 / 126 loss=7.83, nll_loss=4.812, ppl=28.09, wps=1488.7, ups=0.35, wpb=4260, bsz=244, num_updates=184, lr=2.208e-06, gnorm=2.097, train_wall=6, gb_free=10.8, wall=580
2025-04-03 05:13:47 | INFO | train_inner | epoch 002:     60 / 126 loss=7.73, nll_loss=4.682, ppl=25.67, wps=913, ups=0.19, wpb=4915.5, bsz=232, num_updates=186, lr=2.232e-06, gnorm=2.36, train_wall=11, gb_free=12.2, wall=591
2025-04-03 05:13:52 | INFO | train_inner | epoch 002:     62 / 126 loss=7.827, nll_loss=4.834, ppl=28.52, wps=1545.7, ups=0.38, wpb=4041.5, bsz=324, num_updates=188, lr=2.256e-06, gnorm=2.273, train_wall=5, gb_free=11.9, wall=596
2025-04-03 05:13:57 | INFO | train_inner | epoch 002:     64 / 126 loss=7.942, nll_loss=4.967, ppl=31.28, wps=1632.5, ups=0.37, wpb=4418, bsz=224, num_updates=190, lr=2.28e-06, gnorm=2.466, train_wall=5, gb_free=13.6, wall=602
2025-04-03 05:14:03 | INFO | train_inner | epoch 002:     66 / 126 loss=7.908, nll_loss=4.923, ppl=30.34, wps=1699.4, ups=0.38, wpb=4512, bsz=228, num_updates=192, lr=2.304e-06, gnorm=2.071, train_wall=5, gb_free=13.5, wall=607
2025-04-03 05:14:08 | INFO | train_inner | epoch 002:     68 / 126 loss=7.818, nll_loss=4.806, ppl=27.98, wps=1883, ups=0.36, wpb=5216.5, bsz=260, num_updates=194, lr=2.328e-06, gnorm=2.533, train_wall=6, gb_free=11.7, wall=612
2025-04-03 05:14:14 | INFO | train_inner | epoch 002:     70 / 126 loss=7.812, nll_loss=4.795, ppl=27.77, wps=1628.8, ups=0.36, wpb=4573.5, bsz=244, num_updates=196, lr=2.352e-06, gnorm=2.021, train_wall=6, gb_free=10.2, wall=618
2025-04-03 05:14:19 | INFO | train_inner | epoch 002:     72 / 126 loss=7.809, nll_loss=4.796, ppl=27.79, wps=1718.8, ups=0.37, wpb=4704, bsz=300, num_updates=198, lr=2.376e-06, gnorm=1.99, train_wall=5, gb_free=13, wall=623
2025-04-03 05:14:25 | INFO | train_inner | epoch 002:     74 / 126 loss=7.736, nll_loss=4.689, ppl=25.79, wps=1756.8, ups=0.36, wpb=4906.5, bsz=284, num_updates=200, lr=2.4e-06, gnorm=2.091, train_wall=6, gb_free=9.9, wall=629
2025-04-03 05:14:31 | INFO | train_inner | epoch 002:     76 / 126 loss=7.822, nll_loss=4.802, ppl=27.89, wps=1701.7, ups=0.34, wpb=5069.5, bsz=252, num_updates=202, lr=2.424e-06, gnorm=2.148, train_wall=6, gb_free=10.5, wall=635
2025-04-03 05:14:36 | INFO | train_inner | epoch 002:     78 / 126 loss=7.984, nll_loss=5.007, ppl=32.16, wps=1725, ups=0.37, wpb=4638, bsz=224, num_updates=204, lr=2.448e-06, gnorm=2.106, train_wall=5, gb_free=12.6, wall=640
2025-04-03 05:14:42 | INFO | train_inner | epoch 002:     80 / 126 loss=7.783, nll_loss=4.757, ppl=27.04, wps=1589.8, ups=0.36, wpb=4362, bsz=304, num_updates=206, lr=2.472e-06, gnorm=2.441, train_wall=5, gb_free=10.1, wall=646
2025-04-03 05:14:47 | INFO | train_inner | epoch 002:     82 / 126 loss=7.742, nll_loss=4.689, ppl=25.79, wps=1692.9, ups=0.36, wpb=4674, bsz=192, num_updates=208, lr=2.496e-06, gnorm=2.375, train_wall=6, gb_free=8.9, wall=651
2025-04-03 05:14:53 | INFO | train_inner | epoch 002:     84 / 126 loss=7.861, nll_loss=4.857, ppl=28.98, wps=1667.4, ups=0.37, wpb=4457.5, bsz=252, num_updates=210, lr=2.52e-06, gnorm=2.092, train_wall=5, gb_free=14.3, wall=657
2025-04-03 05:14:58 | INFO | train_inner | epoch 002:     86 / 126 loss=7.864, nll_loss=4.865, ppl=29.14, wps=1593.6, ups=0.36, wpb=4459, bsz=292, num_updates=212, lr=2.544e-06, gnorm=2.404, train_wall=6, gb_free=12.7, wall=662
2025-04-03 05:15:04 | INFO | train_inner | epoch 002:     88 / 126 loss=7.767, nll_loss=4.752, ppl=26.94, wps=1802.6, ups=0.37, wpb=4843, bsz=312, num_updates=214, lr=2.568e-06, gnorm=2.059, train_wall=5, gb_free=13, wall=668
2025-04-03 05:15:09 | INFO | train_inner | epoch 002:     90 / 126 loss=7.966, nll_loss=5.006, ppl=32.14, wps=1573, ups=0.36, wpb=4354, bsz=284, num_updates=216, lr=2.592e-06, gnorm=2.025, train_wall=6, gb_free=13.2, wall=673
2025-04-03 05:15:15 | INFO | train_inner | epoch 002:     92 / 126 loss=7.805, nll_loss=4.793, ppl=27.72, wps=1667.2, ups=0.36, wpb=4604, bsz=248, num_updates=218, lr=2.616e-06, gnorm=2.205, train_wall=6, gb_free=13.5, wall=679
2025-04-03 05:15:20 | INFO | train_inner | epoch 002:     94 / 126 loss=7.96, nll_loss=4.993, ppl=31.84, wps=1617.3, ups=0.37, wpb=4368.5, bsz=208, num_updates=220, lr=2.64e-06, gnorm=2.323, train_wall=5, gb_free=10.2, wall=684
2025-04-03 05:15:26 | INFO | train_inner | epoch 002:     96 / 126 loss=8.017, nll_loss=5.067, ppl=33.52, wps=1576, ups=0.36, wpb=4420, bsz=156, num_updates=222, lr=2.664e-06, gnorm=2.169, train_wall=6, gb_free=11.6, wall=690
2025-04-03 05:15:31 | INFO | train_inner | epoch 002:     98 / 126 loss=7.894, nll_loss=4.899, ppl=29.83, wps=1655, ups=0.38, wpb=4355, bsz=200, num_updates=224, lr=2.688e-06, gnorm=2.212, train_wall=5, gb_free=15.6, wall=695
2025-04-03 05:15:37 | INFO | train_inner | epoch 002:    100 / 126 loss=7.73, nll_loss=4.7, ppl=26, wps=1757.8, ups=0.35, wpb=4985.5, bsz=304, num_updates=226, lr=2.712e-06, gnorm=2.029, train_wall=6, gb_free=10.5, wall=701
2025-04-03 05:15:42 | INFO | train_inner | epoch 002:    102 / 126 loss=7.873, nll_loss=4.881, ppl=29.47, wps=1681.7, ups=0.37, wpb=4585.5, bsz=284, num_updates=228, lr=2.736e-06, gnorm=2.299, train_wall=5, gb_free=12.7, wall=706
2025-04-03 05:15:47 | INFO | train_inner | epoch 002:    104 / 126 loss=7.969, nll_loss=5, ppl=32.01, wps=1657.4, ups=0.38, wpb=4321.5, bsz=264, num_updates=230, lr=2.76e-06, gnorm=2.063, train_wall=5, gb_free=13.1, wall=711
2025-04-03 05:15:53 | INFO | train_inner | epoch 002:    106 / 126 loss=7.912, nll_loss=4.924, ppl=30.36, wps=1408.1, ups=0.35, wpb=3999.5, bsz=168, num_updates=232, lr=2.784e-06, gnorm=2.434, train_wall=6, gb_free=14.5, wall=717
2025-04-03 05:15:59 | INFO | train_inner | epoch 002:    108 / 126 loss=7.697, nll_loss=4.659, ppl=25.27, wps=1584.8, ups=0.35, wpb=4466, bsz=324, num_updates=234, lr=2.808e-06, gnorm=2.104, train_wall=6, gb_free=10.1, wall=723
2025-04-03 05:16:04 | INFO | train_inner | epoch 002:    110 / 126 loss=7.634, nll_loss=4.567, ppl=23.7, wps=1868.1, ups=0.34, wpb=5415, bsz=276, num_updates=236, lr=2.832e-06, gnorm=2.387, train_wall=6, gb_free=12.3, wall=729
2025-04-03 05:16:10 | INFO | train_inner | epoch 002:    112 / 126 loss=7.699, nll_loss=4.658, ppl=25.25, wps=1622.9, ups=0.37, wpb=4409, bsz=256, num_updates=238, lr=2.856e-06, gnorm=2.218, train_wall=5, gb_free=11.6, wall=734
2025-04-03 05:16:16 | INFO | train_inner | epoch 002:    114 / 126 loss=7.598, nll_loss=4.509, ppl=22.77, wps=1854.2, ups=0.34, wpb=5534, bsz=272, num_updates=240, lr=2.88e-06, gnorm=2.305, train_wall=6, gb_free=10.3, wall=740
2025-04-03 05:16:22 | INFO | train_inner | epoch 002:    116 / 126 loss=7.917, nll_loss=4.934, ppl=30.58, wps=1568.3, ups=0.34, wpb=4578.5, bsz=220, num_updates=242, lr=2.904e-06, gnorm=2.124, train_wall=6, gb_free=8.7, wall=746
2025-04-03 05:16:26 | INFO | train_inner | epoch 002:    118 / 126 loss=7.868, nll_loss=4.872, ppl=29.28, wps=1541.9, ups=0.42, wpb=3678, bsz=220, num_updates=244, lr=2.928e-06, gnorm=2.726, train_wall=5, gb_free=11.9, wall=751
2025-04-03 05:16:32 | INFO | train_inner | epoch 002:    120 / 126 loss=7.575, nll_loss=4.491, ppl=22.49, wps=1736.2, ups=0.35, wpb=5014.5, bsz=276, num_updates=246, lr=2.952e-06, gnorm=2.026, train_wall=6, gb_free=10.3, wall=756
2025-04-03 05:16:38 | INFO | train_inner | epoch 002:    122 / 126 loss=7.992, nll_loss=5.031, ppl=32.69, wps=1513.2, ups=0.35, wpb=4295, bsz=216, num_updates=248, lr=2.976e-06, gnorm=2.121, train_wall=6, gb_free=9.8, wall=762
2025-04-03 05:16:44 | INFO | train_inner | epoch 002:    124 / 126 loss=7.641, nll_loss=4.55, ppl=23.43, wps=1615.5, ups=0.33, wpb=4908.5, bsz=188, num_updates=250, lr=3e-06, gnorm=2.049, train_wall=6, gb_free=9.8, wall=768
2025-04-03 05:16:48 | INFO | train_inner | epoch 002:    126 / 126 loss=7.971, nll_loss=5.001, ppl=32.02, wps=1435.3, ups=0.46, wpb=3107.5, bsz=136, num_updates=252, lr=3.024e-06, gnorm=2.642, train_wall=4, gb_free=18.3, wall=772
2025-04-03 05:16:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-03 05:16:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=10417.41015625Mb; avail=244667.63671875Mb
2025-04-03 05:16:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000679
2025-04-03 05:16:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=10417.41015625Mb; avail=244667.63671875Mb
2025-04-03 05:16:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012816
2025-04-03 05:16:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=10417.41015625Mb; avail=244667.63671875Mb
2025-04-03 05:16:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.010944
2025-04-03 05:16:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024788
2025-04-03 05:16:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=10417.41015625Mb; avail=244667.63671875Mb
2025-04-03 05:17:03 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.47 | nll_loss 4.19 | ppl 18.25 | wps 3875.8 | wpb 2070.5 | bsz 122.7 | num_updates 252 | best_loss 7.47
2025-04-03 05:17:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 252 updates
2025-04-03 05:17:03 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 05:17:41 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 05:18:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt (epoch 2 @ 252 updates, score 7.47) (writing took 63.65496172802523 seconds)
2025-04-03 05:18:06 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2025-04-03 05:18:06 | INFO | train | epoch 002 | loss 7.881 | nll_loss 4.884 | ppl 29.52 | wps 1330.9 | ups 0.29 | wpb 4549.7 | bsz 252.8 | num_updates 252 | lr 3.024e-06 | gnorm 2.281 | train_wall 352 | gb_free 18.3 | wall 850
2025-04-03 05:18:06 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:mr-hi': 31849}; raw total size: 31849
2025-04-03 05:18:06 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:mr-hi': 31849}; resampled total size: 31849
2025-04-03 05:18:06 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:mr-hi': 1.0}
2025-04-03 05:18:06 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001118
2025-04-03 05:18:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=16256.046875Mb; avail=238828.86328125Mb
2025-04-03 05:18:06 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000411
2025-04-03 05:18:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003101
2025-04-03 05:18:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=16256.046875Mb; avail=238828.86328125Mb
2025-04-03 05:18:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000090
2025-04-03 05:18:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=16256.046875Mb; avail=238828.86328125Mb
2025-04-03 05:18:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001179
2025-04-03 05:18:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.004691
2025-04-03 05:18:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=16256.046875Mb; avail=238828.86328125Mb
2025-04-03 05:18:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 126
2025-04-03 05:18:06 | INFO | fairseq.trainer | begin training epoch 3
2025-04-03 05:18:06 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-03 05:18:17 | INFO | train_inner | epoch 003:      2 / 126 loss=7.674, nll_loss=4.619, ppl=24.57, wps=110, ups=0.02, wpb=4883.5, bsz=256, num_updates=254, lr=3.048e-06, gnorm=2.162, train_wall=11, gb_free=14.9, wall=861
2025-04-03 05:18:22 | INFO | train_inner | epoch 003:      4 / 126 loss=7.718, nll_loss=4.658, ppl=25.24, wps=1676.6, ups=0.37, wpb=4508, bsz=172, num_updates=256, lr=3.072e-06, gnorm=2.282, train_wall=5, gb_free=13.9, wall=867
2025-04-03 05:18:28 | INFO | train_inner | epoch 003:      6 / 126 loss=7.824, nll_loss=4.813, ppl=28.11, wps=1397.9, ups=0.37, wpb=3819.5, bsz=184, num_updates=258, lr=3.096e-06, gnorm=2.364, train_wall=5, gb_free=12.8, wall=872
2025-04-03 05:18:33 | INFO | train_inner | epoch 003:      8 / 126 loss=7.65, nll_loss=4.594, ppl=24.15, wps=1852.2, ups=0.37, wpb=5009.5, bsz=268, num_updates=260, lr=3.12e-06, gnorm=1.922, train_wall=5, gb_free=11.9, wall=877
2025-04-03 05:18:39 | INFO | train_inner | epoch 003:     10 / 126 loss=7.832, nll_loss=4.828, ppl=28.4, wps=1630.4, ups=0.37, wpb=4427.5, bsz=216, num_updates=262, lr=3.144e-06, gnorm=2.082, train_wall=5, gb_free=10, wall=883
2025-04-03 05:18:44 | INFO | train_inner | epoch 003:     12 / 126 loss=7.9, nll_loss=4.919, ppl=30.25, wps=1596.2, ups=0.38, wpb=4224, bsz=208, num_updates=264, lr=3.168e-06, gnorm=2.159, train_wall=5, gb_free=10, wall=888
2025-04-03 05:18:50 | INFO | train_inner | epoch 003:     14 / 126 loss=8.011, nll_loss=5.065, ppl=33.48, wps=1534.6, ups=0.36, wpb=4240.5, bsz=156, num_updates=266, lr=3.192e-06, gnorm=2.374, train_wall=6, gb_free=12, wall=894
2025-04-03 05:18:55 | INFO | train_inner | epoch 003:     16 / 126 loss=7.56, nll_loss=4.485, ppl=22.39, wps=1778, ups=0.35, wpb=5029.5, bsz=312, num_updates=268, lr=3.216e-06, gnorm=1.947, train_wall=6, gb_free=11.4, wall=899
2025-04-03 05:19:01 | INFO | train_inner | epoch 003:     18 / 126 loss=7.571, nll_loss=4.501, ppl=22.64, wps=1830.6, ups=0.37, wpb=5009.5, bsz=276, num_updates=270, lr=3.24e-06, gnorm=2.291, train_wall=5, gb_free=11.8, wall=905
2025-04-03 05:19:05 | INFO | train_inner | epoch 003:     20 / 126 loss=7.899, nll_loss=4.917, ppl=30.22, wps=1418.4, ups=0.46, wpb=3106, bsz=160.5, num_updates=272, lr=3.264e-06, gnorm=2.657, train_wall=4, gb_free=10.2, wall=909
2025-04-03 05:19:11 | INFO | train_inner | epoch 003:     22 / 126 loss=7.787, nll_loss=4.773, ppl=27.35, wps=1574.9, ups=0.37, wpb=4285.5, bsz=248, num_updates=274, lr=3.288e-06, gnorm=2.104, train_wall=5, gb_free=14.3, wall=915
2025-04-03 05:19:16 | INFO | train_inner | epoch 003:     24 / 126 loss=7.619, nll_loss=4.548, ppl=23.4, wps=1664.8, ups=0.36, wpb=4666.5, bsz=264, num_updates=276, lr=3.312e-06, gnorm=2.188, train_wall=6, gb_free=13.4, wall=920
2025-04-03 05:19:21 | INFO | train_inner | epoch 003:     26 / 126 loss=7.609, nll_loss=4.547, ppl=23.38, wps=1758.8, ups=0.38, wpb=4617.5, bsz=324, num_updates=278, lr=3.336e-06, gnorm=1.922, train_wall=5, gb_free=12.9, wall=926
2025-04-03 05:19:27 | INFO | train_inner | epoch 003:     28 / 126 loss=7.641, nll_loss=4.581, ppl=23.94, wps=1588.2, ups=0.36, wpb=4417.5, bsz=256, num_updates=280, lr=3.36e-06, gnorm=2.204, train_wall=6, gb_free=11, wall=931
2025-04-03 05:19:33 | INFO | train_inner | epoch 003:     30 / 126 loss=7.728, nll_loss=4.686, ppl=25.74, wps=1793.6, ups=0.36, wpb=4992, bsz=296, num_updates=282, lr=3.384e-06, gnorm=2.179, train_wall=6, gb_free=11, wall=937
2025-04-03 05:19:38 | INFO | train_inner | epoch 003:     32 / 126 loss=7.497, nll_loss=4.389, ppl=20.94, wps=1811.2, ups=0.36, wpb=5052.5, bsz=296, num_updates=284, lr=3.408e-06, gnorm=1.883, train_wall=6, gb_free=10.2, wall=942
2025-04-03 05:19:44 | INFO | train_inner | epoch 003:     34 / 126 loss=7.775, nll_loss=4.745, ppl=26.82, wps=1569.2, ups=0.37, wpb=4217.5, bsz=220, num_updates=286, lr=3.432e-06, gnorm=2.1, train_wall=5, gb_free=13.7, wall=948
2025-04-03 05:19:49 | INFO | train_inner | epoch 003:     36 / 126 loss=7.529, nll_loss=4.438, ppl=21.68, wps=1627.3, ups=0.36, wpb=4580, bsz=328, num_updates=288, lr=3.456e-06, gnorm=2.154, train_wall=6, gb_free=13.2, wall=953
2025-04-03 05:19:55 | INFO | train_inner | epoch 003:     38 / 126 loss=7.474, nll_loss=4.358, ppl=20.51, wps=1776.3, ups=0.34, wpb=5265.5, bsz=284, num_updates=290, lr=3.48e-06, gnorm=2.111, train_wall=6, gb_free=10.1, wall=959
2025-04-03 05:20:00 | INFO | train_inner | epoch 003:     40 / 126 loss=7.647, nll_loss=4.597, ppl=24.19, wps=1730.7, ups=0.37, wpb=4670.5, bsz=256, num_updates=292, lr=3.504e-06, gnorm=2.112, train_wall=5, gb_free=13.3, wall=965
2025-04-03 05:20:06 | INFO | train_inner | epoch 003:     42 / 126 loss=7.789, nll_loss=4.781, ppl=27.5, wps=1683.9, ups=0.37, wpb=4611.5, bsz=228, num_updates=294, lr=3.528e-06, gnorm=2.293, train_wall=5, gb_free=13.9, wall=970
2025-04-03 05:20:12 | INFO | train_inner | epoch 003:     44 / 126 loss=7.563, nll_loss=4.491, ppl=22.49, wps=1652.7, ups=0.35, wpb=4680.5, bsz=288, num_updates=296, lr=3.552e-06, gnorm=2.519, train_wall=6, gb_free=13.1, wall=976
2025-04-03 05:20:17 | INFO | train_inner | epoch 003:     46 / 126 loss=7.599, nll_loss=4.543, ppl=23.31, wps=1666.9, ups=0.35, wpb=4779.5, bsz=308, num_updates=298, lr=3.576e-06, gnorm=2.043, train_wall=6, gb_free=9, wall=981
2025-04-03 05:20:23 | INFO | train_inner | epoch 003:     48 / 126 loss=7.609, nll_loss=4.55, ppl=23.43, wps=1640.4, ups=0.36, wpb=4600, bsz=248, num_updates=300, lr=3.6e-06, gnorm=2.103, train_wall=6, gb_free=8.3, wall=987
2025-04-03 05:20:28 | INFO | train_inner | epoch 003:     50 / 126 loss=7.691, nll_loss=4.655, ppl=25.2, wps=1581.1, ups=0.41, wpb=3883, bsz=260, num_updates=302, lr=3.624e-06, gnorm=2.432, train_wall=5, gb_free=14.2, wall=992
2025-04-03 05:20:33 | INFO | train_inner | epoch 003:     52 / 126 loss=7.686, nll_loss=4.641, ppl=24.94, wps=1544.9, ups=0.36, wpb=4276, bsz=188, num_updates=304, lr=3.648e-06, gnorm=2.284, train_wall=6, gb_free=8.9, wall=997
2025-04-03 05:20:39 | INFO | train_inner | epoch 003:     54 / 126 loss=7.646, nll_loss=4.591, ppl=24.1, wps=1505.3, ups=0.35, wpb=4318.5, bsz=212, num_updates=306, lr=3.672e-06, gnorm=2.16, train_wall=6, gb_free=9.8, wall=1003
2025-04-03 05:20:45 | INFO | train_inner | epoch 003:     56 / 126 loss=7.473, nll_loss=4.379, ppl=20.8, wps=1773.4, ups=0.36, wpb=4960, bsz=348, num_updates=308, lr=3.696e-06, gnorm=2.085, train_wall=6, gb_free=12.7, wall=1009
2025-04-03 05:20:51 | INFO | train_inner | epoch 003:     58 / 126 loss=7.501, nll_loss=4.395, ppl=21.04, wps=1596.3, ups=0.34, wpb=4718, bsz=284, num_updates=310, lr=3.72e-06, gnorm=1.973, train_wall=6, gb_free=10.3, wall=1015
2025-04-03 05:20:56 | INFO | train_inner | epoch 003:     60 / 126 loss=7.451, nll_loss=4.344, ppl=20.31, wps=1735.1, ups=0.35, wpb=4999, bsz=308, num_updates=312, lr=3.744e-06, gnorm=2.272, train_wall=6, gb_free=12.8, wall=1020
2025-04-03 05:21:02 | INFO | train_inner | epoch 003:     62 / 126 loss=7.733, nll_loss=4.707, ppl=26.12, wps=1639.3, ups=0.37, wpb=4413, bsz=228, num_updates=314, lr=3.768e-06, gnorm=2.174, train_wall=5, gb_free=14, wall=1026
2025-04-03 05:21:07 | INFO | train_inner | epoch 003:     64 / 126 loss=7.452, nll_loss=4.34, ppl=20.25, wps=1511, ups=0.38, wpb=3991.5, bsz=244, num_updates=316, lr=3.792e-06, gnorm=2.254, train_wall=5, gb_free=12.4, wall=1031
2025-04-03 05:21:13 | INFO | train_inner | epoch 003:     66 / 126 loss=7.388, nll_loss=4.248, ppl=19, wps=1924, ups=0.34, wpb=5725, bsz=308, num_updates=318, lr=3.816e-06, gnorm=2.178, train_wall=6, gb_free=10.5, wall=1037
2025-04-03 05:21:18 | INFO | train_inner | epoch 003:     68 / 126 loss=7.601, nll_loss=4.545, ppl=23.35, wps=1634.2, ups=0.38, wpb=4296.5, bsz=280, num_updates=320, lr=3.84e-06, gnorm=2.538, train_wall=5, gb_free=12.7, wall=1042
2025-04-03 05:21:24 | INFO | train_inner | epoch 003:     70 / 126 loss=7.709, nll_loss=4.65, ppl=25.11, wps=1346.7, ups=0.35, wpb=3824, bsz=196, num_updates=322, lr=3.864e-06, gnorm=2.393, train_wall=6, gb_free=9.1, wall=1048
2025-04-03 05:21:30 | INFO | train_inner | epoch 003:     72 / 126 loss=7.549, nll_loss=4.465, ppl=22.09, wps=1732.1, ups=0.36, wpb=4836.5, bsz=284, num_updates=324, lr=3.888e-06, gnorm=1.946, train_wall=6, gb_free=14.7, wall=1054
2025-04-03 05:21:35 | INFO | train_inner | epoch 003:     74 / 126 loss=7.578, nll_loss=4.5, ppl=22.62, wps=1520.8, ups=0.36, wpb=4243.5, bsz=152, num_updates=326, lr=3.912e-06, gnorm=2.23, train_wall=6, gb_free=12.9, wall=1059
2025-04-03 05:21:41 | INFO | train_inner | epoch 003:     76 / 126 loss=7.547, nll_loss=4.466, ppl=22.1, wps=1678.1, ups=0.36, wpb=4702, bsz=232, num_updates=328, lr=3.936e-06, gnorm=1.954, train_wall=6, gb_free=12.4, wall=1065
2025-04-03 05:21:46 | INFO | train_inner | epoch 003:     78 / 126 loss=7.566, nll_loss=4.484, ppl=22.38, wps=1505.2, ups=0.36, wpb=4139, bsz=212, num_updates=330, lr=3.96e-06, gnorm=2.271, train_wall=5, gb_free=9.9, wall=1070
2025-04-03 05:21:52 | INFO | train_inner | epoch 003:     80 / 126 loss=7.619, nll_loss=4.552, ppl=23.46, wps=1454.3, ups=0.33, wpb=4364, bsz=188, num_updates=332, lr=3.984e-06, gnorm=2.338, train_wall=6, gb_free=8.9, wall=1076
2025-04-03 05:21:58 | INFO | train_inner | epoch 003:     82 / 126 loss=7.355, nll_loss=4.219, ppl=18.63, wps=1890.8, ups=0.36, wpb=5288, bsz=320, num_updates=334, lr=4.008e-06, gnorm=1.948, train_wall=6, gb_free=9.5, wall=1082
2025-04-03 05:22:03 | INFO | train_inner | epoch 003:     84 / 126 loss=7.415, nll_loss=4.29, ppl=19.56, wps=1718.3, ups=0.37, wpb=4648.5, bsz=248, num_updates=336, lr=4.032e-06, gnorm=2.003, train_wall=5, gb_free=14.3, wall=1087
2025-04-03 05:22:09 | INFO | train_inner | epoch 003:     86 / 126 loss=7.565, nll_loss=4.476, ppl=22.25, wps=1787.8, ups=0.38, wpb=4738.5, bsz=288, num_updates=338, lr=4.056e-06, gnorm=2.511, train_wall=5, gb_free=15.6, wall=1093
2025-04-03 05:22:14 | INFO | train_inner | epoch 003:     88 / 126 loss=7.612, nll_loss=4.545, ppl=23.35, wps=1635.3, ups=0.34, wpb=4798, bsz=236, num_updates=340, lr=4.08e-06, gnorm=2.022, train_wall=6, gb_free=9.6, wall=1098
2025-04-03 05:22:20 | INFO | train_inner | epoch 003:     90 / 126 loss=7.578, nll_loss=4.516, ppl=22.87, wps=1471.6, ups=0.37, wpb=3959, bsz=236, num_updates=342, lr=4.104e-06, gnorm=2.15, train_wall=5, gb_free=14.7, wall=1104
2025-04-03 05:22:26 | INFO | train_inner | epoch 003:     92 / 126 loss=7.503, nll_loss=4.408, ppl=21.23, wps=1540.1, ups=0.35, wpb=4460.5, bsz=248, num_updates=344, lr=4.128e-06, gnorm=2.076, train_wall=6, gb_free=9.6, wall=1110
2025-04-03 05:22:31 | INFO | train_inner | epoch 003:     94 / 126 loss=7.545, nll_loss=4.448, ppl=21.82, wps=1745.1, ups=0.36, wpb=4810, bsz=264, num_updates=346, lr=4.152e-06, gnorm=2.55, train_wall=6, gb_free=9.4, wall=1115
2025-04-03 05:22:37 | INFO | train_inner | epoch 003:     96 / 126 loss=7.532, nll_loss=4.444, ppl=21.76, wps=1613.5, ups=0.34, wpb=4759.5, bsz=196, num_updates=348, lr=4.176e-06, gnorm=1.995, train_wall=6, gb_free=8.7, wall=1121
2025-04-03 05:22:42 | INFO | train_inner | epoch 003:     98 / 126 loss=7.558, nll_loss=4.494, ppl=22.53, wps=1609.1, ups=0.43, wpb=3753, bsz=232, num_updates=350, lr=4.2e-06, gnorm=2.399, train_wall=5, gb_free=13.2, wall=1126
2025-04-03 05:22:47 | INFO | train_inner | epoch 003:    100 / 126 loss=7.636, nll_loss=4.59, ppl=24.08, wps=1411.3, ups=0.38, wpb=3713.5, bsz=188, num_updates=352, lr=4.224e-06, gnorm=2.301, train_wall=5, gb_free=10.3, wall=1131
2025-04-03 05:22:53 | INFO | train_inner | epoch 003:    102 / 126 loss=7.474, nll_loss=4.363, ppl=20.58, wps=1775.5, ups=0.35, wpb=5105.5, bsz=260, num_updates=354, lr=4.248e-06, gnorm=1.886, train_wall=6, gb_free=11.1, wall=1137
2025-04-03 05:22:59 | INFO | train_inner | epoch 003:    104 / 126 loss=7.442, nll_loss=4.332, ppl=20.14, wps=1543.6, ups=0.33, wpb=4624, bsz=264, num_updates=356, lr=4.272e-06, gnorm=1.908, train_wall=6, gb_free=10.3, wall=1143
2025-04-03 05:23:04 | INFO | train_inner | epoch 003:    106 / 126 loss=7.411, nll_loss=4.291, ppl=19.58, wps=1766, ups=0.34, wpb=5142.5, bsz=264, num_updates=358, lr=4.296e-06, gnorm=2.047, train_wall=6, gb_free=11.3, wall=1149
2025-04-03 05:23:10 | INFO | train_inner | epoch 003:    108 / 126 loss=7.431, nll_loss=4.327, ppl=20.06, wps=1555.7, ups=0.36, wpb=4275, bsz=308, num_updates=360, lr=4.32e-06, gnorm=2.117, train_wall=5, gb_free=14, wall=1154
2025-04-03 05:23:15 | INFO | train_inner | epoch 003:    110 / 126 loss=7.539, nll_loss=4.46, ppl=22.02, wps=1612.8, ups=0.38, wpb=4294.5, bsz=244, num_updates=362, lr=4.344e-06, gnorm=2.068, train_wall=5, gb_free=13.3, wall=1159
2025-04-03 05:23:21 | INFO | train_inner | epoch 003:    112 / 126 loss=7.256, nll_loss=4.084, ppl=16.96, wps=1854.7, ups=0.33, wpb=5602, bsz=328, num_updates=364, lr=4.368e-06, gnorm=1.891, train_wall=6, gb_free=9.7, wall=1165
2025-04-03 05:23:27 | INFO | train_inner | epoch 003:    114 / 126 loss=7.529, nll_loss=4.445, ppl=21.78, wps=1444.9, ups=0.37, wpb=3873.5, bsz=240, num_updates=366, lr=4.392e-06, gnorm=2.321, train_wall=5, gb_free=14.4, wall=1171
2025-04-03 05:23:33 | INFO | train_inner | epoch 003:    116 / 126 loss=7.264, nll_loss=4.095, ppl=17.09, wps=1775.8, ups=0.33, wpb=5327, bsz=324, num_updates=368, lr=4.416e-06, gnorm=1.98, train_wall=6, gb_free=10.5, wall=1177
2025-04-03 05:23:38 | INFO | train_inner | epoch 003:    118 / 126 loss=7.371, nll_loss=4.241, ppl=18.91, wps=1635.9, ups=0.35, wpb=4652.5, bsz=332, num_updates=370, lr=4.44e-06, gnorm=2.02, train_wall=6, gb_free=9.2, wall=1182
2025-04-03 05:23:44 | INFO | train_inner | epoch 003:    120 / 126 loss=7.379, nll_loss=4.257, ppl=19.12, wps=1515.7, ups=0.35, wpb=4349, bsz=248, num_updates=372, lr=4.464e-06, gnorm=2.054, train_wall=6, gb_free=10.6, wall=1188
2025-04-03 05:23:49 | INFO | train_inner | epoch 003:    122 / 126 loss=7.533, nll_loss=4.446, ppl=21.8, wps=1783.3, ups=0.38, wpb=4719.5, bsz=240, num_updates=374, lr=4.488e-06, gnorm=2.221, train_wall=5, gb_free=13.2, wall=1194
2025-04-03 05:23:55 | INFO | train_inner | epoch 003:    124 / 126 loss=7.418, nll_loss=4.298, ppl=19.67, wps=1774.1, ups=0.36, wpb=4932, bsz=268, num_updates=376, lr=4.512e-06, gnorm=2.061, train_wall=6, gb_free=14.3, wall=1199
2025-04-03 05:23:59 | INFO | train_inner | epoch 003:    126 / 126 loss=7.486, nll_loss=4.388, ppl=20.94, wps=1602.7, ups=0.47, wpb=3422.5, bsz=172, num_updates=378, lr=4.536e-06, gnorm=2.408, train_wall=4, gb_free=16.6, wall=1203
2025-04-03 05:23:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-03 05:23:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=10805.7734375Mb; avail=244279.265625Mb
2025-04-03 05:23:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000651
2025-04-03 05:23:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=10805.7734375Mb; avail=244279.265625Mb
2025-04-03 05:23:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012967
2025-04-03 05:23:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=10805.7734375Mb; avail=244279.265625Mb
2025-04-03 05:23:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.010902
2025-04-03 05:23:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024892
2025-04-03 05:23:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=10806.01953125Mb; avail=244279.01953125Mb
2025-04-03 05:24:14 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 7.187 | nll_loss 3.829 | ppl 14.21 | wps 3875.2 | wpb 2070.5 | bsz 122.7 | num_updates 378 | best_loss 7.187
2025-04-03 05:24:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 378 updates
2025-04-03 05:24:14 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 05:24:53 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 05:25:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt (epoch 3 @ 378 updates, score 7.187) (writing took 63.65693520999048 seconds)
2025-04-03 05:25:17 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2025-04-03 05:25:17 | INFO | train | epoch 003 | loss 7.572 | nll_loss 4.495 | ppl 22.54 | wps 1330.1 | ups 0.29 | wpb 4549.7 | bsz 252.8 | num_updates 378 | lr 4.536e-06 | gnorm 2.168 | train_wall 352 | gb_free 16.6 | wall 1281
2025-04-03 05:25:17 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:mr-hi': 31849}; raw total size: 31849
2025-04-03 05:25:17 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:mr-hi': 31849}; resampled total size: 31849
2025-04-03 05:25:17 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:mr-hi': 1.0}
2025-04-03 05:25:17 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001117
2025-04-03 05:25:17 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=16303.30078125Mb; avail=238781.7109375Mb
2025-04-03 05:25:17 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000418
2025-04-03 05:25:17 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003535
2025-04-03 05:25:17 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=16303.30078125Mb; avail=238781.7109375Mb
2025-04-03 05:25:17 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000092
2025-04-03 05:25:17 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=16303.30078125Mb; avail=238781.7109375Mb
2025-04-03 05:25:17 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001155
2025-04-03 05:25:17 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.005100
2025-04-03 05:25:17 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=16303.30078125Mb; avail=238781.7109375Mb
2025-04-03 05:25:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 126
2025-04-03 05:25:17 | INFO | fairseq.trainer | begin training epoch 4
2025-04-03 05:25:17 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-03 05:25:23 | INFO | train_inner | epoch 004:      2 / 126 loss=7.469, nll_loss=4.361, ppl=20.54, wps=105.5, ups=0.02, wpb=4405.5, bsz=196, num_updates=380, lr=4.56e-06, gnorm=2.027, train_wall=5, gb_free=10.1, wall=1287
2025-04-03 05:25:28 | INFO | train_inner | epoch 004:      4 / 126 loss=7.573, nll_loss=4.498, ppl=22.6, wps=1756.9, ups=0.38, wpb=4679, bsz=188, num_updates=382, lr=4.584e-06, gnorm=2.15, train_wall=5, gb_free=14.5, wall=1292
2025-04-03 05:25:34 | INFO | train_inner | epoch 004:      6 / 126 loss=7.308, nll_loss=4.168, ppl=17.98, wps=1781.8, ups=0.37, wpb=4841.5, bsz=292, num_updates=384, lr=4.608e-06, gnorm=2.277, train_wall=5, gb_free=12.5, wall=1298
2025-04-03 05:25:39 | INFO | train_inner | epoch 004:      8 / 126 loss=7.296, nll_loss=4.146, ppl=17.71, wps=1704.3, ups=0.36, wpb=4696.5, bsz=264, num_updates=386, lr=4.632e-06, gnorm=2.102, train_wall=6, gb_free=8.2, wall=1303
2025-04-03 05:25:45 | INFO | train_inner | epoch 004:     10 / 126 loss=7.249, nll_loss=4.08, ppl=16.91, wps=1882, ups=0.35, wpb=5389.5, bsz=312, num_updates=388, lr=4.656e-06, gnorm=1.862, train_wall=6, gb_free=13.8, wall=1309
2025-04-03 05:25:50 | INFO | train_inner | epoch 004:     12 / 126 loss=7.273, nll_loss=4.118, ppl=17.36, wps=1723.4, ups=0.36, wpb=4798, bsz=280, num_updates=390, lr=4.68e-06, gnorm=1.967, train_wall=6, gb_free=13.9, wall=1314
2025-04-03 05:25:56 | INFO | train_inner | epoch 004:     14 / 126 loss=7.345, nll_loss=4.202, ppl=18.4, wps=1636.5, ups=0.35, wpb=4660, bsz=260, num_updates=392, lr=4.704e-06, gnorm=1.981, train_wall=6, gb_free=11.6, wall=1320
2025-04-03 05:26:02 | INFO | train_inner | epoch 004:     16 / 126 loss=7.282, nll_loss=4.131, ppl=17.52, wps=1818.6, ups=0.36, wpb=5096.5, bsz=300, num_updates=394, lr=4.728e-06, gnorm=1.918, train_wall=6, gb_free=10.4, wall=1326
2025-04-03 05:26:07 | INFO | train_inner | epoch 004:     18 / 126 loss=7.442, nll_loss=4.323, ppl=20.02, wps=1682.1, ups=0.36, wpb=4628.5, bsz=260, num_updates=396, lr=4.752e-06, gnorm=2.023, train_wall=5, gb_free=9.7, wall=1331
2025-04-03 05:26:13 | INFO | train_inner | epoch 004:     20 / 126 loss=7.339, nll_loss=4.2, ppl=18.38, wps=1764.3, ups=0.36, wpb=4887.5, bsz=296, num_updates=398, lr=4.776e-06, gnorm=1.933, train_wall=6, gb_free=11.6, wall=1337
2025-04-03 05:26:18 | INFO | train_inner | epoch 004:     22 / 126 loss=7.275, nll_loss=4.116, ppl=17.33, wps=1722.9, ups=0.35, wpb=4952.5, bsz=248, num_updates=400, lr=4.8e-06, gnorm=1.949, train_wall=6, gb_free=13.6, wall=1343
2025-04-03 05:26:24 | INFO | train_inner | epoch 004:     24 / 126 loss=7.352, nll_loss=4.207, ppl=18.47, wps=1695.8, ups=0.38, wpb=4493.5, bsz=220, num_updates=402, lr=4.824e-06, gnorm=2.233, train_wall=5, gb_free=13.2, wall=1348
2025-04-03 05:26:30 | INFO | train_inner | epoch 004:     26 / 126 loss=7.224, nll_loss=4.055, ppl=16.62, wps=1693.2, ups=0.34, wpb=4936, bsz=244, num_updates=404, lr=4.848e-06, gnorm=1.931, train_wall=6, gb_free=9.6, wall=1354
2025-04-03 05:26:35 | INFO | train_inner | epoch 004:     28 / 126 loss=7.25, nll_loss=4.092, ppl=17.05, wps=1798.3, ups=0.37, wpb=4843, bsz=332, num_updates=406, lr=4.872e-06, gnorm=2.068, train_wall=5, gb_free=10.8, wall=1359
2025-04-03 05:26:40 | INFO | train_inner | epoch 004:     30 / 126 loss=7.298, nll_loss=4.152, ppl=17.78, wps=1626.2, ups=0.38, wpb=4316, bsz=248, num_updates=408, lr=4.896e-06, gnorm=2.363, train_wall=5, gb_free=11.6, wall=1364
2025-04-03 05:26:46 | INFO | train_inner | epoch 004:     32 / 126 loss=7.332, nll_loss=4.189, ppl=18.23, wps=1574.2, ups=0.34, wpb=4565.5, bsz=228, num_updates=410, lr=4.92e-06, gnorm=1.973, train_wall=6, gb_free=14.2, wall=1370
2025-04-03 05:26:52 | INFO | train_inner | epoch 004:     34 / 126 loss=7.495, nll_loss=4.404, ppl=21.16, wps=1523.2, ups=0.35, wpb=4323, bsz=224, num_updates=412, lr=4.944e-06, gnorm=2.298, train_wall=6, gb_free=12.9, wall=1376
2025-04-03 05:26:57 | INFO | train_inner | epoch 004:     36 / 126 loss=7.583, nll_loss=4.498, ppl=22.6, wps=1563.4, ups=0.4, wpb=3882.5, bsz=140, num_updates=414, lr=4.968e-06, gnorm=2.807, train_wall=5, gb_free=13.3, wall=1381
2025-04-03 05:27:02 | INFO | train_inner | epoch 004:     38 / 126 loss=7.214, nll_loss=4.056, ppl=16.64, wps=1546.8, ups=0.37, wpb=4184, bsz=348, num_updates=416, lr=4.992e-06, gnorm=1.966, train_wall=5, gb_free=11.6, wall=1386
2025-04-03 05:27:07 | INFO | train_inner | epoch 004:     40 / 126 loss=7.243, nll_loss=4.091, ppl=17.04, wps=1730.8, ups=0.38, wpb=4522, bsz=300, num_updates=418, lr=5.016e-06, gnorm=2.189, train_wall=5, gb_free=15.7, wall=1391
2025-04-03 05:27:13 | INFO | train_inner | epoch 004:     42 / 126 loss=7.348, nll_loss=4.211, ppl=18.52, wps=1588.7, ups=0.35, wpb=4485.5, bsz=192, num_updates=420, lr=5.04e-06, gnorm=2.061, train_wall=6, gb_free=12.7, wall=1397
2025-04-03 05:27:18 | INFO | train_inner | epoch 004:     44 / 126 loss=7.454, nll_loss=4.344, ppl=20.3, wps=1823.8, ups=0.37, wpb=4906, bsz=276, num_updates=422, lr=5.064e-06, gnorm=2.192, train_wall=5, gb_free=12.2, wall=1402
2025-04-03 05:27:29 | INFO | train_inner | epoch 004:     46 / 126 loss=7.274, nll_loss=4.115, ppl=17.33, wps=885.2, ups=0.19, wpb=4752, bsz=264, num_updates=424, lr=5.088e-06, gnorm=1.912, train_wall=11, gb_free=14.3, wall=1413
2025-04-03 05:27:35 | INFO | train_inner | epoch 004:     48 / 126 loss=7.336, nll_loss=4.199, ppl=18.37, wps=1680.7, ups=0.37, wpb=4599.5, bsz=276, num_updates=426, lr=5.112e-06, gnorm=2.172, train_wall=5, gb_free=12.1, wall=1419
2025-04-03 05:27:40 | INFO | train_inner | epoch 004:     50 / 126 loss=7.271, nll_loss=4.113, ppl=17.3, wps=1767, ups=0.38, wpb=4678.5, bsz=248, num_updates=428, lr=5.136e-06, gnorm=1.963, train_wall=5, gb_free=13.4, wall=1424
2025-04-03 05:27:45 | INFO | train_inner | epoch 004:     52 / 126 loss=7.33, nll_loss=4.175, ppl=18.06, wps=1618.3, ups=0.36, wpb=4520, bsz=260, num_updates=430, lr=5.16e-06, gnorm=2.027, train_wall=6, gb_free=11.5, wall=1430
2025-04-03 05:27:50 | INFO | train_inner | epoch 004:     54 / 126 loss=7.562, nll_loss=4.486, ppl=22.41, wps=1588.3, ups=0.41, wpb=3831.5, bsz=208, num_updates=432, lr=5.184e-06, gnorm=2.298, train_wall=5, gb_free=13.7, wall=1434
2025-04-03 05:27:56 | INFO | train_inner | epoch 004:     56 / 126 loss=7.159, nll_loss=3.967, ppl=15.64, wps=1791.2, ups=0.35, wpb=5118, bsz=316, num_updates=434, lr=5.208e-06, gnorm=1.96, train_wall=6, gb_free=10.7, wall=1440
2025-04-03 05:28:02 | INFO | train_inner | epoch 004:     58 / 126 loss=7.224, nll_loss=4.049, ppl=16.55, wps=1640.3, ups=0.34, wpb=4823, bsz=256, num_updates=436, lr=5.232e-06, gnorm=1.943, train_wall=6, gb_free=13.2, wall=1446
2025-04-03 05:28:08 | INFO | train_inner | epoch 004:     60 / 126 loss=7.187, nll_loss=4.017, ppl=16.19, wps=1521.9, ups=0.36, wpb=4278.5, bsz=316, num_updates=438, lr=5.256e-06, gnorm=1.934, train_wall=6, gb_free=10.9, wall=1452
2025-04-03 05:28:13 | INFO | train_inner | epoch 004:     62 / 126 loss=7.223, nll_loss=4.048, ppl=16.55, wps=1628.5, ups=0.38, wpb=4244, bsz=204, num_updates=440, lr=5.28e-06, gnorm=2.159, train_wall=5, gb_free=13.9, wall=1457
2025-04-03 05:28:18 | INFO | train_inner | epoch 004:     64 / 126 loss=7.189, nll_loss=4.014, ppl=16.16, wps=1713.5, ups=0.35, wpb=4933, bsz=268, num_updates=442, lr=5.304e-06, gnorm=2.11, train_wall=6, gb_free=13.5, wall=1463
2025-04-03 05:28:24 | INFO | train_inner | epoch 004:     66 / 126 loss=7.343, nll_loss=4.22, ppl=18.64, wps=1623, ups=0.37, wpb=4340, bsz=268, num_updates=444, lr=5.328e-06, gnorm=2.127, train_wall=5, gb_free=10.3, wall=1468
2025-04-03 05:28:29 | INFO | train_inner | epoch 004:     68 / 126 loss=7.403, nll_loss=4.289, ppl=19.55, wps=1710.6, ups=0.36, wpb=4798, bsz=272, num_updates=446, lr=5.352e-06, gnorm=2.215, train_wall=6, gb_free=12.5, wall=1474
2025-04-03 05:28:35 | INFO | train_inner | epoch 004:     70 / 126 loss=7.464, nll_loss=4.363, ppl=20.58, wps=1399.7, ups=0.36, wpb=3863.5, bsz=204, num_updates=448, lr=5.376e-06, gnorm=2.315, train_wall=6, gb_free=10.1, wall=1479
2025-04-03 05:28:41 | INFO | train_inner | epoch 004:     72 / 126 loss=7.297, nll_loss=4.137, ppl=17.59, wps=1497.6, ups=0.35, wpb=4288, bsz=136, num_updates=450, lr=5.4e-06, gnorm=2.147, train_wall=6, gb_free=11.8, wall=1485
2025-04-03 05:28:46 | INFO | train_inner | epoch 004:     74 / 126 loss=7.214, nll_loss=4.02, ppl=16.22, wps=1595.2, ups=0.35, wpb=4623.5, bsz=264, num_updates=452, lr=5.424e-06, gnorm=2.333, train_wall=6, gb_free=12.3, wall=1491
2025-04-03 05:28:52 | INFO | train_inner | epoch 004:     76 / 126 loss=7.214, nll_loss=4.033, ppl=16.37, wps=1769.5, ups=0.38, wpb=4716.5, bsz=216, num_updates=454, lr=5.448e-06, gnorm=2.173, train_wall=5, gb_free=10.5, wall=1496
2025-04-03 05:28:56 | INFO | train_inner | epoch 004:     78 / 126 loss=7.264, nll_loss=4.111, ppl=17.27, wps=1664.5, ups=0.46, wpb=3618, bsz=188.5, num_updates=456, lr=5.472e-06, gnorm=2.563, train_wall=4, gb_free=14.7, wall=1500
2025-04-03 05:29:02 | INFO | train_inner | epoch 004:     80 / 126 loss=7.324, nll_loss=4.155, ppl=17.81, wps=1704.9, ups=0.34, wpb=5019.5, bsz=208, num_updates=458, lr=5.496e-06, gnorm=2.052, train_wall=6, gb_free=12.9, wall=1506
2025-04-03 05:29:08 | INFO | train_inner | epoch 004:     82 / 126 loss=7.303, nll_loss=4.152, ppl=17.77, wps=1666.9, ups=0.37, wpb=4547.5, bsz=232, num_updates=460, lr=5.52e-06, gnorm=2.092, train_wall=5, gb_free=10.2, wall=1512
2025-04-03 05:29:13 | INFO | train_inner | epoch 004:     84 / 126 loss=7.12, nll_loss=3.91, ppl=15.03, wps=1690.5, ups=0.37, wpb=4560.5, bsz=212, num_updates=462, lr=5.544e-06, gnorm=2.01, train_wall=5, gb_free=12.9, wall=1517
2025-04-03 05:29:18 | INFO | train_inner | epoch 004:     86 / 126 loss=7.326, nll_loss=4.18, ppl=18.13, wps=1556.1, ups=0.43, wpb=3646, bsz=212, num_updates=464, lr=5.568e-06, gnorm=2.575, train_wall=5, gb_free=11, wall=1522
2025-04-03 05:29:23 | INFO | train_inner | epoch 004:     88 / 126 loss=7.173, nll_loss=3.979, ppl=15.77, wps=1747.6, ups=0.36, wpb=4810, bsz=284, num_updates=466, lr=5.592e-06, gnorm=1.921, train_wall=5, gb_free=13.9, wall=1527
2025-04-03 05:29:29 | INFO | train_inner | epoch 004:     90 / 126 loss=7.276, nll_loss=4.11, ppl=17.27, wps=1535.1, ups=0.36, wpb=4223, bsz=212, num_updates=468, lr=5.616e-06, gnorm=2.158, train_wall=5, gb_free=13.5, wall=1533
2025-04-03 05:29:35 | INFO | train_inner | epoch 004:     92 / 126 loss=7.19, nll_loss=4.011, ppl=16.12, wps=1453.9, ups=0.33, wpb=4415, bsz=260, num_updates=470, lr=5.64e-06, gnorm=2.221, train_wall=6, gb_free=10.7, wall=1539
2025-04-03 05:29:40 | INFO | train_inner | epoch 004:     94 / 126 loss=7.247, nll_loss=4.073, ppl=16.83, wps=1670.9, ups=0.36, wpb=4585, bsz=216, num_updates=472, lr=5.664e-06, gnorm=2.147, train_wall=5, gb_free=10, wall=1544
2025-04-03 05:29:46 | INFO | train_inner | epoch 004:     96 / 126 loss=7.258, nll_loss=4.109, ppl=17.25, wps=1575.1, ups=0.37, wpb=4241.5, bsz=240, num_updates=474, lr=5.688e-06, gnorm=2.249, train_wall=5, gb_free=13.6, wall=1550
2025-04-03 05:29:51 | INFO | train_inner | epoch 004:     98 / 126 loss=7.216, nll_loss=4.054, ppl=16.61, wps=1759, ups=0.36, wpb=4829, bsz=280, num_updates=476, lr=5.712e-06, gnorm=2.11, train_wall=5, gb_free=12.7, wall=1555
2025-04-03 05:29:57 | INFO | train_inner | epoch 004:    100 / 126 loss=7.302, nll_loss=4.175, ppl=18.06, wps=1489.6, ups=0.35, wpb=4217, bsz=240, num_updates=478, lr=5.736e-06, gnorm=2.073, train_wall=6, gb_free=11, wall=1561
2025-04-03 05:30:02 | INFO | train_inner | epoch 004:    102 / 126 loss=7.077, nll_loss=3.871, ppl=14.63, wps=1787.5, ups=0.36, wpb=4971, bsz=320, num_updates=480, lr=5.76e-06, gnorm=1.958, train_wall=6, gb_free=9.6, wall=1566
2025-04-03 05:30:08 | INFO | train_inner | epoch 004:    104 / 126 loss=7.073, nll_loss=3.88, ppl=14.72, wps=1450.9, ups=0.37, wpb=3907, bsz=292, num_updates=482, lr=5.784e-06, gnorm=2.234, train_wall=5, gb_free=12.2, wall=1572
2025-04-03 05:30:13 | INFO | train_inner | epoch 004:    106 / 126 loss=7.248, nll_loss=4.082, ppl=16.93, wps=1468.2, ups=0.35, wpb=4173, bsz=244, num_updates=484, lr=5.808e-06, gnorm=2.324, train_wall=6, gb_free=14.7, wall=1577
2025-04-03 05:30:19 | INFO | train_inner | epoch 004:    108 / 126 loss=7.078, nll_loss=3.886, ppl=14.78, wps=1761.9, ups=0.35, wpb=4976.5, bsz=372, num_updates=486, lr=5.832e-06, gnorm=1.763, train_wall=6, gb_free=13.2, wall=1583
2025-04-03 05:30:25 | INFO | train_inner | epoch 004:    110 / 126 loss=7.149, nll_loss=3.955, ppl=15.51, wps=1628, ups=0.34, wpb=4765.5, bsz=260, num_updates=488, lr=5.856e-06, gnorm=1.872, train_wall=6, gb_free=9, wall=1589
2025-04-03 05:30:31 | INFO | train_inner | epoch 004:    112 / 126 loss=7.082, nll_loss=3.881, ppl=14.73, wps=1854.3, ups=0.35, wpb=5252, bsz=368, num_updates=490, lr=5.88e-06, gnorm=1.88, train_wall=6, gb_free=12, wall=1595
2025-04-03 05:30:36 | INFO | train_inner | epoch 004:    114 / 126 loss=7.152, nll_loss=3.964, ppl=15.6, wps=1614.7, ups=0.35, wpb=4591, bsz=284, num_updates=492, lr=5.904e-06, gnorm=1.926, train_wall=6, gb_free=13.9, wall=1600
2025-04-03 05:30:42 | INFO | train_inner | epoch 004:    116 / 126 loss=7.23, nll_loss=4.053, ppl=16.6, wps=1541.2, ups=0.36, wpb=4299.5, bsz=228, num_updates=494, lr=5.928e-06, gnorm=2.098, train_wall=6, gb_free=11.5, wall=1606
2025-04-03 05:30:48 | INFO | train_inner | epoch 004:    118 / 126 loss=7.227, nll_loss=4.062, ppl=16.7, wps=1575.7, ups=0.35, wpb=4548, bsz=264, num_updates=496, lr=5.952e-06, gnorm=1.911, train_wall=6, gb_free=12.2, wall=1612
2025-04-03 05:30:54 | INFO | train_inner | epoch 004:    120 / 126 loss=7.044, nll_loss=3.832, ppl=14.24, wps=1544.2, ups=0.32, wpb=4769, bsz=300, num_updates=498, lr=5.976e-06, gnorm=1.956, train_wall=6, gb_free=9.5, wall=1618
2025-04-03 05:30:59 | INFO | train_inner | epoch 004:    122 / 126 loss=7.123, nll_loss=3.938, ppl=15.33, wps=1760.9, ups=0.37, wpb=4792, bsz=284, num_updates=500, lr=6e-06, gnorm=1.907, train_wall=5, gb_free=11.8, wall=1623
2025-04-03 05:31:05 | INFO | train_inner | epoch 004:    124 / 126 loss=7.298, nll_loss=4.14, ppl=17.62, wps=1428.3, ups=0.34, wpb=4236.5, bsz=124, num_updates=502, lr=6.024e-06, gnorm=2.121, train_wall=6, gb_free=9.8, wall=1629
2025-04-03 05:31:10 | INFO | train_inner | epoch 004:    126 / 126 loss=7.097, nll_loss=3.885, ppl=14.78, wps=1668.5, ups=0.45, wpb=3739, bsz=176, num_updates=504, lr=6.048e-06, gnorm=2.119, train_wall=4, gb_free=17.4, wall=1634
2025-04-03 05:31:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-03 05:31:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=10477.2265625Mb; avail=244607.79296875Mb
2025-04-03 05:31:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000637
2025-04-03 05:31:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=10477.2265625Mb; avail=244607.79296875Mb
2025-04-03 05:31:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012724
2025-04-03 05:31:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=10477.2265625Mb; avail=244607.79296875Mb
2025-04-03 05:31:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.010866
2025-04-03 05:31:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024614
2025-04-03 05:31:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=10477.2265625Mb; avail=244607.79296875Mb
2025-04-03 05:31:24 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 6.945 | nll_loss 3.517 | ppl 11.44 | wps 3865.7 | wpb 2070.5 | bsz 122.7 | num_updates 504 | best_loss 6.945
2025-04-03 05:31:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 504 updates
2025-04-03 05:31:24 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 05:32:03 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 05:32:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt (epoch 4 @ 504 updates, score 6.945) (writing took 63.97753864398692 seconds)
2025-04-03 05:32:28 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2025-04-03 05:32:28 | INFO | train | epoch 004 | loss 7.271 | nll_loss 4.113 | ppl 17.3 | wps 1331.1 | ups 0.29 | wpb 4549.7 | bsz 252.8 | num_updates 504 | lr 6.048e-06 | gnorm 2.1 | train_wall 352 | gb_free 17.4 | wall 1712
2025-04-03 05:32:28 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:mr-hi': 31849}; raw total size: 31849
2025-04-03 05:32:28 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:mr-hi': 31849}; resampled total size: 31849
2025-04-03 05:32:28 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:mr-hi': 1.0}
2025-04-03 05:32:28 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.000881
2025-04-03 05:32:28 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=12830.6484375Mb; avail=242254.34375Mb
2025-04-03 05:32:28 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000407
2025-04-03 05:32:28 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003523
2025-04-03 05:32:28 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=12830.6484375Mb; avail=242254.34375Mb
2025-04-03 05:32:28 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000087
2025-04-03 05:32:28 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=12830.6484375Mb; avail=242254.34375Mb
2025-04-03 05:32:28 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001124
2025-04-03 05:32:28 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.005051
2025-04-03 05:32:28 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=12830.6484375Mb; avail=242254.34375Mb
2025-04-03 05:32:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 126
2025-04-03 05:32:28 | INFO | fairseq.trainer | begin training epoch 5
2025-04-03 05:32:28 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-03 05:32:34 | INFO | train_inner | epoch 005:      2 / 126 loss=6.938, nll_loss=3.691, ppl=12.92, wps=119.8, ups=0.02, wpb=5036.5, bsz=280, num_updates=506, lr=6.072e-06, gnorm=1.786, train_wall=6, gb_free=9.2, wall=1718
2025-04-03 05:32:39 | INFO | train_inner | epoch 005:      4 / 126 loss=7.175, nll_loss=4.006, ppl=16.06, wps=1686.2, ups=0.39, wpb=4349.5, bsz=288, num_updates=508, lr=6.096e-06, gnorm=2.03, train_wall=5, gb_free=14.8, wall=1723
2025-04-03 05:32:44 | INFO | train_inner | epoch 005:      6 / 126 loss=7.203, nll_loss=4.02, ppl=16.23, wps=1742.7, ups=0.41, wpb=4244.5, bsz=168, num_updates=510, lr=6.12e-06, gnorm=2.232, train_wall=5, gb_free=13.2, wall=1728
2025-04-03 05:32:49 | INFO | train_inner | epoch 005:      8 / 126 loss=7.167, nll_loss=3.973, ppl=15.7, wps=1690.6, ups=0.39, wpb=4355, bsz=216, num_updates=512, lr=6.144e-06, gnorm=2.093, train_wall=5, gb_free=13.3, wall=1733
2025-04-03 05:32:54 | INFO | train_inner | epoch 005:     10 / 126 loss=7.027, nll_loss=3.792, ppl=13.85, wps=1770.5, ups=0.36, wpb=4861, bsz=272, num_updates=514, lr=6.168e-06, gnorm=1.996, train_wall=5, gb_free=13.6, wall=1738
2025-04-03 05:33:00 | INFO | train_inner | epoch 005:     12 / 126 loss=7.035, nll_loss=3.812, ppl=14.05, wps=1667.3, ups=0.39, wpb=4292.5, bsz=288, num_updates=516, lr=6.192e-06, gnorm=2.013, train_wall=5, gb_free=14.1, wall=1744
2025-04-03 05:33:05 | INFO | train_inner | epoch 005:     14 / 126 loss=7.007, nll_loss=3.774, ppl=13.68, wps=1844.6, ups=0.35, wpb=5241.5, bsz=348, num_updates=518, lr=6.216e-06, gnorm=1.913, train_wall=6, gb_free=10.2, wall=1749
2025-04-03 05:33:11 | INFO | train_inner | epoch 005:     16 / 126 loss=7.042, nll_loss=3.812, ppl=14.05, wps=1525.2, ups=0.35, wpb=4399, bsz=184, num_updates=520, lr=6.24e-06, gnorm=1.987, train_wall=6, gb_free=9.5, wall=1755
2025-04-03 05:33:17 | INFO | train_inner | epoch 005:     18 / 126 loss=6.911, nll_loss=3.661, ppl=12.65, wps=1694.8, ups=0.34, wpb=5016.5, bsz=376, num_updates=522, lr=6.264e-06, gnorm=2.179, train_wall=6, gb_free=9.2, wall=1761
2025-04-03 05:33:22 | INFO | train_inner | epoch 005:     20 / 126 loss=7.103, nll_loss=3.918, ppl=15.11, wps=1704.7, ups=0.38, wpb=4477.5, bsz=332, num_updates=524, lr=6.288e-06, gnorm=1.982, train_wall=5, gb_free=11.8, wall=1766
2025-04-03 05:33:28 | INFO | train_inner | epoch 005:     22 / 126 loss=7.206, nll_loss=4.014, ppl=16.16, wps=1575.2, ups=0.36, wpb=4426, bsz=132, num_updates=526, lr=6.312e-06, gnorm=2.12, train_wall=6, gb_free=11.9, wall=1772
2025-04-03 05:33:33 | INFO | train_inner | epoch 005:     24 / 126 loss=7.061, nll_loss=3.861, ppl=14.53, wps=1679, ups=0.36, wpb=4605, bsz=264, num_updates=528, lr=6.336e-06, gnorm=1.969, train_wall=5, gb_free=11.1, wall=1777
2025-04-03 05:33:39 | INFO | train_inner | epoch 005:     26 / 126 loss=6.934, nll_loss=3.691, ppl=12.92, wps=1787.8, ups=0.35, wpb=5071.5, bsz=300, num_updates=530, lr=6.36e-06, gnorm=1.78, train_wall=6, gb_free=13, wall=1783
2025-04-03 05:33:44 | INFO | train_inner | epoch 005:     28 / 126 loss=7.212, nll_loss=4.047, ppl=16.53, wps=1557.5, ups=0.36, wpb=4307, bsz=256, num_updates=532, lr=6.384e-06, gnorm=2.167, train_wall=6, gb_free=13.7, wall=1789
2025-04-03 05:33:50 | INFO | train_inner | epoch 005:     30 / 126 loss=7.132, nll_loss=3.929, ppl=15.23, wps=1566.2, ups=0.35, wpb=4526, bsz=152, num_updates=534, lr=6.408e-06, gnorm=2.249, train_wall=6, gb_free=10, wall=1794
2025-04-03 05:33:55 | INFO | train_inner | epoch 005:     32 / 126 loss=7.163, nll_loss=3.99, ppl=15.89, wps=1543.6, ups=0.38, wpb=4030, bsz=264, num_updates=536, lr=6.432e-06, gnorm=2.215, train_wall=5, gb_free=14.9, wall=1800
2025-04-03 05:33:59 | INFO | train_inner | epoch 005:     34 / 126 loss=7.2, nll_loss=4.012, ppl=16.13, wps=1459.4, ups=0.51, wpb=2857.5, bsz=144.5, num_updates=538, lr=6.456e-06, gnorm=3.462, train_wall=4, gb_free=13.3, wall=1803
2025-04-03 05:34:05 | INFO | train_inner | epoch 005:     36 / 126 loss=7.042, nll_loss=3.83, ppl=14.22, wps=1738.3, ups=0.37, wpb=4698, bsz=296, num_updates=540, lr=6.48e-06, gnorm=2.278, train_wall=5, gb_free=13.8, wall=1809
2025-04-03 05:34:11 | INFO | train_inner | epoch 005:     38 / 126 loss=7.061, nll_loss=3.849, ppl=14.41, wps=1680.7, ups=0.35, wpb=4831, bsz=280, num_updates=542, lr=6.504e-06, gnorm=2.165, train_wall=6, gb_free=12, wall=1815
2025-04-03 05:34:16 | INFO | train_inner | epoch 005:     40 / 126 loss=7.132, nll_loss=3.948, ppl=15.43, wps=1524.7, ups=0.38, wpb=4015.5, bsz=272, num_updates=544, lr=6.528e-06, gnorm=2.201, train_wall=5, gb_free=15.1, wall=1820
2025-04-03 05:34:22 | INFO | train_inner | epoch 005:     42 / 126 loss=7.098, nll_loss=3.881, ppl=14.73, wps=1587.1, ups=0.34, wpb=4659.5, bsz=228, num_updates=546, lr=6.552e-06, gnorm=2.023, train_wall=6, gb_free=12.5, wall=1826
2025-04-03 05:34:27 | INFO | train_inner | epoch 005:     44 / 126 loss=7.064, nll_loss=3.86, ppl=14.52, wps=1428.6, ups=0.37, wpb=3858.5, bsz=236, num_updates=548, lr=6.576e-06, gnorm=2.343, train_wall=5, gb_free=10.6, wall=1831
2025-04-03 05:34:33 | INFO | train_inner | epoch 005:     46 / 126 loss=7.044, nll_loss=3.812, ppl=14.05, wps=1690.7, ups=0.35, wpb=4767, bsz=220, num_updates=550, lr=6.6e-06, gnorm=1.941, train_wall=6, gb_free=10, wall=1837
2025-04-03 05:34:38 | INFO | train_inner | epoch 005:     48 / 126 loss=7.076, nll_loss=3.878, ppl=14.71, wps=1658.6, ups=0.39, wpb=4227.5, bsz=304, num_updates=552, lr=6.624e-06, gnorm=2.138, train_wall=5, gb_free=13.4, wall=1842
2025-04-03 05:34:43 | INFO | train_inner | epoch 005:     50 / 126 loss=7.041, nll_loss=3.816, ppl=14.08, wps=1533.3, ups=0.37, wpb=4132.5, bsz=192, num_updates=554, lr=6.648e-06, gnorm=2.159, train_wall=5, gb_free=14.1, wall=1847
2025-04-03 05:34:49 | INFO | train_inner | epoch 005:     52 / 126 loss=7.079, nll_loss=3.875, ppl=14.67, wps=1699.7, ups=0.34, wpb=4951, bsz=292, num_updates=556, lr=6.672e-06, gnorm=2.107, train_wall=6, gb_free=11.8, wall=1853
2025-04-03 05:34:55 | INFO | train_inner | epoch 005:     54 / 126 loss=7.034, nll_loss=3.821, ppl=14.13, wps=1820, ups=0.34, wpb=5323, bsz=256, num_updates=558, lr=6.696e-06, gnorm=2.047, train_wall=6, gb_free=10.9, wall=1859
2025-04-03 05:35:00 | INFO | train_inner | epoch 005:     56 / 126 loss=7.027, nll_loss=3.831, ppl=14.23, wps=1696.6, ups=0.38, wpb=4429, bsz=300, num_updates=560, lr=6.72e-06, gnorm=1.924, train_wall=5, gb_free=13.6, wall=1864
2025-04-03 05:35:05 | INFO | train_inner | epoch 005:     58 / 126 loss=7.146, nll_loss=3.968, ppl=15.65, wps=1680.2, ups=0.37, wpb=4508, bsz=256, num_updates=562, lr=6.744e-06, gnorm=2.297, train_wall=5, gb_free=14.3, wall=1870
2025-04-03 05:35:11 | INFO | train_inner | epoch 005:     60 / 126 loss=7.001, nll_loss=3.774, ppl=13.68, wps=1734.3, ups=0.37, wpb=4713.5, bsz=272, num_updates=564, lr=6.768e-06, gnorm=1.861, train_wall=5, gb_free=13.3, wall=1875
2025-04-03 05:35:17 | INFO | train_inner | epoch 005:     62 / 126 loss=6.883, nll_loss=3.62, ppl=12.29, wps=1621.3, ups=0.35, wpb=4647, bsz=272, num_updates=566, lr=6.792e-06, gnorm=1.919, train_wall=6, gb_free=11.5, wall=1881
2025-04-03 05:35:27 | INFO | train_inner | epoch 005:     64 / 126 loss=6.903, nll_loss=3.646, ppl=12.52, wps=925.3, ups=0.19, wpb=4828.5, bsz=320, num_updates=568, lr=6.816e-06, gnorm=1.948, train_wall=10, gb_free=9.9, wall=1891
2025-04-03 05:35:33 | INFO | train_inner | epoch 005:     66 / 126 loss=6.949, nll_loss=3.69, ppl=12.91, wps=1617.1, ups=0.35, wpb=4557, bsz=236, num_updates=570, lr=6.84e-06, gnorm=2.043, train_wall=6, gb_free=11.1, wall=1897
2025-04-03 05:35:38 | INFO | train_inner | epoch 005:     68 / 126 loss=6.914, nll_loss=3.665, ppl=12.68, wps=1857, ups=0.35, wpb=5339, bsz=364, num_updates=572, lr=6.864e-06, gnorm=1.778, train_wall=6, gb_free=9.8, wall=1903
2025-04-03 05:35:44 | INFO | train_inner | epoch 005:     70 / 126 loss=7.151, nll_loss=3.97, ppl=15.67, wps=1418.4, ups=0.36, wpb=3886.5, bsz=276, num_updates=574, lr=6.888e-06, gnorm=2.499, train_wall=5, gb_free=9.9, wall=1908
2025-04-03 05:35:49 | INFO | train_inner | epoch 005:     72 / 126 loss=7.059, nll_loss=3.836, ppl=14.28, wps=1760.7, ups=0.36, wpb=4833, bsz=244, num_updates=576, lr=6.912e-06, gnorm=2.029, train_wall=5, gb_free=11, wall=1914
2025-04-03 05:35:55 | INFO | train_inner | epoch 005:     74 / 126 loss=7.054, nll_loss=3.832, ppl=14.24, wps=1787.5, ups=0.35, wpb=5163.5, bsz=240, num_updates=578, lr=6.936e-06, gnorm=2.337, train_wall=6, gb_free=11, wall=1919
2025-04-03 05:36:01 | INFO | train_inner | epoch 005:     76 / 126 loss=7.036, nll_loss=3.829, ppl=14.21, wps=1505.4, ups=0.37, wpb=4037, bsz=264, num_updates=580, lr=6.96e-06, gnorm=2.008, train_wall=5, gb_free=13.5, wall=1925
2025-04-03 05:36:06 | INFO | train_inner | epoch 005:     78 / 126 loss=7.026, nll_loss=3.804, ppl=13.97, wps=1625, ups=0.36, wpb=4536, bsz=244, num_updates=582, lr=6.984e-06, gnorm=2.068, train_wall=6, gb_free=9.7, wall=1930
2025-04-03 05:36:12 | INFO | train_inner | epoch 005:     80 / 126 loss=6.969, nll_loss=3.729, ppl=13.26, wps=1723.5, ups=0.36, wpb=4806.5, bsz=284, num_updates=584, lr=7.008e-06, gnorm=1.839, train_wall=6, gb_free=14.6, wall=1936
2025-04-03 05:36:17 | INFO | train_inner | epoch 005:     82 / 126 loss=6.807, nll_loss=3.532, ppl=11.57, wps=1879.5, ups=0.35, wpb=5440.5, bsz=388, num_updates=586, lr=7.032e-06, gnorm=1.857, train_wall=6, gb_free=9.6, wall=1942
2025-04-03 05:36:23 | INFO | train_inner | epoch 005:     84 / 126 loss=7.128, nll_loss=3.942, ppl=15.37, wps=1174.7, ups=0.36, wpb=3271, bsz=180, num_updates=588, lr=7.056e-06, gnorm=2.423, train_wall=6, gb_free=9.8, wall=1947
2025-04-03 05:36:29 | INFO | train_inner | epoch 005:     86 / 126 loss=6.992, nll_loss=3.758, ppl=13.53, wps=1614.2, ups=0.36, wpb=4534, bsz=180, num_updates=590, lr=7.08e-06, gnorm=2.032, train_wall=6, gb_free=12.7, wall=1953
2025-04-03 05:36:34 | INFO | train_inner | epoch 005:     88 / 126 loss=6.856, nll_loss=3.581, ppl=11.97, wps=1799.7, ups=0.37, wpb=4874.5, bsz=260, num_updates=592, lr=7.104e-06, gnorm=1.976, train_wall=5, gb_free=11.6, wall=1958
2025-04-03 05:36:40 | INFO | train_inner | epoch 005:     90 / 126 loss=6.891, nll_loss=3.624, ppl=12.33, wps=1820.3, ups=0.33, wpb=5439, bsz=272, num_updates=594, lr=7.128e-06, gnorm=2.006, train_wall=6, gb_free=9.1, wall=1964
2025-04-03 05:36:46 | INFO | train_inner | epoch 005:     92 / 126 loss=7.054, nll_loss=3.831, ppl=14.23, wps=1522.7, ups=0.35, wpb=4367.5, bsz=232, num_updates=596, lr=7.152e-06, gnorm=1.917, train_wall=6, gb_free=9.3, wall=1970
2025-04-03 05:36:51 | INFO | train_inner | epoch 005:     94 / 126 loss=6.985, nll_loss=3.734, ppl=13.31, wps=1622.8, ups=0.4, wpb=4039, bsz=168, num_updates=598, lr=7.176e-06, gnorm=2.141, train_wall=5, gb_free=12.2, wall=1975
2025-04-03 05:36:56 | INFO | train_inner | epoch 005:     96 / 126 loss=7.203, nll_loss=4.032, ppl=16.36, wps=1363.7, ups=0.35, wpb=3842, bsz=224, num_updates=600, lr=7.2e-06, gnorm=2.175, train_wall=6, gb_free=10.6, wall=1981
2025-04-03 05:37:02 | INFO | train_inner | epoch 005:     98 / 126 loss=6.971, nll_loss=3.727, ppl=13.24, wps=1647.2, ups=0.34, wpb=4897.5, bsz=220, num_updates=602, lr=7.224e-06, gnorm=2.05, train_wall=6, gb_free=8.9, wall=1986
2025-04-03 05:37:08 | INFO | train_inner | epoch 005:    100 / 126 loss=6.97, nll_loss=3.733, ppl=13.3, wps=1513.9, ups=0.35, wpb=4379.5, bsz=176, num_updates=604, lr=7.248e-06, gnorm=2.001, train_wall=6, gb_free=8.7, wall=1992
2025-04-03 05:37:14 | INFO | train_inner | epoch 005:    102 / 126 loss=7.099, nll_loss=3.897, ppl=14.89, wps=1654.9, ups=0.35, wpb=4705, bsz=240, num_updates=606, lr=7.272e-06, gnorm=1.819, train_wall=6, gb_free=8.7, wall=1998
2025-04-03 05:37:20 | INFO | train_inner | epoch 005:    104 / 126 loss=6.921, nll_loss=3.678, ppl=12.8, wps=1732.3, ups=0.34, wpb=5041, bsz=312, num_updates=608, lr=7.296e-06, gnorm=1.703, train_wall=6, gb_free=12.1, wall=2004
2025-04-03 05:37:25 | INFO | train_inner | epoch 005:    106 / 126 loss=7.005, nll_loss=3.777, ppl=13.71, wps=1692.4, ups=0.35, wpb=4839, bsz=212, num_updates=610, lr=7.32e-06, gnorm=1.971, train_wall=6, gb_free=13, wall=2009
2025-04-03 05:37:31 | INFO | train_inner | epoch 005:    108 / 126 loss=7.044, nll_loss=3.826, ppl=14.18, wps=1440.1, ups=0.37, wpb=3937, bsz=212, num_updates=612, lr=7.344e-06, gnorm=2.045, train_wall=5, gb_free=10.2, wall=2015
2025-04-03 05:37:37 | INFO | train_inner | epoch 005:    110 / 126 loss=6.872, nll_loss=3.602, ppl=12.14, wps=1782, ups=0.32, wpb=5519, bsz=272, num_updates=614, lr=7.368e-06, gnorm=1.752, train_wall=6, gb_free=9.5, wall=2021
2025-04-03 05:37:43 | INFO | train_inner | epoch 005:    112 / 126 loss=7.046, nll_loss=3.817, ppl=14.1, wps=1723.6, ups=0.35, wpb=4965.5, bsz=248, num_updates=616, lr=7.392e-06, gnorm=1.915, train_wall=6, gb_free=11.1, wall=2027
2025-04-03 05:37:48 | INFO | train_inner | epoch 005:    114 / 126 loss=7.019, nll_loss=3.81, ppl=14.02, wps=1441.4, ups=0.37, wpb=3891.5, bsz=304, num_updates=618, lr=7.416e-06, gnorm=2.488, train_wall=5, gb_free=11.9, wall=2032
2025-04-03 05:37:54 | INFO | train_inner | epoch 005:    116 / 126 loss=7.047, nll_loss=3.839, ppl=14.31, wps=1768, ups=0.36, wpb=4889.5, bsz=316, num_updates=620, lr=7.44e-06, gnorm=1.914, train_wall=6, gb_free=10.4, wall=2038
2025-04-03 05:37:59 | INFO | train_inner | epoch 005:    118 / 126 loss=7.003, nll_loss=3.778, ppl=13.72, wps=1737.9, ups=0.35, wpb=4918.5, bsz=272, num_updates=622, lr=7.464e-06, gnorm=2.04, train_wall=6, gb_free=12.9, wall=2043
2025-04-03 05:38:05 | INFO | train_inner | epoch 005:    120 / 126 loss=6.966, nll_loss=3.729, ppl=13.26, wps=1562.1, ups=0.35, wpb=4490.5, bsz=228, num_updates=624, lr=7.488e-06, gnorm=1.918, train_wall=6, gb_free=11.9, wall=2049
2025-04-03 05:38:11 | INFO | train_inner | epoch 005:    122 / 126 loss=7.054, nll_loss=3.827, ppl=14.19, wps=1673, ups=0.36, wpb=4629, bsz=192, num_updates=626, lr=7.512e-06, gnorm=2.114, train_wall=6, gb_free=11.3, wall=2055
2025-04-03 05:38:16 | INFO | train_inner | epoch 005:    124 / 126 loss=7.026, nll_loss=3.8, ppl=13.93, wps=1489.9, ups=0.35, wpb=4205.5, bsz=204, num_updates=628, lr=7.536e-06, gnorm=1.99, train_wall=6, gb_free=14.2, wall=2060
2025-04-03 05:38:21 | INFO | train_inner | epoch 005:    126 / 126 loss=6.864, nll_loss=3.601, ppl=12.14, wps=1686.2, ups=0.46, wpb=3671.5, bsz=200, num_updates=630, lr=7.56e-06, gnorm=2.068, train_wall=4, gb_free=16.3, wall=2065
2025-04-03 05:38:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-03 05:38:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=7391.1484375Mb; avail=247693.87109375Mb
2025-04-03 05:38:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000618
2025-04-03 05:38:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=7391.1484375Mb; avail=247693.87109375Mb
2025-04-03 05:38:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012893
2025-04-03 05:38:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=7391.1484375Mb; avail=247693.87109375Mb
2025-04-03 05:38:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.010984
2025-04-03 05:38:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024894
2025-04-03 05:38:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=7391.1484375Mb; avail=247693.87109375Mb
2025-04-03 05:38:35 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 6.778 | nll_loss 3.302 | ppl 9.86 | wps 3869 | wpb 2070.5 | bsz 122.7 | num_updates 630 | best_loss 6.778
2025-04-03 05:38:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 630 updates
2025-04-03 05:38:35 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 05:39:14 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 05:39:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt (epoch 5 @ 630 updates, score 6.778) (writing took 63.599893581005745 seconds)
2025-04-03 05:39:39 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2025-04-03 05:39:39 | INFO | train | epoch 005 | loss 7.028 | nll_loss 3.806 | ppl 13.99 | wps 1331 | ups 0.29 | wpb 4549.7 | bsz 252.8 | num_updates 630 | lr 7.56e-06 | gnorm 2.07 | train_wall 352 | gb_free 16.3 | wall 2143
2025-04-03 05:39:39 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:mr-hi': 31849}; raw total size: 31849
2025-04-03 05:39:39 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:mr-hi': 31849}; resampled total size: 31849
2025-04-03 05:39:39 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:mr-hi': 1.0}
2025-04-03 05:39:39 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001006
2025-04-03 05:39:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=10314.83984375Mb; avail=244770.19140625Mb
2025-04-03 05:39:39 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000676
2025-04-03 05:39:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003777
2025-04-03 05:39:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=10315.33203125Mb; avail=244769.69921875Mb
2025-04-03 05:39:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000106
2025-04-03 05:39:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=10315.33203125Mb; avail=244769.69921875Mb
2025-04-03 05:39:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001128
2025-04-03 05:39:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.005351
2025-04-03 05:39:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=10315.33203125Mb; avail=244769.69921875Mb
2025-04-03 05:39:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 126
2025-04-03 05:39:39 | INFO | fairseq.trainer | begin training epoch 6
2025-04-03 05:39:39 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-03 05:39:48 | INFO | train_inner | epoch 006:      2 / 126 loss=6.781, nll_loss=3.502, ppl=11.33, wps=94.5, ups=0.02, wpb=4145, bsz=284.5, num_updates=632, lr=7.584e-06, gnorm=2.462, train_wall=10, gb_free=14.4, wall=2153
2025-04-03 05:39:54 | INFO | train_inner | epoch 006:      4 / 126 loss=6.833, nll_loss=3.564, ppl=11.83, wps=1850.6, ups=0.36, wpb=5085, bsz=292, num_updates=634, lr=7.608e-06, gnorm=1.753, train_wall=5, gb_free=10.8, wall=2158
2025-04-03 05:39:59 | INFO | train_inner | epoch 006:      6 / 126 loss=7.005, nll_loss=3.786, ppl=13.79, wps=1502.2, ups=0.37, wpb=4013, bsz=232, num_updates=636, lr=7.632e-06, gnorm=2.231, train_wall=5, gb_free=12.1, wall=2163
2025-04-03 05:40:05 | INFO | train_inner | epoch 006:      8 / 126 loss=6.975, nll_loss=3.742, ppl=13.38, wps=1720.4, ups=0.37, wpb=4637.5, bsz=272, num_updates=638, lr=7.656e-06, gnorm=1.879, train_wall=5, gb_free=12.2, wall=2169
2025-04-03 05:40:10 | INFO | train_inner | epoch 006:     10 / 126 loss=6.887, nll_loss=3.637, ppl=12.44, wps=1762.8, ups=0.38, wpb=4597, bsz=308, num_updates=640, lr=7.68e-06, gnorm=2.115, train_wall=5, gb_free=13.2, wall=2174
2025-04-03 05:40:15 | INFO | train_inner | epoch 006:     12 / 126 loss=7.007, nll_loss=3.78, ppl=13.74, wps=1655.8, ups=0.37, wpb=4434.5, bsz=160, num_updates=642, lr=7.704e-06, gnorm=2.291, train_wall=5, gb_free=11.2, wall=2179
2025-04-03 05:40:21 | INFO | train_inner | epoch 006:     14 / 126 loss=6.961, nll_loss=3.711, ppl=13.1, wps=1689.7, ups=0.36, wpb=4656, bsz=192, num_updates=644, lr=7.728e-06, gnorm=2.119, train_wall=6, gb_free=13.3, wall=2185
2025-04-03 05:40:26 | INFO | train_inner | epoch 006:     16 / 126 loss=6.888, nll_loss=3.628, ppl=12.36, wps=1864.1, ups=0.36, wpb=5236, bsz=340, num_updates=646, lr=7.752e-06, gnorm=1.863, train_wall=6, gb_free=14.5, wall=2190
2025-04-03 05:40:32 | INFO | train_inner | epoch 006:     18 / 126 loss=6.889, nll_loss=3.618, ppl=12.28, wps=1470.5, ups=0.36, wpb=4105, bsz=244, num_updates=648, lr=7.776e-06, gnorm=2.515, train_wall=6, gb_free=10.3, wall=2196
2025-04-03 05:40:38 | INFO | train_inner | epoch 006:     20 / 126 loss=6.957, nll_loss=3.698, ppl=12.98, wps=1620.5, ups=0.35, wpb=4615.5, bsz=200, num_updates=650, lr=7.8e-06, gnorm=1.898, train_wall=6, gb_free=11.4, wall=2202
2025-04-03 05:40:43 | INFO | train_inner | epoch 006:     22 / 126 loss=6.98, nll_loss=3.752, ppl=13.47, wps=1421.6, ups=0.4, wpb=3567.5, bsz=220, num_updates=652, lr=7.824e-06, gnorm=2.207, train_wall=5, gb_free=14.4, wall=2207
2025-04-03 05:40:48 | INFO | train_inner | epoch 006:     24 / 126 loss=6.934, nll_loss=3.689, ppl=12.89, wps=1478.3, ups=0.39, wpb=3775.5, bsz=160, num_updates=654, lr=7.848e-06, gnorm=2.281, train_wall=5, gb_free=12.6, wall=2212
2025-04-03 05:40:53 | INFO | train_inner | epoch 006:     26 / 126 loss=6.896, nll_loss=3.646, ppl=12.52, wps=1396.6, ups=0.38, wpb=3722.5, bsz=224, num_updates=656, lr=7.872e-06, gnorm=2.096, train_wall=5, gb_free=11.9, wall=2217
2025-04-03 05:40:59 | INFO | train_inner | epoch 006:     28 / 126 loss=6.843, nll_loss=3.575, ppl=11.92, wps=1866.6, ups=0.35, wpb=5284.5, bsz=300, num_updates=658, lr=7.896e-06, gnorm=2.03, train_wall=6, gb_free=11.2, wall=2223
2025-04-03 05:41:05 | INFO | train_inner | epoch 006:     30 / 126 loss=6.652, nll_loss=3.334, ppl=10.09, wps=1756.1, ups=0.32, wpb=5432.5, bsz=396, num_updates=660, lr=7.92e-06, gnorm=1.798, train_wall=6, gb_free=9.4, wall=2229
2025-04-03 05:41:11 | INFO | train_inner | epoch 006:     32 / 126 loss=6.896, nll_loss=3.611, ppl=12.22, wps=1717.2, ups=0.35, wpb=4868.5, bsz=188, num_updates=662, lr=7.944e-06, gnorm=1.979, train_wall=6, gb_free=8.9, wall=2235
2025-04-03 05:41:17 | INFO | train_inner | epoch 006:     34 / 126 loss=6.823, nll_loss=3.549, ppl=11.7, wps=1715.6, ups=0.34, wpb=5060.5, bsz=308, num_updates=664, lr=7.968e-06, gnorm=2.097, train_wall=6, gb_free=13, wall=2241
2025-04-03 05:41:22 | INFO | train_inner | epoch 006:     36 / 126 loss=6.906, nll_loss=3.646, ppl=12.52, wps=1672.7, ups=0.38, wpb=4447, bsz=224, num_updates=666, lr=7.992e-06, gnorm=2.047, train_wall=5, gb_free=13.8, wall=2246
2025-04-03 05:41:27 | INFO | train_inner | epoch 006:     38 / 126 loss=7.035, nll_loss=3.826, ppl=14.18, wps=1513.3, ups=0.37, wpb=4039, bsz=276, num_updates=668, lr=8.016e-06, gnorm=2.193, train_wall=5, gb_free=13.1, wall=2251
2025-04-03 05:41:33 | INFO | train_inner | epoch 006:     40 / 126 loss=6.749, nll_loss=3.467, ppl=11.06, wps=1680.8, ups=0.35, wpb=4804.5, bsz=332, num_updates=670, lr=8.04e-06, gnorm=1.799, train_wall=6, gb_free=13.5, wall=2257
2025-04-03 05:41:38 | INFO | train_inner | epoch 006:     42 / 126 loss=7.094, nll_loss=3.89, ppl=14.83, wps=1544.8, ups=0.37, wpb=4220, bsz=180, num_updates=672, lr=8.064e-06, gnorm=2.112, train_wall=5, gb_free=13.8, wall=2262
2025-04-03 05:41:44 | INFO | train_inner | epoch 006:     44 / 126 loss=6.851, nll_loss=3.593, ppl=12.07, wps=1697.3, ups=0.36, wpb=4653, bsz=304, num_updates=674, lr=8.088e-06, gnorm=2.109, train_wall=5, gb_free=10.9, wall=2268
2025-04-03 05:41:49 | INFO | train_inner | epoch 006:     46 / 126 loss=6.975, nll_loss=3.741, ppl=13.37, wps=1500.1, ups=0.36, wpb=4143.5, bsz=236, num_updates=676, lr=8.112e-06, gnorm=2.034, train_wall=6, gb_free=12.7, wall=2273
2025-04-03 05:41:55 | INFO | train_inner | epoch 006:     48 / 126 loss=6.704, nll_loss=3.412, ppl=10.64, wps=1579, ups=0.37, wpb=4264, bsz=356, num_updates=678, lr=8.136e-06, gnorm=1.845, train_wall=5, gb_free=14.7, wall=2279
2025-04-03 05:42:00 | INFO | train_inner | epoch 006:     50 / 126 loss=6.956, nll_loss=3.714, ppl=13.12, wps=1649, ups=0.35, wpb=4653.5, bsz=240, num_updates=680, lr=8.16e-06, gnorm=1.955, train_wall=6, gb_free=13.5, wall=2285
2025-04-03 05:42:06 | INFO | train_inner | epoch 006:     52 / 126 loss=6.875, nll_loss=3.614, ppl=12.24, wps=1575.5, ups=0.38, wpb=4169, bsz=220, num_updates=682, lr=8.184e-06, gnorm=2.203, train_wall=5, gb_free=14.1, wall=2290
2025-04-03 05:42:11 | INFO | train_inner | epoch 006:     54 / 126 loss=6.796, nll_loss=3.515, ppl=11.43, wps=1642.1, ups=0.35, wpb=4691, bsz=280, num_updates=684, lr=8.208e-06, gnorm=1.851, train_wall=6, gb_free=10.4, wall=2296
2025-04-03 05:42:17 | INFO | train_inner | epoch 006:     56 / 126 loss=6.844, nll_loss=3.579, ppl=11.95, wps=1647.2, ups=0.38, wpb=4303, bsz=228, num_updates=686, lr=8.232e-06, gnorm=1.886, train_wall=5, gb_free=13.4, wall=2301
2025-04-03 05:42:22 | INFO | train_inner | epoch 006:     58 / 126 loss=6.738, nll_loss=3.444, ppl=10.89, wps=1702.8, ups=0.37, wpb=4659.5, bsz=252, num_updates=688, lr=8.256e-06, gnorm=1.888, train_wall=5, gb_free=14, wall=2306
2025-04-03 05:42:28 | INFO | train_inner | epoch 006:     60 / 126 loss=6.778, nll_loss=3.493, ppl=11.26, wps=1671.5, ups=0.36, wpb=4678, bsz=276, num_updates=690, lr=8.28e-06, gnorm=1.908, train_wall=6, gb_free=12.7, wall=2312
2025-04-03 05:42:34 | INFO | train_inner | epoch 006:     62 / 126 loss=6.785, nll_loss=3.481, ppl=11.16, wps=1714, ups=0.34, wpb=5016.5, bsz=232, num_updates=692, lr=8.304e-06, gnorm=1.828, train_wall=6, gb_free=8.8, wall=2318
2025-04-03 05:42:39 | INFO | train_inner | epoch 006:     64 / 126 loss=6.83, nll_loss=3.557, ppl=11.77, wps=1638.1, ups=0.36, wpb=4597.5, bsz=272, num_updates=694, lr=8.328e-06, gnorm=1.857, train_wall=6, gb_free=13.1, wall=2323
2025-04-03 05:42:45 | INFO | train_inner | epoch 006:     66 / 126 loss=6.856, nll_loss=3.572, ppl=11.89, wps=1423.2, ups=0.34, wpb=4164, bsz=176, num_updates=696, lr=8.352e-06, gnorm=2.017, train_wall=6, gb_free=9.9, wall=2329
2025-04-03 05:42:51 | INFO | train_inner | epoch 006:     68 / 126 loss=6.827, nll_loss=3.543, ppl=11.66, wps=1755.3, ups=0.35, wpb=5022, bsz=284, num_updates=698, lr=8.376e-06, gnorm=1.744, train_wall=6, gb_free=12.1, wall=2335
2025-04-03 05:42:56 | INFO | train_inner | epoch 006:     70 / 126 loss=6.898, nll_loss=3.638, ppl=12.45, wps=1654.8, ups=0.36, wpb=4534, bsz=232, num_updates=700, lr=8.4e-06, gnorm=1.957, train_wall=5, gb_free=13.2, wall=2340
2025-04-03 05:43:02 | INFO | train_inner | epoch 006:     72 / 126 loss=6.824, nll_loss=3.571, ppl=11.88, wps=1468.2, ups=0.37, wpb=4004.5, bsz=292, num_updates=702, lr=8.424e-06, gnorm=2.071, train_wall=5, gb_free=10.4, wall=2346
2025-04-03 05:43:07 | INFO | train_inner | epoch 006:     74 / 126 loss=6.847, nll_loss=3.601, ppl=12.14, wps=1496.3, ups=0.37, wpb=4087.5, bsz=284, num_updates=704, lr=8.448e-06, gnorm=1.938, train_wall=5, gb_free=10, wall=2351
2025-04-03 05:43:13 | INFO | train_inner | epoch 006:     76 / 126 loss=6.704, nll_loss=3.406, ppl=10.6, wps=1870.6, ups=0.34, wpb=5432, bsz=376, num_updates=706, lr=8.472e-06, gnorm=1.871, train_wall=6, gb_free=10.2, wall=2357
2025-04-03 05:43:19 | INFO | train_inner | epoch 006:     78 / 126 loss=6.881, nll_loss=3.595, ppl=12.08, wps=1641.2, ups=0.35, wpb=4735.5, bsz=156, num_updates=708, lr=8.496e-06, gnorm=2.088, train_wall=6, gb_free=11.5, wall=2363
2025-04-03 05:43:25 | INFO | train_inner | epoch 006:     80 / 126 loss=6.905, nll_loss=3.646, ppl=12.52, wps=1678.7, ups=0.34, wpb=4878, bsz=240, num_updates=710, lr=8.52e-06, gnorm=2.076, train_wall=6, gb_free=10.2, wall=2369
2025-04-03 05:43:30 | INFO | train_inner | epoch 006:     82 / 126 loss=6.967, nll_loss=3.711, ppl=13.1, wps=1731.3, ups=0.36, wpb=4774.5, bsz=196, num_updates=712, lr=8.544e-06, gnorm=1.862, train_wall=6, gb_free=10.8, wall=2374
2025-04-03 05:43:36 | INFO | train_inner | epoch 006:     84 / 126 loss=6.818, nll_loss=3.519, ppl=11.47, wps=1741.3, ups=0.35, wpb=4989.5, bsz=224, num_updates=714, lr=8.568e-06, gnorm=1.87, train_wall=6, gb_free=10.3, wall=2380
2025-04-03 05:43:41 | INFO | train_inner | epoch 006:     86 / 126 loss=6.698, nll_loss=3.382, ppl=10.43, wps=1823.1, ups=0.36, wpb=5062.5, bsz=280, num_updates=716, lr=8.592e-06, gnorm=1.83, train_wall=6, gb_free=13.2, wall=2385
2025-04-03 05:43:47 | INFO | train_inner | epoch 006:     88 / 126 loss=6.856, nll_loss=3.597, ppl=12.1, wps=1696, ups=0.37, wpb=4601, bsz=276, num_updates=718, lr=8.616e-06, gnorm=2.126, train_wall=5, gb_free=11.6, wall=2391
2025-04-03 05:43:52 | INFO | train_inner | epoch 006:     90 / 126 loss=6.894, nll_loss=3.637, ppl=12.44, wps=1515, ups=0.35, wpb=4284, bsz=184, num_updates=720, lr=8.64e-06, gnorm=1.884, train_wall=6, gb_free=10.5, wall=2397
2025-04-03 05:43:58 | INFO | train_inner | epoch 006:     92 / 126 loss=6.725, nll_loss=3.431, ppl=10.79, wps=1707.2, ups=0.35, wpb=4909.5, bsz=272, num_updates=722, lr=8.664e-06, gnorm=1.833, train_wall=6, gb_free=11.6, wall=2402
2025-04-03 05:44:04 | INFO | train_inner | epoch 006:     94 / 126 loss=6.777, nll_loss=3.484, ppl=11.19, wps=1654.9, ups=0.34, wpb=4833, bsz=228, num_updates=724, lr=8.688e-06, gnorm=2.2, train_wall=6, gb_free=9.4, wall=2408
2025-04-03 05:44:09 | INFO | train_inner | epoch 006:     96 / 126 loss=6.866, nll_loss=3.592, ppl=12.06, wps=1573, ups=0.38, wpb=4185.5, bsz=216, num_updates=726, lr=8.712e-06, gnorm=2.101, train_wall=5, gb_free=14.1, wall=2413
2025-04-03 05:44:15 | INFO | train_inner | epoch 006:     98 / 126 loss=6.808, nll_loss=3.522, ppl=11.49, wps=1677.3, ups=0.35, wpb=4728, bsz=228, num_updates=728, lr=8.736e-06, gnorm=1.866, train_wall=6, gb_free=9.2, wall=2419
2025-04-03 05:44:20 | INFO | train_inner | epoch 006:    100 / 126 loss=6.862, nll_loss=3.59, ppl=12.04, wps=1668.5, ups=0.4, wpb=4144.5, bsz=192, num_updates=730, lr=8.76e-06, gnorm=2.116, train_wall=5, gb_free=14.4, wall=2424
2025-04-03 05:44:26 | INFO | train_inner | epoch 006:    102 / 126 loss=6.932, nll_loss=3.685, ppl=12.86, wps=1555.2, ups=0.35, wpb=4434.5, bsz=272, num_updates=732, lr=8.784e-06, gnorm=2.078, train_wall=6, gb_free=9.6, wall=2430
2025-04-03 05:44:31 | INFO | train_inner | epoch 006:    104 / 126 loss=6.712, nll_loss=3.408, ppl=10.61, wps=1736.1, ups=0.34, wpb=5066.5, bsz=344, num_updates=734, lr=8.808e-06, gnorm=1.873, train_wall=6, gb_free=13.9, wall=2436
2025-04-03 05:44:37 | INFO | train_inner | epoch 006:    106 / 126 loss=6.796, nll_loss=3.5, ppl=11.32, wps=1676.9, ups=0.34, wpb=4902.5, bsz=200, num_updates=736, lr=8.832e-06, gnorm=1.847, train_wall=6, gb_free=10.8, wall=2441
2025-04-03 05:44:43 | INFO | train_inner | epoch 006:    108 / 126 loss=6.782, nll_loss=3.489, ppl=11.23, wps=1846.5, ups=0.35, wpb=5280, bsz=260, num_updates=738, lr=8.856e-06, gnorm=1.865, train_wall=6, gb_free=12.2, wall=2447
2025-04-03 05:44:48 | INFO | train_inner | epoch 006:    110 / 126 loss=6.955, nll_loss=3.732, ppl=13.29, wps=1613.9, ups=0.39, wpb=4134.5, bsz=248, num_updates=740, lr=8.88e-06, gnorm=2.153, train_wall=5, gb_free=13.4, wall=2452
2025-04-03 05:44:54 | INFO | train_inner | epoch 006:    112 / 126 loss=6.832, nll_loss=3.555, ppl=11.75, wps=1703.9, ups=0.35, wpb=4805.5, bsz=252, num_updates=742, lr=8.904e-06, gnorm=1.879, train_wall=6, gb_free=12.3, wall=2458
2025-04-03 05:44:59 | INFO | train_inner | epoch 006:    114 / 126 loss=6.601, nll_loss=3.275, ppl=9.68, wps=1788.8, ups=0.37, wpb=4771, bsz=372, num_updates=744, lr=8.928e-06, gnorm=1.683, train_wall=5, gb_free=13.1, wall=2463
2025-04-03 05:45:05 | INFO | train_inner | epoch 006:    116 / 126 loss=7.012, nll_loss=3.777, ppl=13.71, wps=1379.3, ups=0.36, wpb=3833, bsz=200, num_updates=746, lr=8.952e-06, gnorm=2.237, train_wall=6, gb_free=10.5, wall=2469
2025-04-03 05:45:10 | INFO | train_inner | epoch 006:    118 / 126 loss=6.859, nll_loss=3.59, ppl=12.04, wps=1569.7, ups=0.37, wpb=4293, bsz=244, num_updates=748, lr=8.976e-06, gnorm=1.956, train_wall=5, gb_free=13.5, wall=2474
2025-04-03 05:45:16 | INFO | train_inner | epoch 006:    120 / 126 loss=6.703, nll_loss=3.391, ppl=10.49, wps=1561, ups=0.36, wpb=4321, bsz=204, num_updates=750, lr=9e-06, gnorm=1.978, train_wall=6, gb_free=12.5, wall=2480
2025-04-03 05:45:21 | INFO | train_inner | epoch 006:    122 / 126 loss=6.728, nll_loss=3.421, ppl=10.71, wps=1657.8, ups=0.37, wpb=4477, bsz=264, num_updates=752, lr=9.024e-06, gnorm=1.851, train_wall=5, gb_free=14.4, wall=2485
2025-04-03 05:45:27 | INFO | train_inner | epoch 006:    124 / 126 loss=6.769, nll_loss=3.499, ppl=11.3, wps=1694.3, ups=0.35, wpb=4792, bsz=300, num_updates=754, lr=9.048e-06, gnorm=1.852, train_wall=6, gb_free=11.7, wall=2491
2025-04-03 05:45:31 | INFO | train_inner | epoch 006:    126 / 126 loss=6.766, nll_loss=3.488, ppl=11.22, wps=1737.6, ups=0.49, wpb=3576.5, bsz=200, num_updates=756, lr=9.072e-06, gnorm=2.238, train_wall=4, gb_free=17.9, wall=2495
2025-04-03 05:45:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-03 05:45:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=7984.51953125Mb; avail=247100.546875Mb
2025-04-03 05:45:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000638
2025-04-03 05:45:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=7984.51953125Mb; avail=247100.546875Mb
2025-04-03 05:45:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.013017
2025-04-03 05:45:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=7984.51953125Mb; avail=247100.546875Mb
2025-04-03 05:45:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.010830
2025-04-03 05:45:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024868
2025-04-03 05:45:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=7984.51953125Mb; avail=247100.546875Mb
2025-04-03 05:45:45 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 6.649 | nll_loss 3.145 | ppl 8.85 | wps 3872.5 | wpb 2070.5 | bsz 122.7 | num_updates 756 | best_loss 6.649
2025-04-03 05:45:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 756 updates
2025-04-03 05:45:45 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 05:46:24 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 05:46:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt (epoch 6 @ 756 updates, score 6.649) (writing took 63.77369578008074 seconds)
2025-04-03 05:46:49 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2025-04-03 05:46:49 | INFO | train | epoch 006 | loss 6.846 | nll_loss 3.576 | ppl 11.92 | wps 1332 | ups 0.29 | wpb 4549.7 | bsz 252.8 | num_updates 756 | lr 9.072e-06 | gnorm 2.001 | train_wall 352 | gb_free 17.9 | wall 2573
2025-04-03 05:46:49 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:mr-hi': 31849}; raw total size: 31849
2025-04-03 05:46:49 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:mr-hi': 31849}; resampled total size: 31849
2025-04-03 05:46:49 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:mr-hi': 1.0}
2025-04-03 05:46:49 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001110
2025-04-03 05:46:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=12776.45703125Mb; avail=242308.578125Mb
2025-04-03 05:46:49 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000409
2025-04-03 05:46:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003254
2025-04-03 05:46:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=12776.45703125Mb; avail=242308.578125Mb
2025-04-03 05:46:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000091
2025-04-03 05:46:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=12776.45703125Mb; avail=242308.578125Mb
2025-04-03 05:46:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001176
2025-04-03 05:46:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.004872
2025-04-03 05:46:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=12776.45703125Mb; avail=242308.578125Mb
2025-04-03 05:46:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 126
2025-04-03 05:46:49 | INFO | fairseq.trainer | begin training epoch 7
2025-04-03 05:46:49 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-03 05:46:54 | INFO | train_inner | epoch 007:      2 / 126 loss=6.874, nll_loss=3.609, ppl=12.2, wps=89, ups=0.02, wpb=3690, bsz=140, num_updates=758, lr=9.096e-06, gnorm=2.174, train_wall=5, gb_free=10.7, wall=2578
2025-04-03 05:46:59 | INFO | train_inner | epoch 007:      4 / 126 loss=6.707, nll_loss=3.41, ppl=10.63, wps=1824, ups=0.37, wpb=4962.5, bsz=320, num_updates=760, lr=9.12e-06, gnorm=1.935, train_wall=5, gb_free=12.3, wall=2583
2025-04-03 05:47:05 | INFO | train_inner | epoch 007:      6 / 126 loss=6.953, nll_loss=3.713, ppl=13.12, wps=1339.1, ups=0.35, wpb=3791.5, bsz=236, num_updates=762, lr=9.144e-06, gnorm=2.052, train_wall=6, gb_free=10.1, wall=2589
2025-04-03 05:47:10 | INFO | train_inner | epoch 007:      8 / 126 loss=6.684, nll_loss=3.373, ppl=10.36, wps=1769.4, ups=0.38, wpb=4613, bsz=308, num_updates=764, lr=9.168e-06, gnorm=1.759, train_wall=5, gb_free=12.8, wall=2594
2025-04-03 05:47:16 | INFO | train_inner | epoch 007:     10 / 126 loss=6.753, nll_loss=3.468, ppl=11.07, wps=1903.4, ups=0.37, wpb=5206.5, bsz=344, num_updates=766, lr=9.192e-06, gnorm=2.085, train_wall=5, gb_free=9.8, wall=2600
2025-04-03 05:47:21 | INFO | train_inner | epoch 007:     12 / 126 loss=6.85, nll_loss=3.574, ppl=11.91, wps=1457.7, ups=0.39, wpb=3705.5, bsz=184, num_updates=768, lr=9.216e-06, gnorm=2.063, train_wall=5, gb_free=15.2, wall=2605
2025-04-03 05:47:26 | INFO | train_inner | epoch 007:     14 / 126 loss=6.809, nll_loss=3.532, ppl=11.57, wps=1697.3, ups=0.37, wpb=4590.5, bsz=232, num_updates=770, lr=9.24e-06, gnorm=1.78, train_wall=5, gb_free=12.9, wall=2610
2025-04-03 05:47:32 | INFO | train_inner | epoch 007:     16 / 126 loss=6.845, nll_loss=3.58, ppl=11.96, wps=1446.5, ups=0.36, wpb=3974.5, bsz=264, num_updates=772, lr=9.264e-06, gnorm=2.01, train_wall=5, gb_free=10.7, wall=2616
2025-04-03 05:47:37 | INFO | train_inner | epoch 007:     18 / 126 loss=6.761, nll_loss=3.457, ppl=10.98, wps=1583, ups=0.36, wpb=4361.5, bsz=188, num_updates=774, lr=9.288e-06, gnorm=1.971, train_wall=6, gb_free=11.9, wall=2621
2025-04-03 05:47:43 | INFO | train_inner | epoch 007:     20 / 126 loss=6.782, nll_loss=3.474, ppl=11.11, wps=1595.3, ups=0.35, wpb=4526, bsz=160, num_updates=776, lr=9.312e-06, gnorm=1.883, train_wall=6, gb_free=12.9, wall=2627
2025-04-03 05:47:49 | INFO | train_inner | epoch 007:     22 / 126 loss=6.686, nll_loss=3.365, ppl=10.3, wps=1677.6, ups=0.35, wpb=4806, bsz=276, num_updates=778, lr=9.336e-06, gnorm=1.879, train_wall=6, gb_free=12.1, wall=2633
2025-04-03 05:47:54 | INFO | train_inner | epoch 007:     24 / 126 loss=6.77, nll_loss=3.471, ppl=11.09, wps=1866.4, ups=0.36, wpb=5157.5, bsz=256, num_updates=780, lr=9.36e-06, gnorm=1.689, train_wall=6, gb_free=12.5, wall=2638
2025-04-03 05:47:59 | INFO | train_inner | epoch 007:     26 / 126 loss=6.72, nll_loss=3.43, ppl=10.78, wps=1517.6, ups=0.38, wpb=3995, bsz=240, num_updates=782, lr=9.384e-06, gnorm=2.109, train_wall=5, gb_free=12.6, wall=2643
2025-04-03 05:48:05 | INFO | train_inner | epoch 007:     28 / 126 loss=6.521, nll_loss=3.169, ppl=8.99, wps=1880.2, ups=0.34, wpb=5464, bsz=356, num_updates=784, lr=9.408e-06, gnorm=1.604, train_wall=6, gb_free=11.5, wall=2649
2025-04-03 05:48:16 | INFO | train_inner | epoch 007:     30 / 126 loss=6.847, nll_loss=3.575, ppl=11.92, wps=963.9, ups=0.19, wpb=5132, bsz=268, num_updates=786, lr=9.432e-06, gnorm=1.996, train_wall=11, gb_free=9.6, wall=2660
2025-04-03 05:48:21 | INFO | train_inner | epoch 007:     32 / 126 loss=6.732, nll_loss=3.429, ppl=10.77, wps=1615, ups=0.37, wpb=4341.5, bsz=212, num_updates=788, lr=9.456e-06, gnorm=2.017, train_wall=5, gb_free=10.6, wall=2665
2025-04-03 05:48:27 | INFO | train_inner | epoch 007:     34 / 126 loss=6.7, nll_loss=3.37, ppl=10.34, wps=1785.1, ups=0.33, wpb=5389.5, bsz=240, num_updates=790, lr=9.48e-06, gnorm=1.801, train_wall=6, gb_free=10.8, wall=2671
2025-04-03 05:48:33 | INFO | train_inner | epoch 007:     36 / 126 loss=6.688, nll_loss=3.365, ppl=10.3, wps=1754.1, ups=0.37, wpb=4725, bsz=292, num_updates=792, lr=9.504e-06, gnorm=1.753, train_wall=5, gb_free=12.2, wall=2677
2025-04-03 05:48:38 | INFO | train_inner | epoch 007:     38 / 126 loss=6.699, nll_loss=3.39, ppl=10.48, wps=1778.4, ups=0.37, wpb=4825, bsz=272, num_updates=794, lr=9.528e-06, gnorm=1.752, train_wall=5, gb_free=12.4, wall=2682
2025-04-03 05:48:44 | INFO | train_inner | epoch 007:     40 / 126 loss=6.661, nll_loss=3.338, ppl=10.11, wps=1791, ups=0.33, wpb=5348, bsz=256, num_updates=796, lr=9.552e-06, gnorm=1.726, train_wall=6, gb_free=10.7, wall=2688
2025-04-03 05:48:50 | INFO | train_inner | epoch 007:     42 / 126 loss=6.772, nll_loss=3.493, ppl=11.26, wps=1484.7, ups=0.35, wpb=4252, bsz=220, num_updates=798, lr=9.576e-06, gnorm=2.044, train_wall=6, gb_free=14.4, wall=2694
2025-04-03 05:48:55 | INFO | train_inner | epoch 007:     44 / 126 loss=6.699, nll_loss=3.412, ppl=10.64, wps=1592.8, ups=0.37, wpb=4265.5, bsz=252, num_updates=800, lr=9.6e-06, gnorm=1.794, train_wall=5, gb_free=14.1, wall=2699
2025-04-03 05:49:01 | INFO | train_inner | epoch 007:     46 / 126 loss=6.763, nll_loss=3.489, ppl=11.23, wps=1511.8, ups=0.36, wpb=4218.5, bsz=244, num_updates=802, lr=9.624e-06, gnorm=2.05, train_wall=6, gb_free=11.8, wall=2705
2025-04-03 05:49:06 | INFO | train_inner | epoch 007:     48 / 126 loss=6.704, nll_loss=3.394, ppl=10.51, wps=1578.9, ups=0.36, wpb=4390, bsz=232, num_updates=804, lr=9.648e-06, gnorm=2.035, train_wall=6, gb_free=12.3, wall=2710
2025-04-03 05:49:12 | INFO | train_inner | epoch 007:     50 / 126 loss=6.687, nll_loss=3.375, ppl=10.38, wps=1618.4, ups=0.35, wpb=4630.5, bsz=348, num_updates=806, lr=9.672e-06, gnorm=1.815, train_wall=6, gb_free=9.5, wall=2716
2025-04-03 05:49:17 | INFO | train_inner | epoch 007:     52 / 126 loss=6.605, nll_loss=3.259, ppl=9.57, wps=1512.9, ups=0.37, wpb=4101, bsz=224, num_updates=808, lr=9.696e-06, gnorm=1.975, train_wall=5, gb_free=10.7, wall=2721
2025-04-03 05:49:23 | INFO | train_inner | epoch 007:     54 / 126 loss=6.614, nll_loss=3.275, ppl=9.68, wps=1550.9, ups=0.36, wpb=4319, bsz=228, num_updates=810, lr=9.72e-06, gnorm=1.97, train_wall=6, gb_free=12.5, wall=2727
2025-04-03 05:49:28 | INFO | train_inner | epoch 007:     56 / 126 loss=6.664, nll_loss=3.356, ppl=10.24, wps=1576.1, ups=0.38, wpb=4182.5, bsz=272, num_updates=812, lr=9.744e-06, gnorm=1.886, train_wall=5, gb_free=14.5, wall=2732
2025-04-03 05:49:33 | INFO | train_inner | epoch 007:     58 / 126 loss=6.562, nll_loss=3.22, ppl=9.32, wps=1639.5, ups=0.44, wpb=3697.5, bsz=212.5, num_updates=814, lr=9.768e-06, gnorm=2.037, train_wall=4, gb_free=12.6, wall=2737
2025-04-03 05:49:38 | INFO | train_inner | epoch 007:     60 / 126 loss=6.803, nll_loss=3.529, ppl=11.54, wps=1801.9, ups=0.36, wpb=5015.5, bsz=276, num_updates=816, lr=9.792e-06, gnorm=2.016, train_wall=6, gb_free=10.1, wall=2742
2025-04-03 05:49:44 | INFO | train_inner | epoch 007:     62 / 126 loss=6.69, nll_loss=3.363, ppl=10.29, wps=1646.8, ups=0.34, wpb=4801, bsz=172, num_updates=818, lr=9.816e-06, gnorm=1.88, train_wall=6, gb_free=11.5, wall=2748
2025-04-03 05:49:50 | INFO | train_inner | epoch 007:     64 / 126 loss=6.714, nll_loss=3.395, ppl=10.52, wps=1547.2, ups=0.34, wpb=4515, bsz=176, num_updates=820, lr=9.84e-06, gnorm=1.863, train_wall=6, gb_free=10, wall=2754
2025-04-03 05:49:56 | INFO | train_inner | epoch 007:     66 / 126 loss=6.718, nll_loss=3.412, ppl=10.64, wps=1614.9, ups=0.33, wpb=4861.5, bsz=280, num_updates=822, lr=9.864e-06, gnorm=1.856, train_wall=6, gb_free=8.3, wall=2760
2025-04-03 05:50:02 | INFO | train_inner | epoch 007:     68 / 126 loss=6.924, nll_loss=3.666, ppl=12.69, wps=1470.9, ups=0.36, wpb=4060, bsz=148, num_updates=824, lr=9.888e-06, gnorm=2.278, train_wall=6, gb_free=11.2, wall=2766
2025-04-03 05:50:07 | INFO | train_inner | epoch 007:     70 / 126 loss=6.869, nll_loss=3.604, ppl=12.16, wps=1574.1, ups=0.35, wpb=4479, bsz=204, num_updates=826, lr=9.912e-06, gnorm=1.867, train_wall=6, gb_free=12.8, wall=2771
2025-04-03 05:50:12 | INFO | train_inner | epoch 007:     72 / 126 loss=6.67, nll_loss=3.354, ppl=10.22, wps=1640.3, ups=0.39, wpb=4227.5, bsz=236, num_updates=828, lr=9.936e-06, gnorm=1.906, train_wall=5, gb_free=11.8, wall=2776
2025-04-03 05:50:18 | INFO | train_inner | epoch 007:     74 / 126 loss=6.598, nll_loss=3.263, ppl=9.6, wps=1814, ups=0.35, wpb=5226, bsz=324, num_updates=830, lr=9.96e-06, gnorm=1.841, train_wall=6, gb_free=13.1, wall=2782
2025-04-03 05:50:24 | INFO | train_inner | epoch 007:     76 / 126 loss=6.534, nll_loss=3.197, ppl=9.17, wps=1669.2, ups=0.37, wpb=4529, bsz=320, num_updates=832, lr=9.984e-06, gnorm=1.644, train_wall=5, gb_free=13.2, wall=2788
2025-04-03 05:50:29 | INFO | train_inner | epoch 007:     78 / 126 loss=6.751, nll_loss=3.451, ppl=10.94, wps=1645.7, ups=0.34, wpb=4791.5, bsz=252, num_updates=834, lr=1.0008e-05, gnorm=1.84, train_wall=6, gb_free=13.7, wall=2793
2025-04-03 05:50:35 | INFO | train_inner | epoch 007:     80 / 126 loss=6.746, nll_loss=3.438, ppl=10.84, wps=1855.4, ups=0.36, wpb=5101.5, bsz=260, num_updates=836, lr=1.0032e-05, gnorm=1.82, train_wall=5, gb_free=13.6, wall=2799
2025-04-03 05:50:40 | INFO | train_inner | epoch 007:     82 / 126 loss=6.711, nll_loss=3.412, ppl=10.65, wps=1615.8, ups=0.41, wpb=3953.5, bsz=236, num_updates=838, lr=1.0056e-05, gnorm=2.202, train_wall=5, gb_free=11.9, wall=2804
2025-04-03 05:50:45 | INFO | train_inner | epoch 007:     84 / 126 loss=6.63, nll_loss=3.333, ppl=10.08, wps=1588.2, ups=0.39, wpb=4117, bsz=348, num_updates=840, lr=1.008e-05, gnorm=2.307, train_wall=5, gb_free=15.2, wall=2809
2025-04-03 05:50:51 | INFO | train_inner | epoch 007:     86 / 126 loss=6.634, nll_loss=3.313, ppl=9.94, wps=1625.6, ups=0.35, wpb=4674, bsz=292, num_updates=842, lr=1.0104e-05, gnorm=1.821, train_wall=6, gb_free=13.4, wall=2815
2025-04-03 05:50:57 | INFO | train_inner | epoch 007:     88 / 126 loss=6.541, nll_loss=3.182, ppl=9.08, wps=1851.4, ups=0.34, wpb=5514, bsz=340, num_updates=844, lr=1.0128e-05, gnorm=1.97, train_wall=6, gb_free=11.2, wall=2821
2025-04-03 05:51:02 | INFO | train_inner | epoch 007:     90 / 126 loss=6.661, nll_loss=3.345, ppl=10.16, wps=1685.3, ups=0.37, wpb=4601.5, bsz=252, num_updates=846, lr=1.0152e-05, gnorm=2.005, train_wall=5, gb_free=14.3, wall=2826
2025-04-03 05:51:08 | INFO | train_inner | epoch 007:     92 / 126 loss=6.71, nll_loss=3.398, ppl=10.54, wps=1714.6, ups=0.34, wpb=5001, bsz=260, num_updates=848, lr=1.0176e-05, gnorm=1.903, train_wall=6, gb_free=11.4, wall=2832
2025-04-03 05:51:14 | INFO | train_inner | epoch 007:     94 / 126 loss=6.582, nll_loss=3.246, ppl=9.49, wps=1658.1, ups=0.35, wpb=4689, bsz=304, num_updates=850, lr=1.02e-05, gnorm=2.015, train_wall=6, gb_free=12.3, wall=2838
2025-04-03 05:51:19 | INFO | train_inner | epoch 007:     96 / 126 loss=6.691, nll_loss=3.406, ppl=10.6, wps=1724.4, ups=0.38, wpb=4596.5, bsz=380, num_updates=852, lr=1.0224e-05, gnorm=1.985, train_wall=5, gb_free=14.8, wall=2843
2025-04-03 05:51:25 | INFO | train_inner | epoch 007:     98 / 126 loss=6.636, nll_loss=3.327, ppl=10.03, wps=1439.7, ups=0.36, wpb=4036.5, bsz=220, num_updates=854, lr=1.0248e-05, gnorm=2.192, train_wall=6, gb_free=12.4, wall=2849
2025-04-03 05:51:30 | INFO | train_inner | epoch 007:    100 / 126 loss=6.741, nll_loss=3.441, ppl=10.86, wps=1529.9, ups=0.38, wpb=4031.5, bsz=136, num_updates=856, lr=1.0272e-05, gnorm=2.17, train_wall=5, gb_free=13.6, wall=2854
2025-04-03 05:51:36 | INFO | train_inner | epoch 007:    102 / 126 loss=6.618, nll_loss=3.293, ppl=9.8, wps=1730.8, ups=0.34, wpb=5165, bsz=312, num_updates=858, lr=1.0296e-05, gnorm=2.132, train_wall=6, gb_free=10.5, wall=2860
2025-04-03 05:51:41 | INFO | train_inner | epoch 007:    104 / 126 loss=6.662, nll_loss=3.33, ppl=10.06, wps=1581.2, ups=0.35, wpb=4455, bsz=192, num_updates=860, lr=1.032e-05, gnorm=2.24, train_wall=6, gb_free=14.2, wall=2866
2025-04-03 05:51:47 | INFO | train_inner | epoch 007:    106 / 126 loss=6.727, nll_loss=3.411, ppl=10.64, wps=1511.2, ups=0.34, wpb=4410, bsz=224, num_updates=862, lr=1.0344e-05, gnorm=1.961, train_wall=6, gb_free=10.3, wall=2871
2025-04-03 05:51:53 | INFO | train_inner | epoch 007:    108 / 126 loss=6.639, nll_loss=3.302, ppl=9.86, wps=1669.1, ups=0.35, wpb=4826.5, bsz=256, num_updates=864, lr=1.0368e-05, gnorm=1.832, train_wall=6, gb_free=13.5, wall=2877
2025-04-03 05:51:58 | INFO | train_inner | epoch 007:    110 / 126 loss=6.684, nll_loss=3.357, ppl=10.25, wps=1698.4, ups=0.38, wpb=4492, bsz=176, num_updates=866, lr=1.0392e-05, gnorm=2.009, train_wall=5, gb_free=13.4, wall=2882
2025-04-03 05:52:04 | INFO | train_inner | epoch 007:    112 / 126 loss=6.606, nll_loss=3.297, ppl=9.83, wps=1716, ups=0.35, wpb=4890, bsz=336, num_updates=868, lr=1.0416e-05, gnorm=1.827, train_wall=6, gb_free=13.8, wall=2888
2025-04-03 05:52:10 | INFO | train_inner | epoch 007:    114 / 126 loss=6.61, nll_loss=3.293, ppl=9.8, wps=1508.1, ups=0.36, wpb=4158.5, bsz=236, num_updates=870, lr=1.044e-05, gnorm=1.987, train_wall=6, gb_free=9.6, wall=2894
2025-04-03 05:52:15 | INFO | train_inner | epoch 007:    116 / 126 loss=6.686, nll_loss=3.372, ppl=10.35, wps=1705.8, ups=0.35, wpb=4878.5, bsz=248, num_updates=872, lr=1.0464e-05, gnorm=1.788, train_wall=6, gb_free=12.9, wall=2899
2025-04-03 05:52:21 | INFO | train_inner | epoch 007:    118 / 126 loss=6.63, nll_loss=3.316, ppl=9.96, wps=1658, ups=0.38, wpb=4334.5, bsz=276, num_updates=874, lr=1.0488e-05, gnorm=1.769, train_wall=5, gb_free=12.1, wall=2905
2025-04-03 05:52:26 | INFO | train_inner | epoch 007:    120 / 126 loss=6.422, nll_loss=3.048, ppl=8.27, wps=1673.8, ups=0.35, wpb=4824.5, bsz=324, num_updates=876, lr=1.0512e-05, gnorm=1.664, train_wall=6, gb_free=13.8, wall=2910
2025-04-03 05:52:32 | INFO | train_inner | epoch 007:    122 / 126 loss=6.625, nll_loss=3.283, ppl=9.73, wps=1504.4, ups=0.35, wpb=4292, bsz=176, num_updates=878, lr=1.0536e-05, gnorm=1.898, train_wall=6, gb_free=10.3, wall=2916
2025-04-03 05:52:38 | INFO | train_inner | epoch 007:    124 / 126 loss=6.646, nll_loss=3.325, ppl=10.02, wps=1719.3, ups=0.36, wpb=4757.5, bsz=280, num_updates=880, lr=1.056e-05, gnorm=1.827, train_wall=6, gb_free=13.3, wall=2922
2025-04-03 05:52:42 | INFO | train_inner | epoch 007:    126 / 126 loss=6.444, nll_loss=3.065, ppl=8.37, wps=1646.6, ups=0.45, wpb=3664, bsz=196, num_updates=882, lr=1.0584e-05, gnorm=1.995, train_wall=4, gb_free=17.6, wall=2926
2025-04-03 05:52:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-03 05:52:42 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=9851.92578125Mb; avail=245233.11328125Mb
2025-04-03 05:52:42 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000643
2025-04-03 05:52:42 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=9851.92578125Mb; avail=245233.11328125Mb
2025-04-03 05:52:42 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.013069
2025-04-03 05:52:42 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=9851.92578125Mb; avail=245233.11328125Mb
2025-04-03 05:52:42 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.011055
2025-04-03 05:52:42 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.025172
2025-04-03 05:52:42 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=9851.92578125Mb; avail=245233.11328125Mb
2025-04-03 05:52:56 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 6.542 | nll_loss 3.011 | ppl 8.06 | wps 3867.3 | wpb 2070.5 | bsz 122.7 | num_updates 882 | best_loss 6.542
2025-04-03 05:52:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 882 updates
2025-04-03 05:52:56 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 05:53:33 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 05:53:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt (epoch 7 @ 882 updates, score 6.542) (writing took 62.3814913330134 seconds)
2025-04-03 05:53:59 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2025-04-03 05:53:59 | INFO | train | epoch 007 | loss 6.691 | nll_loss 3.38 | ppl 10.41 | wps 1334.1 | ups 0.29 | wpb 4549.7 | bsz 252.8 | num_updates 882 | lr 1.0584e-05 | gnorm 1.936 | train_wall 352 | gb_free 17.6 | wall 3003
2025-04-03 05:53:59 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:mr-hi': 31849}; raw total size: 31849
2025-04-03 05:53:59 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:mr-hi': 31849}; resampled total size: 31849
2025-04-03 05:53:59 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:mr-hi': 1.0}
2025-04-03 05:53:59 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001103
2025-04-03 05:53:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=14971.02734375Mb; avail=240113.96484375Mb
2025-04-03 05:53:59 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000551
2025-04-03 05:53:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003638
2025-04-03 05:53:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=14971.02734375Mb; avail=240113.96484375Mb
2025-04-03 05:53:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000089
2025-04-03 05:53:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=14971.02734375Mb; avail=240113.96484375Mb
2025-04-03 05:53:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001145
2025-04-03 05:53:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.005196
2025-04-03 05:53:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=14971.02734375Mb; avail=240113.96484375Mb
2025-04-03 05:53:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 126
2025-04-03 05:53:59 | INFO | fairseq.trainer | begin training epoch 8
2025-04-03 05:53:59 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-03 05:54:04 | INFO | train_inner | epoch 008:      2 / 126 loss=6.67, nll_loss=3.357, ppl=10.25, wps=94.1, ups=0.02, wpb=3850, bsz=196, num_updates=884, lr=1.0608e-05, gnorm=2.084, train_wall=5, gb_free=15.3, wall=3008
2025-04-03 05:54:09 | INFO | train_inner | epoch 008:      4 / 126 loss=6.602, nll_loss=3.281, ppl=9.72, wps=1672.3, ups=0.38, wpb=4363.5, bsz=252, num_updates=886, lr=1.0632e-05, gnorm=1.966, train_wall=5, gb_free=11.4, wall=3013
2025-04-03 05:54:15 | INFO | train_inner | epoch 008:      6 / 126 loss=6.677, nll_loss=3.358, ppl=10.25, wps=1612.3, ups=0.36, wpb=4537, bsz=144, num_updates=888, lr=1.0656e-05, gnorm=2.021, train_wall=6, gb_free=12, wall=3019
2025-04-03 05:54:20 | INFO | train_inner | epoch 008:      8 / 126 loss=6.599, nll_loss=3.263, ppl=9.6, wps=1756, ups=0.39, wpb=4486.5, bsz=268, num_updates=890, lr=1.068e-05, gnorm=1.829, train_wall=5, gb_free=14.2, wall=3024
2025-04-03 05:54:25 | INFO | train_inner | epoch 008:     10 / 126 loss=6.651, nll_loss=3.324, ppl=10.02, wps=1634, ups=0.37, wpb=4391, bsz=256, num_updates=892, lr=1.0704e-05, gnorm=1.833, train_wall=5, gb_free=10.1, wall=3029
2025-04-03 05:54:31 | INFO | train_inner | epoch 008:     12 / 126 loss=6.621, nll_loss=3.283, ppl=9.74, wps=1760.3, ups=0.36, wpb=4863.5, bsz=256, num_updates=894, lr=1.0728e-05, gnorm=1.77, train_wall=6, gb_free=10.8, wall=3035
2025-04-03 05:54:36 | INFO | train_inner | epoch 008:     14 / 126 loss=6.678, nll_loss=3.351, ppl=10.2, wps=1487.8, ups=0.37, wpb=3991.5, bsz=156, num_updates=896, lr=1.0752e-05, gnorm=1.959, train_wall=5, gb_free=14.7, wall=3040
2025-04-03 05:54:41 | INFO | train_inner | epoch 008:     16 / 126 loss=6.517, nll_loss=3.167, ppl=8.98, wps=1689.6, ups=0.37, wpb=4552, bsz=292, num_updates=898, lr=1.0776e-05, gnorm=1.863, train_wall=5, gb_free=11.1, wall=3045
2025-04-03 05:54:47 | INFO | train_inner | epoch 008:     18 / 126 loss=6.533, nll_loss=3.188, ppl=9.11, wps=1555.4, ups=0.36, wpb=4330, bsz=260, num_updates=900, lr=1.08e-05, gnorm=1.83, train_wall=6, gb_free=14.6, wall=3051
2025-04-03 05:54:52 | INFO | train_inner | epoch 008:     20 / 126 loss=6.447, nll_loss=3.071, ppl=8.4, wps=1639.8, ups=0.37, wpb=4442, bsz=240, num_updates=902, lr=1.0824e-05, gnorm=1.802, train_wall=5, gb_free=10.1, wall=3056
2025-04-03 05:54:58 | INFO | train_inner | epoch 008:     22 / 126 loss=6.706, nll_loss=3.405, ppl=10.59, wps=1514.8, ups=0.36, wpb=4169, bsz=208, num_updates=904, lr=1.0848e-05, gnorm=2.177, train_wall=5, gb_free=9.8, wall=3062
2025-04-03 05:55:04 | INFO | train_inner | epoch 008:     24 / 126 loss=6.525, nll_loss=3.164, ppl=8.97, wps=1798.1, ups=0.34, wpb=5264.5, bsz=256, num_updates=906, lr=1.0872e-05, gnorm=1.99, train_wall=6, gb_free=13.6, wall=3068
2025-04-03 05:55:09 | INFO | train_inner | epoch 008:     26 / 126 loss=6.611, nll_loss=3.271, ppl=9.65, wps=1650.5, ups=0.37, wpb=4412, bsz=196, num_updates=908, lr=1.0896e-05, gnorm=1.979, train_wall=5, gb_free=13.7, wall=3073
2025-04-03 05:55:15 | INFO | train_inner | epoch 008:     28 / 126 loss=6.56, nll_loss=3.21, ppl=9.25, wps=1500.3, ups=0.35, wpb=4279.5, bsz=188, num_updates=910, lr=1.092e-05, gnorm=1.866, train_wall=6, gb_free=13.2, wall=3079
2025-04-03 05:55:20 | INFO | train_inner | epoch 008:     30 / 126 loss=6.587, nll_loss=3.251, ppl=9.52, wps=1753, ups=0.4, wpb=4356, bsz=256, num_updates=912, lr=1.0944e-05, gnorm=1.96, train_wall=5, gb_free=10.9, wall=3084
2025-04-03 05:55:25 | INFO | train_inner | epoch 008:     32 / 126 loss=6.542, nll_loss=3.182, ppl=9.07, wps=1653.5, ups=0.35, wpb=4732.5, bsz=236, num_updates=914, lr=1.0968e-05, gnorm=1.832, train_wall=6, gb_free=8.8, wall=3090
2025-04-03 05:55:31 | INFO | train_inner | epoch 008:     34 / 126 loss=6.622, nll_loss=3.29, ppl=9.78, wps=1700.9, ups=0.35, wpb=4928.5, bsz=264, num_updates=916, lr=1.0992e-05, gnorm=1.821, train_wall=6, gb_free=13.2, wall=3095
2025-04-03 05:55:37 | INFO | train_inner | epoch 008:     36 / 126 loss=6.609, nll_loss=3.275, ppl=9.68, wps=1471.3, ups=0.34, wpb=4277.5, bsz=204, num_updates=918, lr=1.1016e-05, gnorm=2.068, train_wall=6, gb_free=12.8, wall=3101
2025-04-03 05:55:42 | INFO | train_inner | epoch 008:     38 / 126 loss=6.621, nll_loss=3.289, ppl=9.77, wps=1585.1, ups=0.38, wpb=4198.5, bsz=212, num_updates=920, lr=1.104e-05, gnorm=1.936, train_wall=5, gb_free=13.6, wall=3106
2025-04-03 05:55:48 | INFO | train_inner | epoch 008:     40 / 126 loss=6.608, nll_loss=3.278, ppl=9.7, wps=1691.5, ups=0.34, wpb=4961, bsz=256, num_updates=922, lr=1.1064e-05, gnorm=1.934, train_wall=6, gb_free=12.6, wall=3112
2025-04-03 05:55:54 | INFO | train_inner | epoch 008:     42 / 126 loss=6.638, nll_loss=3.318, ppl=9.97, wps=1876.5, ups=0.35, wpb=5423.5, bsz=324, num_updates=924, lr=1.1088e-05, gnorm=2.063, train_wall=6, gb_free=12.6, wall=3118
2025-04-03 05:55:59 | INFO | train_inner | epoch 008:     44 / 126 loss=6.566, nll_loss=3.229, ppl=9.38, wps=1788.4, ups=0.4, wpb=4525.5, bsz=304, num_updates=926, lr=1.1112e-05, gnorm=1.925, train_wall=5, gb_free=15.4, wall=3123
2025-04-03 05:56:05 | INFO | train_inner | epoch 008:     46 / 126 loss=6.548, nll_loss=3.213, ppl=9.27, wps=1388.7, ups=0.34, wpb=4130.5, bsz=268, num_updates=928, lr=1.1136e-05, gnorm=1.997, train_wall=6, gb_free=11.9, wall=3129
2025-04-03 05:56:11 | INFO | train_inner | epoch 008:     48 / 126 loss=6.572, nll_loss=3.231, ppl=9.39, wps=1680.8, ups=0.35, wpb=4859.5, bsz=216, num_updates=930, lr=1.116e-05, gnorm=1.848, train_wall=6, gb_free=12.6, wall=3135
2025-04-03 05:56:16 | INFO | train_inner | epoch 008:     50 / 126 loss=6.566, nll_loss=3.231, ppl=9.39, wps=1600.8, ups=0.37, wpb=4358, bsz=256, num_updates=932, lr=1.1184e-05, gnorm=1.966, train_wall=5, gb_free=10.5, wall=3140
2025-04-03 05:56:22 | INFO | train_inner | epoch 008:     52 / 126 loss=6.649, nll_loss=3.316, ppl=9.96, wps=1361.6, ups=0.35, wpb=3915, bsz=204, num_updates=934, lr=1.1208e-05, gnorm=1.921, train_wall=6, gb_free=11.1, wall=3146
2025-04-03 05:56:27 | INFO | train_inner | epoch 008:     54 / 126 loss=6.613, nll_loss=3.282, ppl=9.73, wps=1513.1, ups=0.37, wpb=4045.5, bsz=284, num_updates=936, lr=1.1232e-05, gnorm=1.86, train_wall=5, gb_free=11.7, wall=3151
2025-04-03 05:56:38 | INFO | train_inner | epoch 008:     56 / 126 loss=6.47, nll_loss=3.104, ppl=8.6, wps=791.5, ups=0.2, wpb=4053, bsz=280, num_updates=938, lr=1.1256e-05, gnorm=1.903, train_wall=10, gb_free=13.2, wall=3162
2025-04-03 05:56:43 | INFO | train_inner | epoch 008:     58 / 126 loss=6.772, nll_loss=3.475, ppl=11.12, wps=1564.5, ups=0.37, wpb=4229, bsz=172, num_updates=940, lr=1.128e-05, gnorm=2.009, train_wall=5, gb_free=10.6, wall=3167
2025-04-03 05:56:49 | INFO | train_inner | epoch 008:     60 / 126 loss=6.504, nll_loss=3.142, ppl=8.83, wps=1821.1, ups=0.36, wpb=5088.5, bsz=292, num_updates=942, lr=1.1304e-05, gnorm=1.738, train_wall=6, gb_free=10.3, wall=3173
2025-04-03 05:56:54 | INFO | train_inner | epoch 008:     62 / 126 loss=6.391, nll_loss=3.03, ppl=8.17, wps=1649.5, ups=0.37, wpb=4464.5, bsz=360, num_updates=944, lr=1.1328e-05, gnorm=1.663, train_wall=5, gb_free=11.5, wall=3178
2025-04-03 05:57:00 | INFO | train_inner | epoch 008:     64 / 126 loss=6.552, nll_loss=3.2, ppl=9.19, wps=1746.3, ups=0.35, wpb=4964, bsz=232, num_updates=946, lr=1.1352e-05, gnorm=1.846, train_wall=6, gb_free=12.5, wall=3184
2025-04-03 05:57:05 | INFO | train_inner | epoch 008:     66 / 126 loss=6.578, nll_loss=3.247, ppl=9.49, wps=1402.6, ups=0.35, wpb=3994, bsz=240, num_updates=948, lr=1.1376e-05, gnorm=2.021, train_wall=6, gb_free=11.7, wall=3190
2025-04-03 05:57:11 | INFO | train_inner | epoch 008:     68 / 126 loss=6.432, nll_loss=3.067, ppl=8.38, wps=1681.4, ups=0.35, wpb=4849, bsz=292, num_updates=950, lr=1.14e-05, gnorm=1.638, train_wall=6, gb_free=11.6, wall=3195
2025-04-03 05:57:17 | INFO | train_inner | epoch 008:     70 / 126 loss=6.589, nll_loss=3.249, ppl=9.5, wps=1852.8, ups=0.36, wpb=5171.5, bsz=252, num_updates=952, lr=1.1424e-05, gnorm=1.705, train_wall=6, gb_free=12.9, wall=3201
2025-04-03 05:57:22 | INFO | train_inner | epoch 008:     72 / 126 loss=6.461, nll_loss=3.085, ppl=8.49, wps=1717.2, ups=0.36, wpb=4723.5, bsz=300, num_updates=954, lr=1.1448e-05, gnorm=1.685, train_wall=5, gb_free=12, wall=3206
2025-04-03 05:57:28 | INFO | train_inner | epoch 008:     74 / 126 loss=6.571, nll_loss=3.218, ppl=9.31, wps=1594.2, ups=0.36, wpb=4368, bsz=256, num_updates=956, lr=1.1472e-05, gnorm=1.8, train_wall=5, gb_free=13, wall=3212
2025-04-03 05:57:33 | INFO | train_inner | epoch 008:     76 / 126 loss=6.678, nll_loss=3.362, ppl=10.28, wps=1408, ups=0.38, wpb=3715, bsz=228, num_updates=958, lr=1.1496e-05, gnorm=1.985, train_wall=5, gb_free=14.6, wall=3217
2025-04-03 05:57:39 | INFO | train_inner | epoch 008:     78 / 126 loss=6.553, nll_loss=3.217, ppl=9.3, wps=1617.4, ups=0.34, wpb=4753, bsz=312, num_updates=960, lr=1.152e-05, gnorm=1.728, train_wall=6, gb_free=10.4, wall=3223
2025-04-03 05:57:45 | INFO | train_inner | epoch 008:     80 / 126 loss=6.702, nll_loss=3.402, ppl=10.57, wps=1648.2, ups=0.35, wpb=4711, bsz=252, num_updates=962, lr=1.1544e-05, gnorm=1.761, train_wall=6, gb_free=9.6, wall=3229
2025-04-03 05:57:50 | INFO | train_inner | epoch 008:     82 / 126 loss=6.606, nll_loss=3.285, ppl=9.75, wps=1804.8, ups=0.35, wpb=5126.5, bsz=284, num_updates=964, lr=1.1568e-05, gnorm=1.795, train_wall=6, gb_free=10.7, wall=3234
2025-04-03 05:57:56 | INFO | train_inner | epoch 008:     84 / 126 loss=6.641, nll_loss=3.324, ppl=10.02, wps=1642.3, ups=0.37, wpb=4479.5, bsz=200, num_updates=966, lr=1.1592e-05, gnorm=1.998, train_wall=5, gb_free=12.9, wall=3240
2025-04-03 05:58:01 | INFO | train_inner | epoch 008:     86 / 126 loss=6.604, nll_loss=3.277, ppl=9.69, wps=1861, ups=0.37, wpb=5092.5, bsz=300, num_updates=968, lr=1.1616e-05, gnorm=1.869, train_wall=5, gb_free=12.9, wall=3245
2025-04-03 05:58:07 | INFO | train_inner | epoch 008:     88 / 126 loss=6.579, nll_loss=3.23, ppl=9.38, wps=1623.1, ups=0.34, wpb=4827.5, bsz=244, num_updates=970, lr=1.164e-05, gnorm=1.681, train_wall=6, gb_free=13.1, wall=3251
2025-04-03 05:58:13 | INFO | train_inner | epoch 008:     90 / 126 loss=6.81, nll_loss=3.53, ppl=11.55, wps=1727.2, ups=0.36, wpb=4773, bsz=256, num_updates=972, lr=1.1664e-05, gnorm=1.85, train_wall=6, gb_free=14.8, wall=3257
2025-04-03 05:58:18 | INFO | train_inner | epoch 008:     92 / 126 loss=6.489, nll_loss=3.108, ppl=8.62, wps=1884.2, ups=0.35, wpb=5309.5, bsz=292, num_updates=974, lr=1.1688e-05, gnorm=1.61, train_wall=6, gb_free=12.6, wall=3262
2025-04-03 05:58:24 | INFO | train_inner | epoch 008:     94 / 126 loss=6.499, nll_loss=3.141, ppl=8.82, wps=1749.4, ups=0.36, wpb=4811, bsz=308, num_updates=976, lr=1.1712e-05, gnorm=1.769, train_wall=5, gb_free=14.4, wall=3268
2025-04-03 05:58:30 | INFO | train_inner | epoch 008:     96 / 126 loss=6.459, nll_loss=3.085, ppl=8.49, wps=1796.7, ups=0.34, wpb=5258.5, bsz=296, num_updates=978, lr=1.1736e-05, gnorm=1.645, train_wall=6, gb_free=13.6, wall=3274
2025-04-03 05:58:35 | INFO | train_inner | epoch 008:     98 / 126 loss=6.449, nll_loss=3.065, ppl=8.37, wps=1541.3, ups=0.35, wpb=4383, bsz=168, num_updates=980, lr=1.176e-05, gnorm=1.774, train_wall=6, gb_free=10.5, wall=3279
2025-04-03 05:58:42 | INFO | train_inner | epoch 008:    100 / 126 loss=6.482, nll_loss=3.124, ppl=8.72, wps=1679.6, ups=0.33, wpb=5150, bsz=276, num_updates=982, lr=1.1784e-05, gnorm=1.832, train_wall=6, gb_free=10.4, wall=3286
2025-04-03 05:58:47 | INFO | train_inner | epoch 008:    102 / 126 loss=6.493, nll_loss=3.153, ppl=8.9, wps=1566.5, ups=0.39, wpb=4040, bsz=276, num_updates=984, lr=1.1808e-05, gnorm=2.062, train_wall=5, gb_free=14, wall=3291
2025-04-03 05:58:52 | INFO | train_inner | epoch 008:    104 / 126 loss=6.645, nll_loss=3.33, ppl=10.05, wps=1616.2, ups=0.38, wpb=4283, bsz=216, num_updates=986, lr=1.1832e-05, gnorm=1.984, train_wall=5, gb_free=13.2, wall=3296
2025-04-03 05:58:58 | INFO | train_inner | epoch 008:    106 / 126 loss=6.291, nll_loss=2.876, ppl=7.34, wps=1723, ups=0.35, wpb=4946, bsz=312, num_updates=988, lr=1.1856e-05, gnorm=1.603, train_wall=6, gb_free=12.5, wall=3302
2025-04-03 05:59:03 | INFO | train_inner | epoch 008:    108 / 126 loss=6.405, nll_loss=3.014, ppl=8.08, wps=1774.7, ups=0.35, wpb=5029, bsz=300, num_updates=990, lr=1.188e-05, gnorm=1.751, train_wall=6, gb_free=9.1, wall=3307
2025-04-03 05:59:09 | INFO | train_inner | epoch 008:    110 / 126 loss=6.469, nll_loss=3.1, ppl=8.57, wps=1785.9, ups=0.36, wpb=5021.5, bsz=328, num_updates=992, lr=1.1904e-05, gnorm=1.757, train_wall=6, gb_free=12.7, wall=3313
2025-04-03 05:59:15 | INFO | train_inner | epoch 008:    112 / 126 loss=6.616, nll_loss=3.268, ppl=9.63, wps=1598.1, ups=0.35, wpb=4537.5, bsz=188, num_updates=994, lr=1.1928e-05, gnorm=2.055, train_wall=6, gb_free=12.7, wall=3319
2025-04-03 05:59:20 | INFO | train_inner | epoch 008:    114 / 126 loss=6.58, nll_loss=3.239, ppl=9.44, wps=1796, ups=0.39, wpb=4657, bsz=284, num_updates=996, lr=1.1952e-05, gnorm=1.88, train_wall=5, gb_free=13.6, wall=3324
2025-04-03 05:59:26 | INFO | train_inner | epoch 008:    116 / 126 loss=6.405, nll_loss=3.028, ppl=8.16, wps=1906.4, ups=0.34, wpb=5561.5, bsz=372, num_updates=998, lr=1.1976e-05, gnorm=1.552, train_wall=6, gb_free=11.4, wall=3330
2025-04-03 05:59:31 | INFO | train_inner | epoch 008:    118 / 126 loss=6.57, nll_loss=3.236, ppl=9.42, wps=1678.4, ups=0.35, wpb=4772, bsz=276, num_updates=1000, lr=1.2e-05, gnorm=1.769, train_wall=6, gb_free=13.9, wall=3335
2025-04-03 05:59:37 | INFO | train_inner | epoch 008:    120 / 126 loss=6.574, nll_loss=3.233, ppl=9.4, wps=1516.2, ups=0.35, wpb=4284, bsz=204, num_updates=1002, lr=1.2024e-05, gnorm=1.778, train_wall=6, gb_free=13.1, wall=3341
2025-04-03 05:59:43 | INFO | train_inner | epoch 008:    122 / 126 loss=6.547, nll_loss=3.185, ppl=9.1, wps=1492.9, ups=0.35, wpb=4291, bsz=152, num_updates=1004, lr=1.2048e-05, gnorm=1.724, train_wall=6, gb_free=10.2, wall=3347
2025-04-03 05:59:49 | INFO | train_inner | epoch 008:    124 / 126 loss=6.469, nll_loss=3.115, ppl=8.66, wps=1597, ups=0.34, wpb=4699.5, bsz=328, num_updates=1006, lr=1.2072e-05, gnorm=1.645, train_wall=6, gb_free=10.5, wall=3353
2025-04-03 05:59:52 | INFO | train_inner | epoch 008:    126 / 126 loss=6.471, nll_loss=3.15, ppl=8.88, wps=1047.1, ups=0.67, wpb=1571, bsz=144.5, num_updates=1008, lr=1.2096e-05, gnorm=3.304, train_wall=3, gb_free=16.6, wall=3356
2025-04-03 05:59:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-03 05:59:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=10179.40625Mb; avail=244905.625Mb
2025-04-03 05:59:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000635
2025-04-03 05:59:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=10179.40625Mb; avail=244905.625Mb
2025-04-03 05:59:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.013014
2025-04-03 05:59:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=10179.40625Mb; avail=244905.625Mb
2025-04-03 05:59:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.011013
2025-04-03 05:59:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.025040
2025-04-03 05:59:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=10179.40625Mb; avail=244905.625Mb
2025-04-03 06:00:06 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 6.453 | nll_loss 2.9 | ppl 7.47 | wps 3873.9 | wpb 2070.5 | bsz 122.7 | num_updates 1008 | best_loss 6.453
2025-04-03 06:00:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1008 updates
2025-04-03 06:00:06 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 06:00:45 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 06:01:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt (epoch 8 @ 1008 updates, score 6.453) (writing took 63.36382838094141 seconds)
2025-04-03 06:01:09 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2025-04-03 06:01:09 | INFO | train | epoch 008 | loss 6.562 | nll_loss 3.219 | ppl 9.31 | wps 1331.1 | ups 0.29 | wpb 4549.7 | bsz 252.8 | num_updates 1008 | lr 1.2096e-05 | gnorm 1.877 | train_wall 352 | gb_free 16.6 | wall 3433
2025-04-03 06:01:09 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:mr-hi': 31849}; raw total size: 31849
2025-04-03 06:01:09 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:mr-hi': 31849}; resampled total size: 31849
2025-04-03 06:01:09 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:mr-hi': 1.0}
2025-04-03 06:01:09 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001124
2025-04-03 06:01:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=18290.18359375Mb; avail=236794.83984375Mb
2025-04-03 06:01:09 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000456
2025-04-03 06:01:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003411
2025-04-03 06:01:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=18290.18359375Mb; avail=236794.83984375Mb
2025-04-03 06:01:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000156
2025-04-03 06:01:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=18290.18359375Mb; avail=236794.83984375Mb
2025-04-03 06:01:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001180
2025-04-03 06:01:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.005101
2025-04-03 06:01:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=18290.18359375Mb; avail=236794.83984375Mb
2025-04-03 06:01:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 126
2025-04-03 06:01:09 | INFO | fairseq.trainer | begin training epoch 9
2025-04-03 06:01:09 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-03 06:01:20 | INFO | train_inner | epoch 009:      2 / 126 loss=6.568, nll_loss=3.208, ppl=9.24, wps=102, ups=0.02, wpb=4518.5, bsz=120, num_updates=1010, lr=1.212e-05, gnorm=2.123, train_wall=11, gb_free=9.2, wall=3444
2025-04-03 06:01:26 | INFO | train_inner | epoch 009:      4 / 126 loss=6.435, nll_loss=3.056, ppl=8.32, wps=1760.3, ups=0.37, wpb=4785, bsz=292, num_updates=1012, lr=1.2144e-05, gnorm=1.632, train_wall=5, gb_free=12.4, wall=3450
2025-04-03 06:01:31 | INFO | train_inner | epoch 009:      6 / 126 loss=6.556, nll_loss=3.199, ppl=9.19, wps=1410.9, ups=0.36, wpb=3921.5, bsz=188, num_updates=1014, lr=1.2168e-05, gnorm=1.938, train_wall=6, gb_free=13.6, wall=3455
2025-04-03 06:01:37 | INFO | train_inner | epoch 009:      8 / 126 loss=6.523, nll_loss=3.163, ppl=8.96, wps=1835.8, ups=0.36, wpb=5159.5, bsz=276, num_updates=1016, lr=1.2192e-05, gnorm=1.721, train_wall=6, gb_free=10.8, wall=3461
2025-04-03 06:01:43 | INFO | train_inner | epoch 009:     10 / 126 loss=6.426, nll_loss=3.036, ppl=8.2, wps=1754.7, ups=0.34, wpb=5204.5, bsz=268, num_updates=1018, lr=1.2216e-05, gnorm=1.635, train_wall=6, gb_free=10.3, wall=3467
2025-04-03 06:01:48 | INFO | train_inner | epoch 009:     12 / 126 loss=6.343, nll_loss=2.968, ppl=7.82, wps=1791.7, ups=0.36, wpb=5039, bsz=392, num_updates=1020, lr=1.224e-05, gnorm=1.59, train_wall=6, gb_free=13.6, wall=3473
2025-04-03 06:01:54 | INFO | train_inner | epoch 009:     14 / 126 loss=6.466, nll_loss=3.097, ppl=8.56, wps=1666.7, ups=0.37, wpb=4551.5, bsz=232, num_updates=1022, lr=1.2264e-05, gnorm=2.015, train_wall=5, gb_free=12.2, wall=3478
2025-04-03 06:02:00 | INFO | train_inner | epoch 009:     16 / 126 loss=6.467, nll_loss=3.091, ppl=8.52, wps=1651, ups=0.35, wpb=4714, bsz=232, num_updates=1024, lr=1.2288e-05, gnorm=1.847, train_wall=6, gb_free=12.2, wall=3484
2025-04-03 06:02:05 | INFO | train_inner | epoch 009:     18 / 126 loss=6.46, nll_loss=3.094, ppl=8.54, wps=1416, ups=0.34, wpb=4145.5, bsz=280, num_updates=1026, lr=1.2312e-05, gnorm=1.828, train_wall=6, gb_free=9.7, wall=3490
2025-04-03 06:02:11 | INFO | train_inner | epoch 009:     20 / 126 loss=6.356, nll_loss=2.968, ppl=7.83, wps=1568.9, ups=0.37, wpb=4287, bsz=288, num_updates=1028, lr=1.2336e-05, gnorm=1.797, train_wall=5, gb_free=13.3, wall=3495
2025-04-03 06:02:16 | INFO | train_inner | epoch 009:     22 / 126 loss=6.446, nll_loss=3.082, ppl=8.47, wps=1567.5, ups=0.38, wpb=4146, bsz=296, num_updates=1030, lr=1.236e-05, gnorm=1.916, train_wall=5, gb_free=15.1, wall=3500
2025-04-03 06:02:22 | INFO | train_inner | epoch 009:     24 / 126 loss=6.507, nll_loss=3.128, ppl=8.74, wps=1707.6, ups=0.34, wpb=4992.5, bsz=180, num_updates=1032, lr=1.2384e-05, gnorm=2.044, train_wall=6, gb_free=10.2, wall=3506
2025-04-03 06:02:28 | INFO | train_inner | epoch 009:     26 / 126 loss=6.448, nll_loss=3.071, ppl=8.41, wps=1702.9, ups=0.35, wpb=4832, bsz=296, num_updates=1034, lr=1.2408e-05, gnorm=1.81, train_wall=6, gb_free=13.5, wall=3512
2025-04-03 06:02:33 | INFO | train_inner | epoch 009:     28 / 126 loss=6.444, nll_loss=3.077, ppl=8.44, wps=1626.5, ups=0.37, wpb=4376.5, bsz=296, num_updates=1036, lr=1.2432e-05, gnorm=1.767, train_wall=5, gb_free=10.6, wall=3517
2025-04-03 06:02:38 | INFO | train_inner | epoch 009:     30 / 126 loss=6.468, nll_loss=3.1, ppl=8.57, wps=1635.6, ups=0.37, wpb=4366, bsz=196, num_updates=1038, lr=1.2456e-05, gnorm=1.881, train_wall=5, gb_free=12.5, wall=3523
2025-04-03 06:02:44 | INFO | train_inner | epoch 009:     32 / 126 loss=6.587, nll_loss=3.26, ppl=9.58, wps=1732.7, ups=0.37, wpb=4728.5, bsz=252, num_updates=1040, lr=1.248e-05, gnorm=1.87, train_wall=5, gb_free=12.7, wall=3528
2025-04-03 06:02:50 | INFO | train_inner | epoch 009:     34 / 126 loss=6.475, nll_loss=3.098, ppl=8.56, wps=1743.2, ups=0.35, wpb=4964, bsz=264, num_updates=1042, lr=1.2504e-05, gnorm=1.613, train_wall=6, gb_free=13.6, wall=3534
2025-04-03 06:02:55 | INFO | train_inner | epoch 009:     36 / 126 loss=6.471, nll_loss=3.085, ppl=8.49, wps=1602.1, ups=0.37, wpb=4308.5, bsz=248, num_updates=1044, lr=1.2528e-05, gnorm=1.826, train_wall=5, gb_free=13.2, wall=3539
2025-04-03 06:03:01 | INFO | train_inner | epoch 009:     38 / 126 loss=6.426, nll_loss=3.036, ppl=8.2, wps=1864.9, ups=0.35, wpb=5392.5, bsz=276, num_updates=1046, lr=1.2552e-05, gnorm=1.734, train_wall=6, gb_free=10.8, wall=3545
2025-04-03 06:03:06 | INFO | train_inner | epoch 009:     40 / 126 loss=6.477, nll_loss=3.101, ppl=8.58, wps=1593.8, ups=0.38, wpb=4208, bsz=196, num_updates=1048, lr=1.2576e-05, gnorm=1.887, train_wall=5, gb_free=12.1, wall=3550
2025-04-03 06:03:12 | INFO | train_inner | epoch 009:     42 / 126 loss=6.581, nll_loss=3.254, ppl=9.54, wps=1724.1, ups=0.35, wpb=4886.5, bsz=280, num_updates=1050, lr=1.26e-05, gnorm=1.728, train_wall=6, gb_free=14.3, wall=3556
2025-04-03 06:03:18 | INFO | train_inner | epoch 009:     44 / 126 loss=6.526, nll_loss=3.168, ppl=8.99, wps=1820.7, ups=0.34, wpb=5361.5, bsz=232, num_updates=1052, lr=1.2624e-05, gnorm=1.719, train_wall=6, gb_free=10.9, wall=3562
2025-04-03 06:03:23 | INFO | train_inner | epoch 009:     46 / 126 loss=6.416, nll_loss=3.031, ppl=8.18, wps=1763.4, ups=0.34, wpb=5130.5, bsz=272, num_updates=1054, lr=1.2648e-05, gnorm=1.554, train_wall=6, gb_free=11.6, wall=3568
2025-04-03 06:03:29 | INFO | train_inner | epoch 009:     48 / 126 loss=6.543, nll_loss=3.198, ppl=9.18, wps=1735.8, ups=0.38, wpb=4628, bsz=280, num_updates=1056, lr=1.2672e-05, gnorm=1.912, train_wall=5, gb_free=12.7, wall=3573
2025-04-03 06:03:34 | INFO | train_inner | epoch 009:     50 / 126 loss=6.383, nll_loss=3.001, ppl=8, wps=1476.3, ups=0.35, wpb=4203.5, bsz=232, num_updates=1058, lr=1.2696e-05, gnorm=1.709, train_wall=6, gb_free=11.2, wall=3579
2025-04-03 06:03:40 | INFO | train_inner | epoch 009:     52 / 126 loss=6.583, nll_loss=3.241, ppl=9.45, wps=1602.4, ups=0.35, wpb=4519.5, bsz=220, num_updates=1060, lr=1.272e-05, gnorm=1.861, train_wall=6, gb_free=10.2, wall=3584
2025-04-03 06:03:46 | INFO | train_inner | epoch 009:     54 / 126 loss=6.445, nll_loss=3.07, ppl=8.4, wps=1621.6, ups=0.33, wpb=4925, bsz=252, num_updates=1062, lr=1.2744e-05, gnorm=1.921, train_wall=6, gb_free=11, wall=3590
2025-04-03 06:03:52 | INFO | train_inner | epoch 009:     56 / 126 loss=6.552, nll_loss=3.199, ppl=9.18, wps=1549.5, ups=0.36, wpb=4274.5, bsz=264, num_updates=1064, lr=1.2768e-05, gnorm=1.932, train_wall=6, gb_free=9.5, wall=3596
2025-04-03 06:03:57 | INFO | train_inner | epoch 009:     58 / 126 loss=6.357, nll_loss=2.949, ppl=7.72, wps=1489.5, ups=0.35, wpb=4220, bsz=188, num_updates=1066, lr=1.2792e-05, gnorm=1.836, train_wall=6, gb_free=7.8, wall=3601
2025-04-03 06:04:02 | INFO | train_inner | epoch 009:     60 / 126 loss=6.353, nll_loss=2.975, ppl=7.86, wps=1590.5, ups=0.4, wpb=3996.5, bsz=296, num_updates=1068, lr=1.2816e-05, gnorm=1.822, train_wall=5, gb_free=14.3, wall=3606
2025-04-03 06:04:08 | INFO | train_inner | epoch 009:     62 / 126 loss=6.396, nll_loss=3.012, ppl=8.06, wps=1607.6, ups=0.36, wpb=4493.5, bsz=264, num_updates=1070, lr=1.284e-05, gnorm=1.679, train_wall=6, gb_free=12.7, wall=3612
2025-04-03 06:04:14 | INFO | train_inner | epoch 009:     64 / 126 loss=6.475, nll_loss=3.098, ppl=8.56, wps=1754, ups=0.35, wpb=4959, bsz=244, num_updates=1072, lr=1.2864e-05, gnorm=1.712, train_wall=6, gb_free=13.4, wall=3618
2025-04-03 06:04:19 | INFO | train_inner | epoch 009:     66 / 126 loss=6.623, nll_loss=3.282, ppl=9.73, wps=1693, ups=0.35, wpb=4781.5, bsz=204, num_updates=1074, lr=1.2888e-05, gnorm=1.77, train_wall=6, gb_free=9.8, wall=3623
2025-04-03 06:04:24 | INFO | train_inner | epoch 009:     68 / 126 loss=6.444, nll_loss=3.069, ppl=8.39, wps=1593.3, ups=0.38, wpb=4170.5, bsz=208, num_updates=1076, lr=1.2912e-05, gnorm=2.02, train_wall=5, gb_free=12.7, wall=3629
2025-04-03 06:04:30 | INFO | train_inner | epoch 009:     70 / 126 loss=6.371, nll_loss=2.982, ppl=7.9, wps=1688.6, ups=0.35, wpb=4847, bsz=316, num_updates=1078, lr=1.2936e-05, gnorm=1.605, train_wall=6, gb_free=10.7, wall=3634
2025-04-03 06:04:36 | INFO | train_inner | epoch 009:     72 / 126 loss=6.426, nll_loss=3.044, ppl=8.25, wps=1626.8, ups=0.36, wpb=4488, bsz=208, num_updates=1080, lr=1.296e-05, gnorm=1.791, train_wall=6, gb_free=12.1, wall=3640
2025-04-03 06:04:41 | INFO | train_inner | epoch 009:     74 / 126 loss=6.363, nll_loss=2.967, ppl=7.82, wps=1658.5, ups=0.36, wpb=4622, bsz=292, num_updates=1082, lr=1.2984e-05, gnorm=1.636, train_wall=6, gb_free=12.3, wall=3645
2025-04-03 06:04:47 | INFO | train_inner | epoch 009:     76 / 126 loss=6.494, nll_loss=3.111, ppl=8.64, wps=1676.3, ups=0.34, wpb=4913.5, bsz=200, num_updates=1084, lr=1.3008e-05, gnorm=1.829, train_wall=6, gb_free=12.4, wall=3651
2025-04-03 06:04:53 | INFO | train_inner | epoch 009:     78 / 126 loss=6.477, nll_loss=3.113, ppl=8.65, wps=1688.5, ups=0.36, wpb=4716.5, bsz=236, num_updates=1086, lr=1.3032e-05, gnorm=1.82, train_wall=6, gb_free=11.2, wall=3657
2025-04-03 06:04:58 | INFO | train_inner | epoch 009:     80 / 126 loss=6.606, nll_loss=3.277, ppl=9.69, wps=1582.5, ups=0.36, wpb=4426, bsz=208, num_updates=1088, lr=1.3056e-05, gnorm=1.797, train_wall=6, gb_free=10.4, wall=3662
2025-04-03 06:05:03 | INFO | train_inner | epoch 009:     82 / 126 loss=6.422, nll_loss=3.071, ppl=8.41, wps=1605.4, ups=0.41, wpb=3910, bsz=272, num_updates=1090, lr=1.308e-05, gnorm=2.038, train_wall=5, gb_free=14.5, wall=3667
2025-04-03 06:05:09 | INFO | train_inner | epoch 009:     84 / 126 loss=6.491, nll_loss=3.137, ppl=8.8, wps=1668.8, ups=0.37, wpb=4526.5, bsz=260, num_updates=1092, lr=1.3104e-05, gnorm=1.748, train_wall=5, gb_free=11.9, wall=3673
2025-04-03 06:05:14 | INFO | train_inner | epoch 009:     86 / 126 loss=6.552, nll_loss=3.2, ppl=9.19, wps=1610.8, ups=0.37, wpb=4394.5, bsz=220, num_updates=1094, lr=1.3128e-05, gnorm=1.987, train_wall=5, gb_free=9.5, wall=3678
2025-04-03 06:05:20 | INFO | train_inner | epoch 009:     88 / 126 loss=6.608, nll_loss=3.271, ppl=9.65, wps=1665.5, ups=0.37, wpb=4547, bsz=260, num_updates=1096, lr=1.3152e-05, gnorm=1.835, train_wall=5, gb_free=13.3, wall=3684
2025-04-03 06:05:25 | INFO | train_inner | epoch 009:     90 / 126 loss=6.331, nll_loss=2.925, ppl=7.59, wps=1446.9, ups=0.36, wpb=4010.5, bsz=256, num_updates=1098, lr=1.3176e-05, gnorm=1.774, train_wall=6, gb_free=10.8, wall=3689
2025-04-03 06:05:30 | INFO | train_inner | epoch 009:     92 / 126 loss=6.351, nll_loss=2.947, ppl=7.71, wps=1630.4, ups=0.38, wpb=4346.5, bsz=260, num_updates=1100, lr=1.32e-05, gnorm=1.759, train_wall=5, gb_free=10.5, wall=3695
2025-04-03 06:05:36 | INFO | train_inner | epoch 009:     94 / 126 loss=6.466, nll_loss=3.106, ppl=8.61, wps=1510.6, ups=0.37, wpb=4030.5, bsz=272, num_updates=1102, lr=1.3224e-05, gnorm=1.867, train_wall=5, gb_free=12.9, wall=3700
2025-04-03 06:05:42 | INFO | train_inner | epoch 009:     96 / 126 loss=6.303, nll_loss=2.875, ppl=7.34, wps=1710.7, ups=0.35, wpb=4900.5, bsz=176, num_updates=1104, lr=1.3248e-05, gnorm=1.732, train_wall=6, gb_free=11.1, wall=3706
2025-04-03 06:05:47 | INFO | train_inner | epoch 009:     98 / 126 loss=6.385, nll_loss=3.013, ppl=8.07, wps=1675.2, ups=0.38, wpb=4392.5, bsz=284, num_updates=1106, lr=1.3272e-05, gnorm=1.708, train_wall=5, gb_free=14.3, wall=3711
2025-04-03 06:05:50 | INFO | train_inner | epoch 009:    100 / 126 loss=6.507, nll_loss=3.145, ppl=8.85, wps=1472.4, ups=0.56, wpb=2607.5, bsz=64.5, num_updates=1108, lr=1.3296e-05, gnorm=3.296, train_wall=4, gb_free=12.5, wall=3714
2025-04-03 06:05:56 | INFO | train_inner | epoch 009:    102 / 126 loss=6.467, nll_loss=3.094, ppl=8.54, wps=1742.4, ups=0.35, wpb=4959, bsz=256, num_updates=1110, lr=1.332e-05, gnorm=1.704, train_wall=6, gb_free=12.6, wall=3720
2025-04-03 06:06:02 | INFO | train_inner | epoch 009:    104 / 126 loss=6.465, nll_loss=3.1, ppl=8.57, wps=1746.2, ups=0.35, wpb=5007.5, bsz=336, num_updates=1112, lr=1.3344e-05, gnorm=1.685, train_wall=6, gb_free=10, wall=3726
2025-04-03 06:06:07 | INFO | train_inner | epoch 009:    106 / 126 loss=6.386, nll_loss=3, ppl=8, wps=1863.1, ups=0.35, wpb=5315.5, bsz=336, num_updates=1114, lr=1.3368e-05, gnorm=1.687, train_wall=6, gb_free=12.9, wall=3732
2025-04-03 06:06:13 | INFO | train_inner | epoch 009:    108 / 126 loss=6.303, nll_loss=2.904, ppl=7.48, wps=1674.5, ups=0.37, wpb=4548.5, bsz=300, num_updates=1116, lr=1.3392e-05, gnorm=1.754, train_wall=5, gb_free=13.7, wall=3737
2025-04-03 06:06:18 | INFO | train_inner | epoch 009:    110 / 126 loss=6.404, nll_loss=3.018, ppl=8.1, wps=1662, ups=0.36, wpb=4555.5, bsz=200, num_updates=1118, lr=1.3416e-05, gnorm=1.852, train_wall=5, gb_free=12.8, wall=3742
2025-04-03 06:06:24 | INFO | train_inner | epoch 009:    112 / 126 loss=6.438, nll_loss=3.071, ppl=8.4, wps=1653.9, ups=0.38, wpb=4296, bsz=244, num_updates=1120, lr=1.344e-05, gnorm=1.779, train_wall=5, gb_free=13.9, wall=3748
2025-04-03 06:06:29 | INFO | train_inner | epoch 009:    114 / 126 loss=6.342, nll_loss=2.952, ppl=7.74, wps=1772.8, ups=0.37, wpb=4803.5, bsz=332, num_updates=1122, lr=1.3464e-05, gnorm=1.629, train_wall=5, gb_free=14.5, wall=3753
2025-04-03 06:06:34 | INFO | train_inner | epoch 009:    116 / 126 loss=6.343, nll_loss=2.952, ppl=7.74, wps=1606.1, ups=0.38, wpb=4186.5, bsz=284, num_updates=1124, lr=1.3488e-05, gnorm=1.776, train_wall=5, gb_free=10.1, wall=3758
2025-04-03 06:06:40 | INFO | train_inner | epoch 009:    118 / 126 loss=6.397, nll_loss=3.013, ppl=8.07, wps=1865.1, ups=0.34, wpb=5469.5, bsz=356, num_updates=1126, lr=1.3512e-05, gnorm=1.648, train_wall=6, gb_free=11.2, wall=3764
2025-04-03 06:06:46 | INFO | train_inner | epoch 009:    120 / 126 loss=6.34, nll_loss=2.932, ppl=7.63, wps=1672.5, ups=0.34, wpb=4848, bsz=300, num_updates=1128, lr=1.3536e-05, gnorm=1.706, train_wall=6, gb_free=12, wall=3770
2025-04-03 06:06:52 | INFO | train_inner | epoch 009:    122 / 126 loss=6.551, nll_loss=3.199, ppl=9.18, wps=1499.7, ups=0.35, wpb=4286.5, bsz=220, num_updates=1130, lr=1.356e-05, gnorm=1.873, train_wall=6, gb_free=11.1, wall=3776
2025-04-03 06:06:57 | INFO | train_inner | epoch 009:    124 / 126 loss=6.346, nll_loss=2.955, ppl=7.75, wps=1553.7, ups=0.36, wpb=4360.5, bsz=288, num_updates=1132, lr=1.3584e-05, gnorm=1.797, train_wall=6, gb_free=10.2, wall=3781
2025-04-03 06:07:01 | INFO | train_inner | epoch 009:    126 / 126 loss=6.465, nll_loss=3.113, ppl=8.65, wps=1539.9, ups=0.49, wpb=3125.5, bsz=184, num_updates=1134, lr=1.3608e-05, gnorm=2.061, train_wall=4, gb_free=18.3, wall=3785
2025-04-03 06:07:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-03 06:07:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13190.6484375Mb; avail=241894.3984375Mb
2025-04-03 06:07:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000631
2025-04-03 06:07:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13190.6484375Mb; avail=241894.3984375Mb
2025-04-03 06:07:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012897
2025-04-03 06:07:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13190.6484375Mb; avail=241894.3984375Mb
2025-04-03 06:07:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.010886
2025-04-03 06:07:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024768
2025-04-03 06:07:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13190.6484375Mb; avail=241894.3984375Mb
2025-04-03 06:07:16 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 6.375 | nll_loss 2.813 | ppl 7.03 | wps 3867.8 | wpb 2070.5 | bsz 122.7 | num_updates 1134 | best_loss 6.375
2025-04-03 06:07:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1134 updates
2025-04-03 06:07:16 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 06:07:54 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 06:08:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt (epoch 9 @ 1134 updates, score 6.375) (writing took 63.04491571499966 seconds)
2025-04-03 06:08:19 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2025-04-03 06:08:19 | INFO | train | epoch 009 | loss 6.451 | nll_loss 3.078 | ppl 8.44 | wps 1335.4 | ups 0.29 | wpb 4549.7 | bsz 252.8 | num_updates 1134 | lr 1.3608e-05 | gnorm 1.823 | train_wall 351 | gb_free 18.3 | wall 3863
2025-04-03 06:08:19 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:mr-hi': 31849}; raw total size: 31849
2025-04-03 06:08:19 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:mr-hi': 31849}; resampled total size: 31849
2025-04-03 06:08:19 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:mr-hi': 1.0}
2025-04-03 06:08:19 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001083
2025-04-03 06:08:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=23485.68359375Mb; avail=231599.421875Mb
2025-04-03 06:08:19 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000416
2025-04-03 06:08:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003196
2025-04-03 06:08:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23485.68359375Mb; avail=231599.421875Mb
2025-04-03 06:08:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000097
2025-04-03 06:08:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23485.68359375Mb; avail=231599.421875Mb
2025-04-03 06:08:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001143
2025-04-03 06:08:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.004768
2025-04-03 06:08:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23485.68359375Mb; avail=231599.421875Mb
2025-04-03 06:08:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 126
2025-04-03 06:08:19 | INFO | fairseq.trainer | begin training epoch 10
2025-04-03 06:08:19 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-03 06:08:24 | INFO | train_inner | epoch 010:      2 / 126 loss=6.387, nll_loss=3.01, ppl=8.06, wps=113, ups=0.02, wpb=4675.5, bsz=244, num_updates=1136, lr=1.3632e-05, gnorm=1.687, train_wall=5, gb_free=12.1, wall=3868
2025-04-03 06:08:30 | INFO | train_inner | epoch 010:      4 / 126 loss=6.365, nll_loss=2.971, ppl=7.84, wps=1694.3, ups=0.36, wpb=4763, bsz=248, num_updates=1138, lr=1.3656e-05, gnorm=1.76, train_wall=6, gb_free=10.2, wall=3874
2025-04-03 06:08:35 | INFO | train_inner | epoch 010:      6 / 126 loss=6.327, nll_loss=2.923, ppl=7.58, wps=1872.5, ups=0.35, wpb=5369, bsz=304, num_updates=1140, lr=1.368e-05, gnorm=1.826, train_wall=6, gb_free=9.2, wall=3879
2025-04-03 06:08:41 | INFO | train_inner | epoch 010:      8 / 126 loss=6.296, nll_loss=2.87, ppl=7.31, wps=1700.5, ups=0.36, wpb=4697.5, bsz=192, num_updates=1142, lr=1.3704e-05, gnorm=1.641, train_wall=6, gb_free=12.2, wall=3885
2025-04-03 06:08:46 | INFO | train_inner | epoch 010:     10 / 126 loss=6.473, nll_loss=3.087, ppl=8.5, wps=1603.1, ups=0.38, wpb=4262, bsz=172, num_updates=1144, lr=1.3728e-05, gnorm=1.908, train_wall=5, gb_free=10.3, wall=3890
2025-04-03 06:08:51 | INFO | train_inner | epoch 010:     12 / 126 loss=6.398, nll_loss=3.003, ppl=8.02, wps=1390.7, ups=0.4, wpb=3500, bsz=224, num_updates=1146, lr=1.3752e-05, gnorm=2.051, train_wall=5, gb_free=10.4, wall=3895
2025-04-03 06:08:56 | INFO | train_inner | epoch 010:     14 / 126 loss=6.403, nll_loss=3.021, ppl=8.12, wps=1570, ups=0.4, wpb=3930.5, bsz=248, num_updates=1148, lr=1.3776e-05, gnorm=1.974, train_wall=5, gb_free=13.8, wall=3900
2025-04-03 06:09:02 | INFO | train_inner | epoch 010:     16 / 126 loss=6.238, nll_loss=2.82, ppl=7.06, wps=1922, ups=0.35, wpb=5526, bsz=336, num_updates=1150, lr=1.38e-05, gnorm=1.775, train_wall=6, gb_free=11.2, wall=3906
2025-04-03 06:09:08 | INFO | train_inner | epoch 010:     18 / 126 loss=6.419, nll_loss=3.043, ppl=8.24, wps=1696, ups=0.35, wpb=4817.5, bsz=288, num_updates=1152, lr=1.3824e-05, gnorm=1.799, train_wall=6, gb_free=10.8, wall=3912
2025-04-03 06:09:13 | INFO | train_inner | epoch 010:     20 / 126 loss=6.595, nll_loss=3.258, ppl=9.57, wps=1789.1, ups=0.38, wpb=4723.5, bsz=248, num_updates=1154, lr=1.3848e-05, gnorm=2.057, train_wall=5, gb_free=13.7, wall=3917
2025-04-03 06:09:18 | INFO | train_inner | epoch 010:     22 / 126 loss=6.463, nll_loss=3.093, ppl=8.54, wps=1761.6, ups=0.37, wpb=4717.5, bsz=288, num_updates=1156, lr=1.3872e-05, gnorm=1.8, train_wall=5, gb_free=13.6, wall=3922
2025-04-03 06:09:24 | INFO | train_inner | epoch 010:     24 / 126 loss=6.379, nll_loss=2.984, ppl=7.91, wps=1753.8, ups=0.37, wpb=4685, bsz=268, num_updates=1158, lr=1.3896e-05, gnorm=1.824, train_wall=5, gb_free=13.9, wall=3928
2025-04-03 06:09:34 | INFO | train_inner | epoch 010:     26 / 126 loss=6.343, nll_loss=2.949, ppl=7.72, wps=743, ups=0.2, wpb=3799, bsz=296, num_updates=1160, lr=1.392e-05, gnorm=2.097, train_wall=10, gb_free=13.2, wall=3938
2025-04-03 06:09:39 | INFO | train_inner | epoch 010:     28 / 126 loss=6.447, nll_loss=3.061, ppl=8.35, wps=1612.5, ups=0.36, wpb=4498, bsz=220, num_updates=1162, lr=1.3944e-05, gnorm=1.765, train_wall=6, gb_free=10.7, wall=3944
2025-04-03 06:09:45 | INFO | train_inner | epoch 010:     30 / 126 loss=6.349, nll_loss=2.95, ppl=7.73, wps=1778, ups=0.36, wpb=4877.5, bsz=292, num_updates=1164, lr=1.3968e-05, gnorm=1.671, train_wall=5, gb_free=11.1, wall=3949
2025-04-03 06:09:50 | INFO | train_inner | epoch 010:     32 / 126 loss=6.467, nll_loss=3.093, ppl=8.53, wps=1732.8, ups=0.36, wpb=4766.5, bsz=236, num_updates=1166, lr=1.3992e-05, gnorm=1.845, train_wall=5, gb_free=14.1, wall=3955
2025-04-03 06:09:56 | INFO | train_inner | epoch 010:     34 / 126 loss=6.273, nll_loss=2.878, ppl=7.35, wps=1617.5, ups=0.36, wpb=4462.5, bsz=304, num_updates=1168, lr=1.4016e-05, gnorm=1.688, train_wall=6, gb_free=10.8, wall=3960
2025-04-03 06:10:01 | INFO | train_inner | epoch 010:     36 / 126 loss=6.351, nll_loss=2.968, ppl=7.83, wps=1570.7, ups=0.39, wpb=4054, bsz=256, num_updates=1170, lr=1.404e-05, gnorm=1.774, train_wall=5, gb_free=13, wall=3965
2025-04-03 06:10:07 | INFO | train_inner | epoch 010:     38 / 126 loss=6.299, nll_loss=2.878, ppl=7.35, wps=1488.8, ups=0.35, wpb=4194, bsz=216, num_updates=1172, lr=1.4064e-05, gnorm=1.725, train_wall=6, gb_free=13.8, wall=3971
2025-04-03 06:10:13 | INFO | train_inner | epoch 010:     40 / 126 loss=6.289, nll_loss=2.852, ppl=7.22, wps=1623.1, ups=0.35, wpb=4687.5, bsz=244, num_updates=1174, lr=1.4088e-05, gnorm=1.626, train_wall=6, gb_free=12, wall=3977
2025-04-03 06:10:18 | INFO | train_inner | epoch 010:     42 / 126 loss=6.386, nll_loss=2.971, ppl=7.84, wps=1653.7, ups=0.36, wpb=4606, bsz=212, num_updates=1176, lr=1.4112e-05, gnorm=1.73, train_wall=6, gb_free=13.3, wall=3982
2025-04-03 06:10:24 | INFO | train_inner | epoch 010:     44 / 126 loss=6.348, nll_loss=2.942, ppl=7.69, wps=1701, ups=0.35, wpb=4928.5, bsz=260, num_updates=1178, lr=1.4136e-05, gnorm=1.727, train_wall=6, gb_free=12.7, wall=3988
2025-04-03 06:10:30 | INFO | train_inner | epoch 010:     46 / 126 loss=6.384, nll_loss=2.994, ppl=7.97, wps=1665.9, ups=0.33, wpb=5025, bsz=236, num_updates=1180, lr=1.416e-05, gnorm=1.63, train_wall=6, gb_free=11.2, wall=3994
2025-04-03 06:10:35 | INFO | train_inner | epoch 010:     48 / 126 loss=6.308, nll_loss=2.924, ppl=7.59, wps=1621.4, ups=0.38, wpb=4234.5, bsz=304, num_updates=1182, lr=1.4184e-05, gnorm=1.725, train_wall=5, gb_free=13.7, wall=3999
2025-04-03 06:10:41 | INFO | train_inner | epoch 010:     50 / 126 loss=6.419, nll_loss=3.054, ppl=8.3, wps=1809, ups=0.35, wpb=5100, bsz=292, num_updates=1184, lr=1.4208e-05, gnorm=1.593, train_wall=6, gb_free=11.6, wall=4005
2025-04-03 06:10:46 | INFO | train_inner | epoch 010:     52 / 126 loss=6.263, nll_loss=2.862, ppl=7.27, wps=1666.8, ups=0.39, wpb=4231.5, bsz=328, num_updates=1186, lr=1.4232e-05, gnorm=1.735, train_wall=5, gb_free=13.9, wall=4010
2025-04-03 06:10:51 | INFO | train_inner | epoch 010:     54 / 126 loss=6.352, nll_loss=2.951, ppl=7.73, wps=1421.8, ups=0.37, wpb=3893, bsz=204, num_updates=1188, lr=1.4256e-05, gnorm=1.8, train_wall=5, gb_free=14.3, wall=4015
2025-04-03 06:10:57 | INFO | train_inner | epoch 010:     56 / 126 loss=6.477, nll_loss=3.101, ppl=8.58, wps=1630.9, ups=0.33, wpb=5015.5, bsz=204, num_updates=1190, lr=1.428e-05, gnorm=2.498, train_wall=6, gb_free=9, wall=4022
2025-04-03 06:11:03 | INFO | train_inner | epoch 010:     58 / 126 loss=6.515, nll_loss=3.159, ppl=8.93, wps=1490.7, ups=0.38, wpb=3975, bsz=244, num_updates=1192, lr=1.4304e-05, gnorm=1.856, train_wall=5, gb_free=11.9, wall=4027
2025-04-03 06:11:09 | INFO | train_inner | epoch 010:     60 / 126 loss=6.41, nll_loss=3.017, ppl=8.1, wps=1664.2, ups=0.35, wpb=4762.5, bsz=208, num_updates=1194, lr=1.4328e-05, gnorm=1.661, train_wall=6, gb_free=9.9, wall=4033
2025-04-03 06:11:14 | INFO | train_inner | epoch 010:     62 / 126 loss=6.302, nll_loss=2.911, ppl=7.52, wps=1634.5, ups=0.38, wpb=4262.5, bsz=292, num_updates=1196, lr=1.4352e-05, gnorm=1.801, train_wall=5, gb_free=12.5, wall=4038
2025-04-03 06:11:19 | INFO | train_inner | epoch 010:     64 / 126 loss=6.281, nll_loss=2.877, ppl=7.35, wps=1497.3, ups=0.35, wpb=4302, bsz=260, num_updates=1198, lr=1.4376e-05, gnorm=1.783, train_wall=6, gb_free=13.5, wall=4044
2025-04-03 06:11:25 | INFO | train_inner | epoch 010:     66 / 126 loss=6.375, nll_loss=2.974, ppl=7.86, wps=1457.2, ups=0.33, wpb=4353, bsz=128, num_updates=1200, lr=1.44e-05, gnorm=1.779, train_wall=6, gb_free=8.9, wall=4050
2025-04-03 06:11:31 | INFO | train_inner | epoch 010:     68 / 126 loss=6.366, nll_loss=2.97, ppl=7.84, wps=1495.6, ups=0.35, wpb=4225, bsz=208, num_updates=1202, lr=1.4424e-05, gnorm=1.7, train_wall=6, gb_free=10.9, wall=4055
2025-04-03 06:11:36 | INFO | train_inner | epoch 010:     70 / 126 loss=6.374, nll_loss=2.979, ppl=7.89, wps=1571.4, ups=0.37, wpb=4198, bsz=244, num_updates=1204, lr=1.4448e-05, gnorm=1.738, train_wall=5, gb_free=14.5, wall=4061
2025-04-03 06:11:42 | INFO | train_inner | epoch 010:     72 / 126 loss=6.424, nll_loss=3.033, ppl=8.19, wps=1698, ups=0.37, wpb=4558, bsz=188, num_updates=1206, lr=1.4472e-05, gnorm=1.819, train_wall=5, gb_free=12, wall=4066
2025-04-03 06:11:47 | INFO | train_inner | epoch 010:     74 / 126 loss=6.18, nll_loss=2.741, ppl=6.68, wps=1723.2, ups=0.36, wpb=4736.5, bsz=392, num_updates=1208, lr=1.4496e-05, gnorm=1.563, train_wall=5, gb_free=13.7, wall=4071
2025-04-03 06:11:53 | INFO | train_inner | epoch 010:     76 / 126 loss=6.425, nll_loss=3.018, ppl=8.1, wps=1685.6, ups=0.34, wpb=4894.5, bsz=160, num_updates=1210, lr=1.452e-05, gnorm=1.672, train_wall=6, gb_free=11.3, wall=4077
2025-04-03 06:11:59 | INFO | train_inner | epoch 010:     78 / 126 loss=6.348, nll_loss=2.96, ppl=7.78, wps=1527.6, ups=0.37, wpb=4160, bsz=288, num_updates=1212, lr=1.4544e-05, gnorm=1.715, train_wall=5, gb_free=9.9, wall=4083
2025-04-03 06:12:04 | INFO | train_inner | epoch 010:     80 / 126 loss=6.299, nll_loss=2.916, ppl=7.55, wps=1501.7, ups=0.35, wpb=4313.5, bsz=316, num_updates=1214, lr=1.4568e-05, gnorm=1.661, train_wall=6, gb_free=12.4, wall=4088
2025-04-03 06:12:10 | INFO | train_inner | epoch 010:     82 / 126 loss=6.463, nll_loss=3.105, ppl=8.61, wps=1533.9, ups=0.35, wpb=4346.5, bsz=320, num_updates=1216, lr=1.4592e-05, gnorm=2.063, train_wall=6, gb_free=10, wall=4094
2025-04-03 06:12:15 | INFO | train_inner | epoch 010:     84 / 126 loss=6.382, nll_loss=3.005, ppl=8.03, wps=1646.6, ups=0.39, wpb=4213, bsz=208, num_updates=1218, lr=1.4616e-05, gnorm=1.86, train_wall=5, gb_free=11.5, wall=4099
2025-04-03 06:12:21 | INFO | train_inner | epoch 010:     86 / 126 loss=6.382, nll_loss=2.986, ppl=7.92, wps=1634.3, ups=0.35, wpb=4620.5, bsz=200, num_updates=1220, lr=1.464e-05, gnorm=2.003, train_wall=6, gb_free=9.3, wall=4105
2025-04-03 06:12:26 | INFO | train_inner | epoch 010:     88 / 126 loss=6.367, nll_loss=2.963, ppl=7.8, wps=1683.2, ups=0.36, wpb=4624, bsz=236, num_updates=1222, lr=1.4664e-05, gnorm=1.752, train_wall=5, gb_free=11.8, wall=4110
2025-04-03 06:12:31 | INFO | train_inner | epoch 010:     90 / 126 loss=6.278, nll_loss=2.847, ppl=7.2, wps=1670.1, ups=0.41, wpb=4102.5, bsz=208, num_updates=1224, lr=1.4688e-05, gnorm=1.826, train_wall=5, gb_free=11, wall=4115
2025-04-03 06:12:36 | INFO | train_inner | epoch 010:     92 / 126 loss=6.372, nll_loss=2.958, ppl=7.77, wps=1726.2, ups=0.41, wpb=4187.5, bsz=192.5, num_updates=1226, lr=1.4712e-05, gnorm=1.879, train_wall=5, gb_free=9.6, wall=4120
2025-04-03 06:12:42 | INFO | train_inner | epoch 010:     94 / 126 loss=6.204, nll_loss=2.765, ppl=6.8, wps=1832.3, ups=0.35, wpb=5190.5, bsz=384, num_updates=1228, lr=1.4736e-05, gnorm=1.458, train_wall=6, gb_free=11.4, wall=4126
2025-04-03 06:12:48 | INFO | train_inner | epoch 010:     96 / 126 loss=6.246, nll_loss=2.812, ppl=7.02, wps=1769.4, ups=0.34, wpb=5268, bsz=292, num_updates=1230, lr=1.476e-05, gnorm=1.688, train_wall=6, gb_free=10.5, wall=4132
2025-04-03 06:12:53 | INFO | train_inner | epoch 010:     98 / 126 loss=6.333, nll_loss=2.919, ppl=7.56, wps=1545.3, ups=0.36, wpb=4312.5, bsz=144, num_updates=1232, lr=1.4784e-05, gnorm=1.712, train_wall=6, gb_free=9.7, wall=4137
2025-04-03 06:12:59 | INFO | train_inner | epoch 010:    100 / 126 loss=6.305, nll_loss=2.906, ppl=7.49, wps=1535.4, ups=0.33, wpb=4590, bsz=248, num_updates=1234, lr=1.4808e-05, gnorm=1.557, train_wall=6, gb_free=11.8, wall=4143
2025-04-03 06:13:05 | INFO | train_inner | epoch 010:    102 / 126 loss=6.406, nll_loss=3.03, ppl=8.17, wps=1822.2, ups=0.35, wpb=5226.5, bsz=232, num_updates=1236, lr=1.4832e-05, gnorm=1.769, train_wall=6, gb_free=10.6, wall=4149
2025-04-03 06:13:11 | INFO | train_inner | epoch 010:    104 / 126 loss=6.245, nll_loss=2.833, ppl=7.13, wps=1606.1, ups=0.36, wpb=4489.5, bsz=268, num_updates=1238, lr=1.4856e-05, gnorm=1.722, train_wall=6, gb_free=9.9, wall=4155
2025-04-03 06:13:16 | INFO | train_inner | epoch 010:    106 / 126 loss=6.241, nll_loss=2.807, ppl=7, wps=1729.2, ups=0.38, wpb=4600, bsz=276, num_updates=1240, lr=1.488e-05, gnorm=1.541, train_wall=5, gb_free=13.1, wall=4160
2025-04-03 06:13:22 | INFO | train_inner | epoch 010:    108 / 126 loss=6.298, nll_loss=2.856, ppl=7.24, wps=1634, ups=0.35, wpb=4668, bsz=236, num_updates=1242, lr=1.4904e-05, gnorm=1.655, train_wall=6, gb_free=8.9, wall=4166
2025-04-03 06:13:27 | INFO | train_inner | epoch 010:    110 / 126 loss=6.296, nll_loss=2.864, ppl=7.28, wps=1738.9, ups=0.37, wpb=4695, bsz=248, num_updates=1244, lr=1.4928e-05, gnorm=1.727, train_wall=5, gb_free=11.3, wall=4171
2025-04-03 06:13:32 | INFO | train_inner | epoch 010:    112 / 126 loss=6.272, nll_loss=2.86, ppl=7.26, wps=1553.1, ups=0.38, wpb=4132.5, bsz=248, num_updates=1246, lr=1.4952e-05, gnorm=1.756, train_wall=5, gb_free=13.4, wall=4176
2025-04-03 06:13:38 | INFO | train_inner | epoch 010:    114 / 126 loss=6.404, nll_loss=3.03, ppl=8.17, wps=1780.5, ups=0.37, wpb=4848, bsz=288, num_updates=1248, lr=1.4976e-05, gnorm=1.776, train_wall=5, gb_free=13.9, wall=4182
2025-04-03 06:13:43 | INFO | train_inner | epoch 010:    116 / 126 loss=6.421, nll_loss=3.052, ppl=8.29, wps=1932.9, ups=0.36, wpb=5421, bsz=308, num_updates=1250, lr=1.5e-05, gnorm=1.688, train_wall=6, gb_free=13.4, wall=4187
2025-04-03 06:13:49 | INFO | train_inner | epoch 010:    118 / 126 loss=6.195, nll_loss=2.76, ppl=6.77, wps=1618.8, ups=0.35, wpb=4638, bsz=288, num_updates=1252, lr=1.5024e-05, gnorm=1.584, train_wall=6, gb_free=11.5, wall=4193
2025-04-03 06:13:55 | INFO | train_inner | epoch 010:    120 / 126 loss=6.294, nll_loss=2.868, ppl=7.3, wps=1443, ups=0.36, wpb=3993, bsz=184, num_updates=1254, lr=1.5048e-05, gnorm=1.707, train_wall=6, gb_free=10.4, wall=4199
2025-04-03 06:14:00 | INFO | train_inner | epoch 010:    122 / 126 loss=6.313, nll_loss=2.887, ppl=7.39, wps=1839.8, ups=0.34, wpb=5335, bsz=260, num_updates=1256, lr=1.5072e-05, gnorm=1.601, train_wall=6, gb_free=9.9, wall=4205
2025-04-03 06:14:06 | INFO | train_inner | epoch 010:    124 / 126 loss=6.336, nll_loss=2.943, ppl=7.69, wps=1741.8, ups=0.37, wpb=4695, bsz=280, num_updates=1258, lr=1.5096e-05, gnorm=1.825, train_wall=5, gb_free=13.1, wall=4210
2025-04-03 06:14:10 | INFO | train_inner | epoch 010:    126 / 126 loss=6.216, nll_loss=2.811, ppl=7.02, wps=1692.3, ups=0.46, wpb=3654.5, bsz=284, num_updates=1260, lr=1.512e-05, gnorm=1.865, train_wall=4, gb_free=16.7, wall=4214
2025-04-03 06:14:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-03 06:14:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=15407.04296875Mb; avail=239678.09375Mb
2025-04-03 06:14:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000640
2025-04-03 06:14:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15407.04296875Mb; avail=239678.09375Mb
2025-04-03 06:14:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012652
2025-04-03 06:14:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15407.04296875Mb; avail=239678.09375Mb
2025-04-03 06:14:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.011002
2025-04-03 06:14:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024641
2025-04-03 06:14:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15407.04296875Mb; avail=239678.09375Mb
2025-04-03 06:14:24 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 6.31 | nll_loss 2.744 | ppl 6.7 | wps 3870.3 | wpb 2070.5 | bsz 122.7 | num_updates 1260 | best_loss 6.31
2025-04-03 06:14:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1260 updates
2025-04-03 06:14:24 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 06:15:04 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 06:15:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt (epoch 10 @ 1260 updates, score 6.31) (writing took 63.88121817703359 seconds)
2025-04-03 06:15:28 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2025-04-03 06:15:28 | INFO | train | epoch 010 | loss 6.35 | nll_loss 2.951 | ppl 7.73 | wps 1334.1 | ups 0.29 | wpb 4549.7 | bsz 252.8 | num_updates 1260 | lr 1.512e-05 | gnorm 1.77 | train_wall 351 | gb_free 16.7 | wall 4292
2025-04-03 06:15:28 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:mr-hi': 31849}; raw total size: 31849
2025-04-03 06:15:28 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:mr-hi': 31849}; resampled total size: 31849
2025-04-03 06:15:28 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:mr-hi': 1.0}
2025-04-03 06:15:28 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.000959
2025-04-03 06:15:28 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=26196.92578125Mb; avail=228888.25Mb
2025-04-03 06:15:28 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000685
2025-04-03 06:15:28 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003573
2025-04-03 06:15:28 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26197.91015625Mb; avail=228887.265625Mb
2025-04-03 06:15:28 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000092
2025-04-03 06:15:28 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26197.91015625Mb; avail=228887.265625Mb
2025-04-03 06:15:28 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001137
2025-04-03 06:15:28 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.005134
2025-04-03 06:15:28 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26197.91015625Mb; avail=228887.265625Mb
2025-04-03 06:15:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 126
2025-04-03 06:15:28 | INFO | fairseq.trainer | begin training epoch 11
2025-04-03 06:15:28 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-03 06:15:34 | INFO | train_inner | epoch 011:      2 / 126 loss=6.192, nll_loss=2.775, ppl=6.85, wps=111.7, ups=0.02, wpb=4678.5, bsz=268, num_updates=1262, lr=1.5144e-05, gnorm=1.567, train_wall=5, gb_free=10.8, wall=4298
2025-04-03 06:15:39 | INFO | train_inner | epoch 011:      4 / 126 loss=6.154, nll_loss=2.712, ppl=6.55, wps=1874.1, ups=0.38, wpb=4908, bsz=320, num_updates=1264, lr=1.5168e-05, gnorm=1.443, train_wall=5, gb_free=13.1, wall=4303
2025-04-03 06:15:45 | INFO | train_inner | epoch 011:      6 / 126 loss=6.239, nll_loss=2.801, ppl=6.97, wps=1679.4, ups=0.36, wpb=4639, bsz=280, num_updates=1266, lr=1.5192e-05, gnorm=1.756, train_wall=6, gb_free=11, wall=4309
2025-04-03 06:15:50 | INFO | train_inner | epoch 011:      8 / 126 loss=6.261, nll_loss=2.825, ppl=7.08, wps=1874.3, ups=0.36, wpb=5205.5, bsz=316, num_updates=1268, lr=1.5216e-05, gnorm=1.539, train_wall=6, gb_free=12.7, wall=4314
2025-04-03 06:15:56 | INFO | train_inner | epoch 011:     10 / 126 loss=6.321, nll_loss=2.897, ppl=7.45, wps=1666.7, ups=0.37, wpb=4512.5, bsz=232, num_updates=1270, lr=1.524e-05, gnorm=1.716, train_wall=5, gb_free=12.6, wall=4320
2025-04-03 06:16:01 | INFO | train_inner | epoch 011:     12 / 126 loss=6.211, nll_loss=2.791, ppl=6.92, wps=1399.2, ups=0.38, wpb=3662.5, bsz=256, num_updates=1272, lr=1.5264e-05, gnorm=2.2, train_wall=5, gb_free=14.2, wall=4325
2025-04-03 06:16:06 | INFO | train_inner | epoch 011:     14 / 126 loss=6.188, nll_loss=2.756, ppl=6.76, wps=1847, ups=0.36, wpb=5093.5, bsz=336, num_updates=1274, lr=1.5288e-05, gnorm=1.786, train_wall=6, gb_free=14, wall=4330
2025-04-03 06:16:12 | INFO | train_inner | epoch 011:     16 / 126 loss=6.236, nll_loss=2.814, ppl=7.03, wps=1620.2, ups=0.36, wpb=4553.5, bsz=264, num_updates=1276, lr=1.5312e-05, gnorm=1.583, train_wall=6, gb_free=13.2, wall=4336
2025-04-03 06:16:18 | INFO | train_inner | epoch 011:     18 / 126 loss=6.234, nll_loss=2.804, ppl=6.98, wps=1644.9, ups=0.35, wpb=4705, bsz=264, num_updates=1278, lr=1.5336e-05, gnorm=1.663, train_wall=6, gb_free=8.7, wall=4342
2025-04-03 06:16:23 | INFO | train_inner | epoch 011:     20 / 126 loss=6.178, nll_loss=2.726, ppl=6.62, wps=1631.9, ups=0.37, wpb=4415, bsz=240, num_updates=1280, lr=1.536e-05, gnorm=1.798, train_wall=5, gb_free=13, wall=4347
2025-04-03 06:16:29 | INFO | train_inner | epoch 011:     22 / 126 loss=6.309, nll_loss=2.91, ppl=7.52, wps=1706.3, ups=0.36, wpb=4728, bsz=280, num_updates=1282, lr=1.5384e-05, gnorm=1.667, train_wall=6, gb_free=14.5, wall=4353
2025-04-03 06:16:34 | INFO | train_inner | epoch 011:     24 / 126 loss=6.247, nll_loss=2.818, ppl=7.05, wps=1350.5, ups=0.36, wpb=3769.5, bsz=160, num_updates=1284, lr=1.5408e-05, gnorm=1.852, train_wall=6, gb_free=12.3, wall=4358
2025-04-03 06:16:40 | INFO | train_inner | epoch 011:     26 / 126 loss=6.183, nll_loss=2.741, ppl=6.68, wps=1690.8, ups=0.35, wpb=4798.5, bsz=248, num_updates=1286, lr=1.5432e-05, gnorm=1.92, train_wall=6, gb_free=10.2, wall=4364
2025-04-03 06:16:45 | INFO | train_inner | epoch 011:     28 / 126 loss=6.325, nll_loss=2.921, ppl=7.57, wps=1529.5, ups=0.4, wpb=3809, bsz=164, num_updates=1288, lr=1.5456e-05, gnorm=1.979, train_wall=5, gb_free=11, wall=4369
2025-04-03 06:16:51 | INFO | train_inner | epoch 011:     30 / 126 loss=6.087, nll_loss=2.623, ppl=6.16, wps=1656.6, ups=0.36, wpb=4622, bsz=316, num_updates=1290, lr=1.548e-05, gnorm=1.629, train_wall=6, gb_free=13.7, wall=4375
2025-04-03 06:16:56 | INFO | train_inner | epoch 011:     32 / 126 loss=6.116, nll_loss=2.638, ppl=6.22, wps=1520.7, ups=0.36, wpb=4272.5, bsz=208, num_updates=1292, lr=1.5504e-05, gnorm=1.775, train_wall=6, gb_free=10.5, wall=4380
2025-04-03 06:17:02 | INFO | train_inner | epoch 011:     34 / 126 loss=6.34, nll_loss=2.919, ppl=7.57, wps=1842.1, ups=0.35, wpb=5254, bsz=272, num_updates=1294, lr=1.5528e-05, gnorm=1.717, train_wall=6, gb_free=11.8, wall=4386
2025-04-03 06:17:08 | INFO | train_inner | epoch 011:     36 / 126 loss=6.413, nll_loss=3.028, ppl=8.16, wps=1703.9, ups=0.35, wpb=4890.5, bsz=200, num_updates=1296, lr=1.5552e-05, gnorm=1.74, train_wall=6, gb_free=13.6, wall=4392
2025-04-03 06:17:13 | INFO | train_inner | epoch 011:     38 / 126 loss=6.293, nll_loss=2.889, ppl=7.41, wps=1497.4, ups=0.4, wpb=3723.5, bsz=180, num_updates=1298, lr=1.5576e-05, gnorm=2.146, train_wall=5, gb_free=17.3, wall=4397
2025-04-03 06:17:18 | INFO | train_inner | epoch 011:     40 / 126 loss=6.212, nll_loss=2.783, ppl=6.88, wps=1778.2, ups=0.35, wpb=5142.5, bsz=252, num_updates=1300, lr=1.56e-05, gnorm=1.544, train_wall=6, gb_free=11.9, wall=4402
2025-04-03 06:17:24 | INFO | train_inner | epoch 011:     42 / 126 loss=6.283, nll_loss=2.866, ppl=7.29, wps=1511.4, ups=0.35, wpb=4289, bsz=252, num_updates=1302, lr=1.5624e-05, gnorm=1.63, train_wall=6, gb_free=13.3, wall=4408
2025-04-03 06:17:30 | INFO | train_inner | epoch 011:     44 / 126 loss=6.257, nll_loss=2.828, ppl=7.1, wps=1777, ups=0.36, wpb=4943, bsz=256, num_updates=1304, lr=1.5648e-05, gnorm=1.581, train_wall=6, gb_free=13, wall=4414
2025-04-03 06:17:35 | INFO | train_inner | epoch 011:     46 / 126 loss=6.256, nll_loss=2.828, ppl=7.1, wps=1695.9, ups=0.36, wpb=4738.5, bsz=332, num_updates=1306, lr=1.5672e-05, gnorm=1.583, train_wall=6, gb_free=13, wall=4419
2025-04-03 06:17:41 | INFO | train_inner | epoch 011:     48 / 126 loss=6.439, nll_loss=3.05, ppl=8.28, wps=1741, ups=0.37, wpb=4688, bsz=236, num_updates=1308, lr=1.5696e-05, gnorm=1.703, train_wall=5, gb_free=13, wall=4425
2025-04-03 06:17:46 | INFO | train_inner | epoch 011:     50 / 126 loss=6.201, nll_loss=2.753, ppl=6.74, wps=1359.5, ups=0.35, wpb=3862.5, bsz=164, num_updates=1310, lr=1.572e-05, gnorm=1.737, train_wall=6, gb_free=11.9, wall=4430
2025-04-03 06:17:52 | INFO | train_inner | epoch 011:     52 / 126 loss=6.24, nll_loss=2.815, ppl=7.04, wps=1570.7, ups=0.35, wpb=4433, bsz=232, num_updates=1312, lr=1.5744e-05, gnorm=1.742, train_wall=6, gb_free=11.5, wall=4436
2025-04-03 06:17:57 | INFO | train_inner | epoch 011:     54 / 126 loss=6.228, nll_loss=2.799, ppl=6.96, wps=1680.4, ups=0.36, wpb=4700, bsz=192, num_updates=1314, lr=1.5768e-05, gnorm=1.652, train_wall=6, gb_free=11.8, wall=4442
2025-04-03 06:18:03 | INFO | train_inner | epoch 011:     56 / 126 loss=6.304, nll_loss=2.897, ppl=7.45, wps=1508.9, ups=0.36, wpb=4182, bsz=192, num_updates=1316, lr=1.5792e-05, gnorm=1.745, train_wall=6, gb_free=14.2, wall=4447
2025-04-03 06:18:09 | INFO | train_inner | epoch 011:     58 / 126 loss=6.279, nll_loss=2.87, ppl=7.31, wps=1618.4, ups=0.35, wpb=4603.5, bsz=240, num_updates=1318, lr=1.5816e-05, gnorm=1.639, train_wall=6, gb_free=9.8, wall=4453
2025-04-03 06:18:14 | INFO | train_inner | epoch 011:     60 / 126 loss=6.353, nll_loss=2.951, ppl=7.73, wps=1543.6, ups=0.36, wpb=4302, bsz=240, num_updates=1320, lr=1.584e-05, gnorm=1.661, train_wall=6, gb_free=8.9, wall=4458
2025-04-03 06:18:20 | INFO | train_inner | epoch 011:     62 / 126 loss=6.287, nll_loss=2.886, ppl=7.39, wps=1799.8, ups=0.34, wpb=5371, bsz=412, num_updates=1322, lr=1.5864e-05, gnorm=1.553, train_wall=6, gb_free=11.8, wall=4464
2025-04-03 06:18:26 | INFO | train_inner | epoch 011:     64 / 126 loss=6.209, nll_loss=2.759, ppl=6.77, wps=1812, ups=0.36, wpb=5097.5, bsz=272, num_updates=1324, lr=1.5888e-05, gnorm=1.694, train_wall=6, gb_free=12.9, wall=4470
2025-04-03 06:18:31 | INFO | train_inner | epoch 011:     66 / 126 loss=6.266, nll_loss=2.843, ppl=7.17, wps=1527.1, ups=0.4, wpb=3865.5, bsz=212, num_updates=1326, lr=1.5912e-05, gnorm=1.821, train_wall=5, gb_free=12, wall=4475
2025-04-03 06:18:36 | INFO | train_inner | epoch 011:     68 / 126 loss=6.191, nll_loss=2.772, ppl=6.83, wps=1776.2, ups=0.36, wpb=4878.5, bsz=372, num_updates=1328, lr=1.5936e-05, gnorm=1.524, train_wall=5, gb_free=13.3, wall=4481
2025-04-03 06:18:42 | INFO | train_inner | epoch 011:     70 / 126 loss=6.221, nll_loss=2.788, ppl=6.91, wps=1613.1, ups=0.37, wpb=4401.5, bsz=236, num_updates=1330, lr=1.596e-05, gnorm=1.644, train_wall=5, gb_free=9.9, wall=4486
2025-04-03 06:18:53 | INFO | train_inner | epoch 011:     72 / 126 loss=6.307, nll_loss=2.899, ppl=7.46, wps=939.8, ups=0.18, wpb=5183.5, bsz=300, num_updates=1332, lr=1.5984e-05, gnorm=1.549, train_wall=11, gb_free=10.4, wall=4497
2025-04-03 06:18:58 | INFO | train_inner | epoch 011:     74 / 126 loss=6.215, nll_loss=2.787, ppl=6.9, wps=1665.5, ups=0.36, wpb=4639, bsz=280, num_updates=1334, lr=1.6008e-05, gnorm=1.65, train_wall=6, gb_free=9.6, wall=4503
2025-04-03 06:19:04 | INFO | train_inner | epoch 011:     76 / 126 loss=6.401, nll_loss=3.022, ppl=8.12, wps=1812.1, ups=0.37, wpb=4925, bsz=292, num_updates=1336, lr=1.6032e-05, gnorm=1.699, train_wall=5, gb_free=13, wall=4508
2025-04-03 06:19:09 | INFO | train_inner | epoch 011:     78 / 126 loss=6.129, nll_loss=2.686, ppl=6.43, wps=1490.9, ups=0.37, wpb=4033.5, bsz=280, num_updates=1338, lr=1.6056e-05, gnorm=1.638, train_wall=5, gb_free=12.8, wall=4513
2025-04-03 06:19:14 | INFO | train_inner | epoch 011:     80 / 126 loss=6.205, nll_loss=2.765, ppl=6.8, wps=1466, ups=0.39, wpb=3758.5, bsz=248, num_updates=1340, lr=1.608e-05, gnorm=1.941, train_wall=5, gb_free=13.8, wall=4519
2025-04-03 06:19:20 | INFO | train_inner | epoch 011:     82 / 126 loss=6.201, nll_loss=2.75, ppl=6.73, wps=1730.6, ups=0.36, wpb=4845, bsz=276, num_updates=1342, lr=1.6104e-05, gnorm=1.526, train_wall=6, gb_free=12.6, wall=4524
2025-04-03 06:19:25 | INFO | train_inner | epoch 011:     84 / 126 loss=6.21, nll_loss=2.761, ppl=6.78, wps=1449.7, ups=0.43, wpb=3358, bsz=152.5, num_updates=1344, lr=1.6128e-05, gnorm=2.018, train_wall=5, gb_free=11.9, wall=4529
2025-04-03 06:19:31 | INFO | train_inner | epoch 011:     86 / 126 loss=6.214, nll_loss=2.777, ppl=6.86, wps=1688.9, ups=0.34, wpb=4920.5, bsz=232, num_updates=1346, lr=1.6152e-05, gnorm=1.561, train_wall=6, gb_free=13.4, wall=4535
2025-04-03 06:19:36 | INFO | train_inner | epoch 011:     88 / 126 loss=6.372, nll_loss=2.996, ppl=7.98, wps=1702.9, ups=0.35, wpb=4806, bsz=248, num_updates=1348, lr=1.6176e-05, gnorm=1.589, train_wall=6, gb_free=12.7, wall=4540
2025-04-03 06:19:42 | INFO | train_inner | epoch 011:     90 / 126 loss=6.306, nll_loss=2.909, ppl=7.51, wps=1397.2, ups=0.33, wpb=4191.5, bsz=244, num_updates=1350, lr=1.62e-05, gnorm=1.656, train_wall=6, gb_free=10.5, wall=4546
2025-04-03 06:19:48 | INFO | train_inner | epoch 011:     92 / 126 loss=6.161, nll_loss=2.731, ppl=6.64, wps=1607, ups=0.36, wpb=4492, bsz=320, num_updates=1352, lr=1.6224e-05, gnorm=1.55, train_wall=6, gb_free=9.6, wall=4552
2025-04-03 06:19:53 | INFO | train_inner | epoch 011:     94 / 126 loss=6.297, nll_loss=2.883, ppl=7.38, wps=1682, ups=0.37, wpb=4594, bsz=256, num_updates=1354, lr=1.6248e-05, gnorm=1.558, train_wall=5, gb_free=13.5, wall=4557
2025-04-03 06:19:59 | INFO | train_inner | epoch 011:     96 / 126 loss=6.357, nll_loss=2.938, ppl=7.66, wps=1735, ups=0.37, wpb=4751, bsz=192, num_updates=1356, lr=1.6272e-05, gnorm=1.789, train_wall=5, gb_free=11.1, wall=4563
2025-04-03 06:20:05 | INFO | train_inner | epoch 011:     98 / 126 loss=6.286, nll_loss=2.84, ppl=7.16, wps=1788.4, ups=0.34, wpb=5278, bsz=216, num_updates=1358, lr=1.6296e-05, gnorm=1.689, train_wall=6, gb_free=11.4, wall=4569
2025-04-03 06:20:10 | INFO | train_inner | epoch 011:    100 / 126 loss=6.287, nll_loss=2.872, ppl=7.32, wps=1630.2, ups=0.36, wpb=4546.5, bsz=256, num_updates=1360, lr=1.632e-05, gnorm=1.751, train_wall=6, gb_free=11, wall=4574
2025-04-03 06:20:16 | INFO | train_inner | epoch 011:    102 / 126 loss=6.289, nll_loss=2.879, ppl=7.36, wps=1666.4, ups=0.34, wpb=4833.5, bsz=260, num_updates=1362, lr=1.6344e-05, gnorm=1.743, train_wall=6, gb_free=14.1, wall=4580
2025-04-03 06:20:21 | INFO | train_inner | epoch 011:    104 / 126 loss=6.219, nll_loss=2.802, ppl=6.97, wps=1765, ups=0.36, wpb=4850.5, bsz=288, num_updates=1364, lr=1.6368e-05, gnorm=1.7, train_wall=5, gb_free=11.9, wall=4586
2025-04-03 06:20:27 | INFO | train_inner | epoch 011:    106 / 126 loss=6.259, nll_loss=2.841, ppl=7.17, wps=1674.2, ups=0.39, wpb=4321, bsz=196, num_updates=1366, lr=1.6392e-05, gnorm=1.635, train_wall=5, gb_free=14.1, wall=4591
2025-04-03 06:20:32 | INFO | train_inner | epoch 011:    108 / 126 loss=6.203, nll_loss=2.764, ppl=6.79, wps=1643.8, ups=0.38, wpb=4349, bsz=232, num_updates=1368, lr=1.6416e-05, gnorm=1.789, train_wall=5, gb_free=13.2, wall=4596
2025-04-03 06:20:37 | INFO | train_inner | epoch 011:    110 / 126 loss=6.169, nll_loss=2.719, ppl=6.58, wps=1741.7, ups=0.38, wpb=4550.5, bsz=292, num_updates=1370, lr=1.644e-05, gnorm=1.573, train_wall=5, gb_free=13.2, wall=4601
2025-04-03 06:20:43 | INFO | train_inner | epoch 011:    112 / 126 loss=6.227, nll_loss=2.795, ppl=6.94, wps=1746.8, ups=0.34, wpb=5121, bsz=324, num_updates=1372, lr=1.6464e-05, gnorm=1.797, train_wall=6, gb_free=11, wall=4607
2025-04-03 06:20:48 | INFO | train_inner | epoch 011:    114 / 126 loss=6.359, nll_loss=2.96, ppl=7.78, wps=1689.8, ups=0.37, wpb=4531, bsz=244, num_updates=1374, lr=1.6488e-05, gnorm=1.703, train_wall=5, gb_free=12.5, wall=4612
2025-04-03 06:20:54 | INFO | train_inner | epoch 011:    116 / 126 loss=6.154, nll_loss=2.718, ppl=6.58, wps=1696.9, ups=0.34, wpb=4928.5, bsz=332, num_updates=1376, lr=1.6512e-05, gnorm=1.597, train_wall=6, gb_free=9, wall=4618
2025-04-03 06:21:00 | INFO | train_inner | epoch 011:    118 / 126 loss=6.265, nll_loss=2.842, ppl=7.17, wps=1688.9, ups=0.36, wpb=4743.5, bsz=240, num_updates=1378, lr=1.6536e-05, gnorm=1.684, train_wall=6, gb_free=12.6, wall=4624
2025-04-03 06:21:05 | INFO | train_inner | epoch 011:    120 / 126 loss=6.218, nll_loss=2.794, ppl=6.93, wps=1635.6, ups=0.36, wpb=4589.5, bsz=252, num_updates=1380, lr=1.656e-05, gnorm=1.76, train_wall=6, gb_free=13.3, wall=4630
2025-04-03 06:21:11 | INFO | train_inner | epoch 011:    122 / 126 loss=6.345, nll_loss=2.946, ppl=7.71, wps=1608.5, ups=0.37, wpb=4359, bsz=164, num_updates=1382, lr=1.6584e-05, gnorm=1.693, train_wall=5, gb_free=12.9, wall=4635
2025-04-03 06:21:16 | INFO | train_inner | epoch 011:    124 / 126 loss=6.243, nll_loss=2.835, ppl=7.14, wps=1623.1, ups=0.39, wpb=4166.5, bsz=264, num_updates=1384, lr=1.6608e-05, gnorm=1.597, train_wall=5, gb_free=12.6, wall=4640
2025-04-03 06:21:20 | INFO | train_inner | epoch 011:    126 / 126 loss=6.179, nll_loss=2.723, ppl=6.6, wps=1457.7, ups=0.45, wpb=3227.5, bsz=148, num_updates=1386, lr=1.6632e-05, gnorm=2.079, train_wall=4, gb_free=12.4, wall=4645
2025-04-03 06:21:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-03 06:21:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=15907.5625Mb; avail=239177.63671875Mb
2025-04-03 06:21:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000612
2025-04-03 06:21:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15907.5625Mb; avail=239177.63671875Mb
2025-04-03 06:21:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012913
2025-04-03 06:21:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15907.5625Mb; avail=239177.63671875Mb
2025-04-03 06:21:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.010935
2025-04-03 06:21:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024813
2025-04-03 06:21:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15907.5625Mb; avail=239177.63671875Mb
2025-04-03 06:21:35 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 6.271 | nll_loss 2.659 | ppl 6.32 | wps 3861.5 | wpb 2070.5 | bsz 122.7 | num_updates 1386 | best_loss 6.271
2025-04-03 06:21:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1386 updates
2025-04-03 06:21:35 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 06:22:12 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 06:22:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt (epoch 11 @ 1386 updates, score 6.271) (writing took 62.35500485799275 seconds)
2025-04-03 06:22:37 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2025-04-03 06:22:37 | INFO | train | epoch 011 | loss 6.252 | nll_loss 2.828 | ppl 7.1 | wps 1337 | ups 0.29 | wpb 4549.7 | bsz 252.8 | num_updates 1386 | lr 1.6632e-05 | gnorm 1.705 | train_wall 351 | gb_free 12.4 | wall 4721
2025-04-03 06:22:37 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:mr-hi': 31849}; raw total size: 31849
2025-04-03 06:22:37 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:mr-hi': 31849}; resampled total size: 31849
2025-04-03 06:22:37 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:mr-hi': 1.0}
2025-04-03 06:22:37 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001114
2025-04-03 06:22:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=26714.06640625Mb; avail=228371.08203125Mb
2025-04-03 06:22:37 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000542
2025-04-03 06:22:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003643
2025-04-03 06:22:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26714.06640625Mb; avail=228371.08203125Mb
2025-04-03 06:22:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000097
2025-04-03 06:22:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26714.06640625Mb; avail=228371.08203125Mb
2025-04-03 06:22:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001141
2025-04-03 06:22:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.005223
2025-04-03 06:22:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26714.06640625Mb; avail=228371.08203125Mb
2025-04-03 06:22:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 126
2025-04-03 06:22:37 | INFO | fairseq.trainer | begin training epoch 12
2025-04-03 06:22:37 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-03 06:22:43 | INFO | train_inner | epoch 012:      2 / 126 loss=6.163, nll_loss=2.701, ppl=6.5, wps=120.3, ups=0.02, wpb=4965.5, bsz=264, num_updates=1388, lr=1.6656e-05, gnorm=1.645, train_wall=6, gb_free=13.1, wall=4727
2025-04-03 06:22:49 | INFO | train_inner | epoch 012:      4 / 126 loss=6.143, nll_loss=2.69, ppl=6.45, wps=1641.9, ups=0.35, wpb=4674.5, bsz=240, num_updates=1390, lr=1.668e-05, gnorm=1.618, train_wall=6, gb_free=10.8, wall=4733
2025-04-03 06:22:59 | INFO | train_inner | epoch 012:      6 / 126 loss=6.078, nll_loss=2.618, ppl=6.14, wps=854.1, ups=0.2, wpb=4348, bsz=272, num_updates=1392, lr=1.6704e-05, gnorm=1.67, train_wall=10, gb_free=14.5, wall=4743
2025-04-03 06:23:04 | INFO | train_inner | epoch 012:      8 / 126 loss=6.108, nll_loss=2.665, ppl=6.34, wps=1446.7, ups=0.36, wpb=3977, bsz=260, num_updates=1394, lr=1.6728e-05, gnorm=1.844, train_wall=5, gb_free=10.5, wall=4748
2025-04-03 06:23:09 | INFO | train_inner | epoch 012:     10 / 126 loss=6.275, nll_loss=2.85, ppl=7.21, wps=1730.2, ups=0.4, wpb=4343.5, bsz=172, num_updates=1396, lr=1.6752e-05, gnorm=1.906, train_wall=5, gb_free=12.7, wall=4753
2025-04-03 06:23:15 | INFO | train_inner | epoch 012:     12 / 126 loss=5.995, nll_loss=2.477, ppl=5.57, wps=1570.2, ups=0.37, wpb=4250.5, bsz=240, num_updates=1398, lr=1.6776e-05, gnorm=1.594, train_wall=5, gb_free=13.6, wall=4759
2025-04-03 06:23:20 | INFO | train_inner | epoch 012:     14 / 126 loss=6.151, nll_loss=2.689, ppl=6.45, wps=1748, ups=0.37, wpb=4777.5, bsz=304, num_updates=1400, lr=1.68e-05, gnorm=1.613, train_wall=5, gb_free=12, wall=4764
2025-04-03 06:23:26 | INFO | train_inner | epoch 012:     16 / 126 loss=6.095, nll_loss=2.624, ppl=6.17, wps=1609.2, ups=0.34, wpb=4671, bsz=272, num_updates=1402, lr=1.6824e-05, gnorm=1.513, train_wall=6, gb_free=9.7, wall=4770
2025-04-03 06:23:32 | INFO | train_inner | epoch 012:     18 / 126 loss=6.152, nll_loss=2.697, ppl=6.48, wps=1694.1, ups=0.36, wpb=4676.5, bsz=224, num_updates=1404, lr=1.6848e-05, gnorm=1.536, train_wall=6, gb_free=12.6, wall=4776
2025-04-03 06:23:38 | INFO | train_inner | epoch 012:     20 / 126 loss=6.229, nll_loss=2.803, ppl=6.98, wps=1595.8, ups=0.34, wpb=4738, bsz=248, num_updates=1406, lr=1.6872e-05, gnorm=1.637, train_wall=6, gb_free=11.9, wall=4782
2025-04-03 06:23:43 | INFO | train_inner | epoch 012:     22 / 126 loss=6.323, nll_loss=2.916, ppl=7.55, wps=1614.3, ups=0.34, wpb=4812, bsz=252, num_updates=1408, lr=1.6896e-05, gnorm=1.636, train_wall=6, gb_free=9.5, wall=4788
2025-04-03 06:23:49 | INFO | train_inner | epoch 012:     24 / 126 loss=6.115, nll_loss=2.664, ppl=6.34, wps=1609.7, ups=0.37, wpb=4317.5, bsz=264, num_updates=1410, lr=1.692e-05, gnorm=1.6, train_wall=5, gb_free=10.7, wall=4793
2025-04-03 06:23:53 | INFO | train_inner | epoch 012:     26 / 126 loss=6.091, nll_loss=2.62, ppl=6.15, wps=1238.7, ups=0.47, wpb=2627.5, bsz=120.5, num_updates=1412, lr=1.6944e-05, gnorm=2.28, train_wall=4, gb_free=11.7, wall=4797
2025-04-03 06:23:59 | INFO | train_inner | epoch 012:     28 / 126 loss=6.153, nll_loss=2.697, ppl=6.49, wps=1785.3, ups=0.36, wpb=4937, bsz=252, num_updates=1414, lr=1.6968e-05, gnorm=1.671, train_wall=6, gb_free=14, wall=4803
2025-04-03 06:24:04 | INFO | train_inner | epoch 012:     30 / 126 loss=6.201, nll_loss=2.774, ppl=6.84, wps=1544.2, ups=0.34, wpb=4523.5, bsz=332, num_updates=1416, lr=1.6992e-05, gnorm=1.638, train_wall=6, gb_free=11.5, wall=4809
2025-04-03 06:24:10 | INFO | train_inner | epoch 012:     32 / 126 loss=6.133, nll_loss=2.65, ppl=6.28, wps=1658.9, ups=0.36, wpb=4631.5, bsz=180, num_updates=1418, lr=1.7016e-05, gnorm=1.567, train_wall=6, gb_free=11.6, wall=4814
2025-04-03 06:24:16 | INFO | train_inner | epoch 012:     34 / 126 loss=6.24, nll_loss=2.807, ppl=7, wps=1622.7, ups=0.37, wpb=4424.5, bsz=240, num_updates=1420, lr=1.704e-05, gnorm=1.751, train_wall=5, gb_free=9.6, wall=4820
2025-04-03 06:24:21 | INFO | train_inner | epoch 012:     36 / 126 loss=6.251, nll_loss=2.817, ppl=7.05, wps=1502.9, ups=0.37, wpb=4029.5, bsz=176, num_updates=1422, lr=1.7064e-05, gnorm=1.87, train_wall=5, gb_free=12, wall=4825
2025-04-03 06:24:26 | INFO | train_inner | epoch 012:     38 / 126 loss=6.24, nll_loss=2.813, ppl=7.03, wps=1651.5, ups=0.37, wpb=4501.5, bsz=220, num_updates=1424, lr=1.7088e-05, gnorm=1.691, train_wall=5, gb_free=12.3, wall=4830
2025-04-03 06:24:32 | INFO | train_inner | epoch 012:     40 / 126 loss=6.129, nll_loss=2.684, ppl=6.43, wps=1659.1, ups=0.35, wpb=4771, bsz=320, num_updates=1426, lr=1.7112e-05, gnorm=1.505, train_wall=6, gb_free=13.3, wall=4836
2025-04-03 06:24:38 | INFO | train_inner | epoch 012:     42 / 126 loss=6.302, nll_loss=2.904, ppl=7.48, wps=1497.7, ups=0.35, wpb=4283, bsz=240, num_updates=1428, lr=1.7136e-05, gnorm=1.647, train_wall=6, gb_free=10.6, wall=4842
2025-04-03 06:24:43 | INFO | train_inner | epoch 012:     44 / 126 loss=6.101, nll_loss=2.634, ppl=6.21, wps=1214.7, ups=0.42, wpb=2924.5, bsz=144, num_updates=1430, lr=1.716e-05, gnorm=2.187, train_wall=5, gb_free=13.6, wall=4847
2025-04-03 06:24:48 | INFO | train_inner | epoch 012:     46 / 126 loss=6.177, nll_loss=2.727, ppl=6.62, wps=1717.8, ups=0.36, wpb=4802, bsz=260, num_updates=1432, lr=1.7184e-05, gnorm=1.756, train_wall=6, gb_free=11.8, wall=4852
2025-04-03 06:24:54 | INFO | train_inner | epoch 012:     48 / 126 loss=6.172, nll_loss=2.715, ppl=6.57, wps=1694.7, ups=0.35, wpb=4868, bsz=244, num_updates=1434, lr=1.7208e-05, gnorm=1.555, train_wall=6, gb_free=12.2, wall=4858
2025-04-03 06:24:59 | INFO | train_inner | epoch 012:     50 / 126 loss=6.273, nll_loss=2.856, ppl=7.24, wps=1820.1, ups=0.36, wpb=5018, bsz=252, num_updates=1436, lr=1.7232e-05, gnorm=1.65, train_wall=6, gb_free=11.5, wall=4864
2025-04-03 06:25:05 | INFO | train_inner | epoch 012:     52 / 126 loss=6.226, nll_loss=2.812, ppl=7.02, wps=1729.1, ups=0.36, wpb=4791.5, bsz=316, num_updates=1438, lr=1.7256e-05, gnorm=1.623, train_wall=6, gb_free=12.6, wall=4869
2025-04-03 06:25:11 | INFO | train_inner | epoch 012:     54 / 126 loss=6.166, nll_loss=2.716, ppl=6.57, wps=1670.5, ups=0.35, wpb=4737, bsz=264, num_updates=1440, lr=1.728e-05, gnorm=1.502, train_wall=6, gb_free=12.3, wall=4875
2025-04-03 06:25:16 | INFO | train_inner | epoch 012:     56 / 126 loss=6.207, nll_loss=2.752, ppl=6.74, wps=1576.3, ups=0.38, wpb=4181, bsz=156, num_updates=1442, lr=1.7304e-05, gnorm=1.752, train_wall=5, gb_free=10.2, wall=4880
2025-04-03 06:25:21 | INFO | train_inner | epoch 012:     58 / 126 loss=6.066, nll_loss=2.599, ppl=6.06, wps=1604.1, ups=0.36, wpb=4395.5, bsz=276, num_updates=1444, lr=1.7328e-05, gnorm=1.641, train_wall=5, gb_free=12.6, wall=4886
2025-04-03 06:25:27 | INFO | train_inner | epoch 012:     60 / 126 loss=6.252, nll_loss=2.827, ppl=7.1, wps=1589, ups=0.36, wpb=4432.5, bsz=212, num_updates=1446, lr=1.7352e-05, gnorm=1.763, train_wall=6, gb_free=11.4, wall=4891
2025-04-03 06:25:33 | INFO | train_inner | epoch 012:     62 / 126 loss=6.112, nll_loss=2.665, ppl=6.34, wps=1550.6, ups=0.36, wpb=4278, bsz=280, num_updates=1448, lr=1.7376e-05, gnorm=1.6, train_wall=6, gb_free=13.9, wall=4897
2025-04-03 06:25:38 | INFO | train_inner | epoch 012:     64 / 126 loss=6.085, nll_loss=2.622, ppl=6.15, wps=1496.8, ups=0.35, wpb=4292.5, bsz=276, num_updates=1450, lr=1.74e-05, gnorm=1.541, train_wall=6, gb_free=13.3, wall=4902
2025-04-03 06:25:44 | INFO | train_inner | epoch 012:     66 / 126 loss=6.081, nll_loss=2.62, ppl=6.15, wps=1667.3, ups=0.34, wpb=4944, bsz=284, num_updates=1452, lr=1.7424e-05, gnorm=1.493, train_wall=6, gb_free=10.3, wall=4908
2025-04-03 06:25:50 | INFO | train_inner | epoch 012:     68 / 126 loss=6.214, nll_loss=2.785, ppl=6.89, wps=1811, ups=0.34, wpb=5322.5, bsz=312, num_updates=1454, lr=1.7448e-05, gnorm=1.529, train_wall=6, gb_free=12.5, wall=4914
2025-04-03 06:25:56 | INFO | train_inner | epoch 012:     70 / 126 loss=6.143, nll_loss=2.693, ppl=6.47, wps=1840.5, ups=0.33, wpb=5541.5, bsz=328, num_updates=1456, lr=1.7472e-05, gnorm=1.455, train_wall=6, gb_free=10.5, wall=4920
2025-04-03 06:26:02 | INFO | train_inner | epoch 012:     72 / 126 loss=6.107, nll_loss=2.643, ppl=6.25, wps=1831.4, ups=0.37, wpb=5001, bsz=328, num_updates=1458, lr=1.7496e-05, gnorm=1.47, train_wall=5, gb_free=11.7, wall=4926
2025-04-03 06:26:07 | INFO | train_inner | epoch 012:     74 / 126 loss=6.14, nll_loss=2.684, ppl=6.43, wps=1472.3, ups=0.35, wpb=4215, bsz=232, num_updates=1460, lr=1.752e-05, gnorm=1.749, train_wall=6, gb_free=13.5, wall=4931
2025-04-03 06:26:13 | INFO | train_inner | epoch 012:     76 / 126 loss=6.176, nll_loss=2.735, ppl=6.66, wps=1697.5, ups=0.34, wpb=4957.5, bsz=248, num_updates=1462, lr=1.7544e-05, gnorm=1.738, train_wall=6, gb_free=13.5, wall=4937
2025-04-03 06:26:19 | INFO | train_inner | epoch 012:     78 / 126 loss=6.257, nll_loss=2.844, ppl=7.18, wps=1741.9, ups=0.36, wpb=4817, bsz=288, num_updates=1464, lr=1.7568e-05, gnorm=1.613, train_wall=6, gb_free=10.9, wall=4943
2025-04-03 06:26:24 | INFO | train_inner | epoch 012:     80 / 126 loss=6.035, nll_loss=2.576, ppl=5.96, wps=1679.6, ups=0.36, wpb=4727, bsz=404, num_updates=1466, lr=1.7592e-05, gnorm=1.434, train_wall=6, gb_free=12.4, wall=4948
2025-04-03 06:26:30 | INFO | train_inner | epoch 012:     82 / 126 loss=6.089, nll_loss=2.62, ppl=6.15, wps=1461.1, ups=0.37, wpb=3983, bsz=232, num_updates=1468, lr=1.7616e-05, gnorm=1.617, train_wall=5, gb_free=13.6, wall=4954
2025-04-03 06:26:35 | INFO | train_inner | epoch 012:     84 / 126 loss=6.037, nll_loss=2.562, ppl=5.9, wps=1619.5, ups=0.39, wpb=4112, bsz=268, num_updates=1470, lr=1.764e-05, gnorm=1.574, train_wall=5, gb_free=13.3, wall=4959
2025-04-03 06:26:40 | INFO | train_inner | epoch 012:     86 / 126 loss=6.097, nll_loss=2.626, ppl=6.17, wps=1741.9, ups=0.36, wpb=4846.5, bsz=240, num_updates=1472, lr=1.7664e-05, gnorm=1.524, train_wall=6, gb_free=12.8, wall=4965
2025-04-03 06:26:46 | INFO | train_inner | epoch 012:     88 / 126 loss=6.123, nll_loss=2.668, ppl=6.36, wps=1705.1, ups=0.35, wpb=4941, bsz=260, num_updates=1474, lr=1.7688e-05, gnorm=1.667, train_wall=6, gb_free=13, wall=4970
2025-04-03 06:26:52 | INFO | train_inner | epoch 012:     90 / 126 loss=6.186, nll_loss=2.741, ppl=6.69, wps=1829.8, ups=0.35, wpb=5219.5, bsz=280, num_updates=1476, lr=1.7712e-05, gnorm=1.589, train_wall=6, gb_free=12.4, wall=4976
2025-04-03 06:26:57 | INFO | train_inner | epoch 012:     92 / 126 loss=6.156, nll_loss=2.708, ppl=6.54, wps=1569.1, ups=0.38, wpb=4143.5, bsz=236, num_updates=1478, lr=1.7736e-05, gnorm=1.851, train_wall=5, gb_free=13.5, wall=4981
2025-04-03 06:27:03 | INFO | train_inner | epoch 012:     94 / 126 loss=6.198, nll_loss=2.763, ppl=6.79, wps=1483.2, ups=0.36, wpb=4144.5, bsz=200, num_updates=1480, lr=1.776e-05, gnorm=1.877, train_wall=6, gb_free=13.8, wall=4987
2025-04-03 06:27:08 | INFO | train_inner | epoch 012:     96 / 126 loss=6.215, nll_loss=2.785, ppl=6.89, wps=1699.6, ups=0.37, wpb=4565, bsz=264, num_updates=1482, lr=1.7784e-05, gnorm=1.696, train_wall=5, gb_free=14.8, wall=4992
2025-04-03 06:27:14 | INFO | train_inner | epoch 012:     98 / 126 loss=6.111, nll_loss=2.653, ppl=6.29, wps=1642.2, ups=0.35, wpb=4631, bsz=276, num_updates=1484, lr=1.7808e-05, gnorm=1.596, train_wall=6, gb_free=12.8, wall=4998
2025-04-03 06:27:20 | INFO | train_inner | epoch 012:    100 / 126 loss=6.115, nll_loss=2.639, ppl=6.23, wps=1685.9, ups=0.33, wpb=5047.5, bsz=204, num_updates=1486, lr=1.7832e-05, gnorm=1.827, train_wall=6, gb_free=12.6, wall=5004
2025-04-03 06:27:26 | INFO | train_inner | epoch 012:    102 / 126 loss=6.081, nll_loss=2.613, ppl=6.12, wps=1453.7, ups=0.35, wpb=4212.5, bsz=252, num_updates=1488, lr=1.7856e-05, gnorm=1.547, train_wall=6, gb_free=10.7, wall=5010
2025-04-03 06:27:31 | INFO | train_inner | epoch 012:    104 / 126 loss=6.121, nll_loss=2.66, ppl=6.32, wps=1697.8, ups=0.35, wpb=4812, bsz=252, num_updates=1490, lr=1.788e-05, gnorm=1.721, train_wall=6, gb_free=11.1, wall=5015
2025-04-03 06:27:37 | INFO | train_inner | epoch 012:    106 / 126 loss=6.159, nll_loss=2.731, ppl=6.64, wps=1727.9, ups=0.34, wpb=5115, bsz=344, num_updates=1492, lr=1.7904e-05, gnorm=1.63, train_wall=6, gb_free=14.2, wall=5021
2025-04-03 06:27:42 | INFO | train_inner | epoch 012:    108 / 126 loss=6.096, nll_loss=2.647, ppl=6.26, wps=1696.6, ups=0.39, wpb=4323, bsz=284, num_updates=1494, lr=1.7928e-05, gnorm=1.606, train_wall=5, gb_free=14.9, wall=5026
2025-04-03 06:27:48 | INFO | train_inner | epoch 012:    110 / 126 loss=6.158, nll_loss=2.712, ppl=6.55, wps=1792.2, ups=0.35, wpb=5050, bsz=280, num_updates=1496, lr=1.7952e-05, gnorm=1.57, train_wall=6, gb_free=12.7, wall=5032
2025-04-03 06:27:54 | INFO | train_inner | epoch 012:    112 / 126 loss=6.254, nll_loss=2.817, ppl=7.04, wps=1635.7, ups=0.35, wpb=4655.5, bsz=212, num_updates=1498, lr=1.7976e-05, gnorm=1.674, train_wall=6, gb_free=10.1, wall=5038
2025-04-03 06:27:59 | INFO | train_inner | epoch 012:    114 / 126 loss=6.104, nll_loss=2.633, ppl=6.2, wps=1895.4, ups=0.36, wpb=5320, bsz=332, num_updates=1500, lr=1.8e-05, gnorm=1.437, train_wall=6, gb_free=12.9, wall=5043
2025-04-03 06:28:04 | INFO | train_inner | epoch 012:    116 / 126 loss=6.162, nll_loss=2.711, ppl=6.55, wps=1520.1, ups=0.38, wpb=3971, bsz=236, num_updates=1502, lr=1.8024e-05, gnorm=1.734, train_wall=5, gb_free=13.8, wall=5049
2025-04-03 06:28:10 | INFO | train_inner | epoch 012:    118 / 126 loss=6.249, nll_loss=2.819, ppl=7.06, wps=1665, ups=0.38, wpb=4420.5, bsz=204, num_updates=1504, lr=1.8048e-05, gnorm=1.654, train_wall=5, gb_free=13.1, wall=5054
2025-04-03 06:28:15 | INFO | train_inner | epoch 012:    120 / 126 loss=6.145, nll_loss=2.706, ppl=6.53, wps=1739.3, ups=0.36, wpb=4878, bsz=220, num_updates=1506, lr=1.8072e-05, gnorm=1.489, train_wall=6, gb_free=11.4, wall=5059
2025-04-03 06:28:21 | INFO | train_inner | epoch 012:    122 / 126 loss=6.051, nll_loss=2.591, ppl=6.02, wps=1609.8, ups=0.36, wpb=4441, bsz=212, num_updates=1508, lr=1.8096e-05, gnorm=1.619, train_wall=6, gb_free=8.6, wall=5065
2025-04-03 06:28:26 | INFO | train_inner | epoch 012:    124 / 126 loss=6.29, nll_loss=2.889, ppl=7.41, wps=1607, ups=0.37, wpb=4336.5, bsz=260, num_updates=1510, lr=1.812e-05, gnorm=1.677, train_wall=5, gb_free=9.6, wall=5070
2025-04-03 06:28:31 | INFO | train_inner | epoch 012:    126 / 126 loss=6.271, nll_loss=2.834, ppl=7.13, wps=1726.4, ups=0.44, wpb=3936.5, bsz=180, num_updates=1512, lr=1.8144e-05, gnorm=1.989, train_wall=5, gb_free=14.4, wall=5075
2025-04-03 06:28:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-03 06:28:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=15928.5390625Mb; avail=239156.6875Mb
2025-04-03 06:28:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000641
2025-04-03 06:28:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15928.5390625Mb; avail=239156.6875Mb
2025-04-03 06:28:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012746
2025-04-03 06:28:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15928.5390625Mb; avail=239156.6875Mb
2025-04-03 06:28:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.010948
2025-04-03 06:28:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024697
2025-04-03 06:28:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15928.5390625Mb; avail=239156.6875Mb
2025-04-03 06:28:45 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 6.219 | nll_loss 2.595 | ppl 6.04 | wps 3867.2 | wpb 2070.5 | bsz 122.7 | num_updates 1512 | best_loss 6.219
2025-04-03 06:28:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1512 updates
2025-04-03 06:28:45 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 06:29:23 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 06:29:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt (epoch 12 @ 1512 updates, score 6.219) (writing took 62.47901131899562 seconds)
2025-04-03 06:29:48 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2025-04-03 06:29:48 | INFO | train | epoch 012 | loss 6.16 | nll_loss 2.712 | ppl 6.55 | wps 1331.5 | ups 0.29 | wpb 4549.7 | bsz 252.8 | num_updates 1512 | lr 1.8144e-05 | gnorm 1.661 | train_wall 353 | gb_free 14.4 | wall 5152
2025-04-03 06:29:48 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:mr-hi': 31849}; raw total size: 31849
2025-04-03 06:29:48 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:mr-hi': 31849}; resampled total size: 31849
2025-04-03 06:29:48 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:mr-hi': 1.0}
2025-04-03 06:29:48 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001095
2025-04-03 06:29:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=26737.46484375Mb; avail=228347.71484375Mb
2025-04-03 06:29:48 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000676
2025-04-03 06:29:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003490
2025-04-03 06:29:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26738.44921875Mb; avail=228346.73046875Mb
2025-04-03 06:29:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000097
2025-04-03 06:29:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26738.44921875Mb; avail=228346.73046875Mb
2025-04-03 06:29:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001150
2025-04-03 06:29:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.005044
2025-04-03 06:29:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26738.44921875Mb; avail=228346.73046875Mb
2025-04-03 06:29:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 126
2025-04-03 06:29:48 | INFO | fairseq.trainer | begin training epoch 13
2025-04-03 06:29:48 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-03 06:29:53 | INFO | train_inner | epoch 013:      2 / 126 loss=6.175, nll_loss=2.714, ppl=6.56, wps=109, ups=0.02, wpb=4492, bsz=172, num_updates=1514, lr=1.8168e-05, gnorm=1.624, train_wall=5, gb_free=14.1, wall=5157
2025-04-03 06:29:59 | INFO | train_inner | epoch 013:      4 / 126 loss=6.137, nll_loss=2.673, ppl=6.38, wps=1404.7, ups=0.35, wpb=3997, bsz=196, num_updates=1516, lr=1.8192e-05, gnorm=1.712, train_wall=6, gb_free=10.6, wall=5163
2025-04-03 06:30:04 | INFO | train_inner | epoch 013:      6 / 126 loss=6.094, nll_loss=2.618, ppl=6.14, wps=1862.3, ups=0.36, wpb=5110, bsz=260, num_updates=1518, lr=1.8216e-05, gnorm=1.521, train_wall=5, gb_free=10.8, wall=5169
2025-04-03 06:30:10 | INFO | train_inner | epoch 013:      8 / 126 loss=5.924, nll_loss=2.431, ppl=5.39, wps=1667.2, ups=0.37, wpb=4462, bsz=312, num_updates=1520, lr=1.824e-05, gnorm=1.71, train_wall=5, gb_free=12.3, wall=5174
2025-04-03 06:30:15 | INFO | train_inner | epoch 013:     10 / 126 loss=6.124, nll_loss=2.667, ppl=6.35, wps=1842.1, ups=0.37, wpb=5022, bsz=240, num_updates=1522, lr=1.8264e-05, gnorm=1.607, train_wall=5, gb_free=12, wall=5179
2025-04-03 06:30:21 | INFO | train_inner | epoch 013:     12 / 126 loss=6.141, nll_loss=2.68, ppl=6.41, wps=1607.8, ups=0.35, wpb=4566, bsz=168, num_updates=1524, lr=1.8288e-05, gnorm=1.743, train_wall=6, gb_free=9.4, wall=5185
2025-04-03 06:30:27 | INFO | train_inner | epoch 013:     14 / 126 loss=5.987, nll_loss=2.486, ppl=5.6, wps=1617.5, ups=0.35, wpb=4602.5, bsz=232, num_updates=1526, lr=1.8312e-05, gnorm=1.808, train_wall=6, gb_free=9.6, wall=5191
2025-04-03 06:30:32 | INFO | train_inner | epoch 013:     16 / 126 loss=5.978, nll_loss=2.479, ppl=5.57, wps=1725.4, ups=0.37, wpb=4725.5, bsz=296, num_updates=1528, lr=1.8336e-05, gnorm=1.444, train_wall=5, gb_free=13.4, wall=5196
2025-04-03 06:30:37 | INFO | train_inner | epoch 013:     18 / 126 loss=6.061, nll_loss=2.591, ppl=6.03, wps=1687.8, ups=0.38, wpb=4479.5, bsz=288, num_updates=1530, lr=1.836e-05, gnorm=1.712, train_wall=5, gb_free=14.3, wall=5201
2025-04-03 06:30:43 | INFO | train_inner | epoch 013:     20 / 126 loss=6.108, nll_loss=2.665, ppl=6.34, wps=1440.4, ups=0.36, wpb=4017, bsz=348, num_updates=1532, lr=1.8384e-05, gnorm=1.702, train_wall=6, gb_free=9.5, wall=5207
2025-04-03 06:30:48 | INFO | train_inner | epoch 013:     22 / 126 loss=6.231, nll_loss=2.807, ppl=7, wps=1638.5, ups=0.36, wpb=4499, bsz=292, num_updates=1534, lr=1.8408e-05, gnorm=1.673, train_wall=5, gb_free=14.1, wall=5213
2025-04-03 06:30:54 | INFO | train_inner | epoch 013:     24 / 126 loss=6.052, nll_loss=2.575, ppl=5.96, wps=1656.1, ups=0.34, wpb=4849.5, bsz=268, num_updates=1536, lr=1.8432e-05, gnorm=1.605, train_wall=6, gb_free=9, wall=5218
2025-04-03 06:31:00 | INFO | train_inner | epoch 013:     26 / 126 loss=6.139, nll_loss=2.681, ppl=6.41, wps=1742.5, ups=0.36, wpb=4815.5, bsz=252, num_updates=1538, lr=1.8456e-05, gnorm=1.529, train_wall=6, gb_free=14.3, wall=5224
2025-04-03 06:31:05 | INFO | train_inner | epoch 013:     28 / 126 loss=6.046, nll_loss=2.571, ppl=5.94, wps=1581.5, ups=0.35, wpb=4460.5, bsz=232, num_updates=1540, lr=1.848e-05, gnorm=1.532, train_wall=6, gb_free=9.5, wall=5230
2025-04-03 06:31:11 | INFO | train_inner | epoch 013:     30 / 126 loss=6.09, nll_loss=2.64, ppl=6.23, wps=1668.7, ups=0.38, wpb=4385.5, bsz=324, num_updates=1542, lr=1.8504e-05, gnorm=1.485, train_wall=5, gb_free=10.8, wall=5235
2025-04-03 06:31:16 | INFO | train_inner | epoch 013:     32 / 126 loss=5.97, nll_loss=2.477, ppl=5.57, wps=1682.6, ups=0.37, wpb=4505.5, bsz=320, num_updates=1544, lr=1.8528e-05, gnorm=1.445, train_wall=5, gb_free=12.7, wall=5240
2025-04-03 06:31:22 | INFO | train_inner | epoch 013:     34 / 126 loss=5.96, nll_loss=2.461, ppl=5.51, wps=1753.9, ups=0.36, wpb=4846.5, bsz=364, num_updates=1546, lr=1.8552e-05, gnorm=1.467, train_wall=6, gb_free=11.4, wall=5246
2025-04-03 06:31:27 | INFO | train_inner | epoch 013:     36 / 126 loss=6.006, nll_loss=2.523, ppl=5.75, wps=1663.7, ups=0.37, wpb=4480.5, bsz=308, num_updates=1548, lr=1.8576e-05, gnorm=1.543, train_wall=5, gb_free=11.7, wall=5251
2025-04-03 06:31:33 | INFO | train_inner | epoch 013:     38 / 126 loss=6.15, nll_loss=2.695, ppl=6.48, wps=1680.4, ups=0.35, wpb=4748, bsz=188, num_updates=1550, lr=1.86e-05, gnorm=1.744, train_wall=6, gb_free=12.4, wall=5257
2025-04-03 06:31:38 | INFO | train_inner | epoch 013:     40 / 126 loss=6.051, nll_loss=2.588, ppl=6.01, wps=1751.6, ups=0.35, wpb=5066.5, bsz=272, num_updates=1552, lr=1.8624e-05, gnorm=1.478, train_wall=6, gb_free=9.9, wall=5263
2025-04-03 06:31:48 | INFO | train_inner | epoch 013:     42 / 126 loss=6.099, nll_loss=2.614, ppl=6.12, wps=683.4, ups=0.2, wpb=3404.5, bsz=96.5, num_updates=1554, lr=1.8648e-05, gnorm=1.911, train_wall=10, gb_free=10.6, wall=5272
2025-04-03 06:31:54 | INFO | train_inner | epoch 013:     44 / 126 loss=6.203, nll_loss=2.752, ppl=6.74, wps=1580, ups=0.35, wpb=4540, bsz=220, num_updates=1556, lr=1.8672e-05, gnorm=1.59, train_wall=6, gb_free=9.9, wall=5278
2025-04-03 06:32:00 | INFO | train_inner | epoch 013:     46 / 126 loss=6.037, nll_loss=2.545, ppl=5.84, wps=1750.1, ups=0.37, wpb=4734.5, bsz=272, num_updates=1558, lr=1.8696e-05, gnorm=1.518, train_wall=5, gb_free=13.1, wall=5284
2025-04-03 06:32:05 | INFO | train_inner | epoch 013:     48 / 126 loss=6.01, nll_loss=2.514, ppl=5.71, wps=1563, ups=0.36, wpb=4330.5, bsz=204, num_updates=1560, lr=1.872e-05, gnorm=1.687, train_wall=6, gb_free=11.8, wall=5289
2025-04-03 06:32:10 | INFO | train_inner | epoch 013:     50 / 126 loss=6.148, nll_loss=2.69, ppl=6.45, wps=1385.9, ups=0.4, wpb=3504.5, bsz=132, num_updates=1562, lr=1.8744e-05, gnorm=1.779, train_wall=5, gb_free=13.7, wall=5294
2025-04-03 06:32:16 | INFO | train_inner | epoch 013:     52 / 126 loss=6.04, nll_loss=2.563, ppl=5.91, wps=1549.4, ups=0.37, wpb=4197, bsz=244, num_updates=1564, lr=1.8768e-05, gnorm=1.73, train_wall=5, gb_free=10.4, wall=5300
2025-04-03 06:32:21 | INFO | train_inner | epoch 013:     54 / 126 loss=6.044, nll_loss=2.561, ppl=5.9, wps=1631.8, ups=0.34, wpb=4792, bsz=176, num_updates=1566, lr=1.8792e-05, gnorm=1.664, train_wall=6, gb_free=12.5, wall=5306
2025-04-03 06:32:27 | INFO | train_inner | epoch 013:     56 / 126 loss=6.05, nll_loss=2.58, ppl=5.98, wps=1619, ups=0.34, wpb=4787, bsz=316, num_updates=1568, lr=1.8816e-05, gnorm=1.494, train_wall=6, gb_free=11.4, wall=5311
2025-04-03 06:32:33 | INFO | train_inner | epoch 013:     58 / 126 loss=6.108, nll_loss=2.62, ppl=6.15, wps=1500.4, ups=0.37, wpb=4057.5, bsz=128, num_updates=1570, lr=1.884e-05, gnorm=1.844, train_wall=5, gb_free=13.9, wall=5317
2025-04-03 06:32:39 | INFO | train_inner | epoch 013:     60 / 126 loss=6.218, nll_loss=2.781, ppl=6.87, wps=1549.3, ups=0.33, wpb=4630.5, bsz=200, num_updates=1572, lr=1.8864e-05, gnorm=1.611, train_wall=6, gb_free=9.1, wall=5323
2025-04-03 06:32:44 | INFO | train_inner | epoch 013:     62 / 126 loss=6.114, nll_loss=2.657, ppl=6.31, wps=1713.6, ups=0.36, wpb=4791, bsz=224, num_updates=1574, lr=1.8888e-05, gnorm=1.573, train_wall=6, gb_free=12.5, wall=5328
2025-04-03 06:32:50 | INFO | train_inner | epoch 013:     64 / 126 loss=6.193, nll_loss=2.755, ppl=6.75, wps=1852.9, ups=0.33, wpb=5543, bsz=312, num_updates=1576, lr=1.8912e-05, gnorm=1.572, train_wall=6, gb_free=9.2, wall=5334
2025-04-03 06:32:56 | INFO | train_inner | epoch 013:     66 / 126 loss=6.076, nll_loss=2.605, ppl=6.09, wps=1728.3, ups=0.36, wpb=4833, bsz=308, num_updates=1578, lr=1.8936e-05, gnorm=1.656, train_wall=6, gb_free=11.3, wall=5340
2025-04-03 06:33:01 | INFO | train_inner | epoch 013:     68 / 126 loss=6.08, nll_loss=2.604, ppl=6.08, wps=1577.1, ups=0.36, wpb=4346, bsz=256, num_updates=1580, lr=1.896e-05, gnorm=1.754, train_wall=6, gb_free=10.2, wall=5346
2025-04-03 06:33:07 | INFO | train_inner | epoch 013:     70 / 126 loss=6.097, nll_loss=2.611, ppl=6.11, wps=1694.3, ups=0.39, wpb=4371, bsz=176, num_updates=1582, lr=1.8984e-05, gnorm=1.766, train_wall=5, gb_free=11.9, wall=5351
2025-04-03 06:33:12 | INFO | train_inner | epoch 013:     72 / 126 loss=5.975, nll_loss=2.5, ppl=5.66, wps=1455.8, ups=0.37, wpb=3898.5, bsz=276, num_updates=1584, lr=1.9008e-05, gnorm=1.674, train_wall=5, gb_free=13.9, wall=5356
2025-04-03 06:33:18 | INFO | train_inner | epoch 013:     74 / 126 loss=6.019, nll_loss=2.549, ppl=5.85, wps=1633, ups=0.35, wpb=4656, bsz=256, num_updates=1586, lr=1.9032e-05, gnorm=1.594, train_wall=6, gb_free=9, wall=5362
2025-04-03 06:33:23 | INFO | train_inner | epoch 013:     76 / 126 loss=6.138, nll_loss=2.693, ppl=6.46, wps=1686.3, ups=0.37, wpb=4561.5, bsz=252, num_updates=1588, lr=1.9056e-05, gnorm=1.627, train_wall=5, gb_free=14.5, wall=5367
2025-04-03 06:33:29 | INFO | train_inner | epoch 013:     78 / 126 loss=6.172, nll_loss=2.725, ppl=6.61, wps=1794.7, ups=0.35, wpb=5057.5, bsz=256, num_updates=1590, lr=1.908e-05, gnorm=1.922, train_wall=6, gb_free=11, wall=5373
2025-04-03 06:33:34 | INFO | train_inner | epoch 013:     80 / 126 loss=6.014, nll_loss=2.528, ppl=5.77, wps=1589.8, ups=0.38, wpb=4205.5, bsz=348, num_updates=1592, lr=1.9104e-05, gnorm=1.608, train_wall=5, gb_free=11.6, wall=5378
2025-04-03 06:33:40 | INFO | train_inner | epoch 013:     82 / 126 loss=6.009, nll_loss=2.508, ppl=5.69, wps=1403.3, ups=0.35, wpb=4032, bsz=228, num_updates=1594, lr=1.9128e-05, gnorm=1.589, train_wall=6, gb_free=13.4, wall=5384
2025-04-03 06:33:45 | INFO | train_inner | epoch 013:     84 / 126 loss=6.121, nll_loss=2.651, ppl=6.28, wps=1714.8, ups=0.35, wpb=4917, bsz=296, num_updates=1596, lr=1.9152e-05, gnorm=1.611, train_wall=6, gb_free=9.9, wall=5390
2025-04-03 06:33:51 | INFO | train_inner | epoch 013:     86 / 126 loss=6.209, nll_loss=2.781, ppl=6.87, wps=1635.3, ups=0.36, wpb=4500, bsz=232, num_updates=1598, lr=1.9176e-05, gnorm=1.624, train_wall=5, gb_free=12.1, wall=5395
2025-04-03 06:33:57 | INFO | train_inner | epoch 013:     88 / 126 loss=6.058, nll_loss=2.606, ppl=6.09, wps=1547.7, ups=0.36, wpb=4303.5, bsz=224, num_updates=1600, lr=1.92e-05, gnorm=1.591, train_wall=6, gb_free=13.5, wall=5401
2025-04-03 06:34:02 | INFO | train_inner | epoch 013:     90 / 126 loss=6.014, nll_loss=2.546, ppl=5.84, wps=1688.8, ups=0.35, wpb=4815.5, bsz=316, num_updates=1602, lr=1.9224e-05, gnorm=1.503, train_wall=6, gb_free=13.3, wall=5406
2025-04-03 06:34:08 | INFO | train_inner | epoch 013:     92 / 126 loss=6.113, nll_loss=2.645, ppl=6.25, wps=1709.2, ups=0.36, wpb=4795, bsz=232, num_updates=1604, lr=1.9248e-05, gnorm=1.569, train_wall=6, gb_free=10.6, wall=5412
2025-04-03 06:34:13 | INFO | train_inner | epoch 013:     94 / 126 loss=6.046, nll_loss=2.544, ppl=5.83, wps=1633.6, ups=0.36, wpb=4599, bsz=192, num_updates=1606, lr=1.9272e-05, gnorm=1.568, train_wall=6, gb_free=9.9, wall=5418
2025-04-03 06:34:19 | INFO | train_inner | epoch 013:     96 / 126 loss=6.032, nll_loss=2.536, ppl=5.8, wps=1685.2, ups=0.36, wpb=4623.5, bsz=204, num_updates=1608, lr=1.9296e-05, gnorm=1.578, train_wall=5, gb_free=9.7, wall=5423
2025-04-03 06:34:25 | INFO | train_inner | epoch 013:     98 / 126 loss=6.04, nll_loss=2.563, ppl=5.91, wps=1801.2, ups=0.36, wpb=5063, bsz=324, num_updates=1610, lr=1.932e-05, gnorm=1.505, train_wall=6, gb_free=10.8, wall=5429
2025-04-03 06:34:30 | INFO | train_inner | epoch 013:    100 / 126 loss=5.956, nll_loss=2.484, ppl=5.6, wps=1562.5, ups=0.37, wpb=4240.5, bsz=288, num_updates=1612, lr=1.9344e-05, gnorm=1.579, train_wall=5, gb_free=11.1, wall=5434
2025-04-03 06:34:36 | INFO | train_inner | epoch 013:    102 / 126 loss=6.178, nll_loss=2.757, ppl=6.76, wps=1833.7, ups=0.35, wpb=5256, bsz=296, num_updates=1614, lr=1.9368e-05, gnorm=1.565, train_wall=6, gb_free=10.8, wall=5440
2025-04-03 06:34:41 | INFO | train_inner | epoch 013:    104 / 126 loss=6.054, nll_loss=2.588, ppl=6.01, wps=1611.1, ups=0.37, wpb=4364, bsz=272, num_updates=1616, lr=1.9392e-05, gnorm=1.509, train_wall=5, gb_free=11, wall=5445
2025-04-03 06:34:47 | INFO | train_inner | epoch 013:    106 / 126 loss=6.115, nll_loss=2.631, ppl=6.19, wps=1809.8, ups=0.33, wpb=5459, bsz=284, num_updates=1618, lr=1.9416e-05, gnorm=1.508, train_wall=6, gb_free=11.5, wall=5451
2025-04-03 06:34:53 | INFO | train_inner | epoch 013:    108 / 126 loss=5.972, nll_loss=2.46, ppl=5.5, wps=1560.5, ups=0.37, wpb=4189.5, bsz=248, num_updates=1620, lr=1.944e-05, gnorm=1.691, train_wall=5, gb_free=12.9, wall=5457
2025-04-03 06:34:58 | INFO | train_inner | epoch 013:    110 / 126 loss=6.017, nll_loss=2.526, ppl=5.76, wps=1768.7, ups=0.36, wpb=4897.5, bsz=296, num_updates=1622, lr=1.9464e-05, gnorm=1.455, train_wall=6, gb_free=11.7, wall=5462
2025-04-03 06:35:04 | INFO | train_inner | epoch 013:    112 / 126 loss=6.034, nll_loss=2.562, ppl=5.91, wps=1505.6, ups=0.33, wpb=4520.5, bsz=224, num_updates=1624, lr=1.9488e-05, gnorm=1.551, train_wall=6, gb_free=9.9, wall=5468
2025-04-03 06:35:10 | INFO | train_inner | epoch 013:    114 / 126 loss=6.224, nll_loss=2.807, ppl=7, wps=1706.8, ups=0.35, wpb=4905.5, bsz=244, num_updates=1626, lr=1.9512e-05, gnorm=1.549, train_wall=6, gb_free=10.4, wall=5474
2025-04-03 06:35:15 | INFO | train_inner | epoch 013:    116 / 126 loss=5.987, nll_loss=2.506, ppl=5.68, wps=1643.8, ups=0.37, wpb=4385, bsz=212, num_updates=1628, lr=1.9536e-05, gnorm=1.539, train_wall=5, gb_free=12.8, wall=5479
2025-04-03 06:35:21 | INFO | train_inner | epoch 013:    118 / 126 loss=6.123, nll_loss=2.661, ppl=6.32, wps=1537.6, ups=0.35, wpb=4440, bsz=232, num_updates=1630, lr=1.956e-05, gnorm=1.57, train_wall=6, gb_free=11.7, wall=5485
2025-04-03 06:35:26 | INFO | train_inner | epoch 013:    120 / 126 loss=6.124, nll_loss=2.683, ppl=6.42, wps=1519.9, ups=0.36, wpb=4203.5, bsz=324, num_updates=1632, lr=1.9584e-05, gnorm=1.809, train_wall=6, gb_free=9.4, wall=5491
2025-04-03 06:35:32 | INFO | train_inner | epoch 013:    122 / 126 loss=6.047, nll_loss=2.552, ppl=5.87, wps=1651.4, ups=0.38, wpb=4293, bsz=224, num_updates=1634, lr=1.9608e-05, gnorm=1.76, train_wall=5, gb_free=14.4, wall=5496
2025-04-03 06:35:37 | INFO | train_inner | epoch 013:    124 / 126 loss=6.021, nll_loss=2.537, ppl=5.81, wps=1642.3, ups=0.36, wpb=4527, bsz=300, num_updates=1636, lr=1.9632e-05, gnorm=1.449, train_wall=6, gb_free=14, wall=5501
2025-04-03 06:35:41 | INFO | train_inner | epoch 013:    126 / 126 loss=6.026, nll_loss=2.543, ppl=5.83, wps=1868.2, ups=0.48, wpb=3930.5, bsz=248, num_updates=1638, lr=1.9656e-05, gnorm=1.617, train_wall=4, gb_free=16.7, wall=5506
2025-04-03 06:35:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-03 06:35:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=15934.609375Mb; avail=239150.58984375Mb
2025-04-03 06:35:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000633
2025-04-03 06:35:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15934.609375Mb; avail=239150.58984375Mb
2025-04-03 06:35:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012777
2025-04-03 06:35:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15934.609375Mb; avail=239150.58984375Mb
2025-04-03 06:35:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.010910
2025-04-03 06:35:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024699
2025-04-03 06:35:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15934.609375Mb; avail=239150.58984375Mb
2025-04-03 06:35:56 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 6.163 | nll_loss 2.54 | ppl 5.81 | wps 3864.6 | wpb 2070.5 | bsz 122.7 | num_updates 1638 | best_loss 6.163
2025-04-03 06:35:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 1638 updates
2025-04-03 06:35:56 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 06:36:34 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 06:36:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt (epoch 13 @ 1638 updates, score 6.163) (writing took 62.78233482106589 seconds)
2025-04-03 06:36:59 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2025-04-03 06:36:59 | INFO | train | epoch 013 | loss 6.077 | nll_loss 2.607 | ppl 6.09 | wps 1330.4 | ups 0.29 | wpb 4549.7 | bsz 252.8 | num_updates 1638 | lr 1.9656e-05 | gnorm 1.618 | train_wall 353 | gb_free 16.7 | wall 5583
2025-04-03 06:36:59 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:mr-hi': 31849}; raw total size: 31849
2025-04-03 06:36:59 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:mr-hi': 31849}; resampled total size: 31849
2025-04-03 06:36:59 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:mr-hi': 1.0}
2025-04-03 06:36:59 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001057
2025-04-03 06:36:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=26738.75390625Mb; avail=228346.42578125Mb
2025-04-03 06:36:59 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000678
2025-04-03 06:36:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003533
2025-04-03 06:36:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26739.24609375Mb; avail=228345.93359375Mb
2025-04-03 06:36:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000090
2025-04-03 06:36:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26739.24609375Mb; avail=228345.93359375Mb
2025-04-03 06:36:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001245
2025-04-03 06:36:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.005178
2025-04-03 06:36:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26739.24609375Mb; avail=228345.93359375Mb
2025-04-03 06:36:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 126
2025-04-03 06:36:59 | INFO | fairseq.trainer | begin training epoch 14
2025-04-03 06:36:59 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-03 06:37:04 | INFO | train_inner | epoch 014:      2 / 126 loss=6.074, nll_loss=2.619, ppl=6.14, wps=102.2, ups=0.02, wpb=4209.5, bsz=260, num_updates=1640, lr=1.968e-05, gnorm=1.576, train_wall=5, gb_free=13.1, wall=5588
2025-04-03 06:37:09 | INFO | train_inner | epoch 014:      4 / 126 loss=6.023, nll_loss=2.533, ppl=5.79, wps=1627.9, ups=0.37, wpb=4367.5, bsz=200, num_updates=1642, lr=1.9704e-05, gnorm=1.61, train_wall=5, gb_free=10.8, wall=5593
2025-04-03 06:37:15 | INFO | train_inner | epoch 014:      6 / 126 loss=6.112, nll_loss=2.659, ppl=6.32, wps=1792.1, ups=0.36, wpb=5029, bsz=320, num_updates=1644, lr=1.9728e-05, gnorm=1.589, train_wall=6, gb_free=12, wall=5599
2025-04-03 06:37:20 | INFO | train_inner | epoch 014:      8 / 126 loss=5.955, nll_loss=2.454, ppl=5.48, wps=1718, ups=0.38, wpb=4470, bsz=244, num_updates=1646, lr=1.9752e-05, gnorm=1.529, train_wall=5, gb_free=11.8, wall=5604
2025-04-03 06:37:25 | INFO | train_inner | epoch 014:     10 / 126 loss=5.899, nll_loss=2.387, ppl=5.23, wps=1752.2, ups=0.42, wpb=4208.5, bsz=248, num_updates=1648, lr=1.9776e-05, gnorm=1.687, train_wall=5, gb_free=12.1, wall=5609
2025-04-03 06:37:30 | INFO | train_inner | epoch 014:     12 / 126 loss=6.016, nll_loss=2.521, ppl=5.74, wps=1580, ups=0.39, wpb=4061.5, bsz=196, num_updates=1650, lr=1.98e-05, gnorm=1.617, train_wall=5, gb_free=13.6, wall=5614
2025-04-03 06:37:36 | INFO | train_inner | epoch 014:     14 / 126 loss=5.913, nll_loss=2.401, ppl=5.28, wps=1451, ups=0.35, wpb=4167.5, bsz=244, num_updates=1652, lr=1.9824e-05, gnorm=1.529, train_wall=6, gb_free=10.3, wall=5620
2025-04-03 06:37:41 | INFO | train_inner | epoch 014:     16 / 126 loss=6.132, nll_loss=2.685, ppl=6.43, wps=1790.9, ups=0.37, wpb=4889.5, bsz=304, num_updates=1654, lr=1.9848e-05, gnorm=1.862, train_wall=5, gb_free=12.8, wall=5625
2025-04-03 06:37:47 | INFO | train_inner | epoch 014:     18 / 126 loss=5.982, nll_loss=2.49, ppl=5.62, wps=1727.6, ups=0.35, wpb=4987, bsz=296, num_updates=1656, lr=1.9872e-05, gnorm=1.515, train_wall=6, gb_free=12.2, wall=5631
2025-04-03 06:37:52 | INFO | train_inner | epoch 014:     20 / 126 loss=6.079, nll_loss=2.607, ppl=6.09, wps=1820.9, ups=0.36, wpb=5016.5, bsz=296, num_updates=1658, lr=1.9896e-05, gnorm=1.721, train_wall=6, gb_free=9.2, wall=5637
2025-04-03 06:37:58 | INFO | train_inner | epoch 014:     22 / 126 loss=5.872, nll_loss=2.344, ppl=5.08, wps=1681.8, ups=0.36, wpb=4689.5, bsz=228, num_updates=1660, lr=1.992e-05, gnorm=1.507, train_wall=6, gb_free=13.1, wall=5642
2025-04-03 06:38:03 | INFO | train_inner | epoch 014:     24 / 126 loss=6.066, nll_loss=2.6, ppl=6.06, wps=1825.5, ups=0.37, wpb=4972.5, bsz=288, num_updates=1662, lr=1.9944e-05, gnorm=1.447, train_wall=5, gb_free=12.8, wall=5648
2025-04-03 06:38:09 | INFO | train_inner | epoch 014:     26 / 126 loss=6.038, nll_loss=2.555, ppl=5.88, wps=1743.5, ups=0.37, wpb=4748, bsz=268, num_updates=1664, lr=1.9968e-05, gnorm=1.612, train_wall=5, gb_free=13.9, wall=5653
2025-04-03 06:38:15 | INFO | train_inner | epoch 014:     28 / 126 loss=6.114, nll_loss=2.63, ppl=6.19, wps=1599, ups=0.34, wpb=4653.5, bsz=180, num_updates=1666, lr=1.9992e-05, gnorm=1.518, train_wall=6, gb_free=11.4, wall=5659
2025-04-03 06:38:20 | INFO | train_inner | epoch 014:     30 / 126 loss=5.972, nll_loss=2.469, ppl=5.54, wps=1571.8, ups=0.35, wpb=4443, bsz=184, num_updates=1668, lr=2.0016e-05, gnorm=1.84, train_wall=6, gb_free=9.7, wall=5664
2025-04-03 06:38:26 | INFO | train_inner | epoch 014:     32 / 126 loss=6.042, nll_loss=2.557, ppl=5.89, wps=1636.5, ups=0.33, wpb=4907.5, bsz=244, num_updates=1670, lr=2.004e-05, gnorm=1.553, train_wall=6, gb_free=10.9, wall=5670
2025-04-03 06:38:32 | INFO | train_inner | epoch 014:     34 / 126 loss=5.983, nll_loss=2.47, ppl=5.54, wps=1526.5, ups=0.36, wpb=4297, bsz=132, num_updates=1672, lr=2.0064e-05, gnorm=1.558, train_wall=6, gb_free=12.2, wall=5676
2025-04-03 06:38:37 | INFO | train_inner | epoch 014:     36 / 126 loss=6.087, nll_loss=2.631, ppl=6.2, wps=1689.6, ups=0.38, wpb=4445.5, bsz=308, num_updates=1674, lr=2.0088e-05, gnorm=1.557, train_wall=5, gb_free=13.3, wall=5681
2025-04-03 06:38:43 | INFO | train_inner | epoch 014:     38 / 126 loss=5.963, nll_loss=2.456, ppl=5.49, wps=1715.8, ups=0.33, wpb=5139.5, bsz=268, num_updates=1676, lr=2.0112e-05, gnorm=1.457, train_wall=6, gb_free=11.5, wall=5687
2025-04-03 06:38:49 | INFO | train_inner | epoch 014:     40 / 126 loss=6.003, nll_loss=2.489, ppl=5.61, wps=1470.9, ups=0.35, wpb=4255.5, bsz=132, num_updates=1678, lr=2.0136e-05, gnorm=1.662, train_wall=6, gb_free=12.9, wall=5693
2025-04-03 06:38:55 | INFO | train_inner | epoch 014:     42 / 126 loss=6.038, nll_loss=2.558, ppl=5.89, wps=1676, ups=0.36, wpb=4697, bsz=228, num_updates=1680, lr=2.016e-05, gnorm=1.527, train_wall=6, gb_free=10.5, wall=5699
2025-04-03 06:39:00 | INFO | train_inner | epoch 014:     44 / 126 loss=5.988, nll_loss=2.5, ppl=5.66, wps=1727.4, ups=0.38, wpb=4533, bsz=244, num_updates=1682, lr=2.0184e-05, gnorm=1.545, train_wall=5, gb_free=12.6, wall=5704
2025-04-03 06:39:06 | INFO | train_inner | epoch 014:     46 / 126 loss=5.987, nll_loss=2.494, ppl=5.63, wps=1726.5, ups=0.34, wpb=5014.5, bsz=252, num_updates=1684, lr=2.0208e-05, gnorm=1.464, train_wall=6, gb_free=9.8, wall=5710
2025-04-03 06:39:11 | INFO | train_inner | epoch 014:     48 / 126 loss=6.066, nll_loss=2.588, ppl=6.01, wps=1553, ups=0.36, wpb=4346, bsz=244, num_updates=1686, lr=2.0232e-05, gnorm=1.668, train_wall=6, gb_free=14.3, wall=5715
2025-04-03 06:39:17 | INFO | train_inner | epoch 014:     50 / 126 loss=6.002, nll_loss=2.493, ppl=5.63, wps=1724.4, ups=0.34, wpb=5071, bsz=272, num_updates=1688, lr=2.0256e-05, gnorm=1.813, train_wall=6, gb_free=10.5, wall=5721
2025-04-03 06:39:23 | INFO | train_inner | epoch 014:     52 / 126 loss=6.082, nll_loss=2.606, ppl=6.09, wps=1603.2, ups=0.35, wpb=4596, bsz=196, num_updates=1690, lr=2.028e-05, gnorm=1.627, train_wall=6, gb_free=9.6, wall=5727
2025-04-03 06:39:29 | INFO | train_inner | epoch 014:     54 / 126 loss=5.942, nll_loss=2.443, ppl=5.44, wps=1765.8, ups=0.36, wpb=4960.5, bsz=260, num_updates=1692, lr=2.0304e-05, gnorm=1.509, train_wall=6, gb_free=13.1, wall=5733
2025-04-03 06:39:34 | INFO | train_inner | epoch 014:     56 / 126 loss=5.909, nll_loss=2.41, ppl=5.31, wps=1643.5, ups=0.38, wpb=4339, bsz=264, num_updates=1694, lr=2.0328e-05, gnorm=1.826, train_wall=5, gb_free=14.2, wall=5738
2025-04-03 06:39:39 | INFO | train_inner | epoch 014:     58 / 126 loss=5.817, nll_loss=2.279, ppl=4.85, wps=1569.9, ups=0.36, wpb=4360, bsz=292, num_updates=1696, lr=2.0352e-05, gnorm=1.443, train_wall=6, gb_free=12.3, wall=5743
2025-04-03 06:39:44 | INFO | train_inner | epoch 014:     60 / 126 loss=5.898, nll_loss=2.368, ppl=5.16, wps=1758.9, ups=0.43, wpb=4081.5, bsz=276.5, num_updates=1698, lr=2.0376e-05, gnorm=1.634, train_wall=5, gb_free=10.7, wall=5748
2025-04-03 06:39:50 | INFO | train_inner | epoch 014:     62 / 126 loss=6.019, nll_loss=2.502, ppl=5.66, wps=1621, ups=0.35, wpb=4663.5, bsz=200, num_updates=1700, lr=2.04e-05, gnorm=1.79, train_wall=6, gb_free=14.7, wall=5754
2025-04-03 06:39:56 | INFO | train_inner | epoch 014:     64 / 126 loss=6.022, nll_loss=2.538, ppl=5.81, wps=1828.6, ups=0.33, wpb=5482, bsz=264, num_updates=1702, lr=2.0424e-05, gnorm=1.48, train_wall=6, gb_free=10.2, wall=5760
2025-04-03 06:40:01 | INFO | train_inner | epoch 014:     66 / 126 loss=5.921, nll_loss=2.427, ppl=5.38, wps=1518.7, ups=0.36, wpb=4201.5, bsz=220, num_updates=1704, lr=2.0448e-05, gnorm=1.688, train_wall=6, gb_free=12.1, wall=5765
2025-04-03 06:40:07 | INFO | train_inner | epoch 014:     68 / 126 loss=6.02, nll_loss=2.55, ppl=5.86, wps=1601, ups=0.37, wpb=4285, bsz=272, num_updates=1706, lr=2.0472e-05, gnorm=1.824, train_wall=5, gb_free=13.7, wall=5771
2025-04-03 06:40:12 | INFO | train_inner | epoch 014:     70 / 126 loss=6.102, nll_loss=2.626, ppl=6.17, wps=1590.4, ups=0.38, wpb=4185, bsz=196, num_updates=1708, lr=2.0496e-05, gnorm=1.638, train_wall=5, gb_free=10.3, wall=5776
2025-04-03 06:40:17 | INFO | train_inner | epoch 014:     72 / 126 loss=6.017, nll_loss=2.508, ppl=5.69, wps=1669.7, ups=0.39, wpb=4272.5, bsz=216, num_updates=1710, lr=2.052e-05, gnorm=1.696, train_wall=5, gb_free=13.4, wall=5781
2025-04-03 06:40:22 | INFO | train_inner | epoch 014:     74 / 126 loss=6.035, nll_loss=2.544, ppl=5.83, wps=1751.6, ups=0.39, wpb=4546, bsz=268, num_updates=1712, lr=2.0544e-05, gnorm=1.619, train_wall=5, gb_free=12.1, wall=5786
2025-04-03 06:40:28 | INFO | train_inner | epoch 014:     76 / 126 loss=5.883, nll_loss=2.363, ppl=5.14, wps=1587.7, ups=0.36, wpb=4368.5, bsz=228, num_updates=1714, lr=2.0568e-05, gnorm=1.509, train_wall=5, gb_free=14.6, wall=5792
2025-04-03 06:40:33 | INFO | train_inner | epoch 014:     78 / 126 loss=6.073, nll_loss=2.613, ppl=6.12, wps=1767.5, ups=0.37, wpb=4788, bsz=268, num_updates=1716, lr=2.0592e-05, gnorm=1.533, train_wall=5, gb_free=12.4, wall=5797
2025-04-03 06:40:39 | INFO | train_inner | epoch 014:     80 / 126 loss=6.033, nll_loss=2.566, ppl=5.92, wps=1358.3, ups=0.35, wpb=3901, bsz=216, num_updates=1718, lr=2.0616e-05, gnorm=1.725, train_wall=6, gb_free=10.7, wall=5803
2025-04-03 06:40:45 | INFO | train_inner | epoch 014:     82 / 126 loss=6.086, nll_loss=2.631, ppl=6.2, wps=1652.9, ups=0.33, wpb=4946.5, bsz=316, num_updates=1720, lr=2.064e-05, gnorm=1.6, train_wall=6, gb_free=9.5, wall=5809
2025-04-03 06:40:56 | INFO | train_inner | epoch 014:     84 / 126 loss=5.887, nll_loss=2.367, ppl=5.16, wps=891.7, ups=0.19, wpb=4789.5, bsz=272, num_updates=1722, lr=2.0664e-05, gnorm=1.404, train_wall=11, gb_free=11.3, wall=5820
2025-04-03 06:41:01 | INFO | train_inner | epoch 014:     86 / 126 loss=6.155, nll_loss=2.689, ppl=6.45, wps=1513.3, ups=0.36, wpb=4228.5, bsz=168, num_updates=1724, lr=2.0688e-05, gnorm=1.702, train_wall=6, gb_free=13.4, wall=5825
2025-04-03 06:41:07 | INFO | train_inner | epoch 014:     88 / 126 loss=5.917, nll_loss=2.419, ppl=5.35, wps=1751.2, ups=0.36, wpb=4832.5, bsz=364, num_updates=1726, lr=2.0712e-05, gnorm=1.379, train_wall=6, gb_free=12.3, wall=5831
2025-04-03 06:41:12 | INFO | train_inner | epoch 014:     90 / 126 loss=5.896, nll_loss=2.391, ppl=5.25, wps=1706.8, ups=0.36, wpb=4738.5, bsz=336, num_updates=1728, lr=2.0736e-05, gnorm=1.307, train_wall=6, gb_free=14.2, wall=5836
2025-04-03 06:41:18 | INFO | train_inner | epoch 014:     92 / 126 loss=5.935, nll_loss=2.448, ppl=5.46, wps=1809.5, ups=0.34, wpb=5267, bsz=320, num_updates=1730, lr=2.076e-05, gnorm=1.429, train_wall=6, gb_free=10.5, wall=5842
2025-04-03 06:41:24 | INFO | train_inner | epoch 014:     94 / 126 loss=5.99, nll_loss=2.492, ppl=5.63, wps=1478, ups=0.34, wpb=4298.5, bsz=228, num_updates=1732, lr=2.0784e-05, gnorm=1.45, train_wall=6, gb_free=8.3, wall=5848
2025-04-03 06:41:30 | INFO | train_inner | epoch 014:     96 / 126 loss=5.985, nll_loss=2.495, ppl=5.64, wps=1652.5, ups=0.35, wpb=4769, bsz=300, num_updates=1734, lr=2.0808e-05, gnorm=1.5, train_wall=6, gb_free=12, wall=5854
2025-04-03 06:41:35 | INFO | train_inner | epoch 014:     98 / 126 loss=5.846, nll_loss=2.32, ppl=4.99, wps=1720.8, ups=0.39, wpb=4371.5, bsz=336, num_updates=1736, lr=2.0832e-05, gnorm=1.523, train_wall=5, gb_free=16.1, wall=5859
2025-04-03 06:41:40 | INFO | train_inner | epoch 014:    100 / 126 loss=5.926, nll_loss=2.419, ppl=5.35, wps=1454, ups=0.37, wpb=3902, bsz=220, num_updates=1738, lr=2.0856e-05, gnorm=1.594, train_wall=5, gb_free=10, wall=5864
2025-04-03 06:41:46 | INFO | train_inner | epoch 014:    102 / 126 loss=5.97, nll_loss=2.472, ppl=5.55, wps=1521.4, ups=0.37, wpb=4158.5, bsz=220, num_updates=1740, lr=2.088e-05, gnorm=1.533, train_wall=5, gb_free=11.1, wall=5870
2025-04-03 06:41:51 | INFO | train_inner | epoch 014:    104 / 126 loss=5.983, nll_loss=2.483, ppl=5.59, wps=1652.5, ups=0.35, wpb=4722.5, bsz=200, num_updates=1742, lr=2.0904e-05, gnorm=1.605, train_wall=6, gb_free=10.1, wall=5875
2025-04-03 06:41:57 | INFO | train_inner | epoch 014:    106 / 126 loss=5.892, nll_loss=2.38, ppl=5.2, wps=1633.9, ups=0.37, wpb=4433, bsz=224, num_updates=1744, lr=2.0928e-05, gnorm=1.496, train_wall=5, gb_free=14.3, wall=5881
2025-04-03 06:42:02 | INFO | train_inner | epoch 014:    108 / 126 loss=5.957, nll_loss=2.466, ppl=5.52, wps=1654.2, ups=0.36, wpb=4544, bsz=296, num_updates=1746, lr=2.0952e-05, gnorm=1.586, train_wall=5, gb_free=12.4, wall=5886
2025-04-03 06:42:08 | INFO | train_inner | epoch 014:    110 / 126 loss=5.89, nll_loss=2.38, ppl=5.21, wps=1691.2, ups=0.37, wpb=4565.5, bsz=352, num_updates=1748, lr=2.0976e-05, gnorm=1.441, train_wall=5, gb_free=13.2, wall=5892
2025-04-03 06:42:14 | INFO | train_inner | epoch 014:    112 / 126 loss=6.151, nll_loss=2.692, ppl=6.46, wps=1645, ups=0.33, wpb=4938, bsz=260, num_updates=1750, lr=2.1e-05, gnorm=1.767, train_wall=6, gb_free=9.6, wall=5898
2025-04-03 06:42:19 | INFO | train_inner | epoch 014:    114 / 126 loss=5.989, nll_loss=2.507, ppl=5.68, wps=1566.9, ups=0.34, wpb=4605, bsz=260, num_updates=1752, lr=2.1024e-05, gnorm=1.49, train_wall=6, gb_free=11.9, wall=5904
2025-04-03 06:42:25 | INFO | train_inner | epoch 014:    116 / 126 loss=5.919, nll_loss=2.431, ppl=5.39, wps=1671.5, ups=0.36, wpb=4652.5, bsz=312, num_updates=1754, lr=2.1048e-05, gnorm=1.509, train_wall=6, gb_free=13.9, wall=5909
2025-04-03 06:42:31 | INFO | train_inner | epoch 014:    118 / 126 loss=6.022, nll_loss=2.543, ppl=5.83, wps=1706.4, ups=0.33, wpb=5102.5, bsz=304, num_updates=1756, lr=2.1072e-05, gnorm=1.394, train_wall=6, gb_free=10, wall=5915
2025-04-03 06:42:37 | INFO | train_inner | epoch 014:    120 / 126 loss=5.992, nll_loss=2.491, ppl=5.62, wps=1385.5, ups=0.36, wpb=3893.5, bsz=200, num_updates=1758, lr=2.1096e-05, gnorm=1.647, train_wall=6, gb_free=12.6, wall=5921
2025-04-03 06:42:42 | INFO | train_inner | epoch 014:    122 / 126 loss=5.9, nll_loss=2.366, ppl=5.16, wps=1573.3, ups=0.38, wpb=4128, bsz=244, num_updates=1760, lr=2.112e-05, gnorm=1.476, train_wall=5, gb_free=14, wall=5926
2025-04-03 06:42:48 | INFO | train_inner | epoch 014:    124 / 126 loss=6.09, nll_loss=2.623, ppl=6.16, wps=1632.7, ups=0.33, wpb=4884.5, bsz=296, num_updates=1762, lr=2.1144e-05, gnorm=1.596, train_wall=6, gb_free=10.1, wall=5932
2025-04-03 06:42:52 | INFO | train_inner | epoch 014:    126 / 126 loss=6.086, nll_loss=2.642, ppl=6.24, wps=1493.1, ups=0.46, wpb=3211, bsz=180, num_updates=1764, lr=2.1168e-05, gnorm=2.499, train_wall=4, gb_free=17.7, wall=5936
2025-04-03 06:42:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-03 06:42:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=15945.0078125Mb; avail=239140.1875Mb
2025-04-03 06:42:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000633
2025-04-03 06:42:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15945.0078125Mb; avail=239140.1875Mb
2025-04-03 06:42:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012831
2025-04-03 06:42:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15945.0078125Mb; avail=239140.1875Mb
2025-04-03 06:42:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.010888
2025-04-03 06:42:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024693
2025-04-03 06:42:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15945.0078125Mb; avail=239140.1875Mb
2025-04-03 06:43:07 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 6.132 | nll_loss 2.502 | ppl 5.67 | wps 3860.9 | wpb 2070.5 | bsz 122.7 | num_updates 1764 | best_loss 6.132
2025-04-03 06:43:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 1764 updates
2025-04-03 06:43:07 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 06:43:44 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 06:44:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt (epoch 14 @ 1764 updates, score 6.132) (writing took 61.969383383053355 seconds)
2025-04-03 06:44:09 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2025-04-03 06:44:09 | INFO | train | epoch 014 | loss 5.995 | nll_loss 2.504 | ppl 5.67 | wps 1333 | ups 0.29 | wpb 4549.7 | bsz 252.8 | num_updates 1764 | lr 2.1168e-05 | gnorm 1.594 | train_wall 353 | gb_free 17.7 | wall 6013
2025-04-03 06:44:09 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:mr-hi': 31849}; raw total size: 31849
2025-04-03 06:44:09 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:mr-hi': 31849}; resampled total size: 31849
2025-04-03 06:44:09 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:mr-hi': 1.0}
2025-04-03 06:44:09 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001075
2025-04-03 06:44:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=26715.41796875Mb; avail=228369.765625Mb
2025-04-03 06:44:09 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000648
2025-04-03 06:44:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003569
2025-04-03 06:44:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26716.40234375Mb; avail=228368.78125Mb
2025-04-03 06:44:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000091
2025-04-03 06:44:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26716.40234375Mb; avail=228368.78125Mb
2025-04-03 06:44:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001162
2025-04-03 06:44:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.005172
2025-04-03 06:44:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26716.40234375Mb; avail=228368.78125Mb
2025-04-03 06:44:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 126
2025-04-03 06:44:09 | INFO | fairseq.trainer | begin training epoch 15
2025-04-03 06:44:09 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-03 06:44:14 | INFO | train_inner | epoch 015:      2 / 126 loss=5.771, nll_loss=2.23, ppl=4.69, wps=110.3, ups=0.02, wpb=4515, bsz=288, num_updates=1766, lr=2.1192e-05, gnorm=1.435, train_wall=5, gb_free=14.4, wall=6018
2025-04-03 06:44:20 | INFO | train_inner | epoch 015:      4 / 126 loss=5.865, nll_loss=2.316, ppl=4.98, wps=1890.1, ups=0.36, wpb=5245.5, bsz=304, num_updates=1768, lr=2.1216e-05, gnorm=1.664, train_wall=6, gb_free=11.6, wall=6024
2025-04-03 06:44:25 | INFO | train_inner | epoch 015:      6 / 126 loss=5.887, nll_loss=2.346, ppl=5.08, wps=1510.8, ups=0.34, wpb=4416.5, bsz=212, num_updates=1770, lr=2.124e-05, gnorm=1.551, train_wall=6, gb_free=9.7, wall=6030
2025-04-03 06:44:31 | INFO | train_inner | epoch 015:      8 / 126 loss=5.886, nll_loss=2.367, ppl=5.16, wps=1705.7, ups=0.36, wpb=4723.5, bsz=268, num_updates=1772, lr=2.1264e-05, gnorm=1.432, train_wall=6, gb_free=13.9, wall=6035
2025-04-03 06:44:41 | INFO | train_inner | epoch 015:     10 / 126 loss=5.984, nll_loss=2.489, ppl=5.61, wps=916.8, ups=0.19, wpb=4746, bsz=272, num_updates=1774, lr=2.1288e-05, gnorm=1.534, train_wall=10, gb_free=13.6, wall=6045
2025-04-03 06:44:47 | INFO | train_inner | epoch 015:     12 / 126 loss=5.784, nll_loss=2.244, ppl=4.74, wps=1466.2, ups=0.37, wpb=3920, bsz=184, num_updates=1776, lr=2.1312e-05, gnorm=1.655, train_wall=5, gb_free=9.8, wall=6051
2025-04-03 06:44:52 | INFO | train_inner | epoch 015:     14 / 126 loss=5.938, nll_loss=2.417, ppl=5.34, wps=1767.6, ups=0.36, wpb=4947.5, bsz=252, num_updates=1778, lr=2.1336e-05, gnorm=1.471, train_wall=6, gb_free=13.1, wall=6056
2025-04-03 06:44:58 | INFO | train_inner | epoch 015:     16 / 126 loss=5.94, nll_loss=2.418, ppl=5.35, wps=1722.4, ups=0.35, wpb=4926.5, bsz=268, num_updates=1780, lr=2.136e-05, gnorm=1.568, train_wall=6, gb_free=14.9, wall=6062
2025-04-03 06:45:04 | INFO | train_inner | epoch 015:     18 / 126 loss=5.935, nll_loss=2.425, ppl=5.37, wps=1847.3, ups=0.36, wpb=5129.5, bsz=316, num_updates=1782, lr=2.1384e-05, gnorm=1.432, train_wall=6, gb_free=9.7, wall=6068
2025-04-03 06:45:09 | INFO | train_inner | epoch 015:     20 / 126 loss=5.874, nll_loss=2.351, ppl=5.1, wps=1656.1, ups=0.36, wpb=4571.5, bsz=256, num_updates=1784, lr=2.1408e-05, gnorm=1.455, train_wall=6, gb_free=13.2, wall=6073
2025-04-03 06:45:14 | INFO | train_inner | epoch 015:     22 / 126 loss=5.99, nll_loss=2.503, ppl=5.67, wps=1407.3, ups=0.38, wpb=3744.5, bsz=208, num_updates=1786, lr=2.1432e-05, gnorm=1.667, train_wall=5, gb_free=9.9, wall=6079
2025-04-03 06:45:20 | INFO | train_inner | epoch 015:     24 / 126 loss=5.81, nll_loss=2.271, ppl=4.83, wps=1681.1, ups=0.35, wpb=4830, bsz=284, num_updates=1788, lr=2.1456e-05, gnorm=1.397, train_wall=6, gb_free=10.2, wall=6084
2025-04-03 06:45:26 | INFO | train_inner | epoch 015:     26 / 126 loss=5.943, nll_loss=2.434, ppl=5.4, wps=1524.7, ups=0.38, wpb=4047.5, bsz=264, num_updates=1790, lr=2.148e-05, gnorm=1.701, train_wall=5, gb_free=9.6, wall=6090
2025-04-03 06:45:31 | INFO | train_inner | epoch 015:     28 / 126 loss=6.079, nll_loss=2.613, ppl=6.12, wps=1839.9, ups=0.36, wpb=5131, bsz=284, num_updates=1792, lr=2.1504e-05, gnorm=1.634, train_wall=6, gb_free=10.3, wall=6095
2025-04-03 06:45:37 | INFO | train_inner | epoch 015:     30 / 126 loss=6.01, nll_loss=2.527, ppl=5.77, wps=1593.6, ups=0.34, wpb=4704.5, bsz=228, num_updates=1794, lr=2.1528e-05, gnorm=1.45, train_wall=6, gb_free=8.4, wall=6101
2025-04-03 06:45:42 | INFO | train_inner | epoch 015:     32 / 126 loss=5.948, nll_loss=2.439, ppl=5.42, wps=1618.2, ups=0.39, wpb=4113, bsz=196, num_updates=1796, lr=2.1552e-05, gnorm=1.701, train_wall=5, gb_free=15.1, wall=6106
2025-04-03 06:45:47 | INFO | train_inner | epoch 015:     34 / 126 loss=6.022, nll_loss=2.528, ppl=5.77, wps=1641.4, ups=0.38, wpb=4281.5, bsz=220, num_updates=1798, lr=2.1576e-05, gnorm=1.798, train_wall=5, gb_free=13.3, wall=6111
2025-04-03 06:45:53 | INFO | train_inner | epoch 015:     36 / 126 loss=5.98, nll_loss=2.482, ppl=5.58, wps=1651.5, ups=0.37, wpb=4519.5, bsz=312, num_updates=1800, lr=2.16e-05, gnorm=1.502, train_wall=5, gb_free=11.3, wall=6117
2025-04-03 06:45:58 | INFO | train_inner | epoch 015:     38 / 126 loss=5.864, nll_loss=2.335, ppl=5.05, wps=1629.2, ups=0.41, wpb=3928, bsz=232, num_updates=1802, lr=2.1624e-05, gnorm=1.652, train_wall=5, gb_free=13.2, wall=6122
2025-04-03 06:46:03 | INFO | train_inner | epoch 015:     40 / 126 loss=5.924, nll_loss=2.415, ppl=5.33, wps=1492, ups=0.35, wpb=4235, bsz=232, num_updates=1804, lr=2.1648e-05, gnorm=1.617, train_wall=6, gb_free=13.3, wall=6127
2025-04-03 06:46:09 | INFO | train_inner | epoch 015:     42 / 126 loss=5.909, nll_loss=2.418, ppl=5.34, wps=1866.9, ups=0.35, wpb=5376, bsz=384, num_updates=1806, lr=2.1672e-05, gnorm=1.397, train_wall=6, gb_free=12, wall=6133
2025-04-03 06:46:15 | INFO | train_inner | epoch 015:     44 / 126 loss=6.033, nll_loss=2.548, ppl=5.85, wps=1514.5, ups=0.35, wpb=4326, bsz=184, num_updates=1808, lr=2.1696e-05, gnorm=1.615, train_wall=6, gb_free=10.3, wall=6139
2025-04-03 06:46:20 | INFO | train_inner | epoch 015:     46 / 126 loss=6.049, nll_loss=2.584, ppl=6, wps=1634.2, ups=0.36, wpb=4553.5, bsz=304, num_updates=1810, lr=2.172e-05, gnorm=1.604, train_wall=6, gb_free=12.4, wall=6144
2025-04-03 06:46:26 | INFO | train_inner | epoch 015:     48 / 126 loss=5.888, nll_loss=2.369, ppl=5.16, wps=1384.6, ups=0.36, wpb=3815, bsz=204, num_updates=1812, lr=2.1744e-05, gnorm=1.577, train_wall=6, gb_free=10.9, wall=6150
2025-04-03 06:46:31 | INFO | train_inner | epoch 015:     50 / 126 loss=5.81, nll_loss=2.255, ppl=4.77, wps=1625.9, ups=0.39, wpb=4216, bsz=232, num_updates=1814, lr=2.1768e-05, gnorm=1.511, train_wall=5, gb_free=11.7, wall=6155
2025-04-03 06:46:37 | INFO | train_inner | epoch 015:     52 / 126 loss=5.935, nll_loss=2.403, ppl=5.29, wps=1664.4, ups=0.34, wpb=4923.5, bsz=196, num_updates=1816, lr=2.1792e-05, gnorm=1.561, train_wall=6, gb_free=10.9, wall=6161
2025-04-03 06:46:42 | INFO | train_inner | epoch 015:     54 / 126 loss=5.916, nll_loss=2.405, ppl=5.3, wps=1638.4, ups=0.37, wpb=4384, bsz=188, num_updates=1818, lr=2.1816e-05, gnorm=1.527, train_wall=5, gb_free=12.9, wall=6166
2025-04-03 06:46:48 | INFO | train_inner | epoch 015:     56 / 126 loss=5.893, nll_loss=2.375, ppl=5.19, wps=1654.3, ups=0.36, wpb=4574.5, bsz=216, num_updates=1820, lr=2.184e-05, gnorm=1.538, train_wall=6, gb_free=13.7, wall=6172
2025-04-03 06:46:54 | INFO | train_inner | epoch 015:     58 / 126 loss=5.834, nll_loss=2.308, ppl=4.95, wps=1824.9, ups=0.33, wpb=5479, bsz=368, num_updates=1822, lr=2.1864e-05, gnorm=1.366, train_wall=6, gb_free=9.4, wall=6178
2025-04-03 06:47:00 | INFO | train_inner | epoch 015:     60 / 126 loss=5.915, nll_loss=2.394, ppl=5.25, wps=1626.5, ups=0.34, wpb=4780.5, bsz=256, num_updates=1824, lr=2.1888e-05, gnorm=1.475, train_wall=6, gb_free=9.1, wall=6184
2025-04-03 06:47:05 | INFO | train_inner | epoch 015:     62 / 126 loss=5.954, nll_loss=2.444, ppl=5.44, wps=1750.6, ups=0.35, wpb=4948.5, bsz=268, num_updates=1826, lr=2.1912e-05, gnorm=1.44, train_wall=6, gb_free=12.5, wall=6189
2025-04-03 06:47:11 | INFO | train_inner | epoch 015:     64 / 126 loss=5.863, nll_loss=2.333, ppl=5.04, wps=1626.5, ups=0.36, wpb=4462.5, bsz=236, num_updates=1828, lr=2.1936e-05, gnorm=1.624, train_wall=5, gb_free=12.7, wall=6195
2025-04-03 06:47:16 | INFO | train_inner | epoch 015:     66 / 126 loss=5.945, nll_loss=2.437, ppl=5.42, wps=1743.5, ups=0.38, wpb=4548.5, bsz=260, num_updates=1830, lr=2.196e-05, gnorm=1.694, train_wall=5, gb_free=14.5, wall=6200
2025-04-03 06:47:22 | INFO | train_inner | epoch 015:     68 / 126 loss=5.999, nll_loss=2.506, ppl=5.68, wps=1605.1, ups=0.36, wpb=4494.5, bsz=132, num_updates=1832, lr=2.1984e-05, gnorm=1.682, train_wall=6, gb_free=10.7, wall=6206
2025-04-03 06:47:27 | INFO | train_inner | epoch 015:     70 / 126 loss=6.022, nll_loss=2.531, ppl=5.78, wps=1393.1, ups=0.36, wpb=3893.5, bsz=216, num_updates=1834, lr=2.2008e-05, gnorm=1.615, train_wall=6, gb_free=13.9, wall=6211
2025-04-03 06:47:33 | INFO | train_inner | epoch 015:     72 / 126 loss=5.874, nll_loss=2.349, ppl=5.09, wps=1658.7, ups=0.35, wpb=4800, bsz=316, num_updates=1836, lr=2.2032e-05, gnorm=1.422, train_wall=6, gb_free=12.5, wall=6217
2025-04-03 06:47:39 | INFO | train_inner | epoch 015:     74 / 126 loss=5.975, nll_loss=2.46, ppl=5.5, wps=1582.5, ups=0.33, wpb=4725.5, bsz=232, num_updates=1838, lr=2.2056e-05, gnorm=1.544, train_wall=6, gb_free=9.9, wall=6223
2025-04-03 06:47:44 | INFO | train_inner | epoch 015:     76 / 126 loss=5.957, nll_loss=2.469, ppl=5.54, wps=1329.8, ups=0.37, wpb=3610.5, bsz=228, num_updates=1840, lr=2.208e-05, gnorm=1.634, train_wall=5, gb_free=13.9, wall=6229
2025-04-03 06:47:50 | INFO | train_inner | epoch 015:     78 / 126 loss=5.983, nll_loss=2.491, ppl=5.62, wps=1740.9, ups=0.35, wpb=4986.5, bsz=264, num_updates=1842, lr=2.2104e-05, gnorm=1.466, train_wall=6, gb_free=10, wall=6234
2025-04-03 06:47:55 | INFO | train_inner | epoch 015:     80 / 126 loss=5.921, nll_loss=2.403, ppl=5.29, wps=1654.7, ups=0.4, wpb=4101.5, bsz=200, num_updates=1844, lr=2.2128e-05, gnorm=1.687, train_wall=5, gb_free=10.9, wall=6239
2025-04-03 06:48:01 | INFO | train_inner | epoch 015:     82 / 126 loss=5.972, nll_loss=2.47, ppl=5.54, wps=1648, ups=0.37, wpb=4450.5, bsz=272, num_updates=1846, lr=2.2152e-05, gnorm=1.561, train_wall=5, gb_free=10.1, wall=6245
2025-04-03 06:48:06 | INFO | train_inner | epoch 015:     84 / 126 loss=5.841, nll_loss=2.31, ppl=4.96, wps=1646.5, ups=0.36, wpb=4612, bsz=308, num_updates=1848, lr=2.2176e-05, gnorm=1.369, train_wall=6, gb_free=11.6, wall=6250
2025-04-03 06:48:12 | INFO | train_inner | epoch 015:     86 / 126 loss=5.889, nll_loss=2.372, ppl=5.18, wps=1765.5, ups=0.35, wpb=5042.5, bsz=268, num_updates=1850, lr=2.22e-05, gnorm=1.428, train_wall=6, gb_free=11.3, wall=6256
2025-04-03 06:48:17 | INFO | train_inner | epoch 015:     88 / 126 loss=5.862, nll_loss=2.353, ppl=5.11, wps=1701.1, ups=0.37, wpb=4611, bsz=260, num_updates=1852, lr=2.2224e-05, gnorm=1.517, train_wall=5, gb_free=13, wall=6261
2025-04-03 06:48:23 | INFO | train_inner | epoch 015:     90 / 126 loss=5.93, nll_loss=2.438, ppl=5.42, wps=1676.9, ups=0.38, wpb=4464.5, bsz=280, num_updates=1854, lr=2.2248e-05, gnorm=1.567, train_wall=5, gb_free=13.3, wall=6267
2025-04-03 06:48:28 | INFO | train_inner | epoch 015:     92 / 126 loss=5.941, nll_loss=2.414, ppl=5.33, wps=1546.6, ups=0.34, wpb=4538, bsz=228, num_updates=1856, lr=2.2272e-05, gnorm=1.418, train_wall=6, gb_free=13.1, wall=6273
2025-04-03 06:48:34 | INFO | train_inner | epoch 015:     94 / 126 loss=5.815, nll_loss=2.274, ppl=4.84, wps=1801, ups=0.34, wpb=5322, bsz=396, num_updates=1858, lr=2.2296e-05, gnorm=1.32, train_wall=6, gb_free=12.4, wall=6278
2025-04-03 06:48:40 | INFO | train_inner | epoch 015:     96 / 126 loss=6.015, nll_loss=2.512, ppl=5.7, wps=1810.6, ups=0.33, wpb=5560.5, bsz=260, num_updates=1860, lr=2.232e-05, gnorm=1.503, train_wall=6, gb_free=10.5, wall=6285
2025-04-03 06:48:47 | INFO | train_inner | epoch 015:     98 / 126 loss=5.88, nll_loss=2.377, ppl=5.2, wps=1641.8, ups=0.33, wpb=4960, bsz=320, num_updates=1862, lr=2.2344e-05, gnorm=1.404, train_wall=6, gb_free=9.7, wall=6291
2025-04-03 06:48:52 | INFO | train_inner | epoch 015:    100 / 126 loss=5.946, nll_loss=2.459, ppl=5.5, wps=1480.1, ups=0.38, wpb=3853.5, bsz=196, num_updates=1864, lr=2.2368e-05, gnorm=1.624, train_wall=5, gb_free=10.7, wall=6296
2025-04-03 06:48:57 | INFO | train_inner | epoch 015:    102 / 126 loss=5.911, nll_loss=2.418, ppl=5.34, wps=1655.2, ups=0.36, wpb=4592, bsz=320, num_updates=1866, lr=2.2392e-05, gnorm=1.452, train_wall=6, gb_free=11.8, wall=6301
2025-04-03 06:49:03 | INFO | train_inner | epoch 015:    104 / 126 loss=5.93, nll_loss=2.412, ppl=5.32, wps=1583.8, ups=0.35, wpb=4507, bsz=256, num_updates=1868, lr=2.2416e-05, gnorm=1.454, train_wall=6, gb_free=12.3, wall=6307
2025-04-03 06:49:08 | INFO | train_inner | epoch 015:    106 / 126 loss=5.887, nll_loss=2.328, ppl=5.02, wps=1769.2, ups=0.37, wpb=4776.5, bsz=272, num_updates=1870, lr=2.244e-05, gnorm=1.741, train_wall=5, gb_free=12.9, wall=6312
2025-04-03 06:49:14 | INFO | train_inner | epoch 015:    108 / 126 loss=5.859, nll_loss=2.338, ppl=5.05, wps=1686.9, ups=0.37, wpb=4544.5, bsz=308, num_updates=1872, lr=2.2464e-05, gnorm=1.413, train_wall=5, gb_free=11.9, wall=6318
2025-04-03 06:49:19 | INFO | train_inner | epoch 015:    110 / 126 loss=5.881, nll_loss=2.344, ppl=5.08, wps=1412.6, ups=0.36, wpb=3910, bsz=164, num_updates=1874, lr=2.2488e-05, gnorm=1.655, train_wall=6, gb_free=8.9, wall=6323
2025-04-03 06:49:25 | INFO | train_inner | epoch 015:    112 / 126 loss=5.991, nll_loss=2.511, ppl=5.7, wps=1691.9, ups=0.35, wpb=4777, bsz=204, num_updates=1876, lr=2.2512e-05, gnorm=1.575, train_wall=6, gb_free=13.5, wall=6329
2025-04-03 06:49:31 | INFO | train_inner | epoch 015:    114 / 126 loss=5.79, nll_loss=2.239, ppl=4.72, wps=1571.1, ups=0.34, wpb=4640.5, bsz=184, num_updates=1878, lr=2.2536e-05, gnorm=1.482, train_wall=6, gb_free=10, wall=6335
2025-04-03 06:49:37 | INFO | train_inner | epoch 015:    116 / 126 loss=5.908, nll_loss=2.381, ppl=5.21, wps=1626.6, ups=0.34, wpb=4837, bsz=232, num_updates=1880, lr=2.256e-05, gnorm=1.477, train_wall=6, gb_free=10.8, wall=6341
2025-04-03 06:49:41 | INFO | train_inner | epoch 015:    118 / 126 loss=6.016, nll_loss=2.524, ppl=5.75, wps=1547, ups=0.46, wpb=3373, bsz=180.5, num_updates=1882, lr=2.2584e-05, gnorm=1.916, train_wall=4, gb_free=19, wall=6345
2025-04-03 06:49:47 | INFO | train_inner | epoch 015:    120 / 126 loss=5.987, nll_loss=2.486, ppl=5.6, wps=1619, ups=0.37, wpb=4400, bsz=244, num_updates=1884, lr=2.2608e-05, gnorm=1.523, train_wall=5, gb_free=13.3, wall=6351
2025-04-03 06:49:52 | INFO | train_inner | epoch 015:    122 / 126 loss=5.825, nll_loss=2.307, ppl=4.95, wps=1793.8, ups=0.36, wpb=5029, bsz=364, num_updates=1886, lr=2.2632e-05, gnorm=1.417, train_wall=6, gb_free=12, wall=6356
2025-04-03 06:49:58 | INFO | train_inner | epoch 015:    124 / 126 loss=6.098, nll_loss=2.633, ppl=6.2, wps=1671.3, ups=0.36, wpb=4668, bsz=256, num_updates=1888, lr=2.2656e-05, gnorm=1.691, train_wall=6, gb_free=13.8, wall=6362
2025-04-03 06:50:02 | INFO | train_inner | epoch 015:    126 / 126 loss=5.961, nll_loss=2.473, ppl=5.55, wps=1662.3, ups=0.48, wpb=3487, bsz=188, num_updates=1890, lr=2.268e-05, gnorm=1.855, train_wall=4, gb_free=17.8, wall=6366
2025-04-03 06:50:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-03 06:50:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=15942.5078125Mb; avail=239142.69140625Mb
2025-04-03 06:50:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000619
2025-04-03 06:50:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15942.5078125Mb; avail=239142.69140625Mb
2025-04-03 06:50:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012820
2025-04-03 06:50:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15942.5078125Mb; avail=239142.69140625Mb
2025-04-03 06:50:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.010952
2025-04-03 06:50:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024751
2025-04-03 06:50:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15942.5078125Mb; avail=239142.69140625Mb
2025-04-03 06:50:16 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 6.092 | nll_loss 2.446 | ppl 5.45 | wps 3865 | wpb 2070.5 | bsz 122.7 | num_updates 1890 | best_loss 6.092
2025-04-03 06:50:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 1890 updates
2025-04-03 06:50:16 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 06:50:56 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 06:51:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt (epoch 15 @ 1890 updates, score 6.092) (writing took 63.87321815500036 seconds)
2025-04-03 06:51:20 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2025-04-03 06:51:20 | INFO | train | epoch 015 | loss 5.924 | nll_loss 2.412 | ppl 5.32 | wps 1328.1 | ups 0.29 | wpb 4549.7 | bsz 252.8 | num_updates 1890 | lr 2.268e-05 | gnorm 1.55 | train_wall 353 | gb_free 17.8 | wall 6444
2025-04-03 06:51:20 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:mr-hi': 31849}; raw total size: 31849
2025-04-03 06:51:20 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:mr-hi': 31849}; resampled total size: 31849
2025-04-03 06:51:20 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:mr-hi': 1.0}
2025-04-03 06:51:20 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001233
2025-04-03 06:51:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=26740.0078125Mb; avail=228345.1640625Mb
2025-04-03 06:51:20 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000589
2025-04-03 06:51:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003456
2025-04-03 06:51:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26740.5Mb; avail=228344.671875Mb
2025-04-03 06:51:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000089
2025-04-03 06:51:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26740.5Mb; avail=228344.671875Mb
2025-04-03 06:51:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001138
2025-04-03 06:51:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.005054
2025-04-03 06:51:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26740.5Mb; avail=228344.671875Mb
2025-04-03 06:51:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 126
2025-04-03 06:51:20 | INFO | fairseq.trainer | begin training epoch 16
2025-04-03 06:51:20 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-03 06:51:26 | INFO | train_inner | epoch 016:      2 / 126 loss=5.784, nll_loss=2.241, ppl=4.73, wps=113.3, ups=0.02, wpb=4745, bsz=280, num_updates=1892, lr=2.2704e-05, gnorm=1.505, train_wall=5, gb_free=12, wall=6450
2025-04-03 06:51:31 | INFO | train_inner | epoch 016:      4 / 126 loss=5.88, nll_loss=2.352, ppl=5.11, wps=1574.4, ups=0.38, wpb=4158.5, bsz=240, num_updates=1894, lr=2.2728e-05, gnorm=1.461, train_wall=5, gb_free=13.3, wall=6455
2025-04-03 06:51:36 | INFO | train_inner | epoch 016:      6 / 126 loss=5.785, nll_loss=2.227, ppl=4.68, wps=1686.2, ups=0.39, wpb=4377.5, bsz=260, num_updates=1896, lr=2.2752e-05, gnorm=1.428, train_wall=5, gb_free=13.4, wall=6460
2025-04-03 06:51:42 | INFO | train_inner | epoch 016:      8 / 126 loss=5.72, nll_loss=2.138, ppl=4.4, wps=1789.9, ups=0.37, wpb=4894.5, bsz=256, num_updates=1898, lr=2.2776e-05, gnorm=1.536, train_wall=5, gb_free=13.4, wall=6466
2025-04-03 06:51:47 | INFO | train_inner | epoch 016:     10 / 126 loss=5.827, nll_loss=2.289, ppl=4.89, wps=1661.4, ups=0.35, wpb=4686.5, bsz=216, num_updates=1900, lr=2.28e-05, gnorm=1.53, train_wall=6, gb_free=9.5, wall=6471
2025-04-03 06:51:53 | INFO | train_inner | epoch 016:     12 / 126 loss=5.889, nll_loss=2.373, ppl=5.18, wps=1760.9, ups=0.34, wpb=5230, bsz=312, num_updates=1902, lr=2.2824e-05, gnorm=1.459, train_wall=6, gb_free=10.5, wall=6477
2025-04-03 06:51:59 | INFO | train_inner | epoch 016:     14 / 126 loss=5.848, nll_loss=2.317, ppl=4.98, wps=1758.1, ups=0.34, wpb=5177, bsz=304, num_updates=1904, lr=2.2848e-05, gnorm=1.401, train_wall=6, gb_free=11.1, wall=6483
2025-04-03 06:52:05 | INFO | train_inner | epoch 016:     16 / 126 loss=5.935, nll_loss=2.415, ppl=5.33, wps=1755.3, ups=0.35, wpb=4966.5, bsz=232, num_updates=1906, lr=2.2872e-05, gnorm=1.667, train_wall=6, gb_free=13.3, wall=6489
2025-04-03 06:52:10 | INFO | train_inner | epoch 016:     18 / 126 loss=5.835, nll_loss=2.313, ppl=4.97, wps=1721.1, ups=0.36, wpb=4771, bsz=360, num_updates=1908, lr=2.2896e-05, gnorm=1.474, train_wall=6, gb_free=12.3, wall=6494
2025-04-03 06:52:16 | INFO | train_inner | epoch 016:     20 / 126 loss=5.807, nll_loss=2.255, ppl=4.77, wps=1594.6, ups=0.38, wpb=4214.5, bsz=160, num_updates=1910, lr=2.292e-05, gnorm=1.623, train_wall=5, gb_free=12, wall=6500
2025-04-03 06:52:21 | INFO | train_inner | epoch 016:     22 / 126 loss=5.896, nll_loss=2.387, ppl=5.23, wps=1705.2, ups=0.36, wpb=4719, bsz=332, num_updates=1912, lr=2.2944e-05, gnorm=1.552, train_wall=6, gb_free=9.8, wall=6505
2025-04-03 06:52:27 | INFO | train_inner | epoch 016:     24 / 126 loss=5.804, nll_loss=2.243, ppl=4.73, wps=1572.5, ups=0.35, wpb=4452.5, bsz=200, num_updates=1914, lr=2.2968e-05, gnorm=1.537, train_wall=6, gb_free=10.6, wall=6511
2025-04-03 06:52:33 | INFO | train_inner | epoch 016:     26 / 126 loss=5.72, nll_loss=2.149, ppl=4.44, wps=1628, ups=0.34, wpb=4848.5, bsz=276, num_updates=1916, lr=2.2992e-05, gnorm=1.381, train_wall=6, gb_free=10.3, wall=6517
2025-04-03 06:52:39 | INFO | train_inner | epoch 016:     28 / 126 loss=5.881, nll_loss=2.343, ppl=5.07, wps=1738.2, ups=0.33, wpb=5264.5, bsz=260, num_updates=1918, lr=2.3016e-05, gnorm=1.465, train_wall=6, gb_free=10.5, wall=6523
2025-04-03 06:52:44 | INFO | train_inner | epoch 016:     30 / 126 loss=5.955, nll_loss=2.452, ppl=5.47, wps=1507.9, ups=0.36, wpb=4177, bsz=240, num_updates=1920, lr=2.304e-05, gnorm=1.715, train_wall=6, gb_free=10.8, wall=6528
2025-04-03 06:52:49 | INFO | train_inner | epoch 016:     32 / 126 loss=5.804, nll_loss=2.272, ppl=4.83, wps=1525.5, ups=0.4, wpb=3791, bsz=224, num_updates=1922, lr=2.3064e-05, gnorm=1.842, train_wall=5, gb_free=14.2, wall=6533
2025-04-03 06:52:55 | INFO | train_inner | epoch 016:     34 / 126 loss=5.824, nll_loss=2.296, ppl=4.91, wps=1760.9, ups=0.36, wpb=4851, bsz=284, num_updates=1924, lr=2.3088e-05, gnorm=1.406, train_wall=6, gb_free=14.9, wall=6539
2025-04-03 06:53:00 | INFO | train_inner | epoch 016:     36 / 126 loss=5.816, nll_loss=2.256, ppl=4.78, wps=1666.5, ups=0.37, wpb=4527.5, bsz=232, num_updates=1926, lr=2.3112e-05, gnorm=1.608, train_wall=5, gb_free=10.9, wall=6544
2025-04-03 06:53:06 | INFO | train_inner | epoch 016:     38 / 126 loss=5.689, nll_loss=2.106, ppl=4.3, wps=1711.1, ups=0.33, wpb=5114, bsz=308, num_updates=1928, lr=2.3136e-05, gnorm=1.35, train_wall=6, gb_free=13.4, wall=6550
2025-04-03 06:53:12 | INFO | train_inner | epoch 016:     40 / 126 loss=5.756, nll_loss=2.209, ppl=4.62, wps=1399.3, ups=0.34, wpb=4060, bsz=224, num_updates=1930, lr=2.316e-05, gnorm=1.423, train_wall=6, gb_free=10.1, wall=6556
2025-04-03 06:53:18 | INFO | train_inner | epoch 016:     42 / 126 loss=5.907, nll_loss=2.402, ppl=5.28, wps=1700.6, ups=0.34, wpb=4952.5, bsz=280, num_updates=1932, lr=2.3184e-05, gnorm=1.465, train_wall=6, gb_free=10.8, wall=6562
2025-04-03 06:53:24 | INFO | train_inner | epoch 016:     44 / 126 loss=5.804, nll_loss=2.27, ppl=4.82, wps=1387.3, ups=0.35, wpb=3972, bsz=176, num_updates=1934, lr=2.3208e-05, gnorm=2.148, train_wall=6, gb_free=11, wall=6568
2025-04-03 06:53:34 | INFO | train_inner | epoch 016:     46 / 126 loss=5.813, nll_loss=2.281, ppl=4.86, wps=890.8, ups=0.19, wpb=4673, bsz=284, num_updates=1936, lr=2.3232e-05, gnorm=1.421, train_wall=10, gb_free=13.8, wall=6578
2025-04-03 06:53:39 | INFO | train_inner | epoch 016:     48 / 126 loss=5.79, nll_loss=2.245, ppl=4.74, wps=1814.1, ups=0.39, wpb=4704.5, bsz=352, num_updates=1938, lr=2.3256e-05, gnorm=1.497, train_wall=5, gb_free=15.1, wall=6583
2025-04-03 06:53:45 | INFO | train_inner | epoch 016:     50 / 126 loss=5.864, nll_loss=2.309, ppl=4.96, wps=1843.8, ups=0.34, wpb=5431.5, bsz=252, num_updates=1940, lr=2.328e-05, gnorm=1.783, train_wall=6, gb_free=9.2, wall=6589
2025-04-03 06:53:51 | INFO | train_inner | epoch 016:     52 / 126 loss=6.001, nll_loss=2.523, ppl=5.75, wps=1784.6, ups=0.36, wpb=4932.5, bsz=308, num_updates=1942, lr=2.3304e-05, gnorm=1.506, train_wall=6, gb_free=13.2, wall=6595
2025-04-03 06:53:56 | INFO | train_inner | epoch 016:     54 / 126 loss=5.932, nll_loss=2.433, ppl=5.4, wps=1730.1, ups=0.36, wpb=4799.5, bsz=312, num_updates=1944, lr=2.3328e-05, gnorm=1.472, train_wall=6, gb_free=12.8, wall=6600
2025-04-03 06:54:01 | INFO | train_inner | epoch 016:     56 / 126 loss=5.891, nll_loss=2.368, ppl=5.16, wps=1470.9, ups=0.39, wpb=3736, bsz=192, num_updates=1946, lr=2.3352e-05, gnorm=1.655, train_wall=5, gb_free=13, wall=6605
2025-04-03 06:54:07 | INFO | train_inner | epoch 016:     58 / 126 loss=5.814, nll_loss=2.295, ppl=4.91, wps=1677.4, ups=0.37, wpb=4499.5, bsz=320, num_updates=1948, lr=2.3376e-05, gnorm=1.424, train_wall=5, gb_free=14.6, wall=6611
2025-04-03 06:54:12 | INFO | train_inner | epoch 016:     60 / 126 loss=5.78, nll_loss=2.228, ppl=4.69, wps=1738.3, ups=0.36, wpb=4882.5, bsz=272, num_updates=1950, lr=2.34e-05, gnorm=1.423, train_wall=6, gb_free=12.5, wall=6616
2025-04-03 06:54:18 | INFO | train_inner | epoch 016:     62 / 126 loss=5.925, nll_loss=2.403, ppl=5.29, wps=1730.5, ups=0.35, wpb=4981, bsz=236, num_updates=1952, lr=2.3424e-05, gnorm=1.581, train_wall=6, gb_free=10.3, wall=6622
2025-04-03 06:54:24 | INFO | train_inner | epoch 016:     64 / 126 loss=5.916, nll_loss=2.402, ppl=5.28, wps=1674.6, ups=0.35, wpb=4750, bsz=284, num_updates=1954, lr=2.3448e-05, gnorm=1.491, train_wall=6, gb_free=13, wall=6628
2025-04-03 06:54:29 | INFO | train_inner | epoch 016:     66 / 126 loss=5.978, nll_loss=2.472, ppl=5.55, wps=1630.3, ups=0.35, wpb=4626, bsz=148, num_updates=1956, lr=2.3472e-05, gnorm=1.666, train_wall=6, gb_free=9.7, wall=6634
2025-04-03 06:54:35 | INFO | train_inner | epoch 016:     68 / 126 loss=5.906, nll_loss=2.39, ppl=5.24, wps=1656.2, ups=0.39, wpb=4212, bsz=148, num_updates=1958, lr=2.3496e-05, gnorm=1.776, train_wall=5, gb_free=11.4, wall=6639
2025-04-03 06:54:40 | INFO | train_inner | epoch 016:     70 / 126 loss=5.862, nll_loss=2.341, ppl=5.07, wps=1750.5, ups=0.37, wpb=4705, bsz=300, num_updates=1960, lr=2.352e-05, gnorm=1.658, train_wall=5, gb_free=13.8, wall=6644
2025-04-03 06:54:46 | INFO | train_inner | epoch 016:     72 / 126 loss=5.865, nll_loss=2.302, ppl=4.93, wps=1533.2, ups=0.35, wpb=4403, bsz=212, num_updates=1962, lr=2.3544e-05, gnorm=1.608, train_wall=6, gb_free=9.7, wall=6650
2025-04-03 06:54:51 | INFO | train_inner | epoch 016:     74 / 126 loss=5.908, nll_loss=2.375, ppl=5.19, wps=1671.9, ups=0.35, wpb=4784.5, bsz=224, num_updates=1964, lr=2.3568e-05, gnorm=1.56, train_wall=6, gb_free=9.1, wall=6655
2025-04-03 06:54:57 | INFO | train_inner | epoch 016:     76 / 126 loss=5.873, nll_loss=2.355, ppl=5.11, wps=1595.9, ups=0.36, wpb=4428, bsz=240, num_updates=1966, lr=2.3592e-05, gnorm=1.438, train_wall=6, gb_free=13.9, wall=6661
2025-04-03 06:55:01 | INFO | train_inner | epoch 016:     78 / 126 loss=5.828, nll_loss=2.321, ppl=5, wps=1274.1, ups=0.45, wpb=2848.5, bsz=156.5, num_updates=1968, lr=2.3616e-05, gnorm=1.916, train_wall=4, gb_free=14.2, wall=6666
2025-04-03 06:55:07 | INFO | train_inner | epoch 016:     80 / 126 loss=5.934, nll_loss=2.442, ppl=5.44, wps=1738.7, ups=0.35, wpb=5003.5, bsz=268, num_updates=1970, lr=2.364e-05, gnorm=1.577, train_wall=6, gb_free=9.6, wall=6671
2025-04-03 06:55:13 | INFO | train_inner | epoch 016:     82 / 126 loss=5.853, nll_loss=2.326, ppl=5.02, wps=1665.6, ups=0.37, wpb=4561.5, bsz=268, num_updates=1972, lr=2.3664e-05, gnorm=1.527, train_wall=5, gb_free=12.2, wall=6677
2025-04-03 06:55:18 | INFO | train_inner | epoch 016:     84 / 126 loss=5.775, nll_loss=2.21, ppl=4.63, wps=1604.3, ups=0.36, wpb=4446.5, bsz=264, num_updates=1974, lr=2.3688e-05, gnorm=1.392, train_wall=6, gb_free=9.4, wall=6682
2025-04-03 06:55:24 | INFO | train_inner | epoch 016:     86 / 126 loss=5.977, nll_loss=2.467, ppl=5.53, wps=1791.3, ups=0.37, wpb=4805, bsz=272, num_updates=1976, lr=2.3712e-05, gnorm=1.505, train_wall=5, gb_free=14, wall=6688
2025-04-03 06:55:29 | INFO | train_inner | epoch 016:     88 / 126 loss=5.746, nll_loss=2.206, ppl=4.61, wps=1667.7, ups=0.36, wpb=4597, bsz=360, num_updates=1978, lr=2.3736e-05, gnorm=1.333, train_wall=6, gb_free=9.9, wall=6693
2025-04-03 06:55:35 | INFO | train_inner | epoch 016:     90 / 126 loss=5.719, nll_loss=2.149, ppl=4.43, wps=1651.4, ups=0.35, wpb=4714, bsz=228, num_updates=1980, lr=2.376e-05, gnorm=1.463, train_wall=6, gb_free=13.9, wall=6699
2025-04-03 06:55:41 | INFO | train_inner | epoch 016:     92 / 126 loss=5.881, nll_loss=2.362, ppl=5.14, wps=1376, ups=0.35, wpb=3951.5, bsz=208, num_updates=1982, lr=2.3784e-05, gnorm=1.628, train_wall=6, gb_free=12.8, wall=6705
2025-04-03 06:55:46 | INFO | train_inner | epoch 016:     94 / 126 loss=5.795, nll_loss=2.265, ppl=4.81, wps=1748, ups=0.37, wpb=4768.5, bsz=312, num_updates=1984, lr=2.3808e-05, gnorm=1.514, train_wall=5, gb_free=11.5, wall=6710
2025-04-03 06:55:51 | INFO | train_inner | epoch 016:     96 / 126 loss=5.836, nll_loss=2.308, ppl=4.95, wps=1636.4, ups=0.37, wpb=4369.5, bsz=276, num_updates=1986, lr=2.3832e-05, gnorm=1.537, train_wall=5, gb_free=13.3, wall=6715
2025-04-03 06:55:57 | INFO | train_inner | epoch 016:     98 / 126 loss=5.856, nll_loss=2.313, ppl=4.97, wps=1442.9, ups=0.35, wpb=4080.5, bsz=212, num_updates=1988, lr=2.3856e-05, gnorm=1.575, train_wall=6, gb_free=13.6, wall=6721
2025-04-03 06:56:03 | INFO | train_inner | epoch 016:    100 / 126 loss=5.874, nll_loss=2.35, ppl=5.1, wps=1541.7, ups=0.35, wpb=4424, bsz=284, num_updates=1990, lr=2.388e-05, gnorm=1.48, train_wall=6, gb_free=10.5, wall=6727
2025-04-03 06:56:08 | INFO | train_inner | epoch 016:    102 / 126 loss=5.853, nll_loss=2.322, ppl=5, wps=1442.1, ups=0.37, wpb=3863.5, bsz=216, num_updates=1992, lr=2.3904e-05, gnorm=1.641, train_wall=5, gb_free=14.7, wall=6732
2025-04-03 06:56:13 | INFO | train_inner | epoch 016:    104 / 126 loss=5.839, nll_loss=2.301, ppl=4.93, wps=1527.4, ups=0.37, wpb=4114, bsz=188, num_updates=1994, lr=2.3928e-05, gnorm=1.575, train_wall=5, gb_free=9.7, wall=6738
2025-04-03 06:56:19 | INFO | train_inner | epoch 016:    106 / 126 loss=5.912, nll_loss=2.401, ppl=5.28, wps=1752.4, ups=0.34, wpb=5117, bsz=264, num_updates=1996, lr=2.3952e-05, gnorm=1.553, train_wall=6, gb_free=12.6, wall=6743
2025-04-03 06:56:25 | INFO | train_inner | epoch 016:    108 / 126 loss=5.796, nll_loss=2.263, ppl=4.8, wps=1749.2, ups=0.35, wpb=4955, bsz=324, num_updates=1998, lr=2.3976e-05, gnorm=1.371, train_wall=6, gb_free=10.2, wall=6749
2025-04-03 06:56:31 | INFO | train_inner | epoch 016:    110 / 126 loss=5.837, nll_loss=2.292, ppl=4.9, wps=1605, ups=0.35, wpb=4615.5, bsz=148, num_updates=2000, lr=2.4e-05, gnorm=1.627, train_wall=6, gb_free=9.2, wall=6755
2025-04-03 06:56:36 | INFO | train_inner | epoch 016:    112 / 126 loss=5.681, nll_loss=2.125, ppl=4.36, wps=1773.3, ups=0.36, wpb=4991, bsz=340, num_updates=2002, lr=2.4024e-05, gnorm=1.295, train_wall=6, gb_free=13.2, wall=6760
2025-04-03 06:56:42 | INFO | train_inner | epoch 016:    114 / 126 loss=5.855, nll_loss=2.328, ppl=5.02, wps=1662.4, ups=0.37, wpb=4477.5, bsz=248, num_updates=2004, lr=2.4048e-05, gnorm=1.48, train_wall=5, gb_free=12.6, wall=6766
2025-04-03 06:56:47 | INFO | train_inner | epoch 016:    116 / 126 loss=5.931, nll_loss=2.413, ppl=5.32, wps=1544, ups=0.35, wpb=4370.5, bsz=220, num_updates=2006, lr=2.4072e-05, gnorm=1.457, train_wall=6, gb_free=12.7, wall=6771
2025-04-03 06:56:53 | INFO | train_inner | epoch 016:    118 / 126 loss=5.9, nll_loss=2.36, ppl=5.13, wps=1576.1, ups=0.37, wpb=4295.5, bsz=140, num_updates=2008, lr=2.4096e-05, gnorm=1.606, train_wall=5, gb_free=12.6, wall=6777
2025-04-03 06:56:58 | INFO | train_inner | epoch 016:    120 / 126 loss=5.814, nll_loss=2.258, ppl=4.78, wps=1489.9, ups=0.37, wpb=4069, bsz=220, num_updates=2010, lr=2.412e-05, gnorm=1.465, train_wall=5, gb_free=12.7, wall=6782
2025-04-03 06:57:04 | INFO | train_inner | epoch 016:    122 / 126 loss=5.871, nll_loss=2.357, ppl=5.12, wps=1653.3, ups=0.35, wpb=4727.5, bsz=288, num_updates=2012, lr=2.4144e-05, gnorm=1.425, train_wall=6, gb_free=14.2, wall=6788
2025-04-03 06:57:10 | INFO | train_inner | epoch 016:    124 / 126 loss=5.801, nll_loss=2.274, ppl=4.84, wps=1625.4, ups=0.35, wpb=4585, bsz=276, num_updates=2014, lr=2.4168e-05, gnorm=1.377, train_wall=6, gb_free=11.8, wall=6794
2025-04-03 06:57:14 | INFO | train_inner | epoch 016:    126 / 126 loss=5.809, nll_loss=2.283, ppl=4.87, wps=1552.9, ups=0.46, wpb=3381.5, bsz=204, num_updates=2016, lr=2.4192e-05, gnorm=1.624, train_wall=4, gb_free=15.6, wall=6798
2025-04-03 06:57:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-03 06:57:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=15967.7890625Mb; avail=239117.4140625Mb
2025-04-03 06:57:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000650
2025-04-03 06:57:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15967.78515625Mb; avail=239117.4140625Mb
2025-04-03 06:57:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012940
2025-04-03 06:57:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15967.78515625Mb; avail=239117.4140625Mb
2025-04-03 06:57:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.011109
2025-04-03 06:57:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.025151
2025-04-03 06:57:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15967.78515625Mb; avail=239117.4140625Mb
2025-04-03 06:57:28 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 6.064 | nll_loss 2.407 | ppl 5.3 | wps 3868.3 | wpb 2070.5 | bsz 122.7 | num_updates 2016 | best_loss 6.064
2025-04-03 06:57:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2016 updates
2025-04-03 06:57:28 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 06:58:08 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 06:58:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt (epoch 16 @ 2016 updates, score 6.064) (writing took 64.20762584195472 seconds)
2025-04-03 06:58:33 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2025-04-03 06:58:33 | INFO | train | epoch 016 | loss 5.846 | nll_loss 2.313 | ppl 4.97 | wps 1326.1 | ups 0.29 | wpb 4549.7 | bsz 252.8 | num_updates 2016 | lr 2.4192e-05 | gnorm 1.538 | train_wall 353 | gb_free 15.6 | wall 6877
2025-04-03 06:58:33 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:mr-hi': 31849}; raw total size: 31849
2025-04-03 06:58:33 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:mr-hi': 31849}; resampled total size: 31849
2025-04-03 06:58:33 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:mr-hi': 1.0}
2025-04-03 06:58:33 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001022
2025-04-03 06:58:33 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=26741.859375Mb; avail=228343.3046875Mb
2025-04-03 06:58:33 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000536
2025-04-03 06:58:33 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003444
2025-04-03 06:58:33 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26741.609375Mb; avail=228343.5546875Mb
2025-04-03 06:58:33 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000097
2025-04-03 06:58:33 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26741.609375Mb; avail=228343.5546875Mb
2025-04-03 06:58:33 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001110
2025-04-03 06:58:33 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.005006
2025-04-03 06:58:33 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26741.609375Mb; avail=228343.5546875Mb
2025-04-03 06:58:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 126
2025-04-03 06:58:33 | INFO | fairseq.trainer | begin training epoch 17
2025-04-03 06:58:33 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-03 06:58:38 | INFO | train_inner | epoch 017:      2 / 126 loss=5.583, nll_loss=1.981, ppl=3.95, wps=119.9, ups=0.02, wpb=5053, bsz=316, num_updates=2018, lr=2.4216e-05, gnorm=1.274, train_wall=6, gb_free=12.7, wall=6882
2025-04-03 06:58:44 | INFO | train_inner | epoch 017:      4 / 126 loss=5.781, nll_loss=2.214, ppl=4.64, wps=1624.6, ups=0.36, wpb=4481, bsz=256, num_updates=2020, lr=2.424e-05, gnorm=1.428, train_wall=6, gb_free=14, wall=6888
2025-04-03 06:58:49 | INFO | train_inner | epoch 017:      6 / 126 loss=5.722, nll_loss=2.159, ppl=4.46, wps=1633.1, ups=0.39, wpb=4161.5, bsz=236, num_updates=2022, lr=2.4264e-05, gnorm=1.579, train_wall=5, gb_free=14.1, wall=6893
2025-04-03 06:58:54 | INFO | train_inner | epoch 017:      8 / 126 loss=5.763, nll_loss=2.233, ppl=4.7, wps=1817.5, ups=0.36, wpb=5054, bsz=356, num_updates=2024, lr=2.4288e-05, gnorm=1.4, train_wall=6, gb_free=10.3, wall=6899
2025-04-03 06:59:00 | INFO | train_inner | epoch 017:     10 / 126 loss=5.781, nll_loss=2.231, ppl=4.69, wps=1606.6, ups=0.36, wpb=4445, bsz=252, num_updates=2026, lr=2.4312e-05, gnorm=1.701, train_wall=6, gb_free=10.7, wall=6904
2025-04-03 06:59:06 | INFO | train_inner | epoch 017:     12 / 126 loss=5.698, nll_loss=2.115, ppl=4.33, wps=1410, ups=0.34, wpb=4112, bsz=192, num_updates=2028, lr=2.4336e-05, gnorm=1.526, train_wall=6, gb_free=9.5, wall=6910
2025-04-03 06:59:11 | INFO | train_inner | epoch 017:     14 / 126 loss=5.698, nll_loss=2.115, ppl=4.33, wps=1761.3, ups=0.37, wpb=4820, bsz=336, num_updates=2030, lr=2.436e-05, gnorm=1.336, train_wall=5, gb_free=12.9, wall=6915
2025-04-03 06:59:17 | INFO | train_inner | epoch 017:     16 / 126 loss=5.823, nll_loss=2.258, ppl=4.78, wps=1544.9, ups=0.36, wpb=4349, bsz=184, num_updates=2032, lr=2.4384e-05, gnorm=1.573, train_wall=6, gb_free=12, wall=6921
2025-04-03 06:59:23 | INFO | train_inner | epoch 017:     18 / 126 loss=5.651, nll_loss=2.072, ppl=4.2, wps=1545.9, ups=0.35, wpb=4479, bsz=144, num_updates=2034, lr=2.4408e-05, gnorm=1.444, train_wall=6, gb_free=9.6, wall=6927
2025-04-03 06:59:29 | INFO | train_inner | epoch 017:     20 / 126 loss=5.833, nll_loss=2.317, ppl=4.98, wps=1653.3, ups=0.34, wpb=4888.5, bsz=272, num_updates=2036, lr=2.4432e-05, gnorm=1.451, train_wall=6, gb_free=11.6, wall=6933
2025-04-03 06:59:34 | INFO | train_inner | epoch 017:     22 / 126 loss=5.771, nll_loss=2.234, ppl=4.71, wps=1618.6, ups=0.38, wpb=4305, bsz=316, num_updates=2038, lr=2.4456e-05, gnorm=1.365, train_wall=5, gb_free=12.2, wall=6938
2025-04-03 06:59:39 | INFO | train_inner | epoch 017:     24 / 126 loss=5.726, nll_loss=2.155, ppl=4.45, wps=1625.1, ups=0.39, wpb=4182, bsz=240, num_updates=2040, lr=2.448e-05, gnorm=1.587, train_wall=5, gb_free=15, wall=6943
2025-04-03 06:59:45 | INFO | train_inner | epoch 017:     26 / 126 loss=5.807, nll_loss=2.235, ppl=4.71, wps=1840.9, ups=0.37, wpb=5040.5, bsz=288, num_updates=2042, lr=2.4504e-05, gnorm=1.514, train_wall=5, gb_free=14.2, wall=6949
2025-04-03 06:59:50 | INFO | train_inner | epoch 017:     28 / 126 loss=5.661, nll_loss=2.069, ppl=4.19, wps=1687.3, ups=0.35, wpb=4761.5, bsz=288, num_updates=2044, lr=2.4528e-05, gnorm=1.281, train_wall=6, gb_free=11.5, wall=6954
2025-04-03 06:59:56 | INFO | train_inner | epoch 017:     30 / 126 loss=5.782, nll_loss=2.236, ppl=4.71, wps=1719.4, ups=0.35, wpb=4894, bsz=208, num_updates=2046, lr=2.4552e-05, gnorm=1.418, train_wall=6, gb_free=11.8, wall=6960
2025-04-03 07:00:02 | INFO | train_inner | epoch 017:     32 / 126 loss=5.771, nll_loss=2.229, ppl=4.69, wps=1646.1, ups=0.35, wpb=4767.5, bsz=240, num_updates=2048, lr=2.4576e-05, gnorm=1.4, train_wall=6, gb_free=8.6, wall=6966
2025-04-03 07:00:07 | INFO | train_inner | epoch 017:     34 / 126 loss=5.768, nll_loss=2.213, ppl=4.64, wps=1528.4, ups=0.38, wpb=4073, bsz=200, num_updates=2050, lr=2.46e-05, gnorm=1.578, train_wall=5, gb_free=10.5, wall=6971
2025-04-03 07:00:13 | INFO | train_inner | epoch 017:     36 / 126 loss=5.871, nll_loss=2.331, ppl=5.03, wps=1523.5, ups=0.34, wpb=4494.5, bsz=204, num_updates=2052, lr=2.4624e-05, gnorm=1.463, train_wall=6, gb_free=10.1, wall=6977
2025-04-03 07:00:19 | INFO | train_inner | epoch 017:     38 / 126 loss=5.94, nll_loss=2.419, ppl=5.35, wps=1563.6, ups=0.35, wpb=4482, bsz=188, num_updates=2054, lr=2.4648e-05, gnorm=1.616, train_wall=6, gb_free=10.9, wall=6983
2025-04-03 07:00:24 | INFO | train_inner | epoch 017:     40 / 126 loss=5.636, nll_loss=2.07, ppl=4.2, wps=1580.7, ups=0.36, wpb=4379.5, bsz=292, num_updates=2056, lr=2.4672e-05, gnorm=1.363, train_wall=6, gb_free=13, wall=6988
2025-04-03 07:00:30 | INFO | train_inner | epoch 017:     42 / 126 loss=5.67, nll_loss=2.109, ppl=4.31, wps=1593.2, ups=0.37, wpb=4280, bsz=284, num_updates=2058, lr=2.4696e-05, gnorm=1.396, train_wall=5, gb_free=14.3, wall=6994
2025-04-03 07:00:35 | INFO | train_inner | epoch 017:     44 / 126 loss=5.853, nll_loss=2.333, ppl=5.04, wps=1823.5, ups=0.36, wpb=5037.5, bsz=348, num_updates=2060, lr=2.472e-05, gnorm=1.403, train_wall=6, gb_free=13.4, wall=6999
2025-04-03 07:00:41 | INFO | train_inner | epoch 017:     46 / 126 loss=5.836, nll_loss=2.282, ppl=4.86, wps=1617.6, ups=0.37, wpb=4378.5, bsz=184, num_updates=2062, lr=2.4744e-05, gnorm=1.62, train_wall=5, gb_free=15.4, wall=7005
2025-04-03 07:00:46 | INFO | train_inner | epoch 017:     48 / 126 loss=5.834, nll_loss=2.283, ppl=4.87, wps=1661.8, ups=0.35, wpb=4748.5, bsz=248, num_updates=2064, lr=2.4768e-05, gnorm=1.516, train_wall=6, gb_free=11.9, wall=7010
2025-04-03 07:00:52 | INFO | train_inner | epoch 017:     50 / 126 loss=5.769, nll_loss=2.229, ppl=4.69, wps=1888.1, ups=0.33, wpb=5716, bsz=372, num_updates=2066, lr=2.4792e-05, gnorm=1.343, train_wall=6, gb_free=9.6, wall=7016
2025-04-03 07:00:58 | INFO | train_inner | epoch 017:     52 / 126 loss=5.748, nll_loss=2.193, ppl=4.57, wps=1607.5, ups=0.36, wpb=4421, bsz=232, num_updates=2068, lr=2.4816e-05, gnorm=1.446, train_wall=5, gb_free=8.9, wall=7022
2025-04-03 07:01:04 | INFO | train_inner | epoch 017:     54 / 126 loss=5.786, nll_loss=2.246, ppl=4.74, wps=1757.5, ups=0.34, wpb=5159.5, bsz=296, num_updates=2070, lr=2.484e-05, gnorm=1.279, train_wall=6, gb_free=10.1, wall=7028
2025-04-03 07:01:09 | INFO | train_inner | epoch 017:     56 / 126 loss=5.744, nll_loss=2.187, ppl=4.56, wps=1568.7, ups=0.36, wpb=4349, bsz=284, num_updates=2072, lr=2.4864e-05, gnorm=1.468, train_wall=6, gb_free=12.8, wall=7033
2025-04-03 07:01:15 | INFO | train_inner | epoch 017:     58 / 126 loss=5.716, nll_loss=2.145, ppl=4.42, wps=1617.8, ups=0.36, wpb=4523, bsz=236, num_updates=2074, lr=2.4888e-05, gnorm=1.5, train_wall=6, gb_free=11.4, wall=7039
2025-04-03 07:01:21 | INFO | train_inner | epoch 017:     60 / 126 loss=5.832, nll_loss=2.309, ppl=4.96, wps=1673.6, ups=0.34, wpb=4948.5, bsz=284, num_updates=2076, lr=2.4912e-05, gnorm=1.412, train_wall=6, gb_free=11.8, wall=7045
2025-04-03 07:01:26 | INFO | train_inner | epoch 017:     62 / 126 loss=5.744, nll_loss=2.188, ppl=4.56, wps=1814.6, ups=0.35, wpb=5173.5, bsz=344, num_updates=2078, lr=2.4936e-05, gnorm=1.452, train_wall=6, gb_free=12.2, wall=7051
2025-04-03 07:01:32 | INFO | train_inner | epoch 017:     64 / 126 loss=5.834, nll_loss=2.291, ppl=4.89, wps=1651.4, ups=0.36, wpb=4547, bsz=216, num_updates=2080, lr=2.496e-05, gnorm=1.481, train_wall=5, gb_free=13.1, wall=7056
2025-04-03 07:01:38 | INFO | train_inner | epoch 017:     66 / 126 loss=5.876, nll_loss=2.331, ppl=5.03, wps=1606, ups=0.34, wpb=4657, bsz=160, num_updates=2082, lr=2.4984e-05, gnorm=1.609, train_wall=6, gb_free=11.7, wall=7062
2025-04-03 07:01:43 | INFO | train_inner | epoch 017:     68 / 126 loss=5.69, nll_loss=2.124, ppl=4.36, wps=1759.8, ups=0.35, wpb=5011.5, bsz=332, num_updates=2084, lr=2.5008e-05, gnorm=1.334, train_wall=6, gb_free=11.3, wall=7068
2025-04-03 07:01:48 | INFO | train_inner | epoch 017:     70 / 126 loss=5.779, nll_loss=2.228, ppl=4.68, wps=1580.7, ups=0.44, wpb=3626.5, bsz=168.5, num_updates=2086, lr=2.5032e-05, gnorm=1.789, train_wall=5, gb_free=10.1, wall=7072
2025-04-03 07:01:54 | INFO | train_inner | epoch 017:     72 / 126 loss=5.791, nll_loss=2.237, ppl=4.71, wps=1375.1, ups=0.34, wpb=4023.5, bsz=116, num_updates=2088, lr=2.5056e-05, gnorm=1.719, train_wall=6, gb_free=9.6, wall=7078
2025-04-03 07:02:00 | INFO | train_inner | epoch 017:     74 / 126 loss=5.741, nll_loss=2.21, ppl=4.63, wps=1468.3, ups=0.35, wpb=4247, bsz=304, num_updates=2090, lr=2.508e-05, gnorm=1.422, train_wall=6, gb_free=10.6, wall=7084
2025-04-03 07:02:05 | INFO | train_inner | epoch 017:     76 / 126 loss=5.902, nll_loss=2.374, ppl=5.19, wps=1453.8, ups=0.39, wpb=3725, bsz=124, num_updates=2092, lr=2.5104e-05, gnorm=1.99, train_wall=5, gb_free=9.9, wall=7089
2025-04-03 07:02:10 | INFO | train_inner | epoch 017:     78 / 126 loss=5.8, nll_loss=2.249, ppl=4.75, wps=1734.9, ups=0.36, wpb=4880, bsz=328, num_updates=2094, lr=2.5128e-05, gnorm=1.467, train_wall=6, gb_free=13.7, wall=7095
2025-04-03 07:02:21 | INFO | train_inner | epoch 017:     80 / 126 loss=5.755, nll_loss=2.193, ppl=4.57, wps=877.1, ups=0.19, wpb=4613, bsz=288, num_updates=2096, lr=2.5152e-05, gnorm=1.59, train_wall=11, gb_free=11.6, wall=7105
2025-04-03 07:02:26 | INFO | train_inner | epoch 017:     82 / 126 loss=5.725, nll_loss=2.158, ppl=4.46, wps=1516.2, ups=0.38, wpb=3950, bsz=220, num_updates=2098, lr=2.5176e-05, gnorm=1.676, train_wall=5, gb_free=14.1, wall=7110
2025-04-03 07:02:32 | INFO | train_inner | epoch 017:     84 / 126 loss=5.721, nll_loss=2.176, ppl=4.52, wps=1622.8, ups=0.37, wpb=4392, bsz=272, num_updates=2100, lr=2.52e-05, gnorm=1.424, train_wall=5, gb_free=11.9, wall=7116
2025-04-03 07:02:37 | INFO | train_inner | epoch 017:     86 / 126 loss=5.699, nll_loss=2.139, ppl=4.4, wps=1606.1, ups=0.37, wpb=4311.5, bsz=248, num_updates=2102, lr=2.5224e-05, gnorm=1.423, train_wall=5, gb_free=14.5, wall=7121
2025-04-03 07:02:43 | INFO | train_inner | epoch 017:     88 / 126 loss=5.732, nll_loss=2.172, ppl=4.51, wps=1713.3, ups=0.35, wpb=4849, bsz=288, num_updates=2104, lr=2.5248e-05, gnorm=1.424, train_wall=6, gb_free=10.7, wall=7127
2025-04-03 07:02:48 | INFO | train_inner | epoch 017:     90 / 126 loss=5.719, nll_loss=2.147, ppl=4.43, wps=1804.3, ups=0.36, wpb=4995, bsz=284, num_updates=2106, lr=2.5272e-05, gnorm=1.421, train_wall=6, gb_free=10.3, wall=7132
2025-04-03 07:02:54 | INFO | train_inner | epoch 017:     92 / 126 loss=5.683, nll_loss=2.106, ppl=4.31, wps=1685.8, ups=0.37, wpb=4562, bsz=292, num_updates=2108, lr=2.5296e-05, gnorm=1.424, train_wall=5, gb_free=12.5, wall=7138
2025-04-03 07:02:59 | INFO | train_inner | epoch 017:     94 / 126 loss=5.826, nll_loss=2.29, ppl=4.89, wps=1809.5, ups=0.36, wpb=5061, bsz=268, num_updates=2110, lr=2.532e-05, gnorm=1.537, train_wall=6, gb_free=11.2, wall=7143
2025-04-03 07:03:05 | INFO | train_inner | epoch 017:     96 / 126 loss=5.791, nll_loss=2.246, ppl=4.74, wps=1799.6, ups=0.37, wpb=4878, bsz=252, num_updates=2112, lr=2.5344e-05, gnorm=1.405, train_wall=5, gb_free=13, wall=7149
2025-04-03 07:03:10 | INFO | train_inner | epoch 017:     98 / 126 loss=5.673, nll_loss=2.104, ppl=4.3, wps=1631.5, ups=0.35, wpb=4615, bsz=320, num_updates=2114, lr=2.5368e-05, gnorm=1.427, train_wall=6, gb_free=15, wall=7154
2025-04-03 07:03:15 | INFO | train_inner | epoch 017:    100 / 126 loss=5.909, nll_loss=2.39, ppl=5.24, wps=1496.3, ups=0.38, wpb=3888.5, bsz=220, num_updates=2116, lr=2.5392e-05, gnorm=1.642, train_wall=5, gb_free=14.5, wall=7160
2025-04-03 07:03:21 | INFO | train_inner | epoch 017:    102 / 126 loss=5.953, nll_loss=2.435, ppl=5.41, wps=1800.2, ups=0.34, wpb=5272.5, bsz=248, num_updates=2118, lr=2.5416e-05, gnorm=1.716, train_wall=6, gb_free=11.5, wall=7165
2025-04-03 07:03:27 | INFO | train_inner | epoch 017:    104 / 126 loss=5.824, nll_loss=2.294, ppl=4.9, wps=1493.5, ups=0.34, wpb=4376, bsz=276, num_updates=2120, lr=2.544e-05, gnorm=1.552, train_wall=6, gb_free=11.7, wall=7171
2025-04-03 07:03:33 | INFO | train_inner | epoch 017:    106 / 126 loss=5.801, nll_loss=2.253, ppl=4.77, wps=1565.4, ups=0.35, wpb=4456, bsz=156, num_updates=2122, lr=2.5464e-05, gnorm=1.486, train_wall=6, gb_free=12.4, wall=7177
2025-04-03 07:03:39 | INFO | train_inner | epoch 017:    108 / 126 loss=5.731, nll_loss=2.192, ppl=4.57, wps=1692.9, ups=0.34, wpb=4950.5, bsz=304, num_updates=2124, lr=2.5488e-05, gnorm=1.425, train_wall=6, gb_free=11, wall=7183
2025-04-03 07:03:44 | INFO | train_inner | epoch 017:    110 / 126 loss=5.67, nll_loss=2.107, ppl=4.31, wps=1574.9, ups=0.37, wpb=4264, bsz=284, num_updates=2126, lr=2.5512e-05, gnorm=1.434, train_wall=5, gb_free=10, wall=7188
2025-04-03 07:03:49 | INFO | train_inner | epoch 017:    112 / 126 loss=5.694, nll_loss=2.109, ppl=4.32, wps=1545.8, ups=0.42, wpb=3710, bsz=200, num_updates=2128, lr=2.5536e-05, gnorm=1.752, train_wall=5, gb_free=16.3, wall=7193
2025-04-03 07:03:55 | INFO | train_inner | epoch 017:    114 / 126 loss=5.866, nll_loss=2.315, ppl=4.98, wps=1700.9, ups=0.34, wpb=4967.5, bsz=156, num_updates=2130, lr=2.556e-05, gnorm=1.648, train_wall=6, gb_free=9.6, wall=7199
2025-04-03 07:04:00 | INFO | train_inner | epoch 017:    116 / 126 loss=5.839, nll_loss=2.294, ppl=4.91, wps=1668.5, ups=0.36, wpb=4651, bsz=176, num_updates=2132, lr=2.5584e-05, gnorm=1.624, train_wall=6, gb_free=10.1, wall=7204
2025-04-03 07:04:06 | INFO | train_inner | epoch 017:    118 / 126 loss=5.749, nll_loss=2.197, ppl=4.59, wps=1644.3, ups=0.37, wpb=4430, bsz=236, num_updates=2134, lr=2.5608e-05, gnorm=1.874, train_wall=5, gb_free=12.9, wall=7210
2025-04-03 07:04:11 | INFO | train_inner | epoch 017:    120 / 126 loss=5.733, nll_loss=2.181, ppl=4.54, wps=1745.2, ups=0.35, wpb=5040, bsz=312, num_updates=2136, lr=2.5632e-05, gnorm=1.367, train_wall=6, gb_free=9.5, wall=7216
2025-04-03 07:04:17 | INFO | train_inner | epoch 017:    122 / 126 loss=5.667, nll_loss=2.097, ppl=4.28, wps=1522.3, ups=0.38, wpb=4048, bsz=276, num_updates=2138, lr=2.5656e-05, gnorm=1.553, train_wall=5, gb_free=14, wall=7221
2025-04-03 07:04:22 | INFO | train_inner | epoch 017:    124 / 126 loss=5.833, nll_loss=2.286, ppl=4.88, wps=1635.4, ups=0.36, wpb=4540.5, bsz=276, num_updates=2140, lr=2.568e-05, gnorm=1.496, train_wall=6, gb_free=12.6, wall=7226
2025-04-03 07:04:26 | INFO | train_inner | epoch 017:    126 / 126 loss=5.721, nll_loss=2.157, ppl=4.46, wps=1607.4, ups=0.51, wpb=3135.5, bsz=204, num_updates=2142, lr=2.5704e-05, gnorm=1.865, train_wall=4, gb_free=16.6, wall=7230
2025-04-03 07:04:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-03 07:04:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=15969.703125Mb; avail=239115.5Mb
2025-04-03 07:04:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000631
2025-04-03 07:04:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15969.703125Mb; avail=239115.5Mb
2025-04-03 07:04:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.013028
2025-04-03 07:04:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15969.703125Mb; avail=239115.5Mb
2025-04-03 07:04:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.011054
2025-04-03 07:04:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.025078
2025-04-03 07:04:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15969.703125Mb; avail=239115.5Mb
2025-04-03 07:04:41 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 6.048 | nll_loss 2.39 | ppl 5.24 | wps 3859 | wpb 2070.5 | bsz 122.7 | num_updates 2142 | best_loss 6.048
2025-04-03 07:04:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2142 updates
2025-04-03 07:04:41 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 07:05:18 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 07:05:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt (epoch 17 @ 2142 updates, score 6.048) (writing took 62.21614872501232 seconds)
2025-04-03 07:05:43 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2025-04-03 07:05:43 | INFO | train | epoch 017 | loss 5.768 | nll_loss 2.215 | ppl 4.64 | wps 1332.3 | ups 0.29 | wpb 4549.7 | bsz 252.8 | num_updates 2142 | lr 2.5704e-05 | gnorm 1.51 | train_wall 353 | gb_free 16.6 | wall 7307
2025-04-03 07:05:43 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:mr-hi': 31849}; raw total size: 31849
2025-04-03 07:05:43 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:mr-hi': 31849}; resampled total size: 31849
2025-04-03 07:05:43 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:mr-hi': 1.0}
2025-04-03 07:05:43 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001264
2025-04-03 07:05:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=26769.1484375Mb; avail=228316.0546875Mb
2025-04-03 07:05:43 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000609
2025-04-03 07:05:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003920
2025-04-03 07:05:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26769.1484375Mb; avail=228316.0546875Mb
2025-04-03 07:05:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000097
2025-04-03 07:05:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26769.1484375Mb; avail=228316.0546875Mb
2025-04-03 07:05:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001198
2025-04-03 07:05:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.005556
2025-04-03 07:05:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26769.1484375Mb; avail=228316.0546875Mb
2025-04-03 07:05:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 126
2025-04-03 07:05:43 | INFO | fairseq.trainer | begin training epoch 18
2025-04-03 07:05:43 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-03 07:05:48 | INFO | train_inner | epoch 018:      2 / 126 loss=5.799, nll_loss=2.265, ppl=4.81, wps=115.9, ups=0.02, wpb=4761.5, bsz=268, num_updates=2144, lr=2.5728e-05, gnorm=1.554, train_wall=5, gb_free=13.2, wall=7312
2025-04-03 07:05:54 | INFO | train_inner | epoch 018:      4 / 126 loss=5.714, nll_loss=2.165, ppl=4.49, wps=1458.7, ups=0.37, wpb=3890.5, bsz=280, num_updates=2146, lr=2.5752e-05, gnorm=1.538, train_wall=5, gb_free=13.3, wall=7318
2025-04-03 07:06:00 | INFO | train_inner | epoch 018:      6 / 126 loss=5.668, nll_loss=2.087, ppl=4.25, wps=1562, ups=0.34, wpb=4552.5, bsz=196, num_updates=2148, lr=2.5776e-05, gnorm=1.489, train_wall=6, gb_free=9.1, wall=7324
2025-04-03 07:06:05 | INFO | train_inner | epoch 018:      8 / 126 loss=5.707, nll_loss=2.149, ppl=4.43, wps=1703.5, ups=0.34, wpb=4961.5, bsz=340, num_updates=2150, lr=2.58e-05, gnorm=1.357, train_wall=6, gb_free=10.1, wall=7329
2025-04-03 07:06:11 | INFO | train_inner | epoch 018:     10 / 126 loss=5.725, nll_loss=2.157, ppl=4.46, wps=1793.4, ups=0.36, wpb=5051.5, bsz=292, num_updates=2152, lr=2.5824e-05, gnorm=1.347, train_wall=6, gb_free=10.5, wall=7335
2025-04-03 07:06:16 | INFO | train_inner | epoch 018:     12 / 126 loss=5.7, nll_loss=2.115, ppl=4.33, wps=1689.1, ups=0.37, wpb=4531.5, bsz=260, num_updates=2154, lr=2.5848e-05, gnorm=1.41, train_wall=5, gb_free=11.3, wall=7340
2025-04-03 07:06:22 | INFO | train_inner | epoch 018:     14 / 126 loss=5.735, nll_loss=2.161, ppl=4.47, wps=1671.2, ups=0.37, wpb=4476.5, bsz=208, num_updates=2156, lr=2.5872e-05, gnorm=1.487, train_wall=5, gb_free=9.3, wall=7346
2025-04-03 07:06:27 | INFO | train_inner | epoch 018:     16 / 126 loss=5.666, nll_loss=2.065, ppl=4.18, wps=1656.3, ups=0.4, wpb=4115.5, bsz=136, num_updates=2158, lr=2.5896e-05, gnorm=1.617, train_wall=5, gb_free=12.3, wall=7351
2025-04-03 07:06:32 | INFO | train_inner | epoch 018:     18 / 126 loss=5.683, nll_loss=2.113, ppl=4.33, wps=1641, ups=0.38, wpb=4375.5, bsz=304, num_updates=2160, lr=2.592e-05, gnorm=1.662, train_wall=5, gb_free=10.9, wall=7356
2025-04-03 07:06:38 | INFO | train_inner | epoch 018:     20 / 126 loss=5.677, nll_loss=2.093, ppl=4.27, wps=1500, ups=0.35, wpb=4279.5, bsz=176, num_updates=2162, lr=2.5944e-05, gnorm=1.699, train_wall=6, gb_free=12.3, wall=7362
2025-04-03 07:06:43 | INFO | train_inner | epoch 018:     22 / 126 loss=5.726, nll_loss=2.141, ppl=4.41, wps=1613.8, ups=0.35, wpb=4546.5, bsz=196, num_updates=2164, lr=2.5968e-05, gnorm=1.478, train_wall=6, gb_free=12.8, wall=7367
2025-04-03 07:06:49 | INFO | train_inner | epoch 018:     24 / 126 loss=5.596, nll_loss=2, ppl=4, wps=1603.8, ups=0.36, wpb=4407, bsz=252, num_updates=2166, lr=2.5992e-05, gnorm=1.505, train_wall=5, gb_free=13.4, wall=7373
2025-04-03 07:06:54 | INFO | train_inner | epoch 018:     26 / 126 loss=5.631, nll_loss=2.051, ppl=4.14, wps=1650.8, ups=0.36, wpb=4588, bsz=300, num_updates=2168, lr=2.6016e-05, gnorm=1.36, train_wall=6, gb_free=11.5, wall=7379
2025-04-03 07:07:00 | INFO | train_inner | epoch 018:     28 / 126 loss=5.66, nll_loss=2.086, ppl=4.24, wps=1672.4, ups=0.39, wpb=4322, bsz=280, num_updates=2170, lr=2.604e-05, gnorm=1.551, train_wall=5, gb_free=14.1, wall=7384
2025-04-03 07:07:10 | INFO | train_inner | epoch 018:     30 / 126 loss=5.689, nll_loss=2.122, ppl=4.35, wps=816.9, ups=0.19, wpb=4320, bsz=216, num_updates=2172, lr=2.6064e-05, gnorm=1.385, train_wall=11, gb_free=13, wall=7394
2025-04-03 07:07:16 | INFO | train_inner | epoch 018:     32 / 126 loss=5.699, nll_loss=2.125, ppl=4.36, wps=1622.7, ups=0.36, wpb=4528.5, bsz=188, num_updates=2174, lr=2.6088e-05, gnorm=1.408, train_wall=6, gb_free=12.8, wall=7400
2025-04-03 07:07:21 | INFO | train_inner | epoch 018:     34 / 126 loss=5.748, nll_loss=2.189, ppl=4.56, wps=1799.2, ups=0.36, wpb=5058, bsz=308, num_updates=2176, lr=2.6112e-05, gnorm=1.51, train_wall=6, gb_free=10.3, wall=7405
2025-04-03 07:07:27 | INFO | train_inner | epoch 018:     36 / 126 loss=5.708, nll_loss=2.118, ppl=4.34, wps=1795.6, ups=0.34, wpb=5220.5, bsz=276, num_updates=2178, lr=2.6136e-05, gnorm=1.349, train_wall=6, gb_free=10.7, wall=7411
2025-04-03 07:07:33 | INFO | train_inner | epoch 018:     38 / 126 loss=5.598, nll_loss=1.999, ppl=4, wps=1593.5, ups=0.36, wpb=4385, bsz=248, num_updates=2180, lr=2.616e-05, gnorm=1.397, train_wall=5, gb_free=12.9, wall=7417
2025-04-03 07:07:39 | INFO | train_inner | epoch 018:     40 / 126 loss=5.722, nll_loss=2.166, ppl=4.49, wps=1677.9, ups=0.34, wpb=4870, bsz=256, num_updates=2182, lr=2.6184e-05, gnorm=1.461, train_wall=6, gb_free=10, wall=7423
2025-04-03 07:07:44 | INFO | train_inner | epoch 018:     42 / 126 loss=5.713, nll_loss=2.145, ppl=4.42, wps=1687.3, ups=0.34, wpb=4951, bsz=248, num_updates=2184, lr=2.6208e-05, gnorm=1.421, train_wall=6, gb_free=11, wall=7428
2025-04-03 07:07:50 | INFO | train_inner | epoch 018:     44 / 126 loss=5.721, nll_loss=2.161, ppl=4.47, wps=1737.9, ups=0.37, wpb=4734, bsz=316, num_updates=2186, lr=2.6232e-05, gnorm=1.453, train_wall=5, gb_free=14.5, wall=7434
2025-04-03 07:07:55 | INFO | train_inner | epoch 018:     46 / 126 loss=5.668, nll_loss=2.09, ppl=4.26, wps=1585.4, ups=0.37, wpb=4307.5, bsz=240, num_updates=2188, lr=2.6256e-05, gnorm=1.46, train_wall=5, gb_free=14.1, wall=7439
2025-04-03 07:08:01 | INFO | train_inner | epoch 018:     48 / 126 loss=5.711, nll_loss=2.135, ppl=4.39, wps=1389.3, ups=0.36, wpb=3817, bsz=232, num_updates=2190, lr=2.628e-05, gnorm=1.494, train_wall=5, gb_free=14.3, wall=7445
2025-04-03 07:08:07 | INFO | train_inner | epoch 018:     50 / 126 loss=5.695, nll_loss=2.117, ppl=4.34, wps=1459, ups=0.34, wpb=4261, bsz=176, num_updates=2192, lr=2.6304e-05, gnorm=1.515, train_wall=6, gb_free=9.8, wall=7451
2025-04-03 07:08:12 | INFO | train_inner | epoch 018:     52 / 126 loss=5.72, nll_loss=2.156, ppl=4.46, wps=1713.6, ups=0.35, wpb=4941.5, bsz=232, num_updates=2194, lr=2.6328e-05, gnorm=1.484, train_wall=6, gb_free=9.8, wall=7456
2025-04-03 07:08:17 | INFO | train_inner | epoch 018:     54 / 126 loss=5.73, nll_loss=2.171, ppl=4.5, wps=1575.1, ups=0.43, wpb=3663, bsz=184.5, num_updates=2196, lr=2.6352e-05, gnorm=1.7, train_wall=5, gb_free=12, wall=7461
2025-04-03 07:08:22 | INFO | train_inner | epoch 018:     56 / 126 loss=5.657, nll_loss=2.065, ppl=4.18, wps=1641.6, ups=0.37, wpb=4435.5, bsz=256, num_updates=2198, lr=2.6376e-05, gnorm=1.487, train_wall=5, gb_free=11.9, wall=7467
2025-04-03 07:08:28 | INFO | train_inner | epoch 018:     58 / 126 loss=5.587, nll_loss=1.977, ppl=3.94, wps=1762, ups=0.34, wpb=5197, bsz=300, num_updates=2200, lr=2.64e-05, gnorm=1.297, train_wall=6, gb_free=9.9, wall=7472
2025-04-03 07:08:34 | INFO | train_inner | epoch 018:     60 / 126 loss=5.586, nll_loss=1.978, ppl=3.94, wps=1651.1, ups=0.36, wpb=4558, bsz=320, num_updates=2202, lr=2.6424e-05, gnorm=1.375, train_wall=6, gb_free=10.5, wall=7478
2025-04-03 07:08:40 | INFO | train_inner | epoch 018:     62 / 126 loss=5.825, nll_loss=2.281, ppl=4.86, wps=1623.8, ups=0.33, wpb=4915, bsz=212, num_updates=2204, lr=2.6448e-05, gnorm=1.469, train_wall=6, gb_free=8.6, wall=7484
2025-04-03 07:08:46 | INFO | train_inner | epoch 018:     64 / 126 loss=5.714, nll_loss=2.15, ppl=4.44, wps=1637, ups=0.35, wpb=4631.5, bsz=204, num_updates=2206, lr=2.6472e-05, gnorm=1.472, train_wall=6, gb_free=13.7, wall=7490
2025-04-03 07:08:51 | INFO | train_inner | epoch 018:     66 / 126 loss=5.741, nll_loss=2.216, ppl=4.65, wps=1709.8, ups=0.35, wpb=4909, bsz=376, num_updates=2208, lr=2.6496e-05, gnorm=1.456, train_wall=6, gb_free=10.5, wall=7495
2025-04-03 07:08:57 | INFO | train_inner | epoch 018:     68 / 126 loss=5.851, nll_loss=2.34, ppl=5.06, wps=1569.9, ups=0.37, wpb=4249.5, bsz=316, num_updates=2210, lr=2.652e-05, gnorm=1.586, train_wall=5, gb_free=11.4, wall=7501
2025-04-03 07:09:03 | INFO | train_inner | epoch 018:     70 / 126 loss=5.67, nll_loss=2.067, ppl=4.19, wps=1451.1, ups=0.34, wpb=4224, bsz=248, num_updates=2212, lr=2.6544e-05, gnorm=1.695, train_wall=6, gb_free=10.1, wall=7507
2025-04-03 07:09:08 | INFO | train_inner | epoch 018:     72 / 126 loss=5.747, nll_loss=2.162, ppl=4.48, wps=1558.7, ups=0.36, wpb=4317.5, bsz=184, num_updates=2214, lr=2.6568e-05, gnorm=1.502, train_wall=6, gb_free=9.7, wall=7512
2025-04-03 07:09:14 | INFO | train_inner | epoch 018:     74 / 126 loss=5.729, nll_loss=2.175, ppl=4.51, wps=1426.1, ups=0.36, wpb=3987, bsz=268, num_updates=2216, lr=2.6592e-05, gnorm=1.471, train_wall=6, gb_free=10.3, wall=7518
2025-04-03 07:09:19 | INFO | train_inner | epoch 018:     76 / 126 loss=5.697, nll_loss=2.128, ppl=4.37, wps=1638.7, ups=0.36, wpb=4510.5, bsz=172, num_updates=2218, lr=2.6616e-05, gnorm=1.422, train_wall=5, gb_free=12.1, wall=7523
2025-04-03 07:09:25 | INFO | train_inner | epoch 018:     78 / 126 loss=5.692, nll_loss=2.132, ppl=4.38, wps=1732.1, ups=0.34, wpb=5157, bsz=284, num_updates=2220, lr=2.664e-05, gnorm=1.311, train_wall=6, gb_free=13.2, wall=7529
2025-04-03 07:09:30 | INFO | train_inner | epoch 018:     80 / 126 loss=5.782, nll_loss=2.217, ppl=4.65, wps=1757.5, ups=0.38, wpb=4603.5, bsz=192, num_updates=2222, lr=2.6664e-05, gnorm=1.579, train_wall=5, gb_free=12.2, wall=7534
2025-04-03 07:09:36 | INFO | train_inner | epoch 018:     82 / 126 loss=5.792, nll_loss=2.254, ppl=4.77, wps=1717.6, ups=0.37, wpb=4627.5, bsz=284, num_updates=2224, lr=2.6688e-05, gnorm=1.579, train_wall=5, gb_free=10.5, wall=7540
2025-04-03 07:09:41 | INFO | train_inner | epoch 018:     84 / 126 loss=5.603, nll_loss=2.003, ppl=4.01, wps=1501.6, ups=0.38, wpb=3929, bsz=268, num_updates=2226, lr=2.6712e-05, gnorm=1.448, train_wall=5, gb_free=13.1, wall=7545
2025-04-03 07:09:46 | INFO | train_inner | epoch 018:     86 / 126 loss=5.656, nll_loss=2.072, ppl=4.2, wps=1739.4, ups=0.37, wpb=4662.5, bsz=280, num_updates=2228, lr=2.6736e-05, gnorm=1.465, train_wall=5, gb_free=13.3, wall=7550
2025-04-03 07:09:52 | INFO | train_inner | epoch 018:     88 / 126 loss=5.695, nll_loss=2.105, ppl=4.3, wps=1499.8, ups=0.34, wpb=4369.5, bsz=160, num_updates=2230, lr=2.676e-05, gnorm=1.598, train_wall=6, gb_free=9.3, wall=7556
2025-04-03 07:09:58 | INFO | train_inner | epoch 018:     90 / 126 loss=5.718, nll_loss=2.162, ppl=4.48, wps=1727.1, ups=0.34, wpb=5115, bsz=276, num_updates=2232, lr=2.6784e-05, gnorm=1.425, train_wall=6, gb_free=10.3, wall=7562
2025-04-03 07:10:03 | INFO | train_inner | epoch 018:     92 / 126 loss=5.658, nll_loss=2.08, ppl=4.23, wps=1556.8, ups=0.42, wpb=3663.5, bsz=196, num_updates=2234, lr=2.6808e-05, gnorm=1.509, train_wall=5, gb_free=13.7, wall=7567
2025-04-03 07:10:09 | INFO | train_inner | epoch 018:     94 / 126 loss=5.712, nll_loss=2.145, ppl=4.42, wps=1838, ups=0.33, wpb=5512, bsz=328, num_updates=2236, lr=2.6832e-05, gnorm=1.329, train_wall=6, gb_free=11.2, wall=7573
2025-04-03 07:10:14 | INFO | train_inner | epoch 018:     96 / 126 loss=5.671, nll_loss=2.084, ppl=4.24, wps=1719.1, ups=0.36, wpb=4762, bsz=268, num_updates=2238, lr=2.6856e-05, gnorm=1.397, train_wall=6, gb_free=13.1, wall=7578
2025-04-03 07:10:20 | INFO | train_inner | epoch 018:     98 / 126 loss=5.692, nll_loss=2.118, ppl=4.34, wps=1573.8, ups=0.33, wpb=4739, bsz=244, num_updates=2240, lr=2.688e-05, gnorm=1.408, train_wall=6, gb_free=9.2, wall=7584
2025-04-03 07:10:26 | INFO | train_inner | epoch 018:    100 / 126 loss=5.704, nll_loss=2.146, ppl=4.43, wps=1792.9, ups=0.36, wpb=5049.5, bsz=280, num_updates=2242, lr=2.6904e-05, gnorm=1.411, train_wall=6, gb_free=13.4, wall=7590
2025-04-03 07:10:31 | INFO | train_inner | epoch 018:    102 / 126 loss=5.659, nll_loss=2.092, ppl=4.26, wps=1484.2, ups=0.38, wpb=3926.5, bsz=232, num_updates=2244, lr=2.6928e-05, gnorm=1.512, train_wall=5, gb_free=14.6, wall=7595
2025-04-03 07:10:37 | INFO | train_inner | epoch 018:    104 / 126 loss=5.728, nll_loss=2.145, ppl=4.42, wps=1620.7, ups=0.35, wpb=4640.5, bsz=212, num_updates=2246, lr=2.6952e-05, gnorm=1.452, train_wall=6, gb_free=13.4, wall=7601
2025-04-03 07:10:43 | INFO | train_inner | epoch 018:    106 / 126 loss=5.744, nll_loss=2.164, ppl=4.48, wps=1607.1, ups=0.36, wpb=4470.5, bsz=232, num_updates=2248, lr=2.6976e-05, gnorm=1.436, train_wall=6, gb_free=14.6, wall=7607
2025-04-03 07:10:48 | INFO | train_inner | epoch 018:    108 / 126 loss=5.709, nll_loss=2.154, ppl=4.45, wps=1657.5, ups=0.39, wpb=4235.5, bsz=284, num_updates=2250, lr=2.7e-05, gnorm=1.462, train_wall=5, gb_free=13.2, wall=7612
2025-04-03 07:10:53 | INFO | train_inner | epoch 018:    110 / 126 loss=5.705, nll_loss=2.137, ppl=4.4, wps=1788.9, ups=0.37, wpb=4802, bsz=276, num_updates=2252, lr=2.7024e-05, gnorm=1.389, train_wall=5, gb_free=12, wall=7617
2025-04-03 07:10:59 | INFO | train_inner | epoch 018:    112 / 126 loss=5.729, nll_loss=2.158, ppl=4.46, wps=1787.6, ups=0.35, wpb=5051.5, bsz=244, num_updates=2254, lr=2.7048e-05, gnorm=1.374, train_wall=6, gb_free=11, wall=7623
2025-04-03 07:11:04 | INFO | train_inner | epoch 018:    114 / 126 loss=5.669, nll_loss=2.097, ppl=4.28, wps=1779.7, ups=0.37, wpb=4831, bsz=308, num_updates=2256, lr=2.7072e-05, gnorm=1.461, train_wall=5, gb_free=14.7, wall=7628
2025-04-03 07:11:10 | INFO | train_inner | epoch 018:    116 / 126 loss=5.634, nll_loss=2.069, ppl=4.2, wps=1761.7, ups=0.35, wpb=5052.5, bsz=396, num_updates=2258, lr=2.7096e-05, gnorm=1.314, train_wall=6, gb_free=10, wall=7634
2025-04-03 07:11:16 | INFO | train_inner | epoch 018:    118 / 126 loss=5.82, nll_loss=2.276, ppl=4.84, wps=1881.9, ups=0.35, wpb=5441.5, bsz=300, num_updates=2260, lr=2.712e-05, gnorm=1.424, train_wall=6, gb_free=14.2, wall=7640
2025-04-03 07:11:21 | INFO | train_inner | epoch 018:    120 / 126 loss=5.69, nll_loss=2.13, ppl=4.38, wps=1510.7, ups=0.35, wpb=4282.5, bsz=276, num_updates=2262, lr=2.7144e-05, gnorm=1.472, train_wall=6, gb_free=9.3, wall=7645
2025-04-03 07:11:27 | INFO | train_inner | epoch 018:    122 / 126 loss=5.654, nll_loss=2.058, ppl=4.16, wps=1649.7, ups=0.37, wpb=4435.5, bsz=220, num_updates=2264, lr=2.7168e-05, gnorm=1.375, train_wall=5, gb_free=14.1, wall=7651
2025-04-03 07:11:32 | INFO | train_inner | epoch 018:    124 / 126 loss=5.627, nll_loss=2.045, ppl=4.13, wps=1597.4, ups=0.38, wpb=4245.5, bsz=240, num_updates=2266, lr=2.7192e-05, gnorm=1.346, train_wall=5, gb_free=14.7, wall=7656
2025-04-03 07:11:36 | INFO | train_inner | epoch 018:    126 / 126 loss=5.69, nll_loss=2.121, ppl=4.35, wps=1631.3, ups=0.51, wpb=3175.5, bsz=180, num_updates=2268, lr=2.7216e-05, gnorm=1.689, train_wall=4, gb_free=17.4, wall=7660
2025-04-03 07:11:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-03 07:11:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=15972.19140625Mb; avail=239113.0Mb
2025-04-03 07:11:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000618
2025-04-03 07:11:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15972.19140625Mb; avail=239113.0Mb
2025-04-03 07:11:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012721
2025-04-03 07:11:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15972.19140625Mb; avail=239113.0Mb
2025-04-03 07:11:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.010803
2025-04-03 07:11:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024522
2025-04-03 07:11:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15972.19140625Mb; avail=239113.0Mb
2025-04-03 07:11:50 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 6.025 | nll_loss 2.347 | ppl 5.09 | wps 3864 | wpb 2070.5 | bsz 122.7 | num_updates 2268 | best_loss 6.025
2025-04-03 07:11:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2268 updates
2025-04-03 07:11:50 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 07:12:29 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 07:12:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt (epoch 18 @ 2268 updates, score 6.025) (writing took 63.663465643068776 seconds)
2025-04-03 07:12:54 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2025-04-03 07:12:54 | INFO | train | epoch 018 | loss 5.7 | nll_loss 2.129 | ppl 4.37 | wps 1329.8 | ups 0.29 | wpb 4549.7 | bsz 252.8 | num_updates 2268 | lr 2.7216e-05 | gnorm 1.468 | train_wall 352 | gb_free 17.4 | wall 7738
2025-04-03 07:12:54 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:mr-hi': 31849}; raw total size: 31849
2025-04-03 07:12:54 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:mr-hi': 31849}; resampled total size: 31849
2025-04-03 07:12:54 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:mr-hi': 1.0}
2025-04-03 07:12:54 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001096
2025-04-03 07:12:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=26767.94140625Mb; avail=228317.22265625Mb
2025-04-03 07:12:54 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000548
2025-04-03 07:12:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003827
2025-04-03 07:12:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26768.43359375Mb; avail=228316.73046875Mb
2025-04-03 07:12:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000118
2025-04-03 07:12:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26768.43359375Mb; avail=228316.73046875Mb
2025-04-03 07:12:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001139
2025-04-03 07:12:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.005408
2025-04-03 07:12:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26768.43359375Mb; avail=228316.73046875Mb
2025-04-03 07:12:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 126
2025-04-03 07:12:54 | INFO | fairseq.trainer | begin training epoch 19
2025-04-03 07:12:54 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-03 07:13:00 | INFO | train_inner | epoch 019:      2 / 126 loss=5.575, nll_loss=1.953, ppl=3.87, wps=113.5, ups=0.02, wpb=4749.5, bsz=184, num_updates=2270, lr=2.724e-05, gnorm=1.391, train_wall=6, gb_free=11.5, wall=7744
2025-04-03 07:13:05 | INFO | train_inner | epoch 019:      4 / 126 loss=5.684, nll_loss=2.101, ppl=4.29, wps=1659, ups=0.37, wpb=4465.5, bsz=240, num_updates=2272, lr=2.7264e-05, gnorm=1.527, train_wall=5, gb_free=11.1, wall=7749
2025-04-03 07:13:11 | INFO | train_inner | epoch 019:      6 / 126 loss=5.668, nll_loss=2.088, ppl=4.25, wps=1764.4, ups=0.36, wpb=4926.5, bsz=224, num_updates=2274, lr=2.7288e-05, gnorm=1.497, train_wall=6, gb_free=9.8, wall=7755
2025-04-03 07:13:16 | INFO | train_inner | epoch 019:      8 / 126 loss=5.603, nll_loss=2, ppl=4, wps=1536.9, ups=0.35, wpb=4339.5, bsz=184, num_updates=2276, lr=2.7312e-05, gnorm=1.516, train_wall=6, gb_free=10.1, wall=7760
2025-04-03 07:13:22 | INFO | train_inner | epoch 019:     10 / 126 loss=5.7, nll_loss=2.122, ppl=4.35, wps=1855.1, ups=0.37, wpb=5010, bsz=292, num_updates=2278, lr=2.7336e-05, gnorm=1.39, train_wall=5, gb_free=15.1, wall=7766
2025-04-03 07:13:27 | INFO | train_inner | epoch 019:     12 / 126 loss=5.662, nll_loss=2.072, ppl=4.21, wps=1544.3, ups=0.35, wpb=4391.5, bsz=196, num_updates=2280, lr=2.736e-05, gnorm=1.698, train_wall=6, gb_free=14.2, wall=7771
2025-04-03 07:13:33 | INFO | train_inner | epoch 019:     14 / 126 loss=5.669, nll_loss=2.084, ppl=4.24, wps=1709.3, ups=0.36, wpb=4700, bsz=188, num_updates=2282, lr=2.7384e-05, gnorm=1.514, train_wall=5, gb_free=12.3, wall=7777
2025-04-03 07:13:39 | INFO | train_inner | epoch 019:     16 / 126 loss=5.601, nll_loss=2.001, ppl=4, wps=1822.1, ups=0.34, wpb=5434, bsz=360, num_updates=2284, lr=2.7408e-05, gnorm=1.245, train_wall=6, gb_free=9.8, wall=7783
2025-04-03 07:13:44 | INFO | train_inner | epoch 019:     18 / 126 loss=5.644, nll_loss=2.052, ppl=4.15, wps=1519.4, ups=0.37, wpb=4053, bsz=252, num_updates=2286, lr=2.7432e-05, gnorm=1.481, train_wall=5, gb_free=13, wall=7788
2025-04-03 07:13:50 | INFO | train_inner | epoch 019:     20 / 126 loss=5.587, nll_loss=1.981, ppl=3.95, wps=1397.8, ups=0.36, wpb=3870.5, bsz=224, num_updates=2288, lr=2.7456e-05, gnorm=1.558, train_wall=6, gb_free=11.6, wall=7794
2025-04-03 07:13:55 | INFO | train_inner | epoch 019:     22 / 126 loss=5.585, nll_loss=1.992, ppl=3.98, wps=1872.4, ups=0.36, wpb=5265, bsz=312, num_updates=2290, lr=2.748e-05, gnorm=1.338, train_wall=6, gb_free=8.6, wall=7799
2025-04-03 07:14:01 | INFO | train_inner | epoch 019:     24 / 126 loss=5.622, nll_loss=2.021, ppl=4.06, wps=1640.1, ups=0.35, wpb=4729, bsz=268, num_updates=2292, lr=2.7504e-05, gnorm=1.354, train_wall=6, gb_free=12.3, wall=7805
2025-04-03 07:14:07 | INFO | train_inner | epoch 019:     26 / 126 loss=5.554, nll_loss=1.95, ppl=3.86, wps=1467.2, ups=0.36, wpb=4026, bsz=324, num_updates=2294, lr=2.7528e-05, gnorm=1.386, train_wall=5, gb_free=13.9, wall=7811
2025-04-03 07:14:13 | INFO | train_inner | epoch 019:     28 / 126 loss=5.639, nll_loss=2.047, ppl=4.13, wps=1628.1, ups=0.33, wpb=4896, bsz=232, num_updates=2296, lr=2.7552e-05, gnorm=1.378, train_wall=6, gb_free=10.9, wall=7817
2025-04-03 07:14:18 | INFO | train_inner | epoch 019:     30 / 126 loss=5.504, nll_loss=1.904, ppl=3.74, wps=1568.2, ups=0.34, wpb=4606.5, bsz=272, num_updates=2298, lr=2.7576e-05, gnorm=1.344, train_wall=6, gb_free=9.5, wall=7823
2025-04-03 07:14:25 | INFO | train_inner | epoch 019:     32 / 126 loss=5.683, nll_loss=2.105, ppl=4.3, wps=1546, ups=0.33, wpb=4704.5, bsz=196, num_updates=2300, lr=2.76e-05, gnorm=1.417, train_wall=6, gb_free=9.8, wall=7829
2025-04-03 07:14:30 | INFO | train_inner | epoch 019:     34 / 126 loss=5.543, nll_loss=1.946, ppl=3.85, wps=1606.8, ups=0.37, wpb=4401, bsz=340, num_updates=2302, lr=2.7624e-05, gnorm=1.357, train_wall=5, gb_free=12.8, wall=7834
2025-04-03 07:14:36 | INFO | train_inner | epoch 019:     36 / 126 loss=5.686, nll_loss=2.097, ppl=4.28, wps=1765.5, ups=0.36, wpb=4948, bsz=208, num_updates=2304, lr=2.7648e-05, gnorm=1.449, train_wall=6, gb_free=11.3, wall=7840
2025-04-03 07:14:41 | INFO | train_inner | epoch 019:     38 / 126 loss=5.617, nll_loss=1.991, ppl=3.98, wps=1667.8, ups=0.34, wpb=4842.5, bsz=232, num_updates=2306, lr=2.7672e-05, gnorm=1.309, train_wall=6, gb_free=11.7, wall=7846
2025-04-03 07:14:47 | INFO | train_inner | epoch 019:     40 / 126 loss=5.81, nll_loss=2.277, ppl=4.85, wps=1798.8, ups=0.36, wpb=4951.5, bsz=296, num_updates=2308, lr=2.7696e-05, gnorm=1.51, train_wall=5, gb_free=14, wall=7851
2025-04-03 07:14:53 | INFO | train_inner | epoch 019:     42 / 126 loss=5.717, nll_loss=2.154, ppl=4.45, wps=1753.3, ups=0.33, wpb=5359.5, bsz=284, num_updates=2310, lr=2.772e-05, gnorm=1.402, train_wall=6, gb_free=9.6, wall=7857
2025-04-03 07:14:59 | INFO | train_inner | epoch 019:     44 / 126 loss=5.652, nll_loss=2.071, ppl=4.2, wps=1374.7, ups=0.35, wpb=3939, bsz=184, num_updates=2312, lr=2.7744e-05, gnorm=1.612, train_wall=6, gb_free=10.2, wall=7863
2025-04-03 07:15:04 | INFO | train_inner | epoch 019:     46 / 126 loss=5.547, nll_loss=1.94, ppl=3.84, wps=1653.8, ups=0.39, wpb=4207.5, bsz=284, num_updates=2314, lr=2.7768e-05, gnorm=1.546, train_wall=5, gb_free=14.3, wall=7868
2025-04-03 07:15:10 | INFO | train_inner | epoch 019:     48 / 126 loss=5.517, nll_loss=1.863, ppl=3.64, wps=1510.8, ups=0.34, wpb=4473.5, bsz=172, num_updates=2316, lr=2.7792e-05, gnorm=1.383, train_wall=6, gb_free=8.9, wall=7874
2025-04-03 07:15:15 | INFO | train_inner | epoch 019:     50 / 126 loss=5.654, nll_loss=2.067, ppl=4.19, wps=1761.6, ups=0.37, wpb=4701.5, bsz=260, num_updates=2318, lr=2.7816e-05, gnorm=1.435, train_wall=5, gb_free=14.4, wall=7879
2025-04-03 07:15:21 | INFO | train_inner | epoch 019:     52 / 126 loss=5.632, nll_loss=2.039, ppl=4.11, wps=1658.8, ups=0.36, wpb=4626.5, bsz=248, num_updates=2320, lr=2.784e-05, gnorm=1.491, train_wall=6, gb_free=12.7, wall=7885
2025-04-03 07:15:26 | INFO | train_inner | epoch 019:     54 / 126 loss=5.66, nll_loss=2.1, ppl=4.29, wps=1465, ups=0.35, wpb=4237, bsz=244, num_updates=2322, lr=2.7864e-05, gnorm=1.448, train_wall=6, gb_free=10.8, wall=7891
2025-04-03 07:15:32 | INFO | train_inner | epoch 019:     56 / 126 loss=5.649, nll_loss=2.064, ppl=4.18, wps=1759.1, ups=0.36, wpb=4851.5, bsz=288, num_updates=2324, lr=2.7888e-05, gnorm=1.33, train_wall=6, gb_free=14.7, wall=7896
2025-04-03 07:15:42 | INFO | train_inner | epoch 019:     58 / 126 loss=5.568, nll_loss=1.961, ppl=3.89, wps=855.3, ups=0.19, wpb=4397.5, bsz=284, num_updates=2326, lr=2.7912e-05, gnorm=1.475, train_wall=10, gb_free=11.8, wall=7906
2025-04-03 07:15:47 | INFO | train_inner | epoch 019:     60 / 126 loss=5.498, nll_loss=1.875, ppl=3.67, wps=1697.6, ups=0.43, wpb=3912, bsz=236.5, num_updates=2328, lr=2.7936e-05, gnorm=1.414, train_wall=5, gb_free=13.8, wall=7911
2025-04-03 07:15:52 | INFO | train_inner | epoch 019:     62 / 126 loss=5.582, nll_loss=1.988, ppl=3.97, wps=1582, ups=0.4, wpb=3991, bsz=272, num_updates=2330, lr=2.796e-05, gnorm=1.557, train_wall=5, gb_free=13.5, wall=7916
2025-04-03 07:15:57 | INFO | train_inner | epoch 019:     64 / 126 loss=5.577, nll_loss=1.98, ppl=3.95, wps=1751.8, ups=0.37, wpb=4794, bsz=308, num_updates=2332, lr=2.7984e-05, gnorm=1.346, train_wall=5, gb_free=13.8, wall=7922
2025-04-03 07:16:03 | INFO | train_inner | epoch 019:     66 / 126 loss=5.738, nll_loss=2.173, ppl=4.51, wps=1585.5, ups=0.35, wpb=4481, bsz=168, num_updates=2334, lr=2.8008e-05, gnorm=1.586, train_wall=6, gb_free=14.4, wall=7927
2025-04-03 07:16:09 | INFO | train_inner | epoch 019:     68 / 126 loss=5.651, nll_loss=2.069, ppl=4.2, wps=1632.4, ups=0.36, wpb=4528.5, bsz=288, num_updates=2336, lr=2.8032e-05, gnorm=1.538, train_wall=6, gb_free=9.5, wall=7933
2025-04-03 07:16:14 | INFO | train_inner | epoch 019:     70 / 126 loss=5.735, nll_loss=2.183, ppl=4.54, wps=1520.5, ups=0.37, wpb=4086.5, bsz=276, num_updates=2338, lr=2.8056e-05, gnorm=1.617, train_wall=5, gb_free=12.5, wall=7938
2025-04-03 07:16:20 | INFO | train_inner | epoch 019:     72 / 126 loss=5.608, nll_loss=2.016, ppl=4.04, wps=1529.2, ups=0.35, wpb=4411.5, bsz=288, num_updates=2340, lr=2.808e-05, gnorm=1.508, train_wall=6, gb_free=12.6, wall=7944
2025-04-03 07:16:25 | INFO | train_inner | epoch 019:     74 / 126 loss=5.571, nll_loss=1.97, ppl=3.92, wps=1620.7, ups=0.37, wpb=4396.5, bsz=316, num_updates=2342, lr=2.8104e-05, gnorm=1.373, train_wall=5, gb_free=11.9, wall=7949
2025-04-03 07:16:31 | INFO | train_inner | epoch 019:     76 / 126 loss=5.546, nll_loss=1.917, ppl=3.78, wps=1561.9, ups=0.36, wpb=4378.5, bsz=160, num_updates=2344, lr=2.8128e-05, gnorm=1.411, train_wall=6, gb_free=10.4, wall=7955
2025-04-03 07:16:36 | INFO | train_inner | epoch 019:     78 / 126 loss=5.549, nll_loss=1.931, ppl=3.81, wps=1664.5, ups=0.36, wpb=4633, bsz=212, num_updates=2346, lr=2.8152e-05, gnorm=1.389, train_wall=6, gb_free=12, wall=7960
2025-04-03 07:16:42 | INFO | train_inner | epoch 019:     80 / 126 loss=5.613, nll_loss=2.036, ppl=4.1, wps=1714.1, ups=0.37, wpb=4600, bsz=280, num_updates=2348, lr=2.8176e-05, gnorm=1.331, train_wall=5, gb_free=13.6, wall=7966
2025-04-03 07:16:47 | INFO | train_inner | epoch 019:     82 / 126 loss=5.572, nll_loss=1.979, ppl=3.94, wps=1694.3, ups=0.39, wpb=4367.5, bsz=296, num_updates=2350, lr=2.82e-05, gnorm=1.383, train_wall=5, gb_free=14.4, wall=7971
2025-04-03 07:16:52 | INFO | train_inner | epoch 019:     84 / 126 loss=5.554, nll_loss=1.962, ppl=3.9, wps=1472.1, ups=0.39, wpb=3758, bsz=288, num_updates=2352, lr=2.8224e-05, gnorm=1.461, train_wall=5, gb_free=11.6, wall=7976
2025-04-03 07:16:57 | INFO | train_inner | epoch 019:     86 / 126 loss=5.55, nll_loss=1.952, ppl=3.87, wps=1737.4, ups=0.37, wpb=4641.5, bsz=348, num_updates=2354, lr=2.8248e-05, gnorm=1.261, train_wall=5, gb_free=14.5, wall=7981
2025-04-03 07:17:03 | INFO | train_inner | epoch 019:     88 / 126 loss=5.627, nll_loss=2.047, ppl=4.13, wps=1660.7, ups=0.36, wpb=4653.5, bsz=344, num_updates=2356, lr=2.8272e-05, gnorm=1.405, train_wall=6, gb_free=11.2, wall=7987
2025-04-03 07:17:08 | INFO | train_inner | epoch 019:     90 / 126 loss=5.643, nll_loss=2.053, ppl=4.15, wps=1774.4, ups=0.36, wpb=4918, bsz=288, num_updates=2358, lr=2.8296e-05, gnorm=1.354, train_wall=6, gb_free=13.5, wall=7993
2025-04-03 07:17:14 | INFO | train_inner | epoch 019:     92 / 126 loss=5.68, nll_loss=2.099, ppl=4.28, wps=1689.7, ups=0.34, wpb=5041.5, bsz=236, num_updates=2360, lr=2.832e-05, gnorm=1.388, train_wall=6, gb_free=10, wall=7999
2025-04-03 07:17:20 | INFO | train_inner | epoch 019:     94 / 126 loss=5.61, nll_loss=2.013, ppl=4.04, wps=1745.8, ups=0.35, wpb=4977, bsz=276, num_updates=2362, lr=2.8344e-05, gnorm=1.336, train_wall=6, gb_free=12.6, wall=8004
2025-04-03 07:17:26 | INFO | train_inner | epoch 019:     96 / 126 loss=5.592, nll_loss=2.001, ppl=4, wps=1822.8, ups=0.36, wpb=5098, bsz=324, num_updates=2364, lr=2.8368e-05, gnorm=1.276, train_wall=6, gb_free=10.9, wall=8010
2025-04-03 07:17:32 | INFO | train_inner | epoch 019:     98 / 126 loss=5.57, nll_loss=1.964, ppl=3.9, wps=1572.9, ups=0.34, wpb=4597, bsz=208, num_updates=2366, lr=2.8392e-05, gnorm=1.337, train_wall=6, gb_free=13.1, wall=8016
2025-04-03 07:17:37 | INFO | train_inner | epoch 019:    100 / 126 loss=5.689, nll_loss=2.108, ppl=4.31, wps=1427, ups=0.34, wpb=4189.5, bsz=160, num_updates=2368, lr=2.8416e-05, gnorm=1.419, train_wall=6, gb_free=10, wall=8022
2025-04-03 07:17:43 | INFO | train_inner | epoch 019:    102 / 126 loss=5.642, nll_loss=2.058, ppl=4.16, wps=1740.6, ups=0.34, wpb=5144.5, bsz=328, num_updates=2370, lr=2.844e-05, gnorm=1.397, train_wall=6, gb_free=10.1, wall=8027
2025-04-03 07:17:49 | INFO | train_inner | epoch 019:    104 / 126 loss=5.601, nll_loss=1.988, ppl=3.97, wps=1552.9, ups=0.34, wpb=4543.5, bsz=164, num_updates=2372, lr=2.8464e-05, gnorm=1.404, train_wall=6, gb_free=10.2, wall=8033
2025-04-03 07:17:54 | INFO | train_inner | epoch 019:    106 / 126 loss=5.573, nll_loss=1.975, ppl=3.93, wps=1649.4, ups=0.42, wpb=3937.5, bsz=204, num_updates=2374, lr=2.8488e-05, gnorm=1.539, train_wall=5, gb_free=14, wall=8038
2025-04-03 07:18:00 | INFO | train_inner | epoch 019:    108 / 126 loss=5.631, nll_loss=2.053, ppl=4.15, wps=1634.8, ups=0.36, wpb=4604, bsz=224, num_updates=2376, lr=2.8512e-05, gnorm=1.462, train_wall=6, gb_free=9.2, wall=8044
2025-04-03 07:18:05 | INFO | train_inner | epoch 019:    110 / 126 loss=5.602, nll_loss=1.99, ppl=3.97, wps=1487.9, ups=0.36, wpb=4173, bsz=196, num_updates=2378, lr=2.8536e-05, gnorm=1.516, train_wall=6, gb_free=13.4, wall=8049
2025-04-03 07:18:11 | INFO | train_inner | epoch 019:    112 / 126 loss=5.742, nll_loss=2.161, ppl=4.47, wps=1639.1, ups=0.35, wpb=4736.5, bsz=232, num_updates=2380, lr=2.856e-05, gnorm=1.476, train_wall=6, gb_free=9.9, wall=8055
2025-04-03 07:18:16 | INFO | train_inner | epoch 019:    114 / 126 loss=5.557, nll_loss=1.95, ppl=3.86, wps=1432.8, ups=0.37, wpb=3870, bsz=232, num_updates=2382, lr=2.8584e-05, gnorm=1.457, train_wall=5, gb_free=12, wall=8061
2025-04-03 07:18:22 | INFO | train_inner | epoch 019:    116 / 126 loss=5.671, nll_loss=2.098, ppl=4.28, wps=1849.5, ups=0.34, wpb=5381, bsz=276, num_updates=2384, lr=2.8608e-05, gnorm=1.365, train_wall=6, gb_free=11.6, wall=8066
2025-04-03 07:18:28 | INFO | train_inner | epoch 019:    118 / 126 loss=5.494, nll_loss=1.879, ppl=3.68, wps=1704.9, ups=0.38, wpb=4526.5, bsz=308, num_updates=2386, lr=2.8632e-05, gnorm=1.613, train_wall=5, gb_free=12.5, wall=8072
2025-04-03 07:18:33 | INFO | train_inner | epoch 019:    120 / 126 loss=5.606, nll_loss=2.02, ppl=4.06, wps=1719.7, ups=0.35, wpb=4967, bsz=356, num_updates=2388, lr=2.8656e-05, gnorm=1.469, train_wall=6, gb_free=12, wall=8077
2025-04-03 07:18:39 | INFO | train_inner | epoch 019:    122 / 126 loss=5.673, nll_loss=2.082, ppl=4.24, wps=1717.3, ups=0.38, wpb=4548.5, bsz=224, num_updates=2390, lr=2.868e-05, gnorm=1.561, train_wall=5, gb_free=11, wall=8083
2025-04-03 07:18:44 | INFO | train_inner | epoch 019:    124 / 126 loss=5.584, nll_loss=1.961, ppl=3.89, wps=1580.2, ups=0.38, wpb=4178.5, bsz=108, num_updates=2392, lr=2.8704e-05, gnorm=1.597, train_wall=5, gb_free=14.7, wall=8088
2025-04-03 07:18:48 | INFO | train_inner | epoch 019:    126 / 126 loss=5.695, nll_loss=2.13, ppl=4.38, wps=1726.8, ups=0.5, wpb=3463.5, bsz=228, num_updates=2394, lr=2.8728e-05, gnorm=1.66, train_wall=4, gb_free=16.8, wall=8092
2025-04-03 07:18:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-03 07:18:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=15988.47265625Mb; avail=239096.73046875Mb
2025-04-03 07:18:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000642
2025-04-03 07:18:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15988.47265625Mb; avail=239096.73046875Mb
2025-04-03 07:18:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012932
2025-04-03 07:18:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15988.47265625Mb; avail=239096.73046875Mb
2025-04-03 07:18:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.010914
2025-04-03 07:18:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024859
2025-04-03 07:18:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15988.47265625Mb; avail=239096.73046875Mb
2025-04-03 07:19:02 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 5.982 | nll_loss 2.321 | ppl 5 | wps 3864.1 | wpb 2070.5 | bsz 122.7 | num_updates 2394 | best_loss 5.982
2025-04-03 07:19:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2394 updates
2025-04-03 07:19:02 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 07:19:40 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 07:20:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt (epoch 19 @ 2394 updates, score 5.982) (writing took 62.708715569926426 seconds)
2025-04-03 07:20:05 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2025-04-03 07:20:05 | INFO | train | epoch 019 | loss 5.621 | nll_loss 2.029 | ppl 4.08 | wps 1329.9 | ups 0.29 | wpb 4549.7 | bsz 252.8 | num_updates 2394 | lr 2.8728e-05 | gnorm 1.444 | train_wall 353 | gb_free 16.8 | wall 8169
2025-04-03 07:20:05 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:mr-hi': 31849}; raw total size: 31849
2025-04-03 07:20:05 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:mr-hi': 31849}; resampled total size: 31849
2025-04-03 07:20:05 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:mr-hi': 1.0}
2025-04-03 07:20:05 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001159
2025-04-03 07:20:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=26776.32421875Mb; avail=228308.796875Mb
2025-04-03 07:20:05 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000592
2025-04-03 07:20:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003714
2025-04-03 07:20:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26776.81640625Mb; avail=228308.3046875Mb
2025-04-03 07:20:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000093
2025-04-03 07:20:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26776.81640625Mb; avail=228308.3046875Mb
2025-04-03 07:20:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001356
2025-04-03 07:20:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.005512
2025-04-03 07:20:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26776.81640625Mb; avail=228308.3046875Mb
2025-04-03 07:20:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 126
2025-04-03 07:20:05 | INFO | fairseq.trainer | begin training epoch 20
2025-04-03 07:20:05 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-03 07:20:10 | INFO | train_inner | epoch 020:      2 / 126 loss=5.513, nll_loss=1.908, ppl=3.75, wps=109.3, ups=0.02, wpb=4505, bsz=260, num_updates=2396, lr=2.8752e-05, gnorm=1.452, train_wall=5, gb_free=12.8, wall=8174
2025-04-03 07:20:16 | INFO | train_inner | epoch 020:      4 / 126 loss=5.729, nll_loss=2.181, ppl=4.54, wps=1952, ups=0.36, wpb=5452.5, bsz=316, num_updates=2398, lr=2.8776e-05, gnorm=1.344, train_wall=6, gb_free=11.3, wall=8180
2025-04-03 07:20:21 | INFO | train_inner | epoch 020:      6 / 126 loss=5.55, nll_loss=1.931, ppl=3.81, wps=1735.3, ups=0.36, wpb=4832, bsz=204, num_updates=2400, lr=2.88e-05, gnorm=1.345, train_wall=6, gb_free=13.7, wall=8186
2025-04-03 07:20:27 | INFO | train_inner | epoch 020:      8 / 126 loss=5.548, nll_loss=1.923, ppl=3.79, wps=1828.9, ups=0.37, wpb=5001.5, bsz=268, num_updates=2402, lr=2.8824e-05, gnorm=1.412, train_wall=5, gb_free=11.4, wall=8191
2025-04-03 07:20:33 | INFO | train_inner | epoch 020:     10 / 126 loss=5.655, nll_loss=2.048, ppl=4.14, wps=1612.1, ups=0.34, wpb=4725, bsz=200, num_updates=2404, lr=2.8848e-05, gnorm=1.626, train_wall=6, gb_free=10.3, wall=8197
2025-04-03 07:20:38 | INFO | train_inner | epoch 020:     12 / 126 loss=5.56, nll_loss=1.938, ppl=3.83, wps=1574.8, ups=0.36, wpb=4353, bsz=164, num_updates=2406, lr=2.8872e-05, gnorm=1.473, train_wall=6, gb_free=8.7, wall=8202
2025-04-03 07:20:44 | INFO | train_inner | epoch 020:     14 / 126 loss=5.559, nll_loss=1.945, ppl=3.85, wps=1659.3, ups=0.38, wpb=4358, bsz=204, num_updates=2408, lr=2.8896e-05, gnorm=1.51, train_wall=5, gb_free=11.7, wall=8208
2025-04-03 07:20:49 | INFO | train_inner | epoch 020:     16 / 126 loss=5.527, nll_loss=1.908, ppl=3.75, wps=1620.1, ups=0.34, wpb=4707, bsz=192, num_updates=2410, lr=2.892e-05, gnorm=1.33, train_wall=6, gb_free=11.3, wall=8214
2025-04-03 07:20:55 | INFO | train_inner | epoch 020:     18 / 126 loss=5.533, nll_loss=1.924, ppl=3.79, wps=1793.1, ups=0.35, wpb=5076, bsz=284, num_updates=2412, lr=2.8944e-05, gnorm=1.343, train_wall=6, gb_free=13.3, wall=8219
2025-04-03 07:21:01 | INFO | train_inner | epoch 020:     20 / 126 loss=5.535, nll_loss=1.91, ppl=3.76, wps=1387.5, ups=0.35, wpb=3957.5, bsz=160, num_updates=2414, lr=2.8968e-05, gnorm=1.499, train_wall=6, gb_free=10.5, wall=8225
2025-04-03 07:21:06 | INFO | train_inner | epoch 020:     22 / 126 loss=5.597, nll_loss=1.992, ppl=3.98, wps=1757, ups=0.36, wpb=4936.5, bsz=240, num_updates=2416, lr=2.8992e-05, gnorm=1.333, train_wall=6, gb_free=12, wall=8231
2025-04-03 07:21:12 | INFO | train_inner | epoch 020:     24 / 126 loss=5.534, nll_loss=1.93, ppl=3.81, wps=1407.1, ups=0.36, wpb=3942.5, bsz=264, num_updates=2418, lr=2.9016e-05, gnorm=1.443, train_wall=6, gb_free=11, wall=8236
2025-04-03 07:21:18 | INFO | train_inner | epoch 020:     26 / 126 loss=5.579, nll_loss=1.97, ppl=3.92, wps=1606.8, ups=0.35, wpb=4564, bsz=260, num_updates=2420, lr=2.904e-05, gnorm=1.353, train_wall=6, gb_free=13.1, wall=8242
2025-04-03 07:21:24 | INFO | train_inner | epoch 020:     28 / 126 loss=5.626, nll_loss=2.024, ppl=4.07, wps=1426.9, ups=0.34, wpb=4172, bsz=184, num_updates=2422, lr=2.9064e-05, gnorm=1.493, train_wall=6, gb_free=8.7, wall=8248
2025-04-03 07:21:29 | INFO | train_inner | epoch 020:     30 / 126 loss=5.573, nll_loss=1.977, ppl=3.94, wps=1894.4, ups=0.35, wpb=5391, bsz=372, num_updates=2424, lr=2.9088e-05, gnorm=1.235, train_wall=6, gb_free=10.6, wall=8253
2025-04-03 07:21:35 | INFO | train_inner | epoch 020:     32 / 126 loss=5.454, nll_loss=1.84, ppl=3.58, wps=1510.1, ups=0.37, wpb=4101, bsz=272, num_updates=2426, lr=2.9112e-05, gnorm=1.531, train_wall=5, gb_free=13.9, wall=8259
2025-04-03 07:21:40 | INFO | train_inner | epoch 020:     34 / 126 loss=5.535, nll_loss=1.915, ppl=3.77, wps=1451.2, ups=0.37, wpb=3911.5, bsz=248, num_updates=2428, lr=2.9136e-05, gnorm=1.526, train_wall=5, gb_free=12.3, wall=8264
2025-04-03 07:21:46 | INFO | train_inner | epoch 020:     36 / 126 loss=5.513, nll_loss=1.872, ppl=3.66, wps=1497.3, ups=0.36, wpb=4165, bsz=192, num_updates=2430, lr=2.916e-05, gnorm=1.607, train_wall=6, gb_free=13.3, wall=8270
2025-04-03 07:21:51 | INFO | train_inner | epoch 020:     38 / 126 loss=5.569, nll_loss=1.963, ppl=3.9, wps=1688.8, ups=0.35, wpb=4872, bsz=292, num_updates=2432, lr=2.9184e-05, gnorm=1.428, train_wall=6, gb_free=11.2, wall=8275
2025-04-03 07:21:57 | INFO | train_inner | epoch 020:     40 / 126 loss=5.54, nll_loss=1.932, ppl=3.82, wps=1499.1, ups=0.38, wpb=3928, bsz=248, num_updates=2434, lr=2.9208e-05, gnorm=1.501, train_wall=5, gb_free=14.3, wall=8281
2025-04-03 07:22:02 | INFO | train_inner | epoch 020:     42 / 126 loss=5.528, nll_loss=1.908, ppl=3.75, wps=1802.2, ups=0.35, wpb=5189.5, bsz=284, num_updates=2436, lr=2.9232e-05, gnorm=1.369, train_wall=6, gb_free=13, wall=8286
2025-04-03 07:22:08 | INFO | train_inner | epoch 020:     44 / 126 loss=5.597, nll_loss=1.99, ppl=3.97, wps=1433.4, ups=0.33, wpb=4293, bsz=176, num_updates=2438, lr=2.9256e-05, gnorm=1.418, train_wall=6, gb_free=9, wall=8292
2025-04-03 07:22:14 | INFO | train_inner | epoch 020:     46 / 126 loss=5.502, nll_loss=1.872, ppl=3.66, wps=1603, ups=0.34, wpb=4679, bsz=260, num_updates=2440, lr=2.928e-05, gnorm=1.301, train_wall=6, gb_free=13.1, wall=8298
2025-04-03 07:22:19 | INFO | train_inner | epoch 020:     48 / 126 loss=5.482, nll_loss=1.851, ppl=3.61, wps=1489.2, ups=0.38, wpb=3898.5, bsz=228, num_updates=2442, lr=2.9304e-05, gnorm=1.38, train_wall=5, gb_free=14, wall=8304
2025-04-03 07:22:25 | INFO | train_inner | epoch 020:     50 / 126 loss=5.519, nll_loss=1.91, ppl=3.76, wps=1694.7, ups=0.37, wpb=4526, bsz=264, num_updates=2444, lr=2.9328e-05, gnorm=1.402, train_wall=5, gb_free=11.8, wall=8309
2025-04-03 07:22:30 | INFO | train_inner | epoch 020:     52 / 126 loss=5.509, nll_loss=1.895, ppl=3.72, wps=1681.5, ups=0.36, wpb=4692.5, bsz=276, num_updates=2446, lr=2.9352e-05, gnorm=1.353, train_wall=6, gb_free=10.7, wall=8314
2025-04-03 07:22:36 | INFO | train_inner | epoch 020:     54 / 126 loss=5.544, nll_loss=1.908, ppl=3.75, wps=1615, ups=0.38, wpb=4280.5, bsz=216, num_updates=2448, lr=2.9376e-05, gnorm=1.457, train_wall=5, gb_free=14.3, wall=8320
2025-04-03 07:22:41 | INFO | train_inner | epoch 020:     56 / 126 loss=5.631, nll_loss=2.034, ppl=4.1, wps=1377.9, ups=0.35, wpb=3935.5, bsz=284, num_updates=2450, lr=2.94e-05, gnorm=1.603, train_wall=6, gb_free=11.1, wall=8325
2025-04-03 07:22:47 | INFO | train_inner | epoch 020:     58 / 126 loss=5.513, nll_loss=1.888, ppl=3.7, wps=1633.5, ups=0.36, wpb=4546.5, bsz=260, num_updates=2452, lr=2.9424e-05, gnorm=1.398, train_wall=6, gb_free=14.3, wall=8331
2025-04-03 07:22:53 | INFO | train_inner | epoch 020:     60 / 126 loss=5.602, nll_loss=2.002, ppl=4, wps=1684, ups=0.36, wpb=4700, bsz=232, num_updates=2454, lr=2.9448e-05, gnorm=1.428, train_wall=6, gb_free=14.4, wall=8337
2025-04-03 07:22:58 | INFO | train_inner | epoch 020:     62 / 126 loss=5.56, nll_loss=1.965, ppl=3.9, wps=1555.8, ups=0.37, wpb=4152.5, bsz=164, num_updates=2456, lr=2.9472e-05, gnorm=1.455, train_wall=5, gb_free=12.9, wall=8342
2025-04-03 07:23:03 | INFO | train_inner | epoch 020:     64 / 126 loss=5.524, nll_loss=1.9, ppl=3.73, wps=1768.5, ups=0.36, wpb=4870, bsz=328, num_updates=2458, lr=2.9496e-05, gnorm=1.316, train_wall=5, gb_free=12.8, wall=8347
2025-04-03 07:23:09 | INFO | train_inner | epoch 020:     66 / 126 loss=5.467, nll_loss=1.842, ppl=3.58, wps=1577.4, ups=0.37, wpb=4320, bsz=340, num_updates=2460, lr=2.952e-05, gnorm=1.319, train_wall=5, gb_free=9.9, wall=8353
2025-04-03 07:23:14 | INFO | train_inner | epoch 020:     68 / 126 loss=5.521, nll_loss=1.894, ppl=3.72, wps=1612.7, ups=0.37, wpb=4381, bsz=236, num_updates=2462, lr=2.9544e-05, gnorm=1.45, train_wall=5, gb_free=12.6, wall=8358
2025-04-03 07:23:20 | INFO | train_inner | epoch 020:     70 / 126 loss=5.633, nll_loss=2.05, ppl=4.14, wps=1409.8, ups=0.36, wpb=3921.5, bsz=192, num_updates=2464, lr=2.9568e-05, gnorm=1.577, train_wall=6, gb_free=9.7, wall=8364
2025-04-03 07:23:26 | INFO | train_inner | epoch 020:     72 / 126 loss=5.547, nll_loss=1.951, ppl=3.87, wps=1659.4, ups=0.35, wpb=4734, bsz=220, num_updates=2466, lr=2.9592e-05, gnorm=1.444, train_wall=6, gb_free=13.1, wall=8370
2025-04-03 07:23:31 | INFO | train_inner | epoch 020:     74 / 126 loss=5.406, nll_loss=1.777, ppl=3.43, wps=1464.5, ups=0.36, wpb=4014, bsz=320, num_updates=2468, lr=2.9616e-05, gnorm=1.421, train_wall=5, gb_free=12.6, wall=8375
2025-04-03 07:23:36 | INFO | train_inner | epoch 020:     76 / 126 loss=5.81, nll_loss=2.255, ppl=4.77, wps=1743.1, ups=0.44, wpb=3941.5, bsz=196.5, num_updates=2470, lr=2.964e-05, gnorm=2.033, train_wall=5, gb_free=10.5, wall=8380
2025-04-03 07:23:41 | INFO | train_inner | epoch 020:     78 / 126 loss=5.516, nll_loss=1.859, ppl=3.63, wps=1800.5, ups=0.37, wpb=4804.5, bsz=316, num_updates=2472, lr=2.9664e-05, gnorm=1.413, train_wall=5, gb_free=13.7, wall=8385
2025-04-03 07:23:47 | INFO | train_inner | epoch 020:     80 / 126 loss=5.512, nll_loss=1.865, ppl=3.64, wps=1754.4, ups=0.35, wpb=5033, bsz=252, num_updates=2474, lr=2.9688e-05, gnorm=1.3, train_wall=6, gb_free=11.6, wall=8391
2025-04-03 07:23:52 | INFO | train_inner | epoch 020:     82 / 126 loss=5.567, nll_loss=1.985, ppl=3.96, wps=1898.9, ups=0.36, wpb=5237.5, bsz=348, num_updates=2476, lr=2.9712e-05, gnorm=1.274, train_wall=6, gb_free=12.3, wall=8396
2025-04-03 07:23:58 | INFO | train_inner | epoch 020:     84 / 126 loss=5.583, nll_loss=2.006, ppl=4.02, wps=1675.3, ups=0.36, wpb=4694.5, bsz=240, num_updates=2478, lr=2.9736e-05, gnorm=1.368, train_wall=6, gb_free=10.9, wall=8402
2025-04-03 07:24:03 | INFO | train_inner | epoch 020:     86 / 126 loss=5.536, nll_loss=1.931, ppl=3.81, wps=1839.8, ups=0.38, wpb=4901.5, bsz=300, num_updates=2480, lr=2.976e-05, gnorm=1.46, train_wall=5, gb_free=13.3, wall=8407
2025-04-03 07:24:09 | INFO | train_inner | epoch 020:     88 / 126 loss=5.669, nll_loss=2.074, ppl=4.21, wps=1513.8, ups=0.37, wpb=4095, bsz=188, num_updates=2482, lr=2.9784e-05, gnorm=1.558, train_wall=5, gb_free=11.9, wall=8413
2025-04-03 07:24:14 | INFO | train_inner | epoch 020:     90 / 126 loss=5.486, nll_loss=1.827, ppl=3.55, wps=1803.9, ups=0.35, wpb=5141.5, bsz=328, num_updates=2484, lr=2.9808e-05, gnorm=1.36, train_wall=6, gb_free=10.3, wall=8418
2025-04-03 07:24:20 | INFO | train_inner | epoch 020:     92 / 126 loss=5.596, nll_loss=1.997, ppl=3.99, wps=1755.2, ups=0.36, wpb=4883, bsz=356, num_updates=2486, lr=2.9832e-05, gnorm=1.342, train_wall=6, gb_free=11.6, wall=8424
2025-04-03 07:24:25 | INFO | train_inner | epoch 020:     94 / 126 loss=5.578, nll_loss=1.983, ppl=3.95, wps=1614.9, ups=0.36, wpb=4438.5, bsz=252, num_updates=2488, lr=2.9856e-05, gnorm=1.375, train_wall=5, gb_free=10.7, wall=8429
2025-04-03 07:24:31 | INFO | train_inner | epoch 020:     96 / 126 loss=5.544, nll_loss=1.961, ppl=3.89, wps=1394.3, ups=0.36, wpb=3894.5, bsz=248, num_updates=2490, lr=2.988e-05, gnorm=1.467, train_wall=6, gb_free=9.6, wall=8435
2025-04-03 07:24:41 | INFO | train_inner | epoch 020:     98 / 126 loss=5.491, nll_loss=1.885, ppl=3.69, wps=940.3, ups=0.19, wpb=4975, bsz=324, num_updates=2492, lr=2.9904e-05, gnorm=1.269, train_wall=11, gb_free=13.1, wall=8446
2025-04-03 07:24:47 | INFO | train_inner | epoch 020:    100 / 126 loss=5.53, nll_loss=1.895, ppl=3.72, wps=1557.3, ups=0.34, wpb=4615, bsz=212, num_updates=2494, lr=2.9928e-05, gnorm=1.354, train_wall=6, gb_free=11.4, wall=8451
2025-04-03 07:24:53 | INFO | train_inner | epoch 020:    102 / 126 loss=5.514, nll_loss=1.884, ppl=3.69, wps=1720.9, ups=0.37, wpb=4647, bsz=292, num_updates=2496, lr=2.9952e-05, gnorm=1.365, train_wall=5, gb_free=12, wall=8457
2025-04-03 07:24:58 | INFO | train_inner | epoch 020:    104 / 126 loss=5.487, nll_loss=1.85, ppl=3.61, wps=1514.7, ups=0.37, wpb=4125.5, bsz=192, num_updates=2498, lr=2.9976e-05, gnorm=1.421, train_wall=5, gb_free=12.6, wall=8462
2025-04-03 07:25:04 | INFO | train_inner | epoch 020:    106 / 126 loss=5.507, nll_loss=1.903, ppl=3.74, wps=1486, ups=0.36, wpb=4166.5, bsz=236, num_updates=2500, lr=3e-05, gnorm=1.387, train_wall=6, gb_free=9.8, wall=8468
2025-04-03 07:25:09 | INFO | train_inner | epoch 020:    108 / 126 loss=5.654, nll_loss=2.077, ppl=4.22, wps=1834.3, ups=0.37, wpb=4945.5, bsz=224, num_updates=2502, lr=2.9988e-05, gnorm=1.673, train_wall=5, gb_free=9.6, wall=8473
2025-04-03 07:25:14 | INFO | train_inner | epoch 020:    110 / 126 loss=5.579, nll_loss=1.97, ppl=3.92, wps=1601.2, ups=0.39, wpb=4149, bsz=244, num_updates=2504, lr=2.9976e-05, gnorm=1.452, train_wall=5, gb_free=15.2, wall=8478
2025-04-03 07:25:20 | INFO | train_inner | epoch 020:    112 / 126 loss=5.533, nll_loss=1.896, ppl=3.72, wps=1684.8, ups=0.37, wpb=4582, bsz=220, num_updates=2506, lr=2.99641e-05, gnorm=1.345, train_wall=5, gb_free=12.2, wall=8484
2025-04-03 07:25:26 | INFO | train_inner | epoch 020:    114 / 126 loss=5.645, nll_loss=2.035, ppl=4.1, wps=1575.4, ups=0.35, wpb=4537, bsz=184, num_updates=2508, lr=2.99521e-05, gnorm=1.411, train_wall=6, gb_free=10.7, wall=8490
2025-04-03 07:25:31 | INFO | train_inner | epoch 020:    116 / 126 loss=5.559, nll_loss=1.963, ppl=3.9, wps=1862.1, ups=0.39, wpb=4746.5, bsz=292, num_updates=2510, lr=2.99402e-05, gnorm=1.431, train_wall=5, gb_free=11.4, wall=8495
2025-04-03 07:25:36 | INFO | train_inner | epoch 020:    118 / 126 loss=5.6, nll_loss=2.033, ppl=4.09, wps=1716.6, ups=0.37, wpb=4690.5, bsz=292, num_updates=2512, lr=2.99283e-05, gnorm=1.518, train_wall=5, gb_free=13.1, wall=8500
2025-04-03 07:25:42 | INFO | train_inner | epoch 020:    120 / 126 loss=5.665, nll_loss=2.082, ppl=4.23, wps=1674, ups=0.33, wpb=5026, bsz=240, num_updates=2514, lr=2.99164e-05, gnorm=1.466, train_wall=6, gb_free=10.8, wall=8506
2025-04-03 07:25:48 | INFO | train_inner | epoch 020:    122 / 126 loss=5.571, nll_loss=1.955, ppl=3.88, wps=1862.7, ups=0.35, wpb=5309, bsz=352, num_updates=2516, lr=2.99045e-05, gnorm=1.247, train_wall=6, gb_free=9.5, wall=8512
2025-04-03 07:25:54 | INFO | train_inner | epoch 020:    124 / 126 loss=5.656, nll_loss=2.046, ppl=4.13, wps=1829.8, ups=0.34, wpb=5377, bsz=272, num_updates=2518, lr=2.98926e-05, gnorm=1.407, train_wall=6, gb_free=13.2, wall=8518
2025-04-03 07:25:58 | INFO | train_inner | epoch 020:    126 / 126 loss=5.582, nll_loss=1.992, ppl=3.98, wps=1780.4, ups=0.5, wpb=3590, bsz=220, num_updates=2520, lr=2.98807e-05, gnorm=1.671, train_wall=4, gb_free=18, wall=8522
2025-04-03 07:25:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-03 07:25:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=15974.62890625Mb; avail=239110.56640625Mb
2025-04-03 07:25:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000636
2025-04-03 07:25:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15974.62890625Mb; avail=239110.56640625Mb
2025-04-03 07:25:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012907
2025-04-03 07:25:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15974.62890625Mb; avail=239110.56640625Mb
2025-04-03 07:25:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.010885
2025-04-03 07:25:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024791
2025-04-03 07:25:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15974.62890625Mb; avail=239110.56640625Mb
2025-04-03 07:26:12 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 5.958 | nll_loss 2.288 | ppl 4.88 | wps 3863.2 | wpb 2070.5 | bsz 122.7 | num_updates 2520 | best_loss 5.958
2025-04-03 07:26:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 2520 updates
2025-04-03 07:26:12 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 07:26:51 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 07:27:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt (epoch 20 @ 2520 updates, score 5.958) (writing took 63.8138142839307 seconds)
2025-04-03 07:27:16 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2025-04-03 07:27:16 | INFO | train | epoch 020 | loss 5.561 | nll_loss 1.951 | ppl 3.87 | wps 1330.2 | ups 0.29 | wpb 4549.7 | bsz 252.8 | num_updates 2520 | lr 2.98807e-05 | gnorm 1.432 | train_wall 352 | gb_free 18 | wall 8600
2025-04-03 07:27:16 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:mr-hi': 31849}; raw total size: 31849
2025-04-03 07:27:16 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:mr-hi': 31849}; resampled total size: 31849
2025-04-03 07:27:16 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:mr-hi': 1.0}
2025-04-03 07:27:16 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001060
2025-04-03 07:27:16 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=26794.01171875Mb; avail=228291.19140625Mb
2025-04-03 07:27:16 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000525
2025-04-03 07:27:16 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003463
2025-04-03 07:27:16 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26794.50390625Mb; avail=228290.69921875Mb
2025-04-03 07:27:16 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000087
2025-04-03 07:27:16 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26794.50390625Mb; avail=228290.69921875Mb
2025-04-03 07:27:16 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001139
2025-04-03 07:27:16 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.005006
2025-04-03 07:27:16 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26794.50390625Mb; avail=228290.69921875Mb
2025-04-03 07:27:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 126
2025-04-03 07:27:16 | INFO | fairseq.trainer | begin training epoch 21
2025-04-03 07:27:16 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-03 07:27:21 | INFO | train_inner | epoch 021:      2 / 126 loss=5.458, nll_loss=1.841, ppl=3.58, wps=111.6, ups=0.02, wpb=4667.5, bsz=284, num_updates=2522, lr=2.98689e-05, gnorm=1.322, train_wall=5, gb_free=12.6, wall=8606
2025-04-03 07:27:27 | INFO | train_inner | epoch 021:      4 / 126 loss=5.424, nll_loss=1.782, ppl=3.44, wps=1840.9, ups=0.36, wpb=5048.5, bsz=368, num_updates=2524, lr=2.9857e-05, gnorm=1.222, train_wall=5, gb_free=12.5, wall=8611
2025-04-03 07:27:32 | INFO | train_inner | epoch 021:      6 / 126 loss=5.511, nll_loss=1.878, ppl=3.68, wps=1776.7, ups=0.37, wpb=4810.5, bsz=268, num_updates=2526, lr=2.98452e-05, gnorm=1.378, train_wall=5, gb_free=14.3, wall=8616
2025-04-03 07:27:38 | INFO | train_inner | epoch 021:      8 / 126 loss=5.56, nll_loss=1.944, ppl=3.85, wps=1752.1, ups=0.35, wpb=5006.5, bsz=244, num_updates=2528, lr=2.98334e-05, gnorm=1.415, train_wall=6, gb_free=13.7, wall=8622
2025-04-03 07:27:44 | INFO | train_inner | epoch 021:     10 / 126 loss=5.418, nll_loss=1.78, ppl=3.43, wps=1715.9, ups=0.36, wpb=4767.5, bsz=308, num_updates=2530, lr=2.98216e-05, gnorm=1.284, train_wall=6, gb_free=10, wall=8628
2025-04-03 07:27:49 | INFO | train_inner | epoch 021:     12 / 126 loss=5.545, nll_loss=1.931, ppl=3.81, wps=1608.3, ups=0.36, wpb=4429.5, bsz=212, num_updates=2532, lr=2.98098e-05, gnorm=1.5, train_wall=5, gb_free=11, wall=8633
2025-04-03 07:27:55 | INFO | train_inner | epoch 021:     14 / 126 loss=5.489, nll_loss=1.855, ppl=3.62, wps=1718.3, ups=0.36, wpb=4802.5, bsz=224, num_updates=2534, lr=2.97981e-05, gnorm=1.432, train_wall=6, gb_free=13.2, wall=8639
2025-04-03 07:28:00 | INFO | train_inner | epoch 021:     16 / 126 loss=5.476, nll_loss=1.808, ppl=3.5, wps=1561.3, ups=0.37, wpb=4251, bsz=136, num_updates=2536, lr=2.97863e-05, gnorm=1.459, train_wall=5, gb_free=14.4, wall=8644
2025-04-03 07:28:06 | INFO | train_inner | epoch 021:     18 / 126 loss=5.462, nll_loss=1.829, ppl=3.55, wps=1462.7, ups=0.37, wpb=4005, bsz=192, num_updates=2538, lr=2.97746e-05, gnorm=1.437, train_wall=5, gb_free=12.2, wall=8650
2025-04-03 07:28:11 | INFO | train_inner | epoch 021:     20 / 126 loss=5.501, nll_loss=1.882, ppl=3.69, wps=1711.5, ups=0.37, wpb=4679, bsz=252, num_updates=2540, lr=2.97628e-05, gnorm=1.289, train_wall=5, gb_free=13.7, wall=8655
2025-04-03 07:28:17 | INFO | train_inner | epoch 021:     22 / 126 loss=5.461, nll_loss=1.834, ppl=3.57, wps=1655, ups=0.36, wpb=4639.5, bsz=332, num_updates=2542, lr=2.97511e-05, gnorm=1.275, train_wall=6, gb_free=10.3, wall=8661
2025-04-03 07:28:23 | INFO | train_inner | epoch 021:     24 / 126 loss=5.573, nll_loss=1.965, ppl=3.9, wps=1499.2, ups=0.32, wpb=4646, bsz=224, num_updates=2544, lr=2.97394e-05, gnorm=1.393, train_wall=6, gb_free=9, wall=8667
2025-04-03 07:28:28 | INFO | train_inner | epoch 021:     26 / 126 loss=5.496, nll_loss=1.874, ppl=3.67, wps=1816.8, ups=0.36, wpb=4988, bsz=264, num_updates=2546, lr=2.97278e-05, gnorm=1.403, train_wall=5, gb_free=12.5, wall=8673
2025-04-03 07:28:34 | INFO | train_inner | epoch 021:     28 / 126 loss=5.468, nll_loss=1.829, ppl=3.55, wps=1702.8, ups=0.33, wpb=5148.5, bsz=288, num_updates=2548, lr=2.97161e-05, gnorm=1.3, train_wall=6, gb_free=8.4, wall=8679
2025-04-03 07:28:40 | INFO | train_inner | epoch 021:     30 / 126 loss=5.616, nll_loss=2.015, ppl=4.04, wps=1656.2, ups=0.34, wpb=4934, bsz=204, num_updates=2550, lr=2.97044e-05, gnorm=1.364, train_wall=6, gb_free=8.9, wall=8685
2025-04-03 07:28:46 | INFO | train_inner | epoch 021:     32 / 126 loss=5.473, nll_loss=1.827, ppl=3.55, wps=1757.2, ups=0.35, wpb=5031.5, bsz=264, num_updates=2552, lr=2.96928e-05, gnorm=1.305, train_wall=6, gb_free=14, wall=8690
2025-04-03 07:28:52 | INFO | train_inner | epoch 021:     34 / 126 loss=5.486, nll_loss=1.859, ppl=3.63, wps=1615.8, ups=0.36, wpb=4431.5, bsz=244, num_updates=2554, lr=2.96812e-05, gnorm=1.442, train_wall=5, gb_free=10.2, wall=8696
2025-04-03 07:29:02 | INFO | train_inner | epoch 021:     36 / 126 loss=5.42, nll_loss=1.766, ppl=3.4, wps=819.4, ups=0.2, wpb=4177, bsz=188, num_updates=2556, lr=2.96695e-05, gnorm=1.552, train_wall=10, gb_free=12, wall=8706
2025-04-03 07:29:07 | INFO | train_inner | epoch 021:     38 / 126 loss=5.403, nll_loss=1.736, ppl=3.33, wps=1797.9, ups=0.36, wpb=5019, bsz=264, num_updates=2558, lr=2.96579e-05, gnorm=1.365, train_wall=6, gb_free=13.4, wall=8712
2025-04-03 07:29:13 | INFO | train_inner | epoch 021:     40 / 126 loss=5.556, nll_loss=1.949, ppl=3.86, wps=1661.6, ups=0.34, wpb=4881.5, bsz=276, num_updates=2560, lr=2.96464e-05, gnorm=1.412, train_wall=6, gb_free=8.9, wall=8717
2025-04-03 07:29:19 | INFO | train_inner | epoch 021:     42 / 126 loss=5.455, nll_loss=1.826, ppl=3.55, wps=1671.1, ups=0.37, wpb=4574, bsz=260, num_updates=2562, lr=2.96348e-05, gnorm=1.387, train_wall=5, gb_free=14.3, wall=8723
2025-04-03 07:29:24 | INFO | train_inner | epoch 021:     44 / 126 loss=5.392, nll_loss=1.748, ppl=3.36, wps=1611.2, ups=0.38, wpb=4236, bsz=308, num_updates=2564, lr=2.96232e-05, gnorm=1.303, train_wall=5, gb_free=13.9, wall=8728
2025-04-03 07:29:30 | INFO | train_inner | epoch 021:     46 / 126 loss=5.701, nll_loss=2.122, ppl=4.35, wps=1622.5, ups=0.35, wpb=4595.5, bsz=216, num_updates=2566, lr=2.96117e-05, gnorm=1.59, train_wall=6, gb_free=13.8, wall=8734
2025-04-03 07:29:35 | INFO | train_inner | epoch 021:     48 / 126 loss=5.399, nll_loss=1.749, ppl=3.36, wps=1467.9, ups=0.37, wpb=4006, bsz=240, num_updates=2568, lr=2.96001e-05, gnorm=1.423, train_wall=5, gb_free=13, wall=8739
2025-04-03 07:29:41 | INFO | train_inner | epoch 021:     50 / 126 loss=5.444, nll_loss=1.79, ppl=3.46, wps=1622.2, ups=0.34, wpb=4713.5, bsz=240, num_updates=2570, lr=2.95886e-05, gnorm=1.241, train_wall=6, gb_free=9.3, wall=8745
2025-04-03 07:29:46 | INFO | train_inner | epoch 021:     52 / 126 loss=5.596, nll_loss=1.991, ppl=3.97, wps=1439.4, ups=0.37, wpb=3924, bsz=132, num_updates=2572, lr=2.95771e-05, gnorm=1.648, train_wall=5, gb_free=14.5, wall=8751
2025-04-03 07:29:52 | INFO | train_inner | epoch 021:     54 / 126 loss=5.476, nll_loss=1.868, ppl=3.65, wps=1650.9, ups=0.37, wpb=4458, bsz=312, num_updates=2574, lr=2.95656e-05, gnorm=1.337, train_wall=5, gb_free=13.9, wall=8756
2025-04-03 07:29:57 | INFO | train_inner | epoch 021:     56 / 126 loss=5.344, nll_loss=1.689, ppl=3.22, wps=1485.8, ups=0.4, wpb=3743.5, bsz=284, num_updates=2576, lr=2.95541e-05, gnorm=1.417, train_wall=5, gb_free=14.4, wall=8761
2025-04-03 07:30:03 | INFO | train_inner | epoch 021:     58 / 126 loss=5.523, nll_loss=1.9, ppl=3.73, wps=1541.1, ups=0.35, wpb=4362, bsz=224, num_updates=2578, lr=2.95427e-05, gnorm=1.532, train_wall=6, gb_free=10.3, wall=8767
2025-04-03 07:30:08 | INFO | train_inner | epoch 021:     60 / 126 loss=5.437, nll_loss=1.787, ppl=3.45, wps=1635.8, ups=0.37, wpb=4452.5, bsz=244, num_updates=2580, lr=2.95312e-05, gnorm=1.448, train_wall=5, gb_free=11, wall=8772
2025-04-03 07:30:13 | INFO | train_inner | epoch 021:     62 / 126 loss=5.514, nll_loss=1.866, ppl=3.65, wps=1664.3, ups=0.36, wpb=4573, bsz=132, num_updates=2582, lr=2.95198e-05, gnorm=1.353, train_wall=5, gb_free=11.8, wall=8778
2025-04-03 07:30:19 | INFO | train_inner | epoch 021:     64 / 126 loss=5.447, nll_loss=1.806, ppl=3.5, wps=1779.2, ups=0.35, wpb=5134, bsz=260, num_updates=2584, lr=2.95084e-05, gnorm=1.389, train_wall=6, gb_free=11.5, wall=8783
2025-04-03 07:30:25 | INFO | train_inner | epoch 021:     66 / 126 loss=5.51, nll_loss=1.92, ppl=3.78, wps=1642.2, ups=0.35, wpb=4651.5, bsz=352, num_updates=2586, lr=2.94969e-05, gnorm=1.497, train_wall=6, gb_free=10, wall=8789
2025-04-03 07:30:30 | INFO | train_inner | epoch 021:     68 / 126 loss=5.314, nll_loss=1.638, ppl=3.11, wps=1391.9, ups=0.38, wpb=3674.5, bsz=272, num_updates=2588, lr=2.94855e-05, gnorm=1.497, train_wall=5, gb_free=13.3, wall=8794
2025-04-03 07:30:36 | INFO | train_inner | epoch 021:     70 / 126 loss=5.505, nll_loss=1.865, ppl=3.64, wps=1579.5, ups=0.37, wpb=4274.5, bsz=212, num_updates=2590, lr=2.94742e-05, gnorm=1.517, train_wall=5, gb_free=12, wall=8800
2025-04-03 07:30:41 | INFO | train_inner | epoch 021:     72 / 126 loss=5.486, nll_loss=1.86, ppl=3.63, wps=1646.8, ups=0.35, wpb=4730.5, bsz=312, num_updates=2592, lr=2.94628e-05, gnorm=1.416, train_wall=6, gb_free=12.2, wall=8805
2025-04-03 07:30:47 | INFO | train_inner | epoch 021:     74 / 126 loss=5.587, nll_loss=1.982, ppl=3.95, wps=1558.3, ups=0.36, wpb=4361.5, bsz=192, num_updates=2594, lr=2.94514e-05, gnorm=1.484, train_wall=6, gb_free=11.1, wall=8811
2025-04-03 07:30:52 | INFO | train_inner | epoch 021:     76 / 126 loss=5.524, nll_loss=1.931, ppl=3.81, wps=1648.1, ups=0.37, wpb=4430.5, bsz=276, num_updates=2596, lr=2.94401e-05, gnorm=1.569, train_wall=5, gb_free=13.5, wall=8816
2025-04-03 07:30:57 | INFO | train_inner | epoch 021:     78 / 126 loss=5.411, nll_loss=1.778, ppl=3.43, wps=1629.1, ups=0.39, wpb=4168.5, bsz=296, num_updates=2598, lr=2.94287e-05, gnorm=1.434, train_wall=5, gb_free=14.1, wall=8822
2025-04-03 07:31:03 | INFO | train_inner | epoch 021:     80 / 126 loss=5.461, nll_loss=1.808, ppl=3.5, wps=1580.4, ups=0.36, wpb=4391, bsz=188, num_updates=2600, lr=2.94174e-05, gnorm=1.648, train_wall=6, gb_free=12, wall=8827
2025-04-03 07:31:08 | INFO | train_inner | epoch 021:     82 / 126 loss=5.549, nll_loss=1.909, ppl=3.76, wps=1505.6, ups=0.43, wpb=3461.5, bsz=140.5, num_updates=2602, lr=2.94061e-05, gnorm=1.61, train_wall=5, gb_free=13.1, wall=8832
2025-04-03 07:31:13 | INFO | train_inner | epoch 021:     84 / 126 loss=5.504, nll_loss=1.876, ppl=3.67, wps=1735.8, ups=0.35, wpb=4903.5, bsz=264, num_updates=2604, lr=2.93948e-05, gnorm=1.385, train_wall=6, gb_free=14.4, wall=8837
2025-04-03 07:31:19 | INFO | train_inner | epoch 021:     86 / 126 loss=5.538, nll_loss=1.944, ppl=3.85, wps=1606.1, ups=0.33, wpb=4795, bsz=276, num_updates=2606, lr=2.93835e-05, gnorm=1.329, train_wall=6, gb_free=13.3, wall=8843
2025-04-03 07:31:25 | INFO | train_inner | epoch 021:     88 / 126 loss=5.576, nll_loss=1.988, ppl=3.97, wps=1574.9, ups=0.34, wpb=4671.5, bsz=300, num_updates=2608, lr=2.93723e-05, gnorm=1.437, train_wall=6, gb_free=14.1, wall=8849
2025-04-03 07:31:30 | INFO | train_inner | epoch 021:     90 / 126 loss=5.421, nll_loss=1.77, ppl=3.41, wps=1604.7, ups=0.41, wpb=3901.5, bsz=248, num_updates=2610, lr=2.9361e-05, gnorm=1.54, train_wall=5, gb_free=12.4, wall=8854
2025-04-03 07:31:36 | INFO | train_inner | epoch 021:     92 / 126 loss=5.459, nll_loss=1.812, ppl=3.51, wps=1761.7, ups=0.36, wpb=4901.5, bsz=296, num_updates=2612, lr=2.93498e-05, gnorm=1.284, train_wall=6, gb_free=13.3, wall=8860
2025-04-03 07:31:41 | INFO | train_inner | epoch 021:     94 / 126 loss=5.593, nll_loss=1.987, ppl=3.96, wps=1638.1, ups=0.36, wpb=4575.5, bsz=192, num_updates=2614, lr=2.93385e-05, gnorm=1.394, train_wall=6, gb_free=10.9, wall=8865
2025-04-03 07:31:47 | INFO | train_inner | epoch 021:     96 / 126 loss=5.386, nll_loss=1.73, ppl=3.32, wps=1710.4, ups=0.36, wpb=4790, bsz=360, num_updates=2616, lr=2.93273e-05, gnorm=1.228, train_wall=6, gb_free=11.4, wall=8871
2025-04-03 07:31:52 | INFO | train_inner | epoch 021:     98 / 126 loss=5.475, nll_loss=1.847, ppl=3.6, wps=1837.4, ups=0.36, wpb=5047, bsz=304, num_updates=2618, lr=2.93161e-05, gnorm=1.346, train_wall=5, gb_free=13, wall=8876
2025-04-03 07:31:58 | INFO | train_inner | epoch 021:    100 / 126 loss=5.555, nll_loss=1.956, ppl=3.88, wps=1785.3, ups=0.38, wpb=4717, bsz=288, num_updates=2620, lr=2.93049e-05, gnorm=1.494, train_wall=5, gb_free=14.2, wall=8882
2025-04-03 07:32:04 | INFO | train_inner | epoch 021:    102 / 126 loss=5.493, nll_loss=1.855, ppl=3.62, wps=1673.5, ups=0.33, wpb=5078, bsz=232, num_updates=2622, lr=2.92937e-05, gnorm=1.306, train_wall=6, gb_free=12.4, wall=8888
2025-04-03 07:32:09 | INFO | train_inner | epoch 021:    104 / 126 loss=5.511, nll_loss=1.897, ppl=3.73, wps=1634.6, ups=0.35, wpb=4722.5, bsz=276, num_updates=2624, lr=2.92826e-05, gnorm=1.317, train_wall=6, gb_free=12.4, wall=8893
2025-04-03 07:32:15 | INFO | train_inner | epoch 021:    106 / 126 loss=5.479, nll_loss=1.842, ppl=3.59, wps=1665.9, ups=0.35, wpb=4781, bsz=224, num_updates=2626, lr=2.92714e-05, gnorm=1.341, train_wall=6, gb_free=8.6, wall=8899
2025-04-03 07:32:21 | INFO | train_inner | epoch 021:    108 / 126 loss=5.577, nll_loss=1.982, ppl=3.95, wps=1746.4, ups=0.36, wpb=4889, bsz=256, num_updates=2628, lr=2.92603e-05, gnorm=1.314, train_wall=6, gb_free=11.4, wall=8905
2025-04-03 07:32:26 | INFO | train_inner | epoch 021:    110 / 126 loss=5.462, nll_loss=1.836, ppl=3.57, wps=1439.6, ups=0.35, wpb=4093, bsz=208, num_updates=2630, lr=2.92492e-05, gnorm=1.501, train_wall=6, gb_free=12.7, wall=8910
2025-04-03 07:32:32 | INFO | train_inner | epoch 021:    112 / 126 loss=5.535, nll_loss=1.915, ppl=3.77, wps=1671, ups=0.35, wpb=4829, bsz=232, num_updates=2632, lr=2.9238e-05, gnorm=1.392, train_wall=6, gb_free=12.5, wall=8916
2025-04-03 07:32:38 | INFO | train_inner | epoch 021:    114 / 126 loss=5.523, nll_loss=1.901, ppl=3.74, wps=1686.1, ups=0.37, wpb=4592.5, bsz=312, num_updates=2634, lr=2.92269e-05, gnorm=1.341, train_wall=5, gb_free=9.5, wall=8922
2025-04-03 07:32:43 | INFO | train_inner | epoch 021:    116 / 126 loss=5.473, nll_loss=1.845, ppl=3.59, wps=1640.3, ups=0.36, wpb=4561, bsz=308, num_updates=2636, lr=2.92159e-05, gnorm=1.346, train_wall=6, gb_free=11.5, wall=8927
2025-04-03 07:32:49 | INFO | train_inner | epoch 021:    118 / 126 loss=5.363, nll_loss=1.704, ppl=3.26, wps=1509.3, ups=0.37, wpb=4061.5, bsz=252, num_updates=2638, lr=2.92048e-05, gnorm=1.324, train_wall=5, gb_free=10.7, wall=8933
2025-04-03 07:32:54 | INFO | train_inner | epoch 021:    120 / 126 loss=5.513, nll_loss=1.921, ppl=3.79, wps=1774.2, ups=0.35, wpb=5004, bsz=320, num_updates=2640, lr=2.91937e-05, gnorm=1.279, train_wall=6, gb_free=10.9, wall=8938
2025-04-03 07:33:00 | INFO | train_inner | epoch 021:    122 / 126 loss=5.506, nll_loss=1.89, ppl=3.71, wps=1598.7, ups=0.37, wpb=4296.5, bsz=196, num_updates=2642, lr=2.91827e-05, gnorm=1.392, train_wall=5, gb_free=10.3, wall=8944
2025-04-03 07:33:05 | INFO | train_inner | epoch 021:    124 / 126 loss=5.575, nll_loss=1.949, ppl=3.86, wps=1709, ups=0.35, wpb=4855, bsz=220, num_updates=2644, lr=2.91716e-05, gnorm=1.35, train_wall=6, gb_free=12.8, wall=8949
2025-04-03 07:33:10 | INFO | train_inner | epoch 021:    126 / 126 loss=5.462, nll_loss=1.823, ppl=3.54, wps=1532.8, ups=0.47, wpb=3286, bsz=232, num_updates=2646, lr=2.91606e-05, gnorm=1.948, train_wall=4, gb_free=14.1, wall=8954
2025-04-03 07:33:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-03 07:33:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=15980.6015625Mb; avail=239104.56640625Mb
2025-04-03 07:33:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000633
2025-04-03 07:33:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15980.6015625Mb; avail=239104.56640625Mb
2025-04-03 07:33:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012840
2025-04-03 07:33:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15980.6015625Mb; avail=239104.56640625Mb
2025-04-03 07:33:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.010917
2025-04-03 07:33:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024738
2025-04-03 07:33:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15980.6015625Mb; avail=239104.56640625Mb
2025-04-03 07:33:24 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 5.944 | nll_loss 2.25 | ppl 4.76 | wps 3863.4 | wpb 2070.5 | bsz 122.7 | num_updates 2646 | best_loss 5.944
2025-04-03 07:33:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 2646 updates
2025-04-03 07:33:24 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 07:34:02 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 07:34:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt (epoch 21 @ 2646 updates, score 5.944) (writing took 62.42295157595072 seconds)
2025-04-03 07:34:26 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2025-04-03 07:34:26 | INFO | train | epoch 021 | loss 5.491 | nll_loss 1.864 | ppl 3.64 | wps 1332 | ups 0.29 | wpb 4549.7 | bsz 252.8 | num_updates 2646 | lr 2.91606e-05 | gnorm 1.411 | train_wall 353 | gb_free 14.1 | wall 9030
2025-04-03 07:34:26 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:mr-hi': 31849}; raw total size: 31849
2025-04-03 07:34:26 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:mr-hi': 31849}; resampled total size: 31849
2025-04-03 07:34:26 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:mr-hi': 1.0}
2025-04-03 07:34:26 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001148
2025-04-03 07:34:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=26790.578125Mb; avail=228294.5546875Mb
2025-04-03 07:34:26 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000635
2025-04-03 07:34:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003862
2025-04-03 07:34:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26791.0703125Mb; avail=228294.0625Mb
2025-04-03 07:34:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000122
2025-04-03 07:34:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26791.0703125Mb; avail=228294.0625Mb
2025-04-03 07:34:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001152
2025-04-03 07:34:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.005458
2025-04-03 07:34:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26791.0703125Mb; avail=228294.0625Mb
2025-04-03 07:34:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 126
2025-04-03 07:34:26 | INFO | fairseq.trainer | begin training epoch 22
2025-04-03 07:34:26 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-03 07:34:32 | INFO | train_inner | epoch 022:      2 / 126 loss=5.383, nll_loss=1.726, ppl=3.31, wps=99.8, ups=0.02, wpb=4100.5, bsz=188, num_updates=2648, lr=2.91496e-05, gnorm=1.368, train_wall=5, gb_free=14, wall=9036
2025-04-03 07:34:37 | INFO | train_inner | epoch 022:      4 / 126 loss=5.382, nll_loss=1.731, ppl=3.32, wps=1654.4, ups=0.36, wpb=4623.5, bsz=212, num_updates=2650, lr=2.91386e-05, gnorm=1.254, train_wall=6, gb_free=12, wall=9041
2025-04-03 07:34:43 | INFO | train_inner | epoch 022:      6 / 126 loss=5.37, nll_loss=1.704, ppl=3.26, wps=1658.3, ups=0.34, wpb=4843, bsz=148, num_updates=2652, lr=2.91276e-05, gnorm=1.293, train_wall=6, gb_free=10.1, wall=9047
2025-04-03 07:34:49 | INFO | train_inner | epoch 022:      8 / 126 loss=5.426, nll_loss=1.78, ppl=3.43, wps=1727.1, ups=0.37, wpb=4662.5, bsz=252, num_updates=2654, lr=2.91166e-05, gnorm=1.383, train_wall=5, gb_free=13.2, wall=9053
2025-04-03 07:34:54 | INFO | train_inner | epoch 022:     10 / 126 loss=5.259, nll_loss=1.59, ppl=3.01, wps=1391, ups=0.37, wpb=3725, bsz=336, num_updates=2656, lr=2.91056e-05, gnorm=1.278, train_wall=5, gb_free=12.8, wall=9058
2025-04-03 07:34:59 | INFO | train_inner | epoch 022:     12 / 126 loss=5.398, nll_loss=1.73, ppl=3.32, wps=1725.4, ups=0.37, wpb=4717.5, bsz=232, num_updates=2658, lr=2.90947e-05, gnorm=1.324, train_wall=5, gb_free=12.1, wall=9063
2025-04-03 07:35:05 | INFO | train_inner | epoch 022:     14 / 126 loss=5.376, nll_loss=1.709, ppl=3.27, wps=1630.2, ups=0.34, wpb=4777, bsz=284, num_updates=2660, lr=2.90838e-05, gnorm=1.213, train_wall=6, gb_free=10.1, wall=9069
2025-04-03 07:35:11 | INFO | train_inner | epoch 022:     16 / 126 loss=5.474, nll_loss=1.842, ppl=3.58, wps=1708.3, ups=0.33, wpb=5107, bsz=280, num_updates=2662, lr=2.90728e-05, gnorm=1.379, train_wall=6, gb_free=10, wall=9075
2025-04-03 07:35:17 | INFO | train_inner | epoch 022:     18 / 126 loss=5.452, nll_loss=1.826, ppl=3.55, wps=1506.3, ups=0.36, wpb=4204.5, bsz=192, num_updates=2664, lr=2.90619e-05, gnorm=1.384, train_wall=6, gb_free=11.3, wall=9081
2025-04-03 07:35:23 | INFO | train_inner | epoch 022:     20 / 126 loss=5.379, nll_loss=1.711, ppl=3.27, wps=1678.1, ups=0.34, wpb=4925, bsz=292, num_updates=2666, lr=2.9051e-05, gnorm=1.182, train_wall=6, gb_free=11.7, wall=9087
2025-04-03 07:35:28 | INFO | train_inner | epoch 022:     22 / 126 loss=5.47, nll_loss=1.818, ppl=3.53, wps=1646.3, ups=0.37, wpb=4396, bsz=220, num_updates=2668, lr=2.90401e-05, gnorm=1.387, train_wall=5, gb_free=13.6, wall=9092
2025-04-03 07:35:33 | INFO | train_inner | epoch 022:     24 / 126 loss=5.264, nll_loss=1.563, ppl=2.96, wps=1657, ups=0.39, wpb=4255, bsz=276, num_updates=2670, lr=2.90292e-05, gnorm=1.284, train_wall=5, gb_free=13.3, wall=9097
2025-04-03 07:35:39 | INFO | train_inner | epoch 022:     26 / 126 loss=5.495, nll_loss=1.87, ppl=3.66, wps=1722.5, ups=0.33, wpb=5253.5, bsz=324, num_updates=2672, lr=2.90184e-05, gnorm=1.286, train_wall=6, gb_free=9.2, wall=9103
2025-04-03 07:35:45 | INFO | train_inner | epoch 022:     28 / 126 loss=5.317, nll_loss=1.669, ppl=3.18, wps=1486, ups=0.37, wpb=4025.5, bsz=260, num_updates=2674, lr=2.90075e-05, gnorm=1.316, train_wall=5, gb_free=13.5, wall=9109
2025-04-03 07:35:50 | INFO | train_inner | epoch 022:     30 / 126 loss=5.284, nll_loss=1.618, ppl=3.07, wps=1548.2, ups=0.36, wpb=4282.5, bsz=260, num_updates=2676, lr=2.89967e-05, gnorm=1.271, train_wall=6, gb_free=14, wall=9114
2025-04-03 07:35:56 | INFO | train_inner | epoch 022:     32 / 126 loss=5.428, nll_loss=1.79, ppl=3.46, wps=1802.7, ups=0.34, wpb=5263.5, bsz=360, num_updates=2678, lr=2.89858e-05, gnorm=1.201, train_wall=6, gb_free=12.5, wall=9120
2025-04-03 07:36:02 | INFO | train_inner | epoch 022:     34 / 126 loss=5.269, nll_loss=1.56, ppl=2.95, wps=1473.3, ups=0.35, wpb=4161.5, bsz=244, num_updates=2680, lr=2.8975e-05, gnorm=1.29, train_wall=6, gb_free=11.5, wall=9126
2025-04-03 07:36:07 | INFO | train_inner | epoch 022:     36 / 126 loss=5.425, nll_loss=1.776, ppl=3.42, wps=1779.7, ups=0.37, wpb=4819.5, bsz=240, num_updates=2682, lr=2.89642e-05, gnorm=1.454, train_wall=5, gb_free=12.7, wall=9131
2025-04-03 07:36:13 | INFO | train_inner | epoch 022:     38 / 126 loss=5.39, nll_loss=1.747, ppl=3.36, wps=1498.9, ups=0.36, wpb=4196.5, bsz=252, num_updates=2684, lr=2.89534e-05, gnorm=1.397, train_wall=6, gb_free=13.2, wall=9137
2025-04-03 07:36:18 | INFO | train_inner | epoch 022:     40 / 126 loss=5.448, nll_loss=1.8, ppl=3.48, wps=1849.8, ups=0.35, wpb=5342, bsz=276, num_updates=2686, lr=2.89426e-05, gnorm=1.222, train_wall=6, gb_free=13, wall=9143
2025-04-03 07:36:24 | INFO | train_inner | epoch 022:     42 / 126 loss=5.495, nll_loss=1.864, ppl=3.64, wps=1749.2, ups=0.35, wpb=5039.5, bsz=272, num_updates=2688, lr=2.89319e-05, gnorm=1.41, train_wall=6, gb_free=12.2, wall=9148
2025-04-03 07:36:30 | INFO | train_inner | epoch 022:     44 / 126 loss=5.458, nll_loss=1.816, ppl=3.52, wps=1825.3, ups=0.34, wpb=5347.5, bsz=288, num_updates=2690, lr=2.89211e-05, gnorm=1.35, train_wall=6, gb_free=10.2, wall=9154
2025-04-03 07:36:36 | INFO | train_inner | epoch 022:     46 / 126 loss=5.443, nll_loss=1.811, ppl=3.51, wps=1600.1, ups=0.34, wpb=4691.5, bsz=224, num_updates=2692, lr=2.89104e-05, gnorm=1.452, train_wall=6, gb_free=10.2, wall=9160
2025-04-03 07:36:42 | INFO | train_inner | epoch 022:     48 / 126 loss=5.429, nll_loss=1.775, ppl=3.42, wps=1679.8, ups=0.35, wpb=4789.5, bsz=212, num_updates=2694, lr=2.88996e-05, gnorm=1.224, train_wall=6, gb_free=11.4, wall=9166
2025-04-03 07:36:47 | INFO | train_inner | epoch 022:     50 / 126 loss=5.393, nll_loss=1.734, ppl=3.33, wps=1585.2, ups=0.37, wpb=4300, bsz=288, num_updates=2696, lr=2.88889e-05, gnorm=1.365, train_wall=5, gb_free=13.1, wall=9171
2025-04-03 07:36:52 | INFO | train_inner | epoch 022:     52 / 126 loss=5.39, nll_loss=1.732, ppl=3.32, wps=1526.1, ups=0.38, wpb=4027, bsz=252, num_updates=2698, lr=2.88782e-05, gnorm=1.437, train_wall=5, gb_free=10.5, wall=9176
2025-04-03 07:36:58 | INFO | train_inner | epoch 022:     54 / 126 loss=5.412, nll_loss=1.769, ppl=3.41, wps=1758.4, ups=0.38, wpb=4653.5, bsz=232, num_updates=2700, lr=2.88675e-05, gnorm=1.3, train_wall=5, gb_free=14, wall=9182
2025-04-03 07:37:03 | INFO | train_inner | epoch 022:     56 / 126 loss=5.398, nll_loss=1.752, ppl=3.37, wps=1731, ups=0.35, wpb=4975.5, bsz=300, num_updates=2702, lr=2.88568e-05, gnorm=1.216, train_wall=6, gb_free=12.4, wall=9187
2025-04-03 07:37:09 | INFO | train_inner | epoch 022:     58 / 126 loss=5.408, nll_loss=1.748, ppl=3.36, wps=1579.8, ups=0.38, wpb=4139, bsz=220, num_updates=2704, lr=2.88462e-05, gnorm=1.404, train_wall=5, gb_free=13.9, wall=9193
2025-04-03 07:37:14 | INFO | train_inner | epoch 022:     60 / 126 loss=5.354, nll_loss=1.699, ppl=3.25, wps=1677.2, ups=0.35, wpb=4732.5, bsz=272, num_updates=2706, lr=2.88355e-05, gnorm=1.287, train_wall=6, gb_free=12.1, wall=9198
2025-04-03 07:37:20 | INFO | train_inner | epoch 022:     62 / 126 loss=5.463, nll_loss=1.833, ppl=3.56, wps=1490.5, ups=0.35, wpb=4300.5, bsz=228, num_updates=2708, lr=2.88248e-05, gnorm=1.411, train_wall=6, gb_free=11.1, wall=9204
2025-04-03 07:37:26 | INFO | train_inner | epoch 022:     64 / 126 loss=5.406, nll_loss=1.769, ppl=3.41, wps=1667.4, ups=0.36, wpb=4642.5, bsz=260, num_updates=2710, lr=2.88142e-05, gnorm=1.287, train_wall=6, gb_free=13.5, wall=9210
2025-04-03 07:37:31 | INFO | train_inner | epoch 022:     66 / 126 loss=5.379, nll_loss=1.718, ppl=3.29, wps=1760.6, ups=0.38, wpb=4688, bsz=292, num_updates=2712, lr=2.88036e-05, gnorm=1.291, train_wall=5, gb_free=13.3, wall=9215
2025-04-03 07:37:36 | INFO | train_inner | epoch 022:     68 / 126 loss=5.378, nll_loss=1.728, ppl=3.31, wps=1621.9, ups=0.37, wpb=4340.5, bsz=288, num_updates=2714, lr=2.8793e-05, gnorm=1.283, train_wall=5, gb_free=10.5, wall=9220
2025-04-03 07:37:42 | INFO | train_inner | epoch 022:     70 / 126 loss=5.471, nll_loss=1.844, ppl=3.59, wps=1786.5, ups=0.34, wpb=5276, bsz=260, num_updates=2716, lr=2.87824e-05, gnorm=1.292, train_wall=6, gb_free=9.5, wall=9226
2025-04-03 07:37:48 | INFO | train_inner | epoch 022:     72 / 126 loss=5.495, nll_loss=1.868, ppl=3.65, wps=1629.3, ups=0.35, wpb=4691.5, bsz=220, num_updates=2718, lr=2.87718e-05, gnorm=1.408, train_wall=6, gb_free=11, wall=9232
2025-04-03 07:37:53 | INFO | train_inner | epoch 022:     74 / 126 loss=5.287, nll_loss=1.618, ppl=3.07, wps=1608, ups=0.43, wpb=3775, bsz=276, num_updates=2720, lr=2.87612e-05, gnorm=1.508, train_wall=5, gb_free=13.4, wall=9237
2025-04-03 07:38:03 | INFO | train_inner | epoch 022:     76 / 126 loss=5.401, nll_loss=1.756, ppl=3.38, wps=866.9, ups=0.19, wpb=4502, bsz=328, num_updates=2722, lr=2.87506e-05, gnorm=1.345, train_wall=10, gb_free=13.3, wall=9247
2025-04-03 07:38:09 | INFO | train_inner | epoch 022:     78 / 126 loss=5.374, nll_loss=1.707, ppl=3.26, wps=1860.7, ups=0.36, wpb=5134, bsz=300, num_updates=2724, lr=2.87401e-05, gnorm=1.354, train_wall=6, gb_free=13.1, wall=9253
2025-04-03 07:38:14 | INFO | train_inner | epoch 022:     80 / 126 loss=5.475, nll_loss=1.845, ppl=3.59, wps=1740.7, ups=0.36, wpb=4897.5, bsz=280, num_updates=2726, lr=2.87295e-05, gnorm=1.358, train_wall=6, gb_free=13.1, wall=9258
2025-04-03 07:38:20 | INFO | train_inner | epoch 022:     82 / 126 loss=5.463, nll_loss=1.831, ppl=3.56, wps=1772.4, ups=0.36, wpb=4952.5, bsz=256, num_updates=2728, lr=2.8719e-05, gnorm=1.347, train_wall=6, gb_free=14.1, wall=9264
2025-04-03 07:38:25 | INFO | train_inner | epoch 022:     84 / 126 loss=5.461, nll_loss=1.834, ppl=3.57, wps=1606.4, ups=0.35, wpb=4543, bsz=212, num_updates=2730, lr=2.87085e-05, gnorm=1.352, train_wall=6, gb_free=10.4, wall=9270
2025-04-03 07:38:31 | INFO | train_inner | epoch 022:     86 / 126 loss=5.315, nll_loss=1.652, ppl=3.14, wps=1589.7, ups=0.35, wpb=4531.5, bsz=316, num_updates=2732, lr=2.8698e-05, gnorm=1.224, train_wall=6, gb_free=9.5, wall=9275
2025-04-03 07:38:36 | INFO | train_inner | epoch 022:     88 / 126 loss=5.331, nll_loss=1.651, ppl=3.14, wps=1549.9, ups=0.4, wpb=3919, bsz=232, num_updates=2734, lr=2.86875e-05, gnorm=1.324, train_wall=5, gb_free=14.5, wall=9280
2025-04-03 07:38:42 | INFO | train_inner | epoch 022:     90 / 126 loss=5.465, nll_loss=1.829, ppl=3.55, wps=1828.7, ups=0.37, wpb=4987, bsz=324, num_updates=2736, lr=2.8677e-05, gnorm=1.41, train_wall=5, gb_free=10, wall=9286
2025-04-03 07:38:47 | INFO | train_inner | epoch 022:     92 / 126 loss=5.493, nll_loss=1.863, ppl=3.64, wps=1478.6, ups=0.37, wpb=4011, bsz=224, num_updates=2738, lr=2.86665e-05, gnorm=1.514, train_wall=5, gb_free=14.6, wall=9291
2025-04-03 07:38:53 | INFO | train_inner | epoch 022:     94 / 126 loss=5.374, nll_loss=1.727, ppl=3.31, wps=1681.1, ups=0.37, wpb=4593, bsz=312, num_updates=2740, lr=2.8656e-05, gnorm=1.393, train_wall=5, gb_free=13.5, wall=9297
2025-04-03 07:38:58 | INFO | train_inner | epoch 022:     96 / 126 loss=5.564, nll_loss=1.966, ppl=3.91, wps=1768.7, ups=0.34, wpb=5165.5, bsz=256, num_updates=2742, lr=2.86456e-05, gnorm=1.442, train_wall=6, gb_free=9.6, wall=9302
2025-04-03 07:39:04 | INFO | train_inner | epoch 022:     98 / 126 loss=5.494, nll_loss=1.872, ppl=3.66, wps=1640, ups=0.35, wpb=4733.5, bsz=232, num_updates=2744, lr=2.86351e-05, gnorm=1.355, train_wall=6, gb_free=12.2, wall=9308
2025-04-03 07:39:10 | INFO | train_inner | epoch 022:    100 / 126 loss=5.397, nll_loss=1.747, ppl=3.36, wps=1551.3, ups=0.36, wpb=4352, bsz=260, num_updates=2746, lr=2.86247e-05, gnorm=1.374, train_wall=6, gb_free=12.1, wall=9314
2025-04-03 07:39:16 | INFO | train_inner | epoch 022:    102 / 126 loss=5.465, nll_loss=1.829, ppl=3.55, wps=1839.9, ups=0.34, wpb=5357.5, bsz=320, num_updates=2748, lr=2.86143e-05, gnorm=1.278, train_wall=6, gb_free=10.1, wall=9320
2025-04-03 07:39:21 | INFO | train_inner | epoch 022:    104 / 126 loss=5.374, nll_loss=1.684, ppl=3.21, wps=1636.3, ups=0.36, wpb=4484.5, bsz=216, num_updates=2750, lr=2.86039e-05, gnorm=1.284, train_wall=5, gb_free=12.4, wall=9325
2025-04-03 07:39:27 | INFO | train_inner | epoch 022:    106 / 126 loss=5.42, nll_loss=1.778, ppl=3.43, wps=1603.2, ups=0.33, wpb=4879.5, bsz=300, num_updates=2752, lr=2.85935e-05, gnorm=1.251, train_wall=6, gb_free=12.5, wall=9331
2025-04-03 07:39:33 | INFO | train_inner | epoch 022:    108 / 126 loss=5.453, nll_loss=1.83, ppl=3.56, wps=1587.8, ups=0.35, wpb=4521, bsz=192, num_updates=2754, lr=2.85831e-05, gnorm=1.384, train_wall=6, gb_free=10, wall=9337
2025-04-03 07:39:38 | INFO | train_inner | epoch 022:    110 / 126 loss=5.464, nll_loss=1.829, ppl=3.55, wps=1499.1, ups=0.35, wpb=4231.5, bsz=212, num_updates=2756, lr=2.85727e-05, gnorm=1.384, train_wall=6, gb_free=8.7, wall=9343
2025-04-03 07:39:44 | INFO | train_inner | epoch 022:    112 / 126 loss=5.535, nll_loss=1.927, ppl=3.8, wps=1809.4, ups=0.35, wpb=5144, bsz=268, num_updates=2758, lr=2.85624e-05, gnorm=1.274, train_wall=6, gb_free=8.4, wall=9348
2025-04-03 07:39:50 | INFO | train_inner | epoch 022:    114 / 126 loss=5.447, nll_loss=1.794, ppl=3.47, wps=1464.5, ups=0.37, wpb=4009, bsz=144, num_updates=2760, lr=2.8552e-05, gnorm=1.494, train_wall=5, gb_free=12.3, wall=9354
2025-04-03 07:39:55 | INFO | train_inner | epoch 022:    116 / 126 loss=5.404, nll_loss=1.743, ppl=3.35, wps=1415, ups=0.37, wpb=3859.5, bsz=192, num_updates=2762, lr=2.85417e-05, gnorm=1.358, train_wall=5, gb_free=13.6, wall=9359
2025-04-03 07:40:00 | INFO | train_inner | epoch 022:    118 / 126 loss=5.538, nll_loss=1.908, ppl=3.75, wps=1534.9, ups=0.41, wpb=3744, bsz=164, num_updates=2764, lr=2.85313e-05, gnorm=1.776, train_wall=5, gb_free=13.8, wall=9364
2025-04-03 07:40:05 | INFO | train_inner | epoch 022:    120 / 126 loss=5.389, nll_loss=1.74, ppl=3.34, wps=1522.8, ups=0.37, wpb=4139.5, bsz=244, num_updates=2766, lr=2.8521e-05, gnorm=1.289, train_wall=5, gb_free=10.4, wall=9370
2025-04-03 07:40:11 | INFO | train_inner | epoch 022:    122 / 126 loss=5.46, nll_loss=1.828, ppl=3.55, wps=1495.7, ups=0.34, wpb=4431, bsz=208, num_updates=2768, lr=2.85107e-05, gnorm=1.453, train_wall=6, gb_free=10.3, wall=9375
2025-04-03 07:40:16 | INFO | train_inner | epoch 022:    124 / 126 loss=5.404, nll_loss=1.773, ppl=3.42, wps=1563.6, ups=0.42, wpb=3740.5, bsz=232.5, num_updates=2770, lr=2.85004e-05, gnorm=1.512, train_wall=5, gb_free=9.3, wall=9380
2025-04-03 07:40:21 | INFO | train_inner | epoch 022:    126 / 126 loss=5.363, nll_loss=1.71, ppl=3.27, wps=1663.6, ups=0.45, wpb=3678, bsz=188, num_updates=2772, lr=2.84901e-05, gnorm=1.621, train_wall=4, gb_free=14.5, wall=9385
2025-04-03 07:40:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-03 07:40:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=15968.8828125Mb; avail=239116.25390625Mb
2025-04-03 07:40:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000641
2025-04-03 07:40:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15968.8828125Mb; avail=239116.25390625Mb
2025-04-03 07:40:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012973
2025-04-03 07:40:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15968.8828125Mb; avail=239116.25390625Mb
2025-04-03 07:40:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.010907
2025-04-03 07:40:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024876
2025-04-03 07:40:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15968.8828125Mb; avail=239116.25390625Mb
2025-04-03 07:40:35 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 5.942 | nll_loss 2.236 | ppl 4.71 | wps 3860.3 | wpb 2070.5 | bsz 122.7 | num_updates 2772 | best_loss 5.942
2025-04-03 07:40:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 2772 updates
2025-04-03 07:40:35 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 07:41:15 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 07:41:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt (epoch 22 @ 2772 updates, score 5.942) (writing took 64.16400055808481 seconds)
2025-04-03 07:41:39 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2025-04-03 07:41:39 | INFO | train | epoch 022 | loss 5.417 | nll_loss 1.77 | ppl 3.41 | wps 1324.6 | ups 0.29 | wpb 4549.7 | bsz 252.8 | num_updates 2772 | lr 2.84901e-05 | gnorm 1.353 | train_wall 354 | gb_free 14.5 | wall 9463
2025-04-03 07:41:39 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:mr-hi': 31849}; raw total size: 31849
2025-04-03 07:41:39 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:mr-hi': 31849}; resampled total size: 31849
2025-04-03 07:41:39 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:mr-hi': 1.0}
2025-04-03 07:41:39 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001060
2025-04-03 07:41:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=26741.66796875Mb; avail=228343.48828125Mb
2025-04-03 07:41:39 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000593
2025-04-03 07:41:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003486
2025-04-03 07:41:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26742.16015625Mb; avail=228342.99609375Mb
2025-04-03 07:41:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000098
2025-04-03 07:41:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26742.16015625Mb; avail=228342.99609375Mb
2025-04-03 07:41:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001133
2025-04-03 07:41:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.005056
2025-04-03 07:41:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26742.16015625Mb; avail=228342.99609375Mb
2025-04-03 07:41:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 126
2025-04-03 07:41:39 | INFO | fairseq.trainer | begin training epoch 23
2025-04-03 07:41:39 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-03 07:41:45 | INFO | train_inner | epoch 023:      2 / 126 loss=5.481, nll_loss=1.849, ppl=3.6, wps=123, ups=0.02, wpb=5178, bsz=324, num_updates=2774, lr=2.84799e-05, gnorm=1.269, train_wall=6, gb_free=10.4, wall=9469
2025-04-03 07:41:50 | INFO | train_inner | epoch 023:      4 / 126 loss=5.339, nll_loss=1.649, ppl=3.14, wps=1614.8, ups=0.38, wpb=4205, bsz=132, num_updates=2776, lr=2.84696e-05, gnorm=1.354, train_wall=5, gb_free=13.2, wall=9474
2025-04-03 07:41:56 | INFO | train_inner | epoch 023:      6 / 126 loss=5.35, nll_loss=1.679, ppl=3.2, wps=1517.9, ups=0.36, wpb=4205, bsz=212, num_updates=2778, lr=2.84594e-05, gnorm=1.344, train_wall=6, gb_free=10, wall=9480
2025-04-03 07:42:01 | INFO | train_inner | epoch 023:      8 / 126 loss=5.268, nll_loss=1.593, ppl=3.02, wps=1782.3, ups=0.37, wpb=4755, bsz=336, num_updates=2780, lr=2.84491e-05, gnorm=1.242, train_wall=5, gb_free=10.3, wall=9485
2025-04-03 07:42:07 | INFO | train_inner | epoch 023:     10 / 126 loss=5.3, nll_loss=1.621, ppl=3.08, wps=1733.3, ups=0.35, wpb=5002.5, bsz=304, num_updates=2782, lr=2.84389e-05, gnorm=1.265, train_wall=6, gb_free=11.7, wall=9491
2025-04-03 07:42:12 | INFO | train_inner | epoch 023:     12 / 126 loss=5.244, nll_loss=1.537, ppl=2.9, wps=1727.4, ups=0.37, wpb=4659.5, bsz=284, num_updates=2784, lr=2.84287e-05, gnorm=1.308, train_wall=5, gb_free=11.8, wall=9496
2025-04-03 07:42:18 | INFO | train_inner | epoch 023:     14 / 126 loss=5.377, nll_loss=1.71, ppl=3.27, wps=1620.3, ups=0.34, wpb=4702.5, bsz=204, num_updates=2786, lr=2.84185e-05, gnorm=1.437, train_wall=6, gb_free=12.5, wall=9502
2025-04-03 07:42:23 | INFO | train_inner | epoch 023:     16 / 126 loss=5.264, nll_loss=1.589, ppl=3.01, wps=1595.9, ups=0.38, wpb=4215.5, bsz=296, num_updates=2788, lr=2.84083e-05, gnorm=1.278, train_wall=5, gb_free=13.3, wall=9507
2025-04-03 07:42:34 | INFO | train_inner | epoch 023:     18 / 126 loss=5.32, nll_loss=1.638, ppl=3.11, wps=877.9, ups=0.19, wpb=4617, bsz=176, num_updates=2790, lr=2.83981e-05, gnorm=1.372, train_wall=11, gb_free=11.3, wall=9518
2025-04-03 07:42:39 | INFO | train_inner | epoch 023:     20 / 126 loss=5.426, nll_loss=1.786, ppl=3.45, wps=1668.4, ups=0.34, wpb=4856.5, bsz=212, num_updates=2792, lr=2.83879e-05, gnorm=1.369, train_wall=6, gb_free=9.7, wall=9524
2025-04-03 07:42:46 | INFO | train_inner | epoch 023:     22 / 126 loss=5.469, nll_loss=1.842, ppl=3.58, wps=1583.1, ups=0.33, wpb=4869.5, bsz=308, num_updates=2794, lr=2.83778e-05, gnorm=1.381, train_wall=6, gb_free=9.8, wall=9530
2025-04-03 07:42:51 | INFO | train_inner | epoch 023:     24 / 126 loss=5.192, nll_loss=1.49, ppl=2.81, wps=1648.4, ups=0.39, wpb=4244, bsz=332, num_updates=2796, lr=2.83676e-05, gnorm=1.212, train_wall=5, gb_free=11.9, wall=9535
2025-04-03 07:42:56 | INFO | train_inner | epoch 023:     26 / 126 loss=5.274, nll_loss=1.578, ppl=2.98, wps=1552.8, ups=0.37, wpb=4246.5, bsz=232, num_updates=2798, lr=2.83575e-05, gnorm=1.283, train_wall=5, gb_free=13.1, wall=9540
2025-04-03 07:43:02 | INFO | train_inner | epoch 023:     28 / 126 loss=5.432, nll_loss=1.781, ppl=3.44, wps=1431.8, ups=0.38, wpb=3785, bsz=172, num_updates=2800, lr=2.83473e-05, gnorm=1.466, train_wall=5, gb_free=11.8, wall=9546
2025-04-03 07:43:07 | INFO | train_inner | epoch 023:     30 / 126 loss=5.501, nll_loss=1.897, ppl=3.72, wps=1922.8, ups=0.35, wpb=5516, bsz=308, num_updates=2802, lr=2.83372e-05, gnorm=1.536, train_wall=6, gb_free=10.3, wall=9551
2025-04-03 07:43:13 | INFO | train_inner | epoch 023:     32 / 126 loss=5.26, nll_loss=1.577, ppl=2.98, wps=1766.8, ups=0.35, wpb=5011.5, bsz=340, num_updates=2804, lr=2.83271e-05, gnorm=1.216, train_wall=6, gb_free=9.5, wall=9557
2025-04-03 07:43:18 | INFO | train_inner | epoch 023:     34 / 126 loss=5.331, nll_loss=1.648, ppl=3.13, wps=1680.8, ups=0.38, wpb=4440, bsz=236, num_updates=2806, lr=2.8317e-05, gnorm=1.357, train_wall=5, gb_free=12.5, wall=9562
2025-04-03 07:43:24 | INFO | train_inner | epoch 023:     36 / 126 loss=5.373, nll_loss=1.703, ppl=3.26, wps=1464.7, ups=0.36, wpb=4016, bsz=204, num_updates=2808, lr=2.83069e-05, gnorm=1.384, train_wall=5, gb_free=13.6, wall=9568
2025-04-03 07:43:28 | INFO | train_inner | epoch 023:     38 / 126 loss=5.285, nll_loss=1.595, ppl=3.02, wps=1539.8, ups=0.45, wpb=3407.5, bsz=152.5, num_updates=2810, lr=2.82969e-05, gnorm=1.986, train_wall=4, gb_free=11.6, wall=9572
2025-04-03 07:43:34 | INFO | train_inner | epoch 023:     40 / 126 loss=5.39, nll_loss=1.74, ppl=3.34, wps=1541.5, ups=0.36, wpb=4336.5, bsz=180, num_updates=2812, lr=2.82868e-05, gnorm=1.434, train_wall=6, gb_free=10.2, wall=9578
2025-04-03 07:43:40 | INFO | train_inner | epoch 023:     42 / 126 loss=5.3, nll_loss=1.624, ppl=3.08, wps=1582.3, ups=0.34, wpb=4604, bsz=204, num_updates=2814, lr=2.82767e-05, gnorm=1.274, train_wall=6, gb_free=13.3, wall=9584
2025-04-03 07:43:45 | INFO | train_inner | epoch 023:     44 / 126 loss=5.299, nll_loss=1.625, ppl=3.08, wps=1711.2, ups=0.37, wpb=4611.5, bsz=260, num_updates=2816, lr=2.82667e-05, gnorm=1.257, train_wall=5, gb_free=13.7, wall=9589
2025-04-03 07:43:50 | INFO | train_inner | epoch 023:     46 / 126 loss=5.222, nll_loss=1.499, ppl=2.83, wps=1412.5, ups=0.38, wpb=3688.5, bsz=144, num_updates=2818, lr=2.82567e-05, gnorm=1.513, train_wall=5, gb_free=12.7, wall=9594
2025-04-03 07:43:56 | INFO | train_inner | epoch 023:     48 / 126 loss=5.311, nll_loss=1.632, ppl=3.1, wps=1808, ups=0.35, wpb=5225, bsz=316, num_updates=2820, lr=2.82466e-05, gnorm=1.206, train_wall=6, gb_free=10.5, wall=9600
2025-04-03 07:44:01 | INFO | train_inner | epoch 023:     50 / 126 loss=5.342, nll_loss=1.682, ppl=3.21, wps=1680.7, ups=0.37, wpb=4511, bsz=300, num_updates=2822, lr=2.82366e-05, gnorm=1.284, train_wall=5, gb_free=13.2, wall=9605
2025-04-03 07:44:07 | INFO | train_inner | epoch 023:     52 / 126 loss=5.315, nll_loss=1.656, ppl=3.15, wps=1789.9, ups=0.36, wpb=4959.5, bsz=348, num_updates=2824, lr=2.82266e-05, gnorm=1.264, train_wall=6, gb_free=14.1, wall=9611
2025-04-03 07:44:12 | INFO | train_inner | epoch 023:     54 / 126 loss=5.399, nll_loss=1.76, ppl=3.39, wps=1750.9, ups=0.36, wpb=4804, bsz=344, num_updates=2826, lr=2.82166e-05, gnorm=1.305, train_wall=5, gb_free=11.5, wall=9616
2025-04-03 07:44:18 | INFO | train_inner | epoch 023:     56 / 126 loss=5.511, nll_loss=1.884, ppl=3.69, wps=1680.6, ups=0.33, wpb=5093.5, bsz=224, num_updates=2828, lr=2.82067e-05, gnorm=1.305, train_wall=6, gb_free=10.1, wall=9623
2025-04-03 07:44:24 | INFO | train_inner | epoch 023:     58 / 126 loss=5.344, nll_loss=1.688, ppl=3.22, wps=1608.9, ups=0.36, wpb=4523.5, bsz=320, num_updates=2830, lr=2.81967e-05, gnorm=1.317, train_wall=6, gb_free=10.3, wall=9628
2025-04-03 07:44:30 | INFO | train_inner | epoch 023:     60 / 126 loss=5.367, nll_loss=1.69, ppl=3.23, wps=1580.9, ups=0.36, wpb=4406, bsz=216, num_updates=2832, lr=2.81867e-05, gnorm=1.429, train_wall=6, gb_free=13.2, wall=9634
2025-04-03 07:44:35 | INFO | train_inner | epoch 023:     62 / 126 loss=5.348, nll_loss=1.676, ppl=3.2, wps=1757.5, ups=0.35, wpb=5079, bsz=252, num_updates=2834, lr=2.81768e-05, gnorm=1.188, train_wall=6, gb_free=12.2, wall=9640
2025-04-03 07:44:41 | INFO | train_inner | epoch 023:     64 / 126 loss=5.387, nll_loss=1.74, ppl=3.34, wps=1450.9, ups=0.35, wpb=4183.5, bsz=204, num_updates=2836, lr=2.81668e-05, gnorm=1.439, train_wall=6, gb_free=9, wall=9645
2025-04-03 07:44:47 | INFO | train_inner | epoch 023:     66 / 126 loss=5.461, nll_loss=1.827, ppl=3.55, wps=1631.2, ups=0.36, wpb=4557, bsz=200, num_updates=2838, lr=2.81569e-05, gnorm=1.525, train_wall=6, gb_free=12.7, wall=9651
2025-04-03 07:44:52 | INFO | train_inner | epoch 023:     68 / 126 loss=5.329, nll_loss=1.651, ppl=3.14, wps=1749.6, ups=0.38, wpb=4613, bsz=280, num_updates=2840, lr=2.8147e-05, gnorm=1.26, train_wall=5, gb_free=14.4, wall=9656
2025-04-03 07:44:58 | INFO | train_inner | epoch 023:     70 / 126 loss=5.336, nll_loss=1.66, ppl=3.16, wps=1795.3, ups=0.35, wpb=5124.5, bsz=332, num_updates=2842, lr=2.81371e-05, gnorm=1.174, train_wall=6, gb_free=9.8, wall=9662
2025-04-03 07:45:03 | INFO | train_inner | epoch 023:     72 / 126 loss=5.5, nll_loss=1.876, ppl=3.67, wps=1614.5, ups=0.36, wpb=4438.5, bsz=264, num_updates=2844, lr=2.81272e-05, gnorm=1.509, train_wall=5, gb_free=14.8, wall=9667
2025-04-03 07:45:09 | INFO | train_inner | epoch 023:     74 / 126 loss=5.313, nll_loss=1.645, ppl=3.13, wps=1430.8, ups=0.36, wpb=3942.5, bsz=248, num_updates=2846, lr=2.81173e-05, gnorm=1.422, train_wall=6, gb_free=10.3, wall=9673
2025-04-03 07:45:15 | INFO | train_inner | epoch 023:     76 / 126 loss=5.42, nll_loss=1.771, ppl=3.41, wps=1627.7, ups=0.34, wpb=4812, bsz=148, num_updates=2848, lr=2.81074e-05, gnorm=1.306, train_wall=6, gb_free=9.7, wall=9679
2025-04-03 07:45:21 | INFO | train_inner | epoch 023:     78 / 126 loss=5.35, nll_loss=1.69, ppl=3.23, wps=1743.9, ups=0.34, wpb=5095.5, bsz=300, num_updates=2850, lr=2.80976e-05, gnorm=1.292, train_wall=6, gb_free=11.3, wall=9685
2025-04-03 07:45:26 | INFO | train_inner | epoch 023:     80 / 126 loss=5.297, nll_loss=1.62, ppl=3.07, wps=1622, ups=0.36, wpb=4534.5, bsz=296, num_updates=2852, lr=2.80877e-05, gnorm=1.321, train_wall=6, gb_free=14, wall=9690
2025-04-03 07:45:32 | INFO | train_inner | epoch 023:     82 / 126 loss=5.32, nll_loss=1.648, ppl=3.13, wps=1807.7, ups=0.36, wpb=4997.5, bsz=236, num_updates=2854, lr=2.80779e-05, gnorm=1.252, train_wall=6, gb_free=10.6, wall=9696
2025-04-03 07:45:37 | INFO | train_inner | epoch 023:     84 / 126 loss=5.365, nll_loss=1.734, ppl=3.33, wps=1449.6, ups=0.37, wpb=3882, bsz=324, num_updates=2856, lr=2.8068e-05, gnorm=1.507, train_wall=5, gb_free=14.6, wall=9701
2025-04-03 07:45:42 | INFO | train_inner | epoch 023:     86 / 126 loss=5.246, nll_loss=1.556, ppl=2.94, wps=1612.6, ups=0.37, wpb=4319, bsz=280, num_updates=2858, lr=2.80582e-05, gnorm=1.274, train_wall=5, gb_free=14.7, wall=9706
2025-04-03 07:45:48 | INFO | train_inner | epoch 023:     88 / 126 loss=5.392, nll_loss=1.723, ppl=3.3, wps=1623.4, ups=0.35, wpb=4628, bsz=264, num_updates=2860, lr=2.80484e-05, gnorm=1.428, train_wall=6, gb_free=9.7, wall=9712
2025-04-03 07:45:54 | INFO | train_inner | epoch 023:     90 / 126 loss=5.356, nll_loss=1.676, ppl=3.2, wps=1782.2, ups=0.34, wpb=5200, bsz=284, num_updates=2862, lr=2.80386e-05, gnorm=1.204, train_wall=6, gb_free=8.8, wall=9718
2025-04-03 07:45:59 | INFO | train_inner | epoch 023:     92 / 126 loss=5.31, nll_loss=1.638, ppl=3.11, wps=1568.7, ups=0.37, wpb=4231, bsz=232, num_updates=2864, lr=2.80288e-05, gnorm=1.297, train_wall=5, gb_free=13, wall=9723
2025-04-03 07:46:05 | INFO | train_inner | epoch 023:     94 / 126 loss=5.325, nll_loss=1.683, ppl=3.21, wps=1506, ups=0.36, wpb=4146, bsz=312, num_updates=2866, lr=2.8019e-05, gnorm=1.244, train_wall=5, gb_free=11.3, wall=9729
2025-04-03 07:46:11 | INFO | train_inner | epoch 023:     96 / 126 loss=5.391, nll_loss=1.749, ppl=3.36, wps=1745.7, ups=0.34, wpb=5108.5, bsz=284, num_updates=2868, lr=2.80093e-05, gnorm=1.219, train_wall=6, gb_free=11.4, wall=9735
2025-04-03 07:46:16 | INFO | train_inner | epoch 023:     98 / 126 loss=5.315, nll_loss=1.635, ppl=3.11, wps=1459.7, ups=0.37, wpb=3989, bsz=248, num_updates=2870, lr=2.79995e-05, gnorm=1.324, train_wall=5, gb_free=12.4, wall=9740
2025-04-03 07:46:22 | INFO | train_inner | epoch 023:    100 / 126 loss=5.342, nll_loss=1.666, ppl=3.17, wps=1519.5, ups=0.36, wpb=4166, bsz=212, num_updates=2872, lr=2.79898e-05, gnorm=1.351, train_wall=5, gb_free=14.7, wall=9746
2025-04-03 07:46:27 | INFO | train_inner | epoch 023:    102 / 126 loss=5.323, nll_loss=1.643, ppl=3.12, wps=1640.6, ups=0.36, wpb=4604, bsz=272, num_updates=2874, lr=2.798e-05, gnorm=1.273, train_wall=6, gb_free=10.3, wall=9751
2025-04-03 07:46:33 | INFO | train_inner | epoch 023:    104 / 126 loss=5.356, nll_loss=1.7, ppl=3.25, wps=1598.2, ups=0.37, wpb=4285.5, bsz=280, num_updates=2876, lr=2.79703e-05, gnorm=1.294, train_wall=5, gb_free=11.5, wall=9757
2025-04-03 07:46:38 | INFO | train_inner | epoch 023:    106 / 126 loss=5.429, nll_loss=1.79, ppl=3.46, wps=1588.9, ups=0.35, wpb=4561, bsz=204, num_updates=2878, lr=2.79606e-05, gnorm=1.387, train_wall=6, gb_free=8.9, wall=9762
2025-04-03 07:46:44 | INFO | train_inner | epoch 023:    108 / 126 loss=5.385, nll_loss=1.72, ppl=3.29, wps=1565.6, ups=0.36, wpb=4343.5, bsz=224, num_updates=2880, lr=2.79508e-05, gnorm=1.427, train_wall=6, gb_free=12.5, wall=9768
2025-04-03 07:46:49 | INFO | train_inner | epoch 023:    110 / 126 loss=5.409, nll_loss=1.749, ppl=3.36, wps=1592.6, ups=0.43, wpb=3725.5, bsz=172, num_updates=2882, lr=2.79411e-05, gnorm=1.604, train_wall=5, gb_free=10.6, wall=9773
2025-04-03 07:46:54 | INFO | train_inner | epoch 023:    112 / 126 loss=5.452, nll_loss=1.825, ppl=3.54, wps=1570, ups=0.34, wpb=4671, bsz=252, num_updates=2884, lr=2.79315e-05, gnorm=1.374, train_wall=6, gb_free=10.6, wall=9779
2025-04-03 07:47:00 | INFO | train_inner | epoch 023:    114 / 126 loss=5.325, nll_loss=1.647, ppl=3.13, wps=1599.9, ups=0.39, wpb=4123.5, bsz=180, num_updates=2886, lr=2.79218e-05, gnorm=1.378, train_wall=5, gb_free=10, wall=9784
2025-04-03 07:47:05 | INFO | train_inner | epoch 023:    116 / 126 loss=5.481, nll_loss=1.844, ppl=3.59, wps=1726.4, ups=0.36, wpb=4840, bsz=204, num_updates=2888, lr=2.79121e-05, gnorm=1.369, train_wall=6, gb_free=12.4, wall=9789
2025-04-03 07:47:11 | INFO | train_inner | epoch 023:    118 / 126 loss=5.366, nll_loss=1.69, ppl=3.23, wps=1809.1, ups=0.37, wpb=4912.5, bsz=304, num_updates=2890, lr=2.79024e-05, gnorm=1.232, train_wall=5, gb_free=10.3, wall=9795
2025-04-03 07:47:16 | INFO | train_inner | epoch 023:    120 / 126 loss=5.344, nll_loss=1.668, ppl=3.18, wps=1632.5, ups=0.35, wpb=4615.5, bsz=268, num_updates=2892, lr=2.78928e-05, gnorm=1.285, train_wall=6, gb_free=12.7, wall=9800
2025-04-03 07:47:22 | INFO | train_inner | epoch 023:    122 / 126 loss=5.504, nll_loss=1.874, ppl=3.67, wps=1911.4, ups=0.34, wpb=5544, bsz=264, num_updates=2894, lr=2.78832e-05, gnorm=1.542, train_wall=6, gb_free=13.6, wall=9806
2025-04-03 07:47:28 | INFO | train_inner | epoch 023:    124 / 126 loss=5.432, nll_loss=1.797, ppl=3.47, wps=1721.2, ups=0.36, wpb=4816.5, bsz=208, num_updates=2896, lr=2.78735e-05, gnorm=1.327, train_wall=6, gb_free=13.2, wall=9812
2025-04-03 07:47:32 | INFO | train_inner | epoch 023:    126 / 126 loss=5.295, nll_loss=1.641, ppl=3.12, wps=1802.7, ups=0.47, wpb=3846.5, bsz=272, num_updates=2898, lr=2.78639e-05, gnorm=1.481, train_wall=4, gb_free=17.4, wall=9816
2025-04-03 07:47:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-03 07:47:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=15926.8125Mb; avail=239158.37890625Mb
2025-04-03 07:47:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000653
2025-04-03 07:47:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15926.8125Mb; avail=239158.37890625Mb
2025-04-03 07:47:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012938
2025-04-03 07:47:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15926.8125Mb; avail=239158.37890625Mb
2025-04-03 07:47:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.010953
2025-04-03 07:47:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024909
2025-04-03 07:47:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15926.8125Mb; avail=239158.37890625Mb
2025-04-03 07:47:46 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 5.924 | nll_loss 2.207 | ppl 4.62 | wps 3862.9 | wpb 2070.5 | bsz 122.7 | num_updates 2898 | best_loss 5.924
2025-04-03 07:47:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 2898 updates
2025-04-03 07:47:46 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 07:48:26 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 07:48:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt (epoch 23 @ 2898 updates, score 5.924) (writing took 63.68782454403117 seconds)
2025-04-03 07:48:50 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2025-04-03 07:48:50 | INFO | train | epoch 023 | loss 5.36 | nll_loss 1.697 | ppl 3.24 | wps 1330.2 | ups 0.29 | wpb 4549.7 | bsz 252.8 | num_updates 2898 | lr 2.78639e-05 | gnorm 1.352 | train_wall 352 | gb_free 17.4 | wall 9894
2025-04-03 07:48:50 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:mr-hi': 31849}; raw total size: 31849
2025-04-03 07:48:50 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:mr-hi': 31849}; resampled total size: 31849
2025-04-03 07:48:50 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:mr-hi': 1.0}
2025-04-03 07:48:50 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001266
2025-04-03 07:48:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=26736.08203125Mb; avail=228348.9765625Mb
2025-04-03 07:48:50 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000591
2025-04-03 07:48:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003460
2025-04-03 07:48:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26736.57421875Mb; avail=228348.484375Mb
2025-04-03 07:48:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000091
2025-04-03 07:48:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26736.57421875Mb; avail=228348.484375Mb
2025-04-03 07:48:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001138
2025-04-03 07:48:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.004999
2025-04-03 07:48:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26736.57421875Mb; avail=228348.484375Mb
2025-04-03 07:48:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 126
2025-04-03 07:48:50 | INFO | fairseq.trainer | begin training epoch 24
2025-04-03 07:48:50 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-03 07:48:56 | INFO | train_inner | epoch 024:      2 / 126 loss=5.272, nll_loss=1.557, ppl=2.94, wps=121.8, ups=0.02, wpb=5112, bsz=240, num_updates=2900, lr=2.78543e-05, gnorm=1.167, train_wall=6, gb_free=13.3, wall=9900
2025-04-03 07:49:01 | INFO | train_inner | epoch 024:      4 / 126 loss=5.298, nll_loss=1.619, ppl=3.07, wps=1681.9, ups=0.37, wpb=4584, bsz=304, num_updates=2902, lr=2.78447e-05, gnorm=1.271, train_wall=5, gb_free=13.9, wall=9905
2025-04-03 07:49:07 | INFO | train_inner | epoch 024:      6 / 126 loss=5.381, nll_loss=1.715, ppl=3.28, wps=1699.5, ups=0.36, wpb=4716, bsz=196, num_updates=2904, lr=2.78351e-05, gnorm=1.34, train_wall=6, gb_free=10.5, wall=9911
2025-04-03 07:49:13 | INFO | train_inner | epoch 024:      8 / 126 loss=5.281, nll_loss=1.596, ppl=3.02, wps=1471.9, ups=0.35, wpb=4166.5, bsz=132, num_updates=2906, lr=2.78255e-05, gnorm=1.419, train_wall=6, gb_free=10.3, wall=9917
2025-04-03 07:49:18 | INFO | train_inner | epoch 024:     10 / 126 loss=5.228, nll_loss=1.548, ppl=2.92, wps=1818.8, ups=0.37, wpb=4966.5, bsz=304, num_updates=2908, lr=2.7816e-05, gnorm=1.233, train_wall=5, gb_free=12.9, wall=9922
2025-04-03 07:49:24 | INFO | train_inner | epoch 024:     12 / 126 loss=5.342, nll_loss=1.661, ppl=3.16, wps=1558.8, ups=0.36, wpb=4287.5, bsz=204, num_updates=2910, lr=2.78064e-05, gnorm=1.344, train_wall=5, gb_free=9.6, wall=9928
2025-04-03 07:49:29 | INFO | train_inner | epoch 024:     14 / 126 loss=5.285, nll_loss=1.583, ppl=2.99, wps=1426.3, ups=0.35, wpb=4050.5, bsz=176, num_updates=2912, lr=2.77968e-05, gnorm=1.372, train_wall=6, gb_free=9.6, wall=9933
2025-04-03 07:49:35 | INFO | train_inner | epoch 024:     16 / 126 loss=5.335, nll_loss=1.661, ppl=3.16, wps=1846.1, ups=0.36, wpb=5155, bsz=276, num_updates=2914, lr=2.77873e-05, gnorm=1.252, train_wall=6, gb_free=12, wall=9939
2025-04-03 07:49:40 | INFO | train_inner | epoch 024:     18 / 126 loss=5.418, nll_loss=1.761, ppl=3.39, wps=1632.1, ups=0.38, wpb=4267.5, bsz=196, num_updates=2916, lr=2.77778e-05, gnorm=1.407, train_wall=5, gb_free=10.7, wall=9944
2025-04-03 07:49:46 | INFO | train_inner | epoch 024:     20 / 126 loss=5.219, nll_loss=1.531, ppl=2.89, wps=1542.3, ups=0.36, wpb=4269, bsz=272, num_updates=2918, lr=2.77683e-05, gnorm=1.28, train_wall=6, gb_free=12.2, wall=9950
2025-04-03 07:49:51 | INFO | train_inner | epoch 024:     22 / 126 loss=5.24, nll_loss=1.54, ppl=2.91, wps=1459.2, ups=0.35, wpb=4179, bsz=204, num_updates=2920, lr=2.77587e-05, gnorm=1.357, train_wall=6, gb_free=10.8, wall=9955
2025-04-03 07:49:57 | INFO | train_inner | epoch 024:     24 / 126 loss=5.429, nll_loss=1.785, ppl=3.45, wps=1715.9, ups=0.35, wpb=4961.5, bsz=276, num_updates=2922, lr=2.77492e-05, gnorm=1.391, train_wall=6, gb_free=9.9, wall=9961
2025-04-03 07:50:03 | INFO | train_inner | epoch 024:     26 / 126 loss=5.247, nll_loss=1.568, ppl=2.96, wps=1553, ups=0.35, wpb=4448.5, bsz=328, num_updates=2924, lr=2.77398e-05, gnorm=1.3, train_wall=6, gb_free=12.8, wall=9967
2025-04-03 07:50:08 | INFO | train_inner | epoch 024:     28 / 126 loss=5.262, nll_loss=1.552, ppl=2.93, wps=1591.5, ups=0.37, wpb=4310, bsz=228, num_updates=2926, lr=2.77303e-05, gnorm=1.37, train_wall=5, gb_free=10.7, wall=9972
2025-04-03 07:50:14 | INFO | train_inner | epoch 024:     30 / 126 loss=5.276, nll_loss=1.591, ppl=3.01, wps=1736.2, ups=0.33, wpb=5336.5, bsz=332, num_updates=2928, lr=2.77208e-05, gnorm=1.151, train_wall=6, gb_free=8.7, wall=9978
2025-04-03 07:50:20 | INFO | train_inner | epoch 024:     32 / 126 loss=5.262, nll_loss=1.579, ppl=2.99, wps=1757.4, ups=0.36, wpb=4823.5, bsz=280, num_updates=2930, lr=2.77113e-05, gnorm=1.293, train_wall=5, gb_free=12.1, wall=9984
2025-04-03 07:50:26 | INFO | train_inner | epoch 024:     34 / 126 loss=5.435, nll_loss=1.796, ppl=3.47, wps=1763.1, ups=0.35, wpb=5096.5, bsz=300, num_updates=2932, lr=2.77019e-05, gnorm=1.295, train_wall=6, gb_free=14.6, wall=9990
2025-04-03 07:50:31 | INFO | train_inner | epoch 024:     36 / 126 loss=5.339, nll_loss=1.658, ppl=3.16, wps=1670, ups=0.37, wpb=4544, bsz=220, num_updates=2934, lr=2.76924e-05, gnorm=1.306, train_wall=5, gb_free=14.9, wall=9995
2025-04-03 07:50:36 | INFO | train_inner | epoch 024:     38 / 126 loss=5.175, nll_loss=1.474, ppl=2.78, wps=1440.3, ups=0.38, wpb=3811, bsz=268, num_updates=2936, lr=2.7683e-05, gnorm=1.36, train_wall=5, gb_free=14.7, wall=10000
2025-04-03 07:50:42 | INFO | train_inner | epoch 024:     40 / 126 loss=5.242, nll_loss=1.547, ppl=2.92, wps=1466.6, ups=0.34, wpb=4287, bsz=232, num_updates=2938, lr=2.76736e-05, gnorm=1.211, train_wall=6, gb_free=10.2, wall=10006
2025-04-03 07:50:48 | INFO | train_inner | epoch 024:     42 / 126 loss=5.276, nll_loss=1.601, ppl=3.03, wps=1756.5, ups=0.35, wpb=4952.5, bsz=348, num_updates=2940, lr=2.76642e-05, gnorm=1.164, train_wall=6, gb_free=10.8, wall=10012
2025-04-03 07:50:53 | INFO | train_inner | epoch 024:     44 / 126 loss=5.284, nll_loss=1.618, ppl=3.07, wps=1729.4, ups=0.37, wpb=4708.5, bsz=336, num_updates=2942, lr=2.76548e-05, gnorm=1.273, train_wall=5, gb_free=13.2, wall=10017
2025-04-03 07:50:59 | INFO | train_inner | epoch 024:     46 / 126 loss=5.174, nll_loss=1.449, ppl=2.73, wps=1487.9, ups=0.38, wpb=3966, bsz=228, num_updates=2944, lr=2.76454e-05, gnorm=1.231, train_wall=5, gb_free=14.3, wall=10023
2025-04-03 07:51:09 | INFO | train_inner | epoch 024:     48 / 126 loss=5.228, nll_loss=1.528, ppl=2.88, wps=769.1, ups=0.19, wpb=4029, bsz=256, num_updates=2946, lr=2.7636e-05, gnorm=1.302, train_wall=10, gb_free=11.3, wall=10033
2025-04-03 07:51:15 | INFO | train_inner | epoch 024:     50 / 126 loss=5.322, nll_loss=1.668, ppl=3.18, wps=1890.5, ups=0.36, wpb=5182.5, bsz=344, num_updates=2948, lr=2.76266e-05, gnorm=1.236, train_wall=5, gb_free=9.8, wall=10039
2025-04-03 07:51:19 | INFO | train_inner | epoch 024:     52 / 126 loss=5.236, nll_loss=1.554, ppl=2.94, wps=1526.1, ups=0.41, wpb=3701, bsz=236, num_updates=2950, lr=2.76172e-05, gnorm=1.334, train_wall=5, gb_free=12.5, wall=10044
2025-04-03 07:51:25 | INFO | train_inner | epoch 024:     54 / 126 loss=5.229, nll_loss=1.527, ppl=2.88, wps=1668.6, ups=0.36, wpb=4675.5, bsz=252, num_updates=2952, lr=2.76079e-05, gnorm=1.174, train_wall=6, gb_free=10.2, wall=10049
2025-04-03 07:51:31 | INFO | train_inner | epoch 024:     56 / 126 loss=5.33, nll_loss=1.664, ppl=3.17, wps=1596.6, ups=0.34, wpb=4647.5, bsz=324, num_updates=2954, lr=2.75985e-05, gnorm=1.302, train_wall=6, gb_free=10.4, wall=10055
2025-04-03 07:51:36 | INFO | train_inner | epoch 024:     58 / 126 loss=5.245, nll_loss=1.551, ppl=2.93, wps=1623.7, ups=0.37, wpb=4434.5, bsz=240, num_updates=2956, lr=2.75892e-05, gnorm=1.281, train_wall=5, gb_free=9.4, wall=10060
2025-04-03 07:51:42 | INFO | train_inner | epoch 024:     60 / 126 loss=5.26, nll_loss=1.564, ppl=2.96, wps=1699.8, ups=0.37, wpb=4547.5, bsz=220, num_updates=2958, lr=2.75799e-05, gnorm=1.263, train_wall=5, gb_free=13.4, wall=10066
2025-04-03 07:51:48 | INFO | train_inner | epoch 024:     62 / 126 loss=5.286, nll_loss=1.597, ppl=3.02, wps=1620.1, ups=0.34, wpb=4717, bsz=256, num_updates=2960, lr=2.75705e-05, gnorm=1.269, train_wall=6, gb_free=10, wall=10072
2025-04-03 07:51:53 | INFO | train_inner | epoch 024:     64 / 126 loss=5.236, nll_loss=1.551, ppl=2.93, wps=1792.1, ups=0.35, wpb=5053, bsz=328, num_updates=2962, lr=2.75612e-05, gnorm=1.273, train_wall=6, gb_free=12.5, wall=10077
2025-04-03 07:51:59 | INFO | train_inner | epoch 024:     66 / 126 loss=5.195, nll_loss=1.5, ppl=2.83, wps=1709.7, ups=0.36, wpb=4780.5, bsz=328, num_updates=2964, lr=2.75519e-05, gnorm=1.151, train_wall=6, gb_free=9.3, wall=10083
2025-04-03 07:52:05 | INFO | train_inner | epoch 024:     68 / 126 loss=5.301, nll_loss=1.617, ppl=3.07, wps=1695.1, ups=0.35, wpb=4887, bsz=192, num_updates=2966, lr=2.75426e-05, gnorm=1.288, train_wall=6, gb_free=10.2, wall=10089
2025-04-03 07:52:10 | INFO | train_inner | epoch 024:     70 / 126 loss=5.319, nll_loss=1.624, ppl=3.08, wps=1587.5, ups=0.37, wpb=4330, bsz=180, num_updates=2968, lr=2.75334e-05, gnorm=1.5, train_wall=5, gb_free=12.3, wall=10094
2025-04-03 07:52:15 | INFO | train_inner | epoch 024:     72 / 126 loss=5.297, nll_loss=1.608, ppl=3.05, wps=1763.7, ups=0.43, wpb=4074.5, bsz=236.5, num_updates=2970, lr=2.75241e-05, gnorm=1.713, train_wall=5, gb_free=10.5, wall=10099
2025-04-03 07:52:20 | INFO | train_inner | epoch 024:     74 / 126 loss=5.353, nll_loss=1.69, ppl=3.23, wps=1716.6, ups=0.34, wpb=4993.5, bsz=240, num_updates=2972, lr=2.75148e-05, gnorm=1.336, train_wall=6, gb_free=10.8, wall=10105
2025-04-03 07:52:26 | INFO | train_inner | epoch 024:     76 / 126 loss=5.264, nll_loss=1.581, ppl=2.99, wps=1679.9, ups=0.37, wpb=4567, bsz=300, num_updates=2974, lr=2.75056e-05, gnorm=1.196, train_wall=5, gb_free=11.2, wall=10110
2025-04-03 07:52:31 | INFO | train_inner | epoch 024:     78 / 126 loss=5.33, nll_loss=1.675, ppl=3.19, wps=1810.1, ups=0.36, wpb=5062.5, bsz=328, num_updates=2976, lr=2.74963e-05, gnorm=1.245, train_wall=6, gb_free=13.1, wall=10116
2025-04-03 07:52:37 | INFO | train_inner | epoch 024:     80 / 126 loss=5.264, nll_loss=1.6, ppl=3.03, wps=1604.9, ups=0.37, wpb=4285.5, bsz=364, num_updates=2978, lr=2.74871e-05, gnorm=1.296, train_wall=5, gb_free=12.9, wall=10121
2025-04-03 07:52:42 | INFO | train_inner | epoch 024:     82 / 126 loss=5.295, nll_loss=1.606, ppl=3.05, wps=1788.7, ups=0.36, wpb=4971, bsz=296, num_updates=2980, lr=2.74779e-05, gnorm=1.251, train_wall=6, gb_free=12.9, wall=10126
2025-04-03 07:52:48 | INFO | train_inner | epoch 024:     84 / 126 loss=5.307, nll_loss=1.628, ppl=3.09, wps=1682.3, ups=0.37, wpb=4524.5, bsz=264, num_updates=2982, lr=2.74687e-05, gnorm=1.383, train_wall=5, gb_free=14.1, wall=10132
2025-04-03 07:52:53 | INFO | train_inner | epoch 024:     86 / 126 loss=5.262, nll_loss=1.59, ppl=3.01, wps=1694.1, ups=0.39, wpb=4390, bsz=292, num_updates=2984, lr=2.74595e-05, gnorm=1.256, train_wall=5, gb_free=13.3, wall=10137
2025-04-03 07:52:59 | INFO | train_inner | epoch 024:     88 / 126 loss=5.372, nll_loss=1.71, ppl=3.27, wps=1540.8, ups=0.36, wpb=4307, bsz=208, num_updates=2986, lr=2.74503e-05, gnorm=1.742, train_wall=6, gb_free=12.2, wall=10143
2025-04-03 07:53:04 | INFO | train_inner | epoch 024:     90 / 126 loss=5.257, nll_loss=1.574, ppl=2.98, wps=1667.3, ups=0.35, wpb=4769, bsz=324, num_updates=2988, lr=2.74411e-05, gnorm=1.238, train_wall=6, gb_free=9.4, wall=10148
2025-04-03 07:53:10 | INFO | train_inner | epoch 024:     92 / 126 loss=5.356, nll_loss=1.674, ppl=3.19, wps=1430.8, ups=0.33, wpb=4402, bsz=168, num_updates=2990, lr=2.74319e-05, gnorm=1.428, train_wall=6, gb_free=9.2, wall=10154
2025-04-03 07:53:16 | INFO | train_inner | epoch 024:     94 / 126 loss=5.428, nll_loss=1.776, ppl=3.42, wps=1783.6, ups=0.35, wpb=5089.5, bsz=240, num_updates=2992, lr=2.74227e-05, gnorm=1.374, train_wall=6, gb_free=11.1, wall=10160
2025-04-03 07:53:21 | INFO | train_inner | epoch 024:     96 / 126 loss=5.323, nll_loss=1.652, ppl=3.14, wps=1740, ups=0.38, wpb=4550, bsz=180, num_updates=2994, lr=2.74136e-05, gnorm=1.543, train_wall=5, gb_free=12.7, wall=10165
2025-04-03 07:53:27 | INFO | train_inner | epoch 024:     98 / 126 loss=5.258, nll_loss=1.585, ppl=3, wps=1738.6, ups=0.37, wpb=4719, bsz=336, num_updates=2996, lr=2.74044e-05, gnorm=1.326, train_wall=5, gb_free=10.3, wall=10171
2025-04-03 07:53:32 | INFO | train_inner | epoch 024:    100 / 126 loss=5.284, nll_loss=1.585, ppl=3, wps=1499.3, ups=0.37, wpb=4076.5, bsz=172, num_updates=2998, lr=2.73953e-05, gnorm=1.416, train_wall=5, gb_free=11.9, wall=10176
2025-04-03 07:53:38 | INFO | train_inner | epoch 024:    102 / 126 loss=5.296, nll_loss=1.613, ppl=3.06, wps=1490.6, ups=0.37, wpb=4016.5, bsz=228, num_updates=3000, lr=2.73861e-05, gnorm=1.287, train_wall=5, gb_free=9.8, wall=10182
2025-04-03 07:53:43 | INFO | train_inner | epoch 024:    104 / 126 loss=5.34, nll_loss=1.678, ppl=3.2, wps=1474.4, ups=0.37, wpb=4027, bsz=216, num_updates=3002, lr=2.7377e-05, gnorm=1.409, train_wall=5, gb_free=10.7, wall=10187
2025-04-03 07:53:49 | INFO | train_inner | epoch 024:    106 / 126 loss=5.333, nll_loss=1.662, ppl=3.17, wps=1627.7, ups=0.36, wpb=4460, bsz=248, num_updates=3004, lr=2.73679e-05, gnorm=1.3, train_wall=5, gb_free=13.9, wall=10193
2025-04-03 07:53:54 | INFO | train_inner | epoch 024:    108 / 126 loss=5.256, nll_loss=1.568, ppl=2.97, wps=1561.4, ups=0.35, wpb=4452.5, bsz=192, num_updates=3006, lr=2.73588e-05, gnorm=1.315, train_wall=6, gb_free=14.2, wall=10198
2025-04-03 07:54:00 | INFO | train_inner | epoch 024:    110 / 126 loss=5.27, nll_loss=1.573, ppl=2.97, wps=1532.5, ups=0.34, wpb=4521.5, bsz=164, num_updates=3008, lr=2.73497e-05, gnorm=1.374, train_wall=6, gb_free=9.8, wall=10204
2025-04-03 07:54:06 | INFO | train_inner | epoch 024:    112 / 126 loss=5.327, nll_loss=1.643, ppl=3.12, wps=1519.8, ups=0.33, wpb=4565.5, bsz=244, num_updates=3010, lr=2.73406e-05, gnorm=1.296, train_wall=6, gb_free=9.8, wall=10210
2025-04-03 07:54:12 | INFO | train_inner | epoch 024:    114 / 126 loss=5.311, nll_loss=1.627, ppl=3.09, wps=1775.8, ups=0.35, wpb=5045, bsz=260, num_updates=3012, lr=2.73315e-05, gnorm=1.292, train_wall=6, gb_free=11.2, wall=10216
2025-04-03 07:54:18 | INFO | train_inner | epoch 024:    116 / 126 loss=5.385, nll_loss=1.736, ppl=3.33, wps=1814.3, ups=0.35, wpb=5164.5, bsz=240, num_updates=3014, lr=2.73224e-05, gnorm=1.249, train_wall=6, gb_free=12.8, wall=10222
2025-04-03 07:54:23 | INFO | train_inner | epoch 024:    118 / 126 loss=5.418, nll_loss=1.771, ppl=3.41, wps=1485.5, ups=0.35, wpb=4305.5, bsz=128, num_updates=3016, lr=2.73134e-05, gnorm=1.433, train_wall=6, gb_free=10.1, wall=10227
2025-04-03 07:54:29 | INFO | train_inner | epoch 024:    120 / 126 loss=5.246, nll_loss=1.575, ppl=2.98, wps=1661.2, ups=0.37, wpb=4468, bsz=280, num_updates=3018, lr=2.73043e-05, gnorm=1.262, train_wall=5, gb_free=12.9, wall=10233
2025-04-03 07:54:34 | INFO | train_inner | epoch 024:    122 / 126 loss=5.243, nll_loss=1.546, ppl=2.92, wps=1670.3, ups=0.36, wpb=4616, bsz=292, num_updates=3020, lr=2.72953e-05, gnorm=1.214, train_wall=6, gb_free=11.6, wall=10238
2025-04-03 07:54:40 | INFO | train_inner | epoch 024:    124 / 126 loss=5.287, nll_loss=1.59, ppl=3.01, wps=1678.6, ups=0.36, wpb=4673, bsz=268, num_updates=3022, lr=2.72863e-05, gnorm=1.263, train_wall=6, gb_free=13.6, wall=10244
2025-04-03 07:54:44 | INFO | train_inner | epoch 024:    126 / 126 loss=5.282, nll_loss=1.592, ppl=3.01, wps=1650.8, ups=0.46, wpb=3551, bsz=180, num_updates=3024, lr=2.72772e-05, gnorm=1.478, train_wall=4, gb_free=15.3, wall=10248
2025-04-03 07:54:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-03 07:54:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=15946.00390625Mb; avail=239139.1953125Mb
2025-04-03 07:54:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000642
2025-04-03 07:54:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15946.00390625Mb; avail=239139.1953125Mb
2025-04-03 07:54:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.013112
2025-04-03 07:54:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15946.00390625Mb; avail=239139.1953125Mb
2025-04-03 07:54:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.011018
2025-04-03 07:54:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.025129
2025-04-03 07:54:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15946.00390625Mb; avail=239139.1953125Mb
2025-04-03 07:54:58 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 5.896 | nll_loss 2.192 | ppl 4.57 | wps 3862.4 | wpb 2070.5 | bsz 122.7 | num_updates 3024 | best_loss 5.896
2025-04-03 07:54:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3024 updates
2025-04-03 07:54:58 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 07:55:37 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 07:56:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt (epoch 24 @ 3024 updates, score 5.896) (writing took 63.14977293997072 seconds)
2025-04-03 07:56:02 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2025-04-03 07:56:02 | INFO | train | epoch 024 | loss 5.296 | nll_loss 1.615 | ppl 3.06 | wps 1328.4 | ups 0.29 | wpb 4549.7 | bsz 252.8 | num_updates 3024 | lr 2.72772e-05 | gnorm 1.319 | train_wall 353 | gb_free 15.3 | wall 10326
2025-04-03 07:56:02 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:mr-hi': 31849}; raw total size: 31849
2025-04-03 07:56:02 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:mr-hi': 31849}; resampled total size: 31849
2025-04-03 07:56:02 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:mr-hi': 1.0}
2025-04-03 07:56:02 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001016
2025-04-03 07:56:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=26769.1171875Mb; avail=228315.98828125Mb
2025-04-03 07:56:02 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000575
2025-04-03 07:56:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003402
2025-04-03 07:56:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26769.1171875Mb; avail=228315.98828125Mb
2025-04-03 07:56:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000088
2025-04-03 07:56:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26769.1171875Mb; avail=228315.98828125Mb
2025-04-03 07:56:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001126
2025-04-03 07:56:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.004934
2025-04-03 07:56:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26769.1171875Mb; avail=228315.98828125Mb
2025-04-03 07:56:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 126
2025-04-03 07:56:02 | INFO | fairseq.trainer | begin training epoch 25
2025-04-03 07:56:02 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-03 07:56:07 | INFO | train_inner | epoch 025:      2 / 126 loss=5.18, nll_loss=1.474, ppl=2.78, wps=98.5, ups=0.02, wpb=4078, bsz=252, num_updates=3026, lr=2.72682e-05, gnorm=1.246, train_wall=5, gb_free=11.8, wall=10331
2025-04-03 07:56:12 | INFO | train_inner | epoch 025:      4 / 126 loss=5.143, nll_loss=1.436, ppl=2.71, wps=1613.1, ups=0.39, wpb=4103, bsz=296, num_updates=3028, lr=2.72592e-05, gnorm=1.211, train_wall=5, gb_free=13.3, wall=10336
2025-04-03 07:56:17 | INFO | train_inner | epoch 025:      6 / 126 loss=5.3, nll_loss=1.633, ppl=3.1, wps=1779.9, ups=0.38, wpb=4700.5, bsz=224, num_updates=3030, lr=2.72502e-05, gnorm=1.349, train_wall=5, gb_free=13.2, wall=10341
2025-04-03 07:56:23 | INFO | train_inner | epoch 025:      8 / 126 loss=5.321, nll_loss=1.642, ppl=3.12, wps=1571.1, ups=0.38, wpb=4160, bsz=204, num_updates=3032, lr=2.72412e-05, gnorm=1.345, train_wall=5, gb_free=11.7, wall=10347
2025-04-03 07:56:28 | INFO | train_inner | epoch 025:     10 / 126 loss=5.212, nll_loss=1.483, ppl=2.79, wps=1625.8, ups=0.36, wpb=4460, bsz=192, num_updates=3034, lr=2.72322e-05, gnorm=1.253, train_wall=5, gb_free=9.4, wall=10352
2025-04-03 07:56:34 | INFO | train_inner | epoch 025:     12 / 126 loss=5.263, nll_loss=1.56, ppl=2.95, wps=1582.2, ups=0.35, wpb=4582.5, bsz=180, num_updates=3036, lr=2.72233e-05, gnorm=1.302, train_wall=6, gb_free=12.8, wall=10358
2025-04-03 07:56:39 | INFO | train_inner | epoch 025:     14 / 126 loss=5.305, nll_loss=1.638, ppl=3.11, wps=1612.8, ups=0.39, wpb=4185, bsz=212, num_updates=3038, lr=2.72143e-05, gnorm=1.371, train_wall=5, gb_free=14.1, wall=10363
2025-04-03 07:56:45 | INFO | train_inner | epoch 025:     16 / 126 loss=5.198, nll_loss=1.497, ppl=2.82, wps=1639.9, ups=0.36, wpb=4546, bsz=292, num_updates=3040, lr=2.72054e-05, gnorm=1.218, train_wall=6, gb_free=14.8, wall=10369
2025-04-03 07:56:50 | INFO | train_inner | epoch 025:     18 / 126 loss=5.212, nll_loss=1.517, ppl=2.86, wps=1574.4, ups=0.4, wpb=3941, bsz=340, num_updates=3042, lr=2.71964e-05, gnorm=1.231, train_wall=5, gb_free=14.8, wall=10374
2025-04-03 07:56:55 | INFO | train_inner | epoch 025:     20 / 126 loss=5.293, nll_loss=1.617, ppl=3.07, wps=1557.5, ups=0.39, wpb=4024.5, bsz=232, num_updates=3044, lr=2.71875e-05, gnorm=1.342, train_wall=5, gb_free=12.4, wall=10379
2025-04-03 07:57:00 | INFO | train_inner | epoch 025:     22 / 126 loss=5.177, nll_loss=1.444, ppl=2.72, wps=1747.4, ups=0.35, wpb=5053, bsz=264, num_updates=3046, lr=2.71786e-05, gnorm=1.221, train_wall=6, gb_free=9.5, wall=10385
2025-04-03 07:57:06 | INFO | train_inner | epoch 025:     24 / 126 loss=5.289, nll_loss=1.591, ppl=3.01, wps=1662.2, ups=0.35, wpb=4731, bsz=188, num_updates=3048, lr=2.71696e-05, gnorm=1.35, train_wall=6, gb_free=10.4, wall=10390
2025-04-03 07:57:12 | INFO | train_inner | epoch 025:     26 / 126 loss=5.235, nll_loss=1.549, ppl=2.93, wps=1680.5, ups=0.37, wpb=4586, bsz=168, num_updates=3050, lr=2.71607e-05, gnorm=1.3, train_wall=5, gb_free=12.3, wall=10396
2025-04-03 07:57:17 | INFO | train_inner | epoch 025:     28 / 126 loss=5.172, nll_loss=1.485, ppl=2.8, wps=1473.9, ups=0.37, wpb=4012, bsz=280, num_updates=3052, lr=2.71518e-05, gnorm=1.419, train_wall=5, gb_free=9.3, wall=10401
2025-04-03 07:57:23 | INFO | train_inner | epoch 025:     30 / 126 loss=5.278, nll_loss=1.604, ppl=3.04, wps=1659.5, ups=0.36, wpb=4587.5, bsz=276, num_updates=3054, lr=2.71429e-05, gnorm=1.251, train_wall=6, gb_free=11.4, wall=10407
2025-04-03 07:57:28 | INFO | train_inner | epoch 025:     32 / 126 loss=5.214, nll_loss=1.498, ppl=2.82, wps=1430.1, ups=0.37, wpb=3867.5, bsz=228, num_updates=3056, lr=2.7134e-05, gnorm=1.361, train_wall=5, gb_free=15.1, wall=10412
2025-04-03 07:57:34 | INFO | train_inner | epoch 025:     34 / 126 loss=5.176, nll_loss=1.46, ppl=2.75, wps=1602.3, ups=0.36, wpb=4397, bsz=328, num_updates=3058, lr=2.71252e-05, gnorm=1.254, train_wall=5, gb_free=11, wall=10418
2025-04-03 07:57:39 | INFO | train_inner | epoch 025:     36 / 126 loss=5.104, nll_loss=1.375, ppl=2.59, wps=1622.6, ups=0.38, wpb=4240, bsz=280, num_updates=3060, lr=2.71163e-05, gnorm=1.257, train_wall=5, gb_free=13.4, wall=10423
2025-04-03 07:57:45 | INFO | train_inner | epoch 025:     38 / 126 loss=5.242, nll_loss=1.562, ppl=2.95, wps=1843.9, ups=0.35, wpb=5317.5, bsz=296, num_updates=3062, lr=2.71075e-05, gnorm=1.216, train_wall=6, gb_free=12.9, wall=10429
2025-04-03 07:57:50 | INFO | train_inner | epoch 025:     40 / 126 loss=5.271, nll_loss=1.588, ppl=3.01, wps=1835.3, ups=0.35, wpb=5196.5, bsz=332, num_updates=3064, lr=2.70986e-05, gnorm=1.312, train_wall=6, gb_free=14.1, wall=10434
2025-04-03 07:57:55 | INFO | train_inner | epoch 025:     42 / 126 loss=5.198, nll_loss=1.483, ppl=2.79, wps=1577.8, ups=0.38, wpb=4147.5, bsz=244, num_updates=3066, lr=2.70898e-05, gnorm=1.395, train_wall=5, gb_free=14, wall=10440
2025-04-03 07:58:01 | INFO | train_inner | epoch 025:     44 / 126 loss=5.215, nll_loss=1.509, ppl=2.85, wps=1635.2, ups=0.35, wpb=4624, bsz=232, num_updates=3068, lr=2.70809e-05, gnorm=1.257, train_wall=6, gb_free=13.1, wall=10445
2025-04-03 07:58:07 | INFO | train_inner | epoch 025:     46 / 126 loss=5.276, nll_loss=1.587, ppl=3, wps=1799.3, ups=0.35, wpb=5163.5, bsz=212, num_updates=3070, lr=2.70721e-05, gnorm=1.288, train_wall=6, gb_free=12.5, wall=10451
2025-04-03 07:58:12 | INFO | train_inner | epoch 025:     48 / 126 loss=5.238, nll_loss=1.555, ppl=2.94, wps=1613.8, ups=0.41, wpb=3961.5, bsz=148, num_updates=3072, lr=2.70633e-05, gnorm=1.685, train_wall=5, gb_free=11, wall=10456
2025-04-03 07:58:17 | INFO | train_inner | epoch 025:     50 / 126 loss=5.298, nll_loss=1.618, ppl=3.07, wps=1652.2, ups=0.38, wpb=4334.5, bsz=192, num_updates=3074, lr=2.70545e-05, gnorm=1.427, train_wall=5, gb_free=13.9, wall=10461
2025-04-03 07:58:22 | INFO | train_inner | epoch 025:     52 / 126 loss=5.343, nll_loss=1.659, ppl=3.16, wps=1607.3, ups=0.41, wpb=3886.5, bsz=200, num_updates=3076, lr=2.70457e-05, gnorm=1.535, train_wall=5, gb_free=10.2, wall=10466
2025-04-03 07:58:27 | INFO | train_inner | epoch 025:     54 / 126 loss=5.233, nll_loss=1.529, ppl=2.89, wps=1777.4, ups=0.41, wpb=4351, bsz=300.5, num_updates=3078, lr=2.70369e-05, gnorm=1.328, train_wall=5, gb_free=12.5, wall=10471
2025-04-03 07:58:32 | INFO | train_inner | epoch 025:     56 / 126 loss=5.164, nll_loss=1.437, ppl=2.71, wps=1771.1, ups=0.37, wpb=4778, bsz=300, num_updates=3080, lr=2.70281e-05, gnorm=1.18, train_wall=5, gb_free=12.3, wall=10476
2025-04-03 07:58:38 | INFO | train_inner | epoch 025:     58 / 126 loss=5.28, nll_loss=1.594, ppl=3.02, wps=1628.2, ups=0.34, wpb=4805.5, bsz=152, num_updates=3082, lr=2.70194e-05, gnorm=1.335, train_wall=6, gb_free=9.9, wall=10482
2025-04-03 07:58:44 | INFO | train_inner | epoch 025:     60 / 126 loss=5.212, nll_loss=1.532, ppl=2.89, wps=1724.6, ups=0.34, wpb=5082, bsz=320, num_updates=3084, lr=2.70106e-05, gnorm=1.413, train_wall=6, gb_free=11.1, wall=10488
2025-04-03 07:58:50 | INFO | train_inner | epoch 025:     62 / 126 loss=5.328, nll_loss=1.658, ppl=3.16, wps=1714.9, ups=0.34, wpb=4997.5, bsz=224, num_updates=3086, lr=2.70018e-05, gnorm=1.32, train_wall=6, gb_free=11.2, wall=10494
2025-04-03 07:58:56 | INFO | train_inner | epoch 025:     64 / 126 loss=5.276, nll_loss=1.565, ppl=2.96, wps=1570, ups=0.34, wpb=4593.5, bsz=264, num_updates=3088, lr=2.69931e-05, gnorm=1.319, train_wall=6, gb_free=11.6, wall=10500
2025-04-03 07:59:01 | INFO | train_inner | epoch 025:     66 / 126 loss=5.289, nll_loss=1.594, ppl=3.02, wps=1615.7, ups=0.35, wpb=4663, bsz=240, num_updates=3090, lr=2.69844e-05, gnorm=1.286, train_wall=6, gb_free=11.6, wall=10505
2025-04-03 07:59:07 | INFO | train_inner | epoch 025:     68 / 126 loss=5.254, nll_loss=1.552, ppl=2.93, wps=1586.5, ups=0.38, wpb=4199.5, bsz=196, num_updates=3092, lr=2.69756e-05, gnorm=1.343, train_wall=5, gb_free=14, wall=10511
2025-04-03 07:59:12 | INFO | train_inner | epoch 025:     70 / 126 loss=5.274, nll_loss=1.602, ppl=3.04, wps=1671.2, ups=0.35, wpb=4771.5, bsz=264, num_updates=3094, lr=2.69669e-05, gnorm=1.224, train_wall=6, gb_free=13.8, wall=10516
2025-04-03 07:59:17 | INFO | train_inner | epoch 025:     72 / 126 loss=5.236, nll_loss=1.557, ppl=2.94, wps=1571.2, ups=0.4, wpb=3927.5, bsz=252, num_updates=3096, lr=2.69582e-05, gnorm=1.335, train_wall=5, gb_free=14.4, wall=10521
2025-04-03 07:59:23 | INFO | train_inner | epoch 025:     74 / 126 loss=5.249, nll_loss=1.536, ppl=2.9, wps=1691.5, ups=0.38, wpb=4436, bsz=176, num_updates=3098, lr=2.69495e-05, gnorm=1.431, train_wall=5, gb_free=15.3, wall=10527
2025-04-03 07:59:29 | INFO | train_inner | epoch 025:     76 / 126 loss=5.244, nll_loss=1.509, ppl=2.85, wps=1409.1, ups=0.33, wpb=4244.5, bsz=96, num_updates=3100, lr=2.69408e-05, gnorm=1.506, train_wall=6, gb_free=9.3, wall=10533
2025-04-03 07:59:34 | INFO | train_inner | epoch 025:     78 / 126 loss=5.233, nll_loss=1.542, ppl=2.91, wps=1624.1, ups=0.36, wpb=4541.5, bsz=284, num_updates=3102, lr=2.69321e-05, gnorm=1.256, train_wall=6, gb_free=9.8, wall=10538
2025-04-03 07:59:40 | INFO | train_inner | epoch 025:     80 / 126 loss=5.188, nll_loss=1.477, ppl=2.78, wps=1730.8, ups=0.37, wpb=4647.5, bsz=300, num_updates=3104, lr=2.69234e-05, gnorm=1.204, train_wall=5, gb_free=11.9, wall=10544
2025-04-03 07:59:45 | INFO | train_inner | epoch 025:     82 / 126 loss=5.283, nll_loss=1.612, ppl=3.06, wps=1621.8, ups=0.36, wpb=4448, bsz=236, num_updates=3106, lr=2.69148e-05, gnorm=1.377, train_wall=5, gb_free=13.4, wall=10549
2025-04-03 07:59:51 | INFO | train_inner | epoch 025:     84 / 126 loss=5.222, nll_loss=1.51, ppl=2.85, wps=1732.1, ups=0.36, wpb=4784.5, bsz=236, num_updates=3108, lr=2.69061e-05, gnorm=1.221, train_wall=6, gb_free=10.8, wall=10555
2025-04-03 07:59:56 | INFO | train_inner | epoch 025:     86 / 126 loss=5.401, nll_loss=1.753, ppl=3.37, wps=1759.9, ups=0.34, wpb=5166.5, bsz=276, num_updates=3110, lr=2.68974e-05, gnorm=1.253, train_wall=6, gb_free=10.2, wall=10561
2025-04-03 08:00:02 | INFO | train_inner | epoch 025:     88 / 126 loss=5.329, nll_loss=1.671, ppl=3.18, wps=1755.4, ups=0.35, wpb=5073, bsz=300, num_updates=3112, lr=2.68888e-05, gnorm=1.295, train_wall=6, gb_free=9.8, wall=10566
2025-04-03 08:00:08 | INFO | train_inner | epoch 025:     90 / 126 loss=5.219, nll_loss=1.529, ppl=2.89, wps=1719.9, ups=0.36, wpb=4792, bsz=336, num_updates=3114, lr=2.68802e-05, gnorm=1.268, train_wall=6, gb_free=12.5, wall=10572
2025-04-03 08:00:19 | INFO | train_inner | epoch 025:     92 / 126 loss=5.327, nll_loss=1.669, ppl=3.18, wps=952.9, ups=0.18, wpb=5168, bsz=336, num_updates=3116, lr=2.68715e-05, gnorm=1.24, train_wall=11, gb_free=12.4, wall=10583
2025-04-03 08:00:24 | INFO | train_inner | epoch 025:     94 / 126 loss=5.223, nll_loss=1.515, ppl=2.86, wps=1453.4, ups=0.37, wpb=3906, bsz=216, num_updates=3118, lr=2.68629e-05, gnorm=1.325, train_wall=5, gb_free=13.5, wall=10588
2025-04-03 08:00:30 | INFO | train_inner | epoch 025:     96 / 126 loss=5.291, nll_loss=1.616, ppl=3.06, wps=1775, ups=0.37, wpb=4857, bsz=312, num_updates=3120, lr=2.68543e-05, gnorm=1.24, train_wall=5, gb_free=13.2, wall=10594
2025-04-03 08:00:35 | INFO | train_inner | epoch 025:     98 / 126 loss=5.306, nll_loss=1.642, ppl=3.12, wps=1807.9, ups=0.35, wpb=5204.5, bsz=332, num_updates=3122, lr=2.68457e-05, gnorm=1.293, train_wall=6, gb_free=12.8, wall=10599
2025-04-03 08:00:41 | INFO | train_inner | epoch 025:    100 / 126 loss=5.225, nll_loss=1.529, ppl=2.89, wps=1536.5, ups=0.37, wpb=4146.5, bsz=244, num_updates=3124, lr=2.68371e-05, gnorm=1.386, train_wall=5, gb_free=13.6, wall=10605
2025-04-03 08:00:46 | INFO | train_inner | epoch 025:    102 / 126 loss=5.238, nll_loss=1.535, ppl=2.9, wps=1597.2, ups=0.36, wpb=4392.5, bsz=228, num_updates=3126, lr=2.68285e-05, gnorm=1.281, train_wall=5, gb_free=12.6, wall=10610
2025-04-03 08:00:52 | INFO | train_inner | epoch 025:    104 / 126 loss=5.244, nll_loss=1.559, ppl=2.95, wps=1736.7, ups=0.34, wpb=5145, bsz=328, num_updates=3128, lr=2.68199e-05, gnorm=1.179, train_wall=6, gb_free=8.5, wall=10616
2025-04-03 08:00:58 | INFO | train_inner | epoch 025:    106 / 126 loss=5.224, nll_loss=1.535, ppl=2.9, wps=1830.3, ups=0.36, wpb=5040.5, bsz=328, num_updates=3130, lr=2.68114e-05, gnorm=1.191, train_wall=5, gb_free=12.2, wall=10622
2025-04-03 08:01:03 | INFO | train_inner | epoch 025:    108 / 126 loss=5.204, nll_loss=1.504, ppl=2.84, wps=1623.4, ups=0.38, wpb=4302, bsz=252, num_updates=3132, lr=2.68028e-05, gnorm=1.325, train_wall=5, gb_free=13.5, wall=10627
2025-04-03 08:01:09 | INFO | train_inner | epoch 025:    110 / 126 loss=5.313, nll_loss=1.621, ppl=3.08, wps=1751.1, ups=0.34, wpb=5185, bsz=324, num_updates=3134, lr=2.67943e-05, gnorm=1.733, train_wall=6, gb_free=11.5, wall=10633
2025-04-03 08:01:15 | INFO | train_inner | epoch 025:    112 / 126 loss=5.198, nll_loss=1.5, ppl=2.83, wps=1674.7, ups=0.35, wpb=4819.5, bsz=352, num_updates=3136, lr=2.67857e-05, gnorm=1.188, train_wall=6, gb_free=9.9, wall=10639
2025-04-03 08:01:20 | INFO | train_inner | epoch 025:    114 / 126 loss=5.371, nll_loss=1.737, ppl=3.33, wps=1769.5, ups=0.34, wpb=5142.5, bsz=340, num_updates=3138, lr=2.67772e-05, gnorm=1.268, train_wall=6, gb_free=10, wall=10645
2025-04-03 08:01:26 | INFO | train_inner | epoch 025:    116 / 126 loss=5.327, nll_loss=1.662, ppl=3.16, wps=1684.8, ups=0.36, wpb=4687.5, bsz=252, num_updates=3140, lr=2.67686e-05, gnorm=1.331, train_wall=6, gb_free=14.2, wall=10650
2025-04-03 08:01:32 | INFO | train_inner | epoch 025:    118 / 126 loss=5.288, nll_loss=1.587, ppl=3, wps=1522.4, ups=0.35, wpb=4387, bsz=172, num_updates=3142, lr=2.67601e-05, gnorm=1.37, train_wall=6, gb_free=9, wall=10656
2025-04-03 08:01:37 | INFO | train_inner | epoch 025:    120 / 126 loss=5.288, nll_loss=1.577, ppl=2.98, wps=1626, ups=0.36, wpb=4545.5, bsz=208, num_updates=3144, lr=2.67516e-05, gnorm=1.29, train_wall=6, gb_free=12.3, wall=10661
2025-04-03 08:01:43 | INFO | train_inner | epoch 025:    122 / 126 loss=5.197, nll_loss=1.481, ppl=2.79, wps=1524, ups=0.37, wpb=4156.5, bsz=212, num_updates=3146, lr=2.67431e-05, gnorm=1.295, train_wall=5, gb_free=9.2, wall=10667
2025-04-03 08:01:48 | INFO | train_inner | epoch 025:    124 / 126 loss=5.228, nll_loss=1.552, ppl=2.93, wps=1724.3, ups=0.36, wpb=4737, bsz=324, num_updates=3148, lr=2.67346e-05, gnorm=1.209, train_wall=5, gb_free=11.1, wall=10672
2025-04-03 08:01:53 | INFO | train_inner | epoch 025:    126 / 126 loss=5.348, nll_loss=1.696, ppl=3.24, wps=1653.2, ups=0.46, wpb=3620.5, bsz=120, num_updates=3150, lr=2.67261e-05, gnorm=1.618, train_wall=4, gb_free=15.7, wall=10677
2025-04-03 08:01:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-03 08:01:53 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=15972.33984375Mb; avail=239112.859375Mb
2025-04-03 08:01:53 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000641
2025-04-03 08:01:53 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15972.33984375Mb; avail=239112.859375Mb
2025-04-03 08:01:53 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012929
2025-04-03 08:01:53 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15972.33984375Mb; avail=239112.859375Mb
2025-04-03 08:01:53 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.011053
2025-04-03 08:01:53 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024975
2025-04-03 08:01:53 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15972.33984375Mb; avail=239112.859375Mb
2025-04-03 08:02:07 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 5.889 | nll_loss 2.195 | ppl 4.58 | wps 3865.1 | wpb 2070.5 | bsz 122.7 | num_updates 3150 | best_loss 5.889
2025-04-03 08:02:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3150 updates
2025-04-03 08:02:07 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 08:02:45 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 08:03:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt (epoch 25 @ 3150 updates, score 5.889) (writing took 62.245251649059355 seconds)
2025-04-03 08:03:09 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2025-04-03 08:03:09 | INFO | train | epoch 025 | loss 5.254 | nll_loss 1.563 | ppl 2.95 | wps 1340.5 | ups 0.29 | wpb 4549.7 | bsz 252.8 | num_updates 3150 | lr 2.67261e-05 | gnorm 1.318 | train_wall 350 | gb_free 15.7 | wall 10753
2025-04-03 08:03:09 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:mr-hi': 31849}; raw total size: 31849
2025-04-03 08:03:09 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:mr-hi': 31849}; resampled total size: 31849
2025-04-03 08:03:09 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:mr-hi': 1.0}
2025-04-03 08:03:09 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001168
2025-04-03 08:03:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=26769.3046875Mb; avail=228315.8203125Mb
2025-04-03 08:03:09 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000574
2025-04-03 08:03:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003838
2025-04-03 08:03:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26769.796875Mb; avail=228315.328125Mb
2025-04-03 08:03:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000127
2025-04-03 08:03:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26769.796875Mb; avail=228315.328125Mb
2025-04-03 08:03:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001150
2025-04-03 08:03:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.005447
2025-04-03 08:03:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26769.796875Mb; avail=228315.328125Mb
2025-04-03 08:03:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 126
2025-04-03 08:03:09 | INFO | fairseq.trainer | begin training epoch 26
2025-04-03 08:03:09 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-03 08:03:15 | INFO | train_inner | epoch 026:      2 / 126 loss=5.107, nll_loss=1.389, ppl=2.62, wps=118, ups=0.02, wpb=4860.5, bsz=304, num_updates=3152, lr=2.67176e-05, gnorm=1.157, train_wall=6, gb_free=8.9, wall=10759
2025-04-03 08:03:21 | INFO | train_inner | epoch 026:      4 / 126 loss=5.179, nll_loss=1.464, ppl=2.76, wps=1683.5, ups=0.35, wpb=4817, bsz=340, num_updates=3154, lr=2.67092e-05, gnorm=1.147, train_wall=6, gb_free=9.3, wall=10765
2025-04-03 08:03:26 | INFO | train_inner | epoch 026:      6 / 126 loss=5.16, nll_loss=1.441, ppl=2.72, wps=1373.8, ups=0.37, wpb=3723.5, bsz=252, num_updates=3156, lr=2.67007e-05, gnorm=1.338, train_wall=5, gb_free=11.7, wall=10770
2025-04-03 08:03:32 | INFO | train_inner | epoch 026:      8 / 126 loss=5.2, nll_loss=1.493, ppl=2.81, wps=1724.8, ups=0.35, wpb=4913.5, bsz=212, num_updates=3158, lr=2.66923e-05, gnorm=1.463, train_wall=6, gb_free=10, wall=10776
2025-04-03 08:03:37 | INFO | train_inner | epoch 026:     10 / 126 loss=5.21, nll_loss=1.502, ppl=2.83, wps=1711.6, ups=0.4, wpb=4302, bsz=224, num_updates=3160, lr=2.66838e-05, gnorm=1.475, train_wall=5, gb_free=10.7, wall=10781
2025-04-03 08:03:42 | INFO | train_inner | epoch 026:     12 / 126 loss=5.112, nll_loss=1.383, ppl=2.61, wps=1541.4, ups=0.38, wpb=4087.5, bsz=280, num_updates=3162, lr=2.66754e-05, gnorm=1.261, train_wall=5, gb_free=13.7, wall=10786
2025-04-03 08:03:48 | INFO | train_inner | epoch 026:     14 / 126 loss=5.066, nll_loss=1.324, ppl=2.5, wps=1593.6, ups=0.36, wpb=4392.5, bsz=232, num_updates=3164, lr=2.66669e-05, gnorm=1.202, train_wall=6, gb_free=10.9, wall=10792
2025-04-03 08:03:53 | INFO | train_inner | epoch 026:     16 / 126 loss=5.228, nll_loss=1.526, ppl=2.88, wps=1704.9, ups=0.35, wpb=4909, bsz=284, num_updates=3166, lr=2.66585e-05, gnorm=1.224, train_wall=6, gb_free=13.8, wall=10798
2025-04-03 08:03:59 | INFO | train_inner | epoch 026:     18 / 126 loss=5.248, nll_loss=1.569, ppl=2.97, wps=1571.6, ups=0.38, wpb=4177, bsz=216, num_updates=3168, lr=2.66501e-05, gnorm=1.552, train_wall=5, gb_free=12.9, wall=10803
2025-04-03 08:04:04 | INFO | train_inner | epoch 026:     20 / 126 loss=5.206, nll_loss=1.51, ppl=2.85, wps=1789.1, ups=0.36, wpb=4947.5, bsz=288, num_updates=3170, lr=2.66417e-05, gnorm=1.127, train_wall=6, gb_free=13.7, wall=10808
2025-04-03 08:04:10 | INFO | train_inner | epoch 026:     22 / 126 loss=5.151, nll_loss=1.413, ppl=2.66, wps=1618.8, ups=0.33, wpb=4881, bsz=236, num_updates=3172, lr=2.66333e-05, gnorm=1.129, train_wall=6, gb_free=11.8, wall=10814
2025-04-03 08:04:21 | INFO | train_inner | epoch 026:     24 / 126 loss=5.129, nll_loss=1.394, ppl=2.63, wps=830, ups=0.19, wpb=4421.5, bsz=268, num_updates=3174, lr=2.66249e-05, gnorm=1.186, train_wall=11, gb_free=13.4, wall=10825
2025-04-03 08:04:27 | INFO | train_inner | epoch 026:     26 / 126 loss=5.222, nll_loss=1.523, ppl=2.87, wps=1675, ups=0.35, wpb=4779.5, bsz=220, num_updates=3176, lr=2.66165e-05, gnorm=1.271, train_wall=6, gb_free=8.1, wall=10831
2025-04-03 08:04:32 | INFO | train_inner | epoch 026:     28 / 126 loss=5.203, nll_loss=1.498, ppl=2.82, wps=1659, ups=0.37, wpb=4496, bsz=224, num_updates=3178, lr=2.66081e-05, gnorm=1.42, train_wall=5, gb_free=11.7, wall=10836
2025-04-03 08:04:38 | INFO | train_inner | epoch 026:     30 / 126 loss=5.308, nll_loss=1.628, ppl=3.09, wps=1738.4, ups=0.35, wpb=4980, bsz=288, num_updates=3180, lr=2.65998e-05, gnorm=1.286, train_wall=6, gb_free=11.1, wall=10842
2025-04-03 08:04:44 | INFO | train_inner | epoch 026:     32 / 126 loss=5.248, nll_loss=1.529, ppl=2.89, wps=1596.2, ups=0.35, wpb=4538, bsz=172, num_updates=3182, lr=2.65914e-05, gnorm=1.27, train_wall=6, gb_free=13.9, wall=10848
2025-04-03 08:04:49 | INFO | train_inner | epoch 026:     34 / 126 loss=5.113, nll_loss=1.375, ppl=2.59, wps=1663.1, ups=0.36, wpb=4633, bsz=224, num_updates=3184, lr=2.6583e-05, gnorm=1.331, train_wall=6, gb_free=12.2, wall=10853
2025-04-03 08:04:55 | INFO | train_inner | epoch 026:     36 / 126 loss=5.188, nll_loss=1.496, ppl=2.82, wps=1743.4, ups=0.36, wpb=4868, bsz=312, num_updates=3186, lr=2.65747e-05, gnorm=1.177, train_wall=6, gb_free=10.2, wall=10859
2025-04-03 08:04:59 | INFO | train_inner | epoch 026:     38 / 126 loss=5.117, nll_loss=1.39, ppl=2.62, wps=1618.6, ups=0.43, wpb=3777, bsz=192, num_updates=3188, lr=2.65664e-05, gnorm=1.584, train_wall=5, gb_free=14.4, wall=10863
2025-04-03 08:05:05 | INFO | train_inner | epoch 026:     40 / 126 loss=5.156, nll_loss=1.432, ppl=2.7, wps=1579.9, ups=0.35, wpb=4467, bsz=248, num_updates=3190, lr=2.6558e-05, gnorm=1.208, train_wall=6, gb_free=12.9, wall=10869
2025-04-03 08:05:11 | INFO | train_inner | epoch 026:     42 / 126 loss=5.191, nll_loss=1.477, ppl=2.78, wps=1719.4, ups=0.35, wpb=4898, bsz=284, num_updates=3192, lr=2.65497e-05, gnorm=1.304, train_wall=6, gb_free=10.2, wall=10875
2025-04-03 08:05:16 | INFO | train_inner | epoch 026:     44 / 126 loss=5.221, nll_loss=1.543, ppl=2.91, wps=1415.5, ups=0.36, wpb=3973.5, bsz=328, num_updates=3194, lr=2.65414e-05, gnorm=1.232, train_wall=6, gb_free=10.3, wall=10880
2025-04-03 08:05:22 | INFO | train_inner | epoch 026:     46 / 126 loss=5.218, nll_loss=1.516, ppl=2.86, wps=1577, ups=0.35, wpb=4552, bsz=256, num_updates=3196, lr=2.65331e-05, gnorm=1.258, train_wall=6, gb_free=10.7, wall=10886
2025-04-03 08:05:28 | INFO | train_inner | epoch 026:     48 / 126 loss=5.146, nll_loss=1.42, ppl=2.68, wps=1615.2, ups=0.37, wpb=4369, bsz=228, num_updates=3198, lr=2.65248e-05, gnorm=1.217, train_wall=5, gb_free=13.4, wall=10892
2025-04-03 08:05:33 | INFO | train_inner | epoch 026:     50 / 126 loss=5.165, nll_loss=1.444, ppl=2.72, wps=1763.3, ups=0.36, wpb=4923.5, bsz=288, num_updates=3200, lr=2.65165e-05, gnorm=1.169, train_wall=6, gb_free=11.6, wall=10897
2025-04-03 08:05:39 | INFO | train_inner | epoch 026:     52 / 126 loss=5.187, nll_loss=1.471, ppl=2.77, wps=1632.4, ups=0.36, wpb=4518.5, bsz=224, num_updates=3202, lr=2.65082e-05, gnorm=1.262, train_wall=6, gb_free=14.4, wall=10903
2025-04-03 08:05:44 | INFO | train_inner | epoch 026:     54 / 126 loss=5.194, nll_loss=1.502, ppl=2.83, wps=1596.3, ups=0.38, wpb=4162.5, bsz=264, num_updates=3204, lr=2.64999e-05, gnorm=1.35, train_wall=5, gb_free=13, wall=10908
2025-04-03 08:05:49 | INFO | train_inner | epoch 026:     56 / 126 loss=5.184, nll_loss=1.485, ppl=2.8, wps=1812.8, ups=0.36, wpb=5023, bsz=240, num_updates=3206, lr=2.64917e-05, gnorm=1.258, train_wall=6, gb_free=14.9, wall=10913
2025-04-03 08:05:55 | INFO | train_inner | epoch 026:     58 / 126 loss=5.245, nll_loss=1.536, ppl=2.9, wps=1669.4, ups=0.34, wpb=4887, bsz=232, num_updates=3208, lr=2.64834e-05, gnorm=1.307, train_wall=6, gb_free=10.4, wall=10919
2025-04-03 08:06:01 | INFO | train_inner | epoch 026:     60 / 126 loss=5.222, nll_loss=1.507, ppl=2.84, wps=1656, ups=0.36, wpb=4651.5, bsz=216, num_updates=3210, lr=2.64752e-05, gnorm=1.34, train_wall=6, gb_free=9, wall=10925
2025-04-03 08:06:07 | INFO | train_inner | epoch 026:     62 / 126 loss=5.231, nll_loss=1.519, ppl=2.87, wps=1609.2, ups=0.34, wpb=4697, bsz=144, num_updates=3212, lr=2.64669e-05, gnorm=1.493, train_wall=6, gb_free=8.6, wall=10931
2025-04-03 08:06:13 | INFO | train_inner | epoch 026:     64 / 126 loss=5.323, nll_loss=1.673, ppl=3.19, wps=1775.2, ups=0.34, wpb=5177.5, bsz=292, num_updates=3214, lr=2.64587e-05, gnorm=1.302, train_wall=6, gb_free=9.1, wall=10937
2025-04-03 08:06:18 | INFO | train_inner | epoch 026:     66 / 126 loss=5.167, nll_loss=1.461, ppl=2.75, wps=1682.7, ups=0.37, wpb=4588, bsz=224, num_updates=3216, lr=2.64505e-05, gnorm=1.286, train_wall=5, gb_free=11.9, wall=10942
2025-04-03 08:06:23 | INFO | train_inner | epoch 026:     68 / 126 loss=5.131, nll_loss=1.395, ppl=2.63, wps=1545.5, ups=0.37, wpb=4228, bsz=228, num_updates=3218, lr=2.64422e-05, gnorm=1.263, train_wall=5, gb_free=14.1, wall=10948
2025-04-03 08:06:29 | INFO | train_inner | epoch 026:     70 / 126 loss=5.164, nll_loss=1.425, ppl=2.69, wps=1669.2, ups=0.37, wpb=4561.5, bsz=200, num_updates=3220, lr=2.6434e-05, gnorm=1.238, train_wall=5, gb_free=12.9, wall=10953
2025-04-03 08:06:34 | INFO | train_inner | epoch 026:     72 / 126 loss=5.125, nll_loss=1.386, ppl=2.61, wps=1717, ups=0.36, wpb=4744.5, bsz=296, num_updates=3222, lr=2.64258e-05, gnorm=1.214, train_wall=6, gb_free=12.1, wall=10959
2025-04-03 08:06:40 | INFO | train_inner | epoch 026:     74 / 126 loss=5.184, nll_loss=1.501, ppl=2.83, wps=1620.8, ups=0.36, wpb=4465.5, bsz=328, num_updates=3224, lr=2.64176e-05, gnorm=1.203, train_wall=6, gb_free=14.2, wall=10964
2025-04-03 08:06:46 | INFO | train_inner | epoch 026:     76 / 126 loss=5.187, nll_loss=1.504, ppl=2.84, wps=1689.8, ups=0.35, wpb=4875, bsz=256, num_updates=3226, lr=2.64094e-05, gnorm=1.22, train_wall=6, gb_free=13, wall=10970
2025-04-03 08:06:51 | INFO | train_inner | epoch 026:     78 / 126 loss=5.151, nll_loss=1.456, ppl=2.74, wps=1639.1, ups=0.37, wpb=4463.5, bsz=356, num_updates=3228, lr=2.64013e-05, gnorm=1.247, train_wall=5, gb_free=11.3, wall=10975
2025-04-03 08:06:57 | INFO | train_inner | epoch 026:     80 / 126 loss=5.125, nll_loss=1.384, ppl=2.61, wps=1568.3, ups=0.36, wpb=4361, bsz=292, num_updates=3230, lr=2.63931e-05, gnorm=1.217, train_wall=6, gb_free=9.2, wall=10981
2025-04-03 08:07:02 | INFO | train_inner | epoch 026:     82 / 126 loss=5.19, nll_loss=1.477, ppl=2.78, wps=1750.6, ups=0.37, wpb=4753.5, bsz=288, num_updates=3232, lr=2.63849e-05, gnorm=1.236, train_wall=5, gb_free=11.8, wall=10986
2025-04-03 08:07:07 | INFO | train_inner | epoch 026:     84 / 126 loss=5.195, nll_loss=1.503, ppl=2.83, wps=1783.2, ups=0.39, wpb=4537.5, bsz=276, num_updates=3234, lr=2.63767e-05, gnorm=1.33, train_wall=5, gb_free=12.7, wall=10991
2025-04-03 08:07:13 | INFO | train_inner | epoch 026:     86 / 126 loss=5.223, nll_loss=1.54, ppl=2.91, wps=1651.3, ups=0.35, wpb=4763, bsz=260, num_updates=3236, lr=2.63686e-05, gnorm=1.32, train_wall=6, gb_free=9, wall=10997
2025-04-03 08:07:19 | INFO | train_inner | epoch 026:     88 / 126 loss=5.208, nll_loss=1.519, ppl=2.87, wps=1746.3, ups=0.36, wpb=4845, bsz=296, num_updates=3238, lr=2.63605e-05, gnorm=1.336, train_wall=6, gb_free=8.7, wall=11003
2025-04-03 08:07:25 | INFO | train_inner | epoch 026:     90 / 126 loss=5.179, nll_loss=1.462, ppl=2.76, wps=1486.1, ups=0.33, wpb=4454.5, bsz=208, num_updates=3240, lr=2.63523e-05, gnorm=1.252, train_wall=6, gb_free=10.3, wall=11009
2025-04-03 08:07:30 | INFO | train_inner | epoch 026:     92 / 126 loss=5.252, nll_loss=1.544, ppl=2.92, wps=1569.5, ups=0.34, wpb=4611, bsz=176, num_updates=3242, lr=2.63442e-05, gnorm=1.32, train_wall=6, gb_free=10.5, wall=11015
2025-04-03 08:07:36 | INFO | train_inner | epoch 026:     94 / 126 loss=5.207, nll_loss=1.484, ppl=2.8, wps=1796.2, ups=0.36, wpb=5031, bsz=276, num_updates=3244, lr=2.63361e-05, gnorm=1.259, train_wall=6, gb_free=12, wall=11020
2025-04-03 08:07:42 | INFO | train_inner | epoch 026:     96 / 126 loss=5.182, nll_loss=1.463, ppl=2.76, wps=1659.2, ups=0.35, wpb=4791, bsz=200, num_updates=3246, lr=2.63279e-05, gnorm=1.237, train_wall=6, gb_free=10.6, wall=11026
2025-04-03 08:07:47 | INFO | train_inner | epoch 026:     98 / 126 loss=5.187, nll_loss=1.496, ppl=2.82, wps=1533.4, ups=0.36, wpb=4311.5, bsz=276, num_updates=3248, lr=2.63198e-05, gnorm=1.27, train_wall=6, gb_free=10.2, wall=11032
2025-04-03 08:07:52 | INFO | train_inner | epoch 026:    100 / 126 loss=5.255, nll_loss=1.574, ppl=2.98, wps=1664.9, ups=0.44, wpb=3768, bsz=236.5, num_updates=3250, lr=2.63117e-05, gnorm=1.51, train_wall=5, gb_free=13.7, wall=11036
2025-04-03 08:07:58 | INFO | train_inner | epoch 026:    102 / 126 loss=5.385, nll_loss=1.734, ppl=3.33, wps=1720.1, ups=0.33, wpb=5157, bsz=284, num_updates=3252, lr=2.63036e-05, gnorm=1.309, train_wall=6, gb_free=10.7, wall=11042
2025-04-03 08:08:04 | INFO | train_inner | epoch 026:    104 / 126 loss=5.162, nll_loss=1.437, ppl=2.71, wps=1611.9, ups=0.35, wpb=4619.5, bsz=212, num_updates=3254, lr=2.62956e-05, gnorm=1.255, train_wall=6, gb_free=12.4, wall=11048
2025-04-03 08:08:09 | INFO | train_inner | epoch 026:    106 / 126 loss=5.075, nll_loss=1.348, ppl=2.55, wps=1694.2, ups=0.37, wpb=4611, bsz=336, num_updates=3256, lr=2.62875e-05, gnorm=1.155, train_wall=5, gb_free=14.3, wall=11053
2025-04-03 08:08:15 | INFO | train_inner | epoch 026:    108 / 126 loss=5.179, nll_loss=1.471, ppl=2.77, wps=1720.7, ups=0.36, wpb=4753, bsz=324, num_updates=3258, lr=2.62794e-05, gnorm=1.16, train_wall=6, gb_free=14.2, wall=11059
2025-04-03 08:08:20 | INFO | train_inner | epoch 026:    110 / 126 loss=5.154, nll_loss=1.433, ppl=2.7, wps=1659.7, ups=0.35, wpb=4695.5, bsz=208, num_updates=3260, lr=2.62714e-05, gnorm=1.172, train_wall=6, gb_free=10.8, wall=11064
2025-04-03 08:08:26 | INFO | train_inner | epoch 026:    112 / 126 loss=5.131, nll_loss=1.404, ppl=2.65, wps=1604.6, ups=0.36, wpb=4493, bsz=184, num_updates=3262, lr=2.62633e-05, gnorm=1.29, train_wall=6, gb_free=12.3, wall=11070
2025-04-03 08:08:32 | INFO | train_inner | epoch 026:    114 / 126 loss=5.136, nll_loss=1.412, ppl=2.66, wps=1339.3, ups=0.35, wpb=3808, bsz=196, num_updates=3264, lr=2.62553e-05, gnorm=1.401, train_wall=6, gb_free=14.3, wall=11076
2025-04-03 08:08:37 | INFO | train_inner | epoch 026:    116 / 126 loss=5.261, nll_loss=1.577, ppl=2.98, wps=1747.1, ups=0.34, wpb=5128, bsz=288, num_updates=3266, lr=2.62472e-05, gnorm=1.336, train_wall=6, gb_free=14.1, wall=11082
2025-04-03 08:08:43 | INFO | train_inner | epoch 026:    118 / 126 loss=5.213, nll_loss=1.518, ppl=2.86, wps=1631.5, ups=0.35, wpb=4678, bsz=308, num_updates=3268, lr=2.62392e-05, gnorm=1.224, train_wall=6, gb_free=13.6, wall=11087
2025-04-03 08:08:48 | INFO | train_inner | epoch 026:    120 / 126 loss=5.167, nll_loss=1.464, ppl=2.76, wps=1536.4, ups=0.4, wpb=3845.5, bsz=236, num_updates=3270, lr=2.62312e-05, gnorm=1.336, train_wall=5, gb_free=14.3, wall=11092
2025-04-03 08:08:53 | INFO | train_inner | epoch 026:    122 / 126 loss=5.139, nll_loss=1.424, ppl=2.68, wps=1631, ups=0.4, wpb=4116, bsz=284, num_updates=3272, lr=2.62231e-05, gnorm=1.299, train_wall=5, gb_free=14.8, wall=11097
2025-04-03 08:08:59 | INFO | train_inner | epoch 026:    124 / 126 loss=5.181, nll_loss=1.454, ppl=2.74, wps=1598.2, ups=0.36, wpb=4453.5, bsz=192, num_updates=3274, lr=2.62151e-05, gnorm=1.306, train_wall=6, gb_free=12.4, wall=11103
2025-04-03 08:09:03 | INFO | train_inner | epoch 026:    126 / 126 loss=5.106, nll_loss=1.371, ppl=2.59, wps=1555.1, ups=0.47, wpb=3316.5, bsz=188, num_updates=3276, lr=2.62071e-05, gnorm=1.406, train_wall=4, gb_free=14.6, wall=11107
2025-04-03 08:09:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-03 08:09:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=15963.83203125Mb; avail=239121.3671875Mb
2025-04-03 08:09:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000641
2025-04-03 08:09:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15963.83203125Mb; avail=239121.3671875Mb
2025-04-03 08:09:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012810
2025-04-03 08:09:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15963.83203125Mb; avail=239121.3671875Mb
2025-04-03 08:09:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.010963
2025-04-03 08:09:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024776
2025-04-03 08:09:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15963.83203125Mb; avail=239121.3671875Mb
2025-04-03 08:09:17 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 5.887 | nll_loss 2.192 | ppl 4.57 | wps 3865.5 | wpb 2070.5 | bsz 122.7 | num_updates 3276 | best_loss 5.887
2025-04-03 08:09:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 3276 updates
2025-04-03 08:09:17 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 08:09:57 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 08:10:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt (epoch 26 @ 3276 updates, score 5.887) (writing took 63.57139884796925 seconds)
2025-04-03 08:10:21 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2025-04-03 08:10:21 | INFO | train | epoch 026 | loss 5.187 | nll_loss 1.479 | ppl 2.79 | wps 1327.7 | ups 0.29 | wpb 4549.7 | bsz 252.8 | num_updates 3276 | lr 2.62071e-05 | gnorm 1.284 | train_wall 353 | gb_free 14.6 | wall 11185
2025-04-03 08:10:21 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:mr-hi': 31849}; raw total size: 31849
2025-04-03 08:10:21 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:mr-hi': 31849}; resampled total size: 31849
2025-04-03 08:10:21 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:mr-hi': 1.0}
2025-04-03 08:10:21 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001073
2025-04-03 08:10:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=26766.05078125Mb; avail=228319.14453125Mb
2025-04-03 08:10:21 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000535
2025-04-03 08:10:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003446
2025-04-03 08:10:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26766.54296875Mb; avail=228318.65234375Mb
2025-04-03 08:10:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000091
2025-04-03 08:10:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26766.54296875Mb; avail=228318.65234375Mb
2025-04-03 08:10:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001156
2025-04-03 08:10:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.004998
2025-04-03 08:10:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26766.54296875Mb; avail=228318.65234375Mb
2025-04-03 08:10:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 126
2025-04-03 08:10:21 | INFO | fairseq.trainer | begin training epoch 27
2025-04-03 08:10:21 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-03 08:10:26 | INFO | train_inner | epoch 027:      2 / 126 loss=5.165, nll_loss=1.464, ppl=2.76, wps=99.6, ups=0.02, wpb=4154, bsz=224, num_updates=3278, lr=2.61991e-05, gnorm=1.226, train_wall=5, gb_free=10, wall=11191
2025-04-03 08:10:32 | INFO | train_inner | epoch 027:      4 / 126 loss=5.074, nll_loss=1.346, ppl=2.54, wps=1680.9, ups=0.36, wpb=4707.5, bsz=236, num_updates=3280, lr=2.61911e-05, gnorm=1.177, train_wall=6, gb_free=9.1, wall=11196
2025-04-03 08:10:37 | INFO | train_inner | epoch 027:      6 / 126 loss=5.159, nll_loss=1.434, ppl=2.7, wps=1546.2, ups=0.37, wpb=4174.5, bsz=156, num_updates=3282, lr=2.61832e-05, gnorm=1.353, train_wall=5, gb_free=14.8, wall=11202
2025-04-03 08:10:43 | INFO | train_inner | epoch 027:      8 / 126 loss=5.122, nll_loss=1.37, ppl=2.59, wps=1570.9, ups=0.37, wpb=4212.5, bsz=128, num_updates=3284, lr=2.61752e-05, gnorm=1.3, train_wall=5, gb_free=13.5, wall=11207
2025-04-03 08:10:48 | INFO | train_inner | epoch 027:     10 / 126 loss=5.158, nll_loss=1.429, ppl=2.69, wps=1733, ups=0.37, wpb=4718.5, bsz=248, num_updates=3286, lr=2.61672e-05, gnorm=1.229, train_wall=5, gb_free=15.1, wall=11212
2025-04-03 08:10:53 | INFO | train_inner | epoch 027:     12 / 126 loss=5.04, nll_loss=1.299, ppl=2.46, wps=1561.9, ups=0.39, wpb=3957.5, bsz=304, num_updates=3288, lr=2.61593e-05, gnorm=1.23, train_wall=5, gb_free=14.3, wall=11217
2025-04-03 08:10:59 | INFO | train_inner | epoch 027:     14 / 126 loss=5.059, nll_loss=1.309, ppl=2.48, wps=1642.1, ups=0.39, wpb=4265, bsz=144, num_updates=3290, lr=2.61513e-05, gnorm=1.406, train_wall=5, gb_free=10.7, wall=11223
2025-04-03 08:11:04 | INFO | train_inner | epoch 027:     16 / 126 loss=5.182, nll_loss=1.495, ppl=2.82, wps=1583.2, ups=0.36, wpb=4387.5, bsz=308, num_updates=3292, lr=2.61434e-05, gnorm=1.231, train_wall=6, gb_free=10.3, wall=11228
2025-04-03 08:11:09 | INFO | train_inner | epoch 027:     18 / 126 loss=5.116, nll_loss=1.381, ppl=2.61, wps=1600.4, ups=0.4, wpb=3980, bsz=168, num_updates=3294, lr=2.61354e-05, gnorm=1.474, train_wall=5, gb_free=14.5, wall=11233
2025-04-03 08:11:15 | INFO | train_inner | epoch 027:     20 / 126 loss=5.199, nll_loss=1.488, ppl=2.8, wps=1612, ups=0.35, wpb=4595, bsz=220, num_updates=3296, lr=2.61275e-05, gnorm=1.262, train_wall=6, gb_free=8.7, wall=11239
2025-04-03 08:11:21 | INFO | train_inner | epoch 027:     22 / 126 loss=5.097, nll_loss=1.362, ppl=2.57, wps=1866.5, ups=0.34, wpb=5477.5, bsz=380, num_updates=3298, lr=2.61196e-05, gnorm=1.053, train_wall=6, gb_free=11.6, wall=11245
2025-04-03 08:11:26 | INFO | train_inner | epoch 027:     24 / 126 loss=5.255, nll_loss=1.571, ppl=2.97, wps=1822.2, ups=0.37, wpb=4956, bsz=280, num_updates=3300, lr=2.61116e-05, gnorm=1.207, train_wall=5, gb_free=13, wall=11250
2025-04-03 08:11:31 | INFO | train_inner | epoch 027:     26 / 126 loss=5.073, nll_loss=1.347, ppl=2.54, wps=1683.9, ups=0.38, wpb=4445.5, bsz=272, num_updates=3302, lr=2.61037e-05, gnorm=1.109, train_wall=5, gb_free=13.8, wall=11255
2025-04-03 08:11:37 | INFO | train_inner | epoch 027:     28 / 126 loss=5.219, nll_loss=1.512, ppl=2.85, wps=1795.3, ups=0.34, wpb=5320.5, bsz=224, num_updates=3304, lr=2.60958e-05, gnorm=1.247, train_wall=6, gb_free=9.2, wall=11261
2025-04-03 08:11:43 | INFO | train_inner | epoch 027:     30 / 126 loss=5.119, nll_loss=1.396, ppl=2.63, wps=1553.9, ups=0.37, wpb=4158.5, bsz=288, num_updates=3306, lr=2.60879e-05, gnorm=1.291, train_wall=5, gb_free=14.5, wall=11267
2025-04-03 08:11:48 | INFO | train_inner | epoch 027:     32 / 126 loss=5.109, nll_loss=1.368, ppl=2.58, wps=1719.4, ups=0.37, wpb=4648, bsz=272, num_updates=3308, lr=2.60801e-05, gnorm=1.194, train_wall=5, gb_free=13.6, wall=11272
2025-04-03 08:11:53 | INFO | train_inner | epoch 027:     34 / 126 loss=5.028, nll_loss=1.271, ppl=2.41, wps=1573.3, ups=0.39, wpb=4045, bsz=276, num_updates=3310, lr=2.60722e-05, gnorm=1.228, train_wall=5, gb_free=14.6, wall=11277
2025-04-03 08:11:59 | INFO | train_inner | epoch 027:     36 / 126 loss=5.135, nll_loss=1.416, ppl=2.67, wps=1682.7, ups=0.35, wpb=4764, bsz=316, num_updates=3312, lr=2.60643e-05, gnorm=1.226, train_wall=6, gb_free=13.1, wall=11283
2025-04-03 08:12:04 | INFO | train_inner | epoch 027:     38 / 126 loss=5.167, nll_loss=1.454, ppl=2.74, wps=1587.2, ups=0.37, wpb=4289, bsz=188, num_updates=3314, lr=2.60564e-05, gnorm=1.513, train_wall=5, gb_free=13.7, wall=11288
2025-04-03 08:12:10 | INFO | train_inner | epoch 027:     40 / 126 loss=5.19, nll_loss=1.475, ppl=2.78, wps=1627.5, ups=0.35, wpb=4673.5, bsz=228, num_updates=3316, lr=2.60486e-05, gnorm=1.36, train_wall=6, gb_free=12.4, wall=11294
2025-04-03 08:12:16 | INFO | train_inner | epoch 027:     42 / 126 loss=5.175, nll_loss=1.467, ppl=2.76, wps=1629.8, ups=0.36, wpb=4488, bsz=244, num_updates=3318, lr=2.60407e-05, gnorm=1.317, train_wall=5, gb_free=14, wall=11300
2025-04-03 08:12:21 | INFO | train_inner | epoch 027:     44 / 126 loss=5.065, nll_loss=1.321, ppl=2.5, wps=1712.9, ups=0.37, wpb=4669, bsz=324, num_updates=3320, lr=2.60329e-05, gnorm=1.202, train_wall=5, gb_free=10.4, wall=11305
2025-04-03 08:12:27 | INFO | train_inner | epoch 027:     46 / 126 loss=5.155, nll_loss=1.409, ppl=2.66, wps=1685.9, ups=0.35, wpb=4783.5, bsz=188, num_updates=3322, lr=2.6025e-05, gnorm=1.35, train_wall=6, gb_free=12.3, wall=11311
2025-04-03 08:12:32 | INFO | train_inner | epoch 027:     48 / 126 loss=5.181, nll_loss=1.484, ppl=2.8, wps=1818.9, ups=0.35, wpb=5207, bsz=264, num_updates=3324, lr=2.60172e-05, gnorm=1.319, train_wall=6, gb_free=13.2, wall=11316
2025-04-03 08:12:38 | INFO | train_inner | epoch 027:     50 / 126 loss=5.107, nll_loss=1.389, ppl=2.62, wps=1527.4, ups=0.36, wpb=4285, bsz=180, num_updates=3326, lr=2.60094e-05, gnorm=1.329, train_wall=6, gb_free=8.8, wall=11322
2025-04-03 08:12:43 | INFO | train_inner | epoch 027:     52 / 126 loss=5.142, nll_loss=1.433, ppl=2.7, wps=1803.9, ups=0.38, wpb=4799, bsz=364, num_updates=3328, lr=2.60016e-05, gnorm=1.163, train_wall=5, gb_free=12, wall=11327
2025-04-03 08:12:54 | INFO | train_inner | epoch 027:     54 / 126 loss=5.201, nll_loss=1.478, ppl=2.79, wps=912, ups=0.2, wpb=4657.5, bsz=220, num_updates=3330, lr=2.59938e-05, gnorm=1.32, train_wall=10, gb_free=11.4, wall=11338
2025-04-03 08:12:59 | INFO | train_inner | epoch 027:     56 / 126 loss=5.176, nll_loss=1.43, ppl=2.7, wps=1575.7, ups=0.37, wpb=4286, bsz=188, num_updates=3332, lr=2.5986e-05, gnorm=1.284, train_wall=5, gb_free=13.1, wall=11343
2025-04-03 08:13:05 | INFO | train_inner | epoch 027:     58 / 126 loss=5.095, nll_loss=1.357, ppl=2.56, wps=1549.5, ups=0.35, wpb=4377, bsz=252, num_updates=3334, lr=2.59782e-05, gnorm=1.183, train_wall=6, gb_free=12, wall=11349
2025-04-03 08:13:10 | INFO | train_inner | epoch 027:     60 / 126 loss=5.188, nll_loss=1.496, ppl=2.82, wps=1469.7, ups=0.35, wpb=4147.5, bsz=236, num_updates=3336, lr=2.59704e-05, gnorm=1.305, train_wall=6, gb_free=10.4, wall=11354
2025-04-03 08:13:15 | INFO | train_inner | epoch 027:     62 / 126 loss=5.129, nll_loss=1.424, ppl=2.68, wps=1685.2, ups=0.43, wpb=3919.5, bsz=240.5, num_updates=3338, lr=2.59626e-05, gnorm=1.259, train_wall=5, gb_free=12.6, wall=11359
2025-04-03 08:13:21 | INFO | train_inner | epoch 027:     64 / 126 loss=5.091, nll_loss=1.355, ppl=2.56, wps=1717.5, ups=0.35, wpb=4925, bsz=260, num_updates=3340, lr=2.59548e-05, gnorm=1.136, train_wall=6, gb_free=10.2, wall=11365
2025-04-03 08:13:26 | INFO | train_inner | epoch 027:     66 / 126 loss=5.181, nll_loss=1.469, ppl=2.77, wps=1881.5, ups=0.36, wpb=5232, bsz=376, num_updates=3342, lr=2.59471e-05, gnorm=1.147, train_wall=6, gb_free=13.9, wall=11370
2025-04-03 08:13:32 | INFO | train_inner | epoch 027:     68 / 126 loss=5.152, nll_loss=1.417, ppl=2.67, wps=1717.8, ups=0.35, wpb=4844, bsz=220, num_updates=3344, lr=2.59393e-05, gnorm=1.216, train_wall=6, gb_free=10.8, wall=11376
2025-04-03 08:13:38 | INFO | train_inner | epoch 027:     70 / 126 loss=5.092, nll_loss=1.351, ppl=2.55, wps=1722, ups=0.34, wpb=5011.5, bsz=264, num_updates=3346, lr=2.59315e-05, gnorm=1.157, train_wall=6, gb_free=9, wall=11382
2025-04-03 08:13:43 | INFO | train_inner | epoch 027:     72 / 126 loss=5.159, nll_loss=1.438, ppl=2.71, wps=1626.8, ups=0.36, wpb=4540.5, bsz=220, num_updates=3348, lr=2.59238e-05, gnorm=1.265, train_wall=6, gb_free=10.4, wall=11387
2025-04-03 08:13:49 | INFO | train_inner | epoch 027:     74 / 126 loss=5.146, nll_loss=1.442, ppl=2.72, wps=1632.5, ups=0.35, wpb=4621.5, bsz=192, num_updates=3350, lr=2.59161e-05, gnorm=1.223, train_wall=6, gb_free=11.1, wall=11393
2025-04-03 08:13:55 | INFO | train_inner | epoch 027:     76 / 126 loss=5.208, nll_loss=1.515, ppl=2.86, wps=1763.9, ups=0.34, wpb=5198.5, bsz=284, num_updates=3352, lr=2.59083e-05, gnorm=1.342, train_wall=6, gb_free=10.6, wall=11399
2025-04-03 08:14:00 | INFO | train_inner | epoch 027:     78 / 126 loss=5.145, nll_loss=1.428, ppl=2.69, wps=1504.8, ups=0.37, wpb=4101, bsz=352, num_updates=3354, lr=2.59006e-05, gnorm=1.315, train_wall=5, gb_free=10.6, wall=11404
2025-04-03 08:14:06 | INFO | train_inner | epoch 027:     80 / 126 loss=5.078, nll_loss=1.328, ppl=2.51, wps=1711.7, ups=0.35, wpb=4842.5, bsz=304, num_updates=3356, lr=2.58929e-05, gnorm=1.114, train_wall=6, gb_free=12.3, wall=11410
2025-04-03 08:14:12 | INFO | train_inner | epoch 027:     82 / 126 loss=5.176, nll_loss=1.472, ppl=2.77, wps=1641.4, ups=0.36, wpb=4622, bsz=244, num_updates=3358, lr=2.58852e-05, gnorm=1.277, train_wall=6, gb_free=11.7, wall=11416
2025-04-03 08:14:17 | INFO | train_inner | epoch 027:     84 / 126 loss=5.112, nll_loss=1.392, ppl=2.62, wps=1712.6, ups=0.34, wpb=4987.5, bsz=308, num_updates=3360, lr=2.58775e-05, gnorm=1.113, train_wall=6, gb_free=9, wall=11421
2025-04-03 08:14:23 | INFO | train_inner | epoch 027:     86 / 126 loss=5.205, nll_loss=1.521, ppl=2.87, wps=1713.8, ups=0.35, wpb=4911, bsz=320, num_updates=3362, lr=2.58698e-05, gnorm=1.226, train_wall=6, gb_free=10.1, wall=11427
2025-04-03 08:14:29 | INFO | train_inner | epoch 027:     88 / 126 loss=5.179, nll_loss=1.454, ppl=2.74, wps=1530.5, ups=0.36, wpb=4225.5, bsz=232, num_updates=3364, lr=2.58621e-05, gnorm=1.317, train_wall=6, gb_free=11.1, wall=11433
2025-04-03 08:14:34 | INFO | train_inner | epoch 027:     90 / 126 loss=5.261, nll_loss=1.567, ppl=2.96, wps=1865, ups=0.36, wpb=5186, bsz=292, num_updates=3366, lr=2.58544e-05, gnorm=1.311, train_wall=6, gb_free=13.6, wall=11438
2025-04-03 08:14:40 | INFO | train_inner | epoch 027:     92 / 126 loss=5.171, nll_loss=1.466, ppl=2.76, wps=1780.7, ups=0.36, wpb=4924, bsz=368, num_updates=3368, lr=2.58467e-05, gnorm=1.212, train_wall=6, gb_free=14.8, wall=11444
2025-04-03 08:14:45 | INFO | train_inner | epoch 027:     94 / 126 loss=5.063, nll_loss=1.326, ppl=2.51, wps=1415.1, ups=0.37, wpb=3797.5, bsz=212, num_updates=3370, lr=2.5839e-05, gnorm=1.245, train_wall=5, gb_free=13.9, wall=11449
2025-04-03 08:14:51 | INFO | train_inner | epoch 027:     96 / 126 loss=5.177, nll_loss=1.479, ppl=2.79, wps=1743, ups=0.35, wpb=5015, bsz=260, num_updates=3372, lr=2.58314e-05, gnorm=1.173, train_wall=6, gb_free=9.2, wall=11455
2025-04-03 08:14:56 | INFO | train_inner | epoch 027:     98 / 126 loss=5.088, nll_loss=1.361, ppl=2.57, wps=1355, ups=0.36, wpb=3782, bsz=224, num_updates=3374, lr=2.58237e-05, gnorm=1.298, train_wall=6, gb_free=10.1, wall=11461
2025-04-03 08:15:02 | INFO | train_inner | epoch 027:    100 / 126 loss=5.121, nll_loss=1.394, ppl=2.63, wps=1467.3, ups=0.36, wpb=4072.5, bsz=276, num_updates=3376, lr=2.58161e-05, gnorm=1.28, train_wall=6, gb_free=13.4, wall=11466
2025-04-03 08:15:08 | INFO | train_inner | epoch 027:    102 / 126 loss=5.132, nll_loss=1.391, ppl=2.62, wps=1683.9, ups=0.35, wpb=4767.5, bsz=212, num_updates=3378, lr=2.58084e-05, gnorm=1.177, train_wall=6, gb_free=12.1, wall=11472
2025-04-03 08:15:13 | INFO | train_inner | epoch 027:    104 / 126 loss=5.125, nll_loss=1.4, ppl=2.64, wps=1710.9, ups=0.38, wpb=4512, bsz=236, num_updates=3380, lr=2.58008e-05, gnorm=1.255, train_wall=5, gb_free=13.7, wall=11477
2025-04-03 08:15:19 | INFO | train_inner | epoch 027:    106 / 126 loss=5.183, nll_loss=1.472, ppl=2.77, wps=1648.4, ups=0.35, wpb=4660.5, bsz=216, num_updates=3382, lr=2.57932e-05, gnorm=1.263, train_wall=6, gb_free=12.8, wall=11483
2025-04-03 08:15:24 | INFO | train_inner | epoch 027:    108 / 126 loss=5.191, nll_loss=1.503, ppl=2.83, wps=1620.3, ups=0.38, wpb=4229.5, bsz=256, num_updates=3384, lr=2.57855e-05, gnorm=1.266, train_wall=5, gb_free=14.5, wall=11488
2025-04-03 08:15:29 | INFO | train_inner | epoch 027:    110 / 126 loss=5.088, nll_loss=1.344, ppl=2.54, wps=1489.3, ups=0.36, wpb=4173, bsz=216, num_updates=3386, lr=2.57779e-05, gnorm=1.186, train_wall=6, gb_free=10, wall=11493
2025-04-03 08:15:35 | INFO | train_inner | epoch 027:    112 / 126 loss=5.122, nll_loss=1.381, ppl=2.6, wps=1572.5, ups=0.36, wpb=4386, bsz=272, num_updates=3388, lr=2.57703e-05, gnorm=1.227, train_wall=6, gb_free=11.6, wall=11499
2025-04-03 08:15:40 | INFO | train_inner | epoch 027:    114 / 126 loss=5.207, nll_loss=1.507, ppl=2.84, wps=1556.9, ups=0.37, wpb=4184.5, bsz=232, num_updates=3390, lr=2.57627e-05, gnorm=1.349, train_wall=5, gb_free=14.6, wall=11504
2025-04-03 08:15:46 | INFO | train_inner | epoch 027:    116 / 126 loss=5.14, nll_loss=1.44, ppl=2.71, wps=1602.7, ups=0.37, wpb=4323, bsz=316, num_updates=3392, lr=2.57551e-05, gnorm=1.344, train_wall=5, gb_free=11.2, wall=11510
2025-04-03 08:15:52 | INFO | train_inner | epoch 027:    118 / 126 loss=5.115, nll_loss=1.397, ppl=2.63, wps=1752.6, ups=0.32, wpb=5428, bsz=296, num_updates=3394, lr=2.57475e-05, gnorm=1.118, train_wall=6, gb_free=9.4, wall=11516
2025-04-03 08:15:57 | INFO | train_inner | epoch 027:    120 / 126 loss=5.083, nll_loss=1.344, ppl=2.54, wps=1556.9, ups=0.37, wpb=4265, bsz=220, num_updates=3396, lr=2.57399e-05, gnorm=1.244, train_wall=5, gb_free=14.2, wall=11522
2025-04-03 08:16:03 | INFO | train_inner | epoch 027:    122 / 126 loss=5.159, nll_loss=1.443, ppl=2.72, wps=1658.8, ups=0.36, wpb=4651.5, bsz=244, num_updates=3398, lr=2.57324e-05, gnorm=1.209, train_wall=6, gb_free=10.8, wall=11527
2025-04-03 08:16:09 | INFO | train_inner | epoch 027:    124 / 126 loss=5.272, nll_loss=1.593, ppl=3.02, wps=1802.6, ups=0.34, wpb=5226, bsz=272, num_updates=3400, lr=2.57248e-05, gnorm=1.185, train_wall=6, gb_free=9.4, wall=11533
2025-04-03 08:16:13 | INFO | train_inner | epoch 027:    126 / 126 loss=5.094, nll_loss=1.358, ppl=2.56, wps=1567.6, ups=0.46, wpb=3437, bsz=168, num_updates=3402, lr=2.57172e-05, gnorm=1.432, train_wall=4, gb_free=17.6, wall=11537
2025-04-03 08:16:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-03 08:16:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=15970.93359375Mb; avail=239114.265625Mb
2025-04-03 08:16:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000629
2025-04-03 08:16:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15970.93359375Mb; avail=239114.265625Mb
2025-04-03 08:16:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.013041
2025-04-03 08:16:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15970.93359375Mb; avail=239114.265625Mb
2025-04-03 08:16:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.010901
2025-04-03 08:16:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024941
2025-04-03 08:16:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15970.93359375Mb; avail=239114.265625Mb
2025-04-03 08:16:28 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 5.882 | nll_loss 2.162 | ppl 4.47 | wps 3864.2 | wpb 2070.5 | bsz 122.7 | num_updates 3402 | best_loss 5.882
2025-04-03 08:16:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 3402 updates
2025-04-03 08:16:28 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 08:17:07 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 08:17:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt (epoch 27 @ 3402 updates, score 5.882) (writing took 63.8319907260593 seconds)
2025-04-03 08:17:31 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2025-04-03 08:17:31 | INFO | train | epoch 027 | loss 5.145 | nll_loss 1.425 | ppl 2.69 | wps 1332.1 | ups 0.29 | wpb 4549.7 | bsz 252.8 | num_updates 3402 | lr 2.57172e-05 | gnorm 1.253 | train_wall 351 | gb_free 17.6 | wall 11615
2025-04-03 08:17:31 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:mr-hi': 31849}; raw total size: 31849
2025-04-03 08:17:31 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:mr-hi': 31849}; resampled total size: 31849
2025-04-03 08:17:31 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:mr-hi': 1.0}
2025-04-03 08:17:31 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001091
2025-04-03 08:17:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=26771.3046875Mb; avail=228313.83984375Mb
2025-04-03 08:17:31 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000555
2025-04-03 08:17:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003398
2025-04-03 08:17:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26771.796875Mb; avail=228313.34765625Mb
2025-04-03 08:17:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000106
2025-04-03 08:17:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26771.796875Mb; avail=228313.34765625Mb
2025-04-03 08:17:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001129
2025-04-03 08:17:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.004945
2025-04-03 08:17:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26771.796875Mb; avail=228313.34765625Mb
2025-04-03 08:17:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 126
2025-04-03 08:17:31 | INFO | fairseq.trainer | begin training epoch 28
2025-04-03 08:17:31 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-03 08:17:37 | INFO | train_inner | epoch 028:      2 / 126 loss=5.049, nll_loss=1.296, ppl=2.46, wps=108.7, ups=0.02, wpb=4542.5, bsz=324, num_updates=3404, lr=2.57097e-05, gnorm=1.143, train_wall=5, gb_free=15, wall=11621
2025-04-03 08:17:42 | INFO | train_inner | epoch 028:      4 / 126 loss=5.097, nll_loss=1.367, ppl=2.58, wps=1738.7, ups=0.38, wpb=4540.5, bsz=308, num_updates=3406, lr=2.57021e-05, gnorm=1.258, train_wall=5, gb_free=12.2, wall=11626
2025-04-03 08:17:47 | INFO | train_inner | epoch 028:      6 / 126 loss=5.11, nll_loss=1.376, ppl=2.6, wps=1860.4, ups=0.37, wpb=4972, bsz=292, num_updates=3408, lr=2.56946e-05, gnorm=1.271, train_wall=5, gb_free=10.3, wall=11631
2025-04-03 08:17:52 | INFO | train_inner | epoch 028:      8 / 126 loss=5.03, nll_loss=1.268, ppl=2.41, wps=1675.3, ups=0.39, wpb=4247.5, bsz=176, num_updates=3410, lr=2.5687e-05, gnorm=1.236, train_wall=5, gb_free=14.7, wall=11637
2025-04-03 08:17:58 | INFO | train_inner | epoch 028:     10 / 126 loss=5.18, nll_loss=1.48, ppl=2.79, wps=1673.2, ups=0.36, wpb=4662.5, bsz=240, num_updates=3412, lr=2.56795e-05, gnorm=1.336, train_wall=6, gb_free=13, wall=11642
2025-04-03 08:18:04 | INFO | train_inner | epoch 028:     12 / 126 loss=5.052, nll_loss=1.317, ppl=2.49, wps=1859, ups=0.36, wpb=5223.5, bsz=324, num_updates=3414, lr=2.5672e-05, gnorm=1.148, train_wall=6, gb_free=12.8, wall=11648
2025-04-03 08:18:09 | INFO | train_inner | epoch 028:     14 / 126 loss=5.117, nll_loss=1.375, ppl=2.59, wps=1719.5, ups=0.35, wpb=4852.5, bsz=248, num_updates=3416, lr=2.56645e-05, gnorm=1.252, train_wall=6, gb_free=9.3, wall=11653
2025-04-03 08:18:15 | INFO | train_inner | epoch 028:     16 / 126 loss=5.302, nll_loss=1.621, ppl=3.08, wps=1853.3, ups=0.35, wpb=5322.5, bsz=276, num_updates=3418, lr=2.5657e-05, gnorm=1.49, train_wall=6, gb_free=10.3, wall=11659
2025-04-03 08:18:21 | INFO | train_inner | epoch 028:     18 / 126 loss=5.207, nll_loss=1.497, ppl=2.82, wps=1781, ups=0.36, wpb=4944.5, bsz=292, num_updates=3420, lr=2.56495e-05, gnorm=1.278, train_wall=6, gb_free=11, wall=11665
2025-04-03 08:18:26 | INFO | train_inner | epoch 028:     20 / 126 loss=5.06, nll_loss=1.317, ppl=2.49, wps=1812.7, ups=0.34, wpb=5263, bsz=292, num_updates=3422, lr=2.5642e-05, gnorm=1.158, train_wall=6, gb_free=12.3, wall=11670
2025-04-03 08:18:31 | INFO | train_inner | epoch 028:     22 / 126 loss=5.147, nll_loss=1.428, ppl=2.69, wps=1394.1, ups=0.44, wpb=3179.5, bsz=140.5, num_updates=3424, lr=2.56345e-05, gnorm=1.583, train_wall=5, gb_free=12.7, wall=11675
2025-04-03 08:18:36 | INFO | train_inner | epoch 028:     24 / 126 loss=5.103, nll_loss=1.382, ppl=2.61, wps=1688.3, ups=0.36, wpb=4666, bsz=256, num_updates=3426, lr=2.5627e-05, gnorm=1.194, train_wall=6, gb_free=12.2, wall=11681
2025-04-03 08:18:42 | INFO | train_inner | epoch 028:     26 / 126 loss=5.054, nll_loss=1.3, ppl=2.46, wps=1706.2, ups=0.34, wpb=4999.5, bsz=292, num_updates=3428, lr=2.56195e-05, gnorm=1.197, train_wall=6, gb_free=8.9, wall=11686
2025-04-03 08:18:48 | INFO | train_inner | epoch 028:     28 / 126 loss=5.069, nll_loss=1.334, ppl=2.52, wps=1773.3, ups=0.36, wpb=4858.5, bsz=332, num_updates=3430, lr=2.5612e-05, gnorm=1.195, train_wall=5, gb_free=14.6, wall=11692
2025-04-03 08:18:54 | INFO | train_inner | epoch 028:     30 / 126 loss=5.193, nll_loss=1.492, ppl=2.81, wps=1648.8, ups=0.35, wpb=4762.5, bsz=200, num_updates=3432, lr=2.56046e-05, gnorm=1.348, train_wall=6, gb_free=10.6, wall=11698
2025-04-03 08:18:59 | INFO | train_inner | epoch 028:     32 / 126 loss=5.021, nll_loss=1.252, ppl=2.38, wps=1442.6, ups=0.35, wpb=4094.5, bsz=216, num_updates=3434, lr=2.55971e-05, gnorm=1.232, train_wall=6, gb_free=12.5, wall=11703
2025-04-03 08:19:05 | INFO | train_inner | epoch 028:     34 / 126 loss=5.05, nll_loss=1.302, ppl=2.47, wps=1618.6, ups=0.35, wpb=4681.5, bsz=280, num_updates=3436, lr=2.55897e-05, gnorm=1.15, train_wall=6, gb_free=9.9, wall=11709
2025-04-03 08:19:10 | INFO | train_inner | epoch 028:     36 / 126 loss=5.101, nll_loss=1.372, ppl=2.59, wps=1796.9, ups=0.37, wpb=4859, bsz=252, num_updates=3438, lr=2.55822e-05, gnorm=1.316, train_wall=5, gb_free=13.4, wall=11715
2025-04-03 08:19:16 | INFO | train_inner | epoch 028:     38 / 126 loss=5.11, nll_loss=1.389, ppl=2.62, wps=1674.1, ups=0.37, wpb=4497.5, bsz=212, num_updates=3440, lr=2.55748e-05, gnorm=1.328, train_wall=5, gb_free=14, wall=11720
2025-04-03 08:19:22 | INFO | train_inner | epoch 028:     40 / 126 loss=5.052, nll_loss=1.314, ppl=2.49, wps=1784.1, ups=0.35, wpb=5116, bsz=280, num_updates=3442, lr=2.55674e-05, gnorm=1.092, train_wall=6, gb_free=9.8, wall=11726
2025-04-03 08:19:27 | INFO | train_inner | epoch 028:     42 / 126 loss=5.106, nll_loss=1.371, ppl=2.59, wps=1737.6, ups=0.36, wpb=4823.5, bsz=316, num_updates=3444, lr=2.55599e-05, gnorm=1.132, train_wall=6, gb_free=9.2, wall=11731
2025-04-03 08:19:33 | INFO | train_inner | epoch 028:     44 / 126 loss=5.094, nll_loss=1.353, ppl=2.55, wps=1638.7, ups=0.36, wpb=4612, bsz=228, num_updates=3446, lr=2.55525e-05, gnorm=1.261, train_wall=6, gb_free=10.8, wall=11737
2025-04-03 08:19:38 | INFO | train_inner | epoch 028:     46 / 126 loss=5.092, nll_loss=1.345, ppl=2.54, wps=1701.6, ups=0.39, wpb=4413.5, bsz=200, num_updates=3448, lr=2.55451e-05, gnorm=1.481, train_wall=5, gb_free=8.4, wall=11742
2025-04-03 08:19:44 | INFO | train_inner | epoch 028:     48 / 126 loss=5.121, nll_loss=1.402, ppl=2.64, wps=1658.3, ups=0.33, wpb=4970.5, bsz=340, num_updates=3450, lr=2.55377e-05, gnorm=1.109, train_wall=6, gb_free=9.9, wall=11748
2025-04-03 08:19:50 | INFO | train_inner | epoch 028:     50 / 126 loss=5.082, nll_loss=1.341, ppl=2.53, wps=1705.3, ups=0.35, wpb=4891, bsz=252, num_updates=3452, lr=2.55303e-05, gnorm=1.133, train_wall=6, gb_free=11.5, wall=11754
2025-04-03 08:19:55 | INFO | train_inner | epoch 028:     52 / 126 loss=5.106, nll_loss=1.375, ppl=2.59, wps=1648.3, ups=0.36, wpb=4542, bsz=180, num_updates=3454, lr=2.55229e-05, gnorm=1.229, train_wall=6, gb_free=12.6, wall=11759
2025-04-03 08:20:01 | INFO | train_inner | epoch 028:     54 / 126 loss=5.05, nll_loss=1.302, ppl=2.47, wps=1542.1, ups=0.37, wpb=4165, bsz=196, num_updates=3456, lr=2.55155e-05, gnorm=1.21, train_wall=5, gb_free=13.5, wall=11765
2025-04-03 08:20:06 | INFO | train_inner | epoch 028:     56 / 126 loss=5.08, nll_loss=1.355, ppl=2.56, wps=1704.8, ups=0.39, wpb=4401, bsz=332, num_updates=3458, lr=2.55081e-05, gnorm=1.253, train_wall=5, gb_free=14.3, wall=11770
2025-04-03 08:20:11 | INFO | train_inner | epoch 028:     58 / 126 loss=5.027, nll_loss=1.275, ppl=2.42, wps=1542.9, ups=0.36, wpb=4326.5, bsz=280, num_updates=3460, lr=2.55008e-05, gnorm=1.177, train_wall=6, gb_free=14.2, wall=11775
2025-04-03 08:20:17 | INFO | train_inner | epoch 028:     60 / 126 loss=5.031, nll_loss=1.282, ppl=2.43, wps=1556.2, ups=0.38, wpb=4090, bsz=260, num_updates=3462, lr=2.54934e-05, gnorm=1.261, train_wall=5, gb_free=13.6, wall=11781
2025-04-03 08:20:22 | INFO | train_inner | epoch 028:     62 / 126 loss=5.112, nll_loss=1.386, ppl=2.61, wps=1630.3, ups=0.35, wpb=4605, bsz=256, num_updates=3464, lr=2.5486e-05, gnorm=1.28, train_wall=6, gb_free=14.7, wall=11786
2025-04-03 08:20:28 | INFO | train_inner | epoch 028:     64 / 126 loss=5.121, nll_loss=1.356, ppl=2.56, wps=1568.5, ups=0.35, wpb=4501.5, bsz=144, num_updates=3466, lr=2.54787e-05, gnorm=1.32, train_wall=6, gb_free=12.3, wall=11792
2025-04-03 08:20:33 | INFO | train_inner | epoch 028:     66 / 126 loss=5.003, nll_loss=1.256, ppl=2.39, wps=1649.5, ups=0.38, wpb=4332.5, bsz=316, num_updates=3468, lr=2.54713e-05, gnorm=1.142, train_wall=5, gb_free=14.5, wall=11797
2025-04-03 08:20:39 | INFO | train_inner | epoch 028:     68 / 126 loss=5.131, nll_loss=1.402, ppl=2.64, wps=1645.5, ups=0.35, wpb=4642.5, bsz=160, num_updates=3470, lr=2.5464e-05, gnorm=1.323, train_wall=6, gb_free=12.3, wall=11803
2025-04-03 08:20:44 | INFO | train_inner | epoch 028:     70 / 126 loss=5.058, nll_loss=1.328, ppl=2.51, wps=1636.1, ups=0.38, wpb=4253, bsz=288, num_updates=3472, lr=2.54567e-05, gnorm=1.271, train_wall=5, gb_free=13.1, wall=11808
2025-04-03 08:20:50 | INFO | train_inner | epoch 028:     72 / 126 loss=5.129, nll_loss=1.4, ppl=2.64, wps=1412.3, ups=0.36, wpb=3931.5, bsz=168, num_updates=3474, lr=2.54493e-05, gnorm=1.3, train_wall=6, gb_free=13.7, wall=11814
2025-04-03 08:20:55 | INFO | train_inner | epoch 028:     74 / 126 loss=5.094, nll_loss=1.358, ppl=2.56, wps=1571.3, ups=0.35, wpb=4491, bsz=236, num_updates=3476, lr=2.5442e-05, gnorm=1.277, train_wall=6, gb_free=12, wall=11819
2025-04-03 08:21:01 | INFO | train_inner | epoch 028:     76 / 126 loss=5.089, nll_loss=1.355, ppl=2.56, wps=1705.3, ups=0.36, wpb=4676.5, bsz=268, num_updates=3478, lr=2.54347e-05, gnorm=1.198, train_wall=5, gb_free=8.6, wall=11825
2025-04-03 08:21:07 | INFO | train_inner | epoch 028:     78 / 126 loss=5.111, nll_loss=1.393, ppl=2.63, wps=1809.3, ups=0.34, wpb=5355.5, bsz=356, num_updates=3480, lr=2.54274e-05, gnorm=1.165, train_wall=6, gb_free=9.7, wall=11831
2025-04-03 08:21:12 | INFO | train_inner | epoch 028:     80 / 126 loss=5.038, nll_loss=1.289, ppl=2.44, wps=1530.3, ups=0.38, wpb=4012, bsz=224, num_updates=3482, lr=2.54201e-05, gnorm=1.323, train_wall=5, gb_free=13.8, wall=11836
2025-04-03 08:21:18 | INFO | train_inner | epoch 028:     82 / 126 loss=5.195, nll_loss=1.487, ppl=2.8, wps=1728.7, ups=0.33, wpb=5273, bsz=244, num_updates=3484, lr=2.54128e-05, gnorm=1.178, train_wall=6, gb_free=10.2, wall=11842
2025-04-03 08:21:24 | INFO | train_inner | epoch 028:     84 / 126 loss=5.156, nll_loss=1.435, ppl=2.7, wps=1594.5, ups=0.36, wpb=4444.5, bsz=212, num_updates=3486, lr=2.54055e-05, gnorm=1.29, train_wall=6, gb_free=11.3, wall=11848
2025-04-03 08:21:29 | INFO | train_inner | epoch 028:     86 / 126 loss=5.075, nll_loss=1.335, ppl=2.52, wps=1633.6, ups=0.35, wpb=4634, bsz=228, num_updates=3488, lr=2.53982e-05, gnorm=1.267, train_wall=6, gb_free=10.5, wall=11853
2025-04-03 08:21:40 | INFO | train_inner | epoch 028:     88 / 126 loss=5.096, nll_loss=1.347, ppl=2.54, wps=951.5, ups=0.19, wpb=5139.5, bsz=224, num_updates=3490, lr=2.53909e-05, gnorm=1.18, train_wall=11, gb_free=10.5, wall=11864
2025-04-03 08:21:46 | INFO | train_inner | epoch 028:     90 / 126 loss=5.145, nll_loss=1.421, ppl=2.68, wps=1558.4, ups=0.37, wpb=4188, bsz=248, num_updates=3492, lr=2.53837e-05, gnorm=1.27, train_wall=5, gb_free=13.7, wall=11870
2025-04-03 08:21:51 | INFO | train_inner | epoch 028:     92 / 126 loss=5.135, nll_loss=1.423, ppl=2.68, wps=1620.4, ups=0.34, wpb=4741.5, bsz=200, num_updates=3494, lr=2.53764e-05, gnorm=1.197, train_wall=6, gb_free=13.7, wall=11875
2025-04-03 08:21:57 | INFO | train_inner | epoch 028:     94 / 126 loss=5.109, nll_loss=1.395, ppl=2.63, wps=1823.3, ups=0.36, wpb=5052.5, bsz=284, num_updates=3496, lr=2.53691e-05, gnorm=1.227, train_wall=6, gb_free=9.8, wall=11881
2025-04-03 08:22:03 | INFO | train_inner | epoch 028:     96 / 126 loss=5.125, nll_loss=1.397, ppl=2.63, wps=1866.5, ups=0.34, wpb=5414.5, bsz=316, num_updates=3498, lr=2.53619e-05, gnorm=1.08, train_wall=6, gb_free=10.2, wall=11887
2025-04-03 08:22:08 | INFO | train_inner | epoch 028:     98 / 126 loss=5.049, nll_loss=1.27, ppl=2.41, wps=1287.3, ups=0.36, wpb=3596, bsz=196, num_updates=3500, lr=2.53546e-05, gnorm=1.343, train_wall=6, gb_free=14.8, wall=11892
2025-04-03 08:22:14 | INFO | train_inner | epoch 028:    100 / 126 loss=5.09, nll_loss=1.348, ppl=2.54, wps=1477.1, ups=0.35, wpb=4270, bsz=228, num_updates=3502, lr=2.53474e-05, gnorm=1.231, train_wall=6, gb_free=10.8, wall=11898
2025-04-03 08:22:19 | INFO | train_inner | epoch 028:    102 / 126 loss=5.118, nll_loss=1.42, ppl=2.67, wps=1777.1, ups=0.37, wpb=4782.5, bsz=320, num_updates=3504, lr=2.53402e-05, gnorm=1.234, train_wall=5, gb_free=13.9, wall=11904
2025-04-03 08:22:25 | INFO | train_inner | epoch 028:    104 / 126 loss=5.166, nll_loss=1.479, ppl=2.79, wps=1764.2, ups=0.36, wpb=4893, bsz=340, num_updates=3506, lr=2.53329e-05, gnorm=1.135, train_wall=6, gb_free=13.9, wall=11909
2025-04-03 08:22:31 | INFO | train_inner | epoch 028:    106 / 126 loss=5.073, nll_loss=1.331, ppl=2.51, wps=1471.6, ups=0.35, wpb=4261.5, bsz=220, num_updates=3508, lr=2.53257e-05, gnorm=1.14, train_wall=6, gb_free=9.7, wall=11915
2025-04-03 08:22:37 | INFO | train_inner | epoch 028:    108 / 126 loss=5.172, nll_loss=1.447, ppl=2.73, wps=1795.4, ups=0.35, wpb=5124.5, bsz=280, num_updates=3510, lr=2.53185e-05, gnorm=1.177, train_wall=6, gb_free=13.5, wall=11921
2025-04-03 08:22:42 | INFO | train_inner | epoch 028:    110 / 126 loss=5.097, nll_loss=1.371, ppl=2.59, wps=1254.4, ups=0.38, wpb=3327.5, bsz=204, num_updates=3512, lr=2.53113e-05, gnorm=1.317, train_wall=5, gb_free=13, wall=11926
2025-04-03 08:22:46 | INFO | train_inner | epoch 028:    112 / 126 loss=5.051, nll_loss=1.299, ppl=2.46, wps=1512, ups=0.43, wpb=3519, bsz=152, num_updates=3514, lr=2.53041e-05, gnorm=1.385, train_wall=5, gb_free=18.7, wall=11931
2025-04-03 08:22:52 | INFO | train_inner | epoch 028:    114 / 126 loss=5.035, nll_loss=1.31, ppl=2.48, wps=1636.5, ups=0.37, wpb=4408, bsz=356, num_updates=3516, lr=2.52969e-05, gnorm=1.163, train_wall=5, gb_free=12.4, wall=11936
2025-04-03 08:22:57 | INFO | train_inner | epoch 028:    116 / 126 loss=5.079, nll_loss=1.35, ppl=2.55, wps=1601.5, ups=0.39, wpb=4116.5, bsz=228, num_updates=3518, lr=2.52897e-05, gnorm=1.233, train_wall=5, gb_free=15, wall=11941
2025-04-03 08:23:03 | INFO | train_inner | epoch 028:    118 / 126 loss=5.168, nll_loss=1.458, ppl=2.75, wps=1561.9, ups=0.36, wpb=4314, bsz=264, num_updates=3520, lr=2.52825e-05, gnorm=1.231, train_wall=6, gb_free=11, wall=11947
2025-04-03 08:23:08 | INFO | train_inner | epoch 028:    120 / 126 loss=5.166, nll_loss=1.452, ppl=2.74, wps=1540.9, ups=0.36, wpb=4304, bsz=224, num_updates=3522, lr=2.52753e-05, gnorm=1.385, train_wall=6, gb_free=11.2, wall=11952
2025-04-03 08:23:14 | INFO | train_inner | epoch 028:    122 / 126 loss=5.012, nll_loss=1.245, ppl=2.37, wps=1514, ups=0.37, wpb=4118.5, bsz=296, num_updates=3524, lr=2.52681e-05, gnorm=1.211, train_wall=5, gb_free=13, wall=11958
2025-04-03 08:23:20 | INFO | train_inner | epoch 028:    124 / 126 loss=5.058, nll_loss=1.313, ppl=2.49, wps=1705.3, ups=0.33, wpb=5145.5, bsz=248, num_updates=3526, lr=2.5261e-05, gnorm=1.268, train_wall=6, gb_free=9.1, wall=11964
2025-04-03 08:23:24 | INFO | train_inner | epoch 028:    126 / 126 loss=5.057, nll_loss=1.322, ppl=2.5, wps=1582, ups=0.49, wpb=3242, bsz=180, num_updates=3528, lr=2.52538e-05, gnorm=1.325, train_wall=4, gb_free=17.8, wall=11968
2025-04-03 08:23:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-03 08:23:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=15973.20703125Mb; avail=239111.9609375Mb
2025-04-03 08:23:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000645
2025-04-03 08:23:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15973.20703125Mb; avail=239111.9609375Mb
2025-04-03 08:23:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012837
2025-04-03 08:23:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15973.20703125Mb; avail=239111.9609375Mb
2025-04-03 08:23:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.010866
2025-04-03 08:23:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024706
2025-04-03 08:23:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15973.20703125Mb; avail=239111.9609375Mb
2025-04-03 08:23:38 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 5.874 | nll_loss 2.166 | ppl 4.49 | wps 3873.2 | wpb 2070.5 | bsz 122.7 | num_updates 3528 | best_loss 5.874
2025-04-03 08:23:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 3528 updates
2025-04-03 08:23:38 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 08:24:18 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 08:24:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt (epoch 28 @ 3528 updates, score 5.874) (writing took 63.83163388806861 seconds)
2025-04-03 08:24:42 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2025-04-03 08:24:42 | INFO | train | epoch 028 | loss 5.1 | nll_loss 1.369 | ppl 2.58 | wps 1331.7 | ups 0.29 | wpb 4549.7 | bsz 252.8 | num_updates 3528 | lr 2.52538e-05 | gnorm 1.246 | train_wall 352 | gb_free 17.8 | wall 12046
2025-04-03 08:24:42 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:mr-hi': 31849}; raw total size: 31849
2025-04-03 08:24:42 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:mr-hi': 31849}; resampled total size: 31849
2025-04-03 08:24:42 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:mr-hi': 1.0}
2025-04-03 08:24:42 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001124
2025-04-03 08:24:42 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=26795.9296875Mb; avail=228289.2421875Mb
2025-04-03 08:24:42 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000560
2025-04-03 08:24:42 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003854
2025-04-03 08:24:42 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26795.9296875Mb; avail=228289.2421875Mb
2025-04-03 08:24:42 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000098
2025-04-03 08:24:42 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26795.9296875Mb; avail=228289.2421875Mb
2025-04-03 08:24:42 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001246
2025-04-03 08:24:42 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.005552
2025-04-03 08:24:42 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26795.9296875Mb; avail=228289.2421875Mb
2025-04-03 08:24:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 126
2025-04-03 08:24:42 | INFO | fairseq.trainer | begin training epoch 29
2025-04-03 08:24:42 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-03 08:24:47 | INFO | train_inner | epoch 029:      2 / 126 loss=5.052, nll_loss=1.317, ppl=2.49, wps=117.2, ups=0.02, wpb=4903.5, bsz=284, num_updates=3530, lr=2.52467e-05, gnorm=1.237, train_wall=5, gb_free=14.6, wall=12051
2025-04-03 08:24:53 | INFO | train_inner | epoch 029:      4 / 126 loss=4.976, nll_loss=1.206, ppl=2.31, wps=1684.4, ups=0.39, wpb=4344.5, bsz=204, num_updates=3532, lr=2.52395e-05, gnorm=1.122, train_wall=5, gb_free=11.6, wall=12057
2025-04-03 08:24:58 | INFO | train_inner | epoch 029:      6 / 126 loss=5.005, nll_loss=1.26, ppl=2.39, wps=1624.1, ups=0.38, wpb=4309.5, bsz=296, num_updates=3534, lr=2.52324e-05, gnorm=1.144, train_wall=5, gb_free=12.9, wall=12062
2025-04-03 08:25:03 | INFO | train_inner | epoch 029:      8 / 126 loss=5.06, nll_loss=1.323, ppl=2.5, wps=1686.1, ups=0.36, wpb=4640.5, bsz=272, num_updates=3536, lr=2.52252e-05, gnorm=1.181, train_wall=5, gb_free=10.1, wall=12067
2025-04-03 08:25:09 | INFO | train_inner | epoch 029:     10 / 126 loss=5.15, nll_loss=1.434, ppl=2.7, wps=1789.2, ups=0.36, wpb=4917.5, bsz=256, num_updates=3538, lr=2.52181e-05, gnorm=1.292, train_wall=5, gb_free=11.3, wall=12073
2025-04-03 08:25:14 | INFO | train_inner | epoch 029:     12 / 126 loss=5.042, nll_loss=1.284, ppl=2.44, wps=1836.5, ups=0.38, wpb=4836.5, bsz=300, num_updates=3540, lr=2.5211e-05, gnorm=1.237, train_wall=5, gb_free=12.6, wall=12078
2025-04-03 08:25:19 | INFO | train_inner | epoch 029:     14 / 126 loss=5.016, nll_loss=1.244, ppl=2.37, wps=1628.6, ups=0.37, wpb=4380.5, bsz=236, num_updates=3542, lr=2.52039e-05, gnorm=1.267, train_wall=5, gb_free=14.9, wall=12084
2025-04-03 08:25:25 | INFO | train_inner | epoch 029:     16 / 126 loss=5.047, nll_loss=1.305, ppl=2.47, wps=1697.4, ups=0.37, wpb=4533, bsz=236, num_updates=3544, lr=2.51967e-05, gnorm=1.259, train_wall=5, gb_free=13.3, wall=12089
2025-04-03 08:25:30 | INFO | train_inner | epoch 029:     18 / 126 loss=5.113, nll_loss=1.396, ppl=2.63, wps=1590.6, ups=0.36, wpb=4359.5, bsz=252, num_updates=3546, lr=2.51896e-05, gnorm=1.255, train_wall=5, gb_free=10, wall=12094
2025-04-03 08:25:36 | INFO | train_inner | epoch 029:     20 / 126 loss=5.143, nll_loss=1.415, ppl=2.67, wps=1841.1, ups=0.35, wpb=5255.5, bsz=280, num_updates=3548, lr=2.51825e-05, gnorm=1.242, train_wall=6, gb_free=11.7, wall=12100
2025-04-03 08:25:42 | INFO | train_inner | epoch 029:     22 / 126 loss=5.076, nll_loss=1.341, ppl=2.53, wps=1852.9, ups=0.34, wpb=5479.5, bsz=352, num_updates=3550, lr=2.51754e-05, gnorm=1.116, train_wall=6, gb_free=9.6, wall=12106
2025-04-03 08:25:52 | INFO | train_inner | epoch 029:     24 / 126 loss=5.069, nll_loss=1.315, ppl=2.49, wps=925.5, ups=0.19, wpb=4855, bsz=244, num_updates=3552, lr=2.51684e-05, gnorm=1.157, train_wall=10, gb_free=11.2, wall=12117
2025-04-03 08:25:57 | INFO | train_inner | epoch 029:     26 / 126 loss=4.99, nll_loss=1.248, ppl=2.38, wps=1592.7, ups=0.46, wpb=3453.5, bsz=228.5, num_updates=3554, lr=2.51613e-05, gnorm=1.443, train_wall=4, gb_free=17.9, wall=12121
2025-04-03 08:26:02 | INFO | train_inner | epoch 029:     28 / 126 loss=5.062, nll_loss=1.315, ppl=2.49, wps=1719.2, ups=0.39, wpb=4413.5, bsz=288, num_updates=3556, lr=2.51542e-05, gnorm=1.245, train_wall=5, gb_free=14.5, wall=12126
2025-04-03 08:26:07 | INFO | train_inner | epoch 029:     30 / 126 loss=5.055, nll_loss=1.314, ppl=2.49, wps=1716.8, ups=0.36, wpb=4704, bsz=300, num_updates=3558, lr=2.51471e-05, gnorm=1.181, train_wall=5, gb_free=14.5, wall=12131
2025-04-03 08:26:13 | INFO | train_inner | epoch 029:     32 / 126 loss=5.034, nll_loss=1.277, ppl=2.42, wps=1438.7, ups=0.33, wpb=4338.5, bsz=132, num_updates=3560, lr=2.51401e-05, gnorm=1.283, train_wall=6, gb_free=9.9, wall=12138
2025-04-03 08:26:19 | INFO | train_inner | epoch 029:     34 / 126 loss=5.113, nll_loss=1.387, ppl=2.62, wps=1659.2, ups=0.35, wpb=4788.5, bsz=148, num_updates=3562, lr=2.5133e-05, gnorm=1.314, train_wall=6, gb_free=11.6, wall=12143
2025-04-03 08:26:25 | INFO | train_inner | epoch 029:     36 / 126 loss=5.044, nll_loss=1.28, ppl=2.43, wps=1649.9, ups=0.34, wpb=4783.5, bsz=184, num_updates=3564, lr=2.51259e-05, gnorm=1.189, train_wall=6, gb_free=11.6, wall=12149
2025-04-03 08:26:31 | INFO | train_inner | epoch 029:     38 / 126 loss=5.069, nll_loss=1.331, ppl=2.52, wps=1598.2, ups=0.36, wpb=4485.5, bsz=256, num_updates=3566, lr=2.51189e-05, gnorm=1.216, train_wall=6, gb_free=12.4, wall=12155
2025-04-03 08:26:36 | INFO | train_inner | epoch 029:     40 / 126 loss=5.076, nll_loss=1.337, ppl=2.53, wps=1704.4, ups=0.36, wpb=4671, bsz=228, num_updates=3568, lr=2.51119e-05, gnorm=1.209, train_wall=5, gb_free=12.9, wall=12160
2025-04-03 08:26:42 | INFO | train_inner | epoch 029:     42 / 126 loss=4.98, nll_loss=1.222, ppl=2.33, wps=1579.7, ups=0.35, wpb=4556.5, bsz=248, num_updates=3570, lr=2.51048e-05, gnorm=1.203, train_wall=6, gb_free=14.3, wall=12166
2025-04-03 08:26:47 | INFO | train_inner | epoch 029:     44 / 126 loss=5.034, nll_loss=1.278, ppl=2.42, wps=1766.4, ups=0.38, wpb=4700, bsz=256, num_updates=3572, lr=2.50978e-05, gnorm=1.112, train_wall=5, gb_free=12.6, wall=12171
2025-04-03 08:26:53 | INFO | train_inner | epoch 029:     46 / 126 loss=5.049, nll_loss=1.307, ppl=2.47, wps=1596.5, ups=0.35, wpb=4579, bsz=220, num_updates=3574, lr=2.50908e-05, gnorm=1.15, train_wall=6, gb_free=10.4, wall=12177
2025-04-03 08:26:59 | INFO | train_inner | epoch 029:     48 / 126 loss=5.14, nll_loss=1.419, ppl=2.67, wps=1543, ups=0.35, wpb=4461, bsz=176, num_updates=3576, lr=2.50838e-05, gnorm=1.318, train_wall=6, gb_free=10.1, wall=12183
2025-04-03 08:27:04 | INFO | train_inner | epoch 029:     50 / 126 loss=5.091, nll_loss=1.354, ppl=2.56, wps=1764.7, ups=0.35, wpb=5081, bsz=292, num_updates=3578, lr=2.50767e-05, gnorm=1.155, train_wall=6, gb_free=13.6, wall=12189
2025-04-03 08:27:10 | INFO | train_inner | epoch 029:     52 / 126 loss=5.083, nll_loss=1.336, ppl=2.53, wps=1730.9, ups=0.33, wpb=5183, bsz=300, num_updates=3580, lr=2.50697e-05, gnorm=1.101, train_wall=6, gb_free=13.5, wall=12195
2025-04-03 08:27:16 | INFO | train_inner | epoch 029:     54 / 126 loss=5.039, nll_loss=1.306, ppl=2.47, wps=1734.3, ups=0.38, wpb=4564.5, bsz=296, num_updates=3582, lr=2.50627e-05, gnorm=1.202, train_wall=5, gb_free=13.3, wall=12200
2025-04-03 08:27:21 | INFO | train_inner | epoch 029:     56 / 126 loss=5.12, nll_loss=1.387, ppl=2.62, wps=1647.5, ups=0.35, wpb=4755.5, bsz=168, num_updates=3584, lr=2.50557e-05, gnorm=1.226, train_wall=6, gb_free=9.8, wall=12206
2025-04-03 08:27:27 | INFO | train_inner | epoch 029:     58 / 126 loss=5.305, nll_loss=1.631, ppl=3.1, wps=1767.3, ups=0.34, wpb=5165.5, bsz=304, num_updates=3586, lr=2.50488e-05, gnorm=1.293, train_wall=6, gb_free=11.3, wall=12211
2025-04-03 08:27:33 | INFO | train_inner | epoch 029:     60 / 126 loss=5.01, nll_loss=1.25, ppl=2.38, wps=1255.8, ups=0.34, wpb=3647.5, bsz=284, num_updates=3588, lr=2.50418e-05, gnorm=1.259, train_wall=6, gb_free=10.4, wall=12217
2025-04-03 08:27:38 | INFO | train_inner | epoch 029:     62 / 126 loss=4.966, nll_loss=1.206, ppl=2.31, wps=1558.7, ups=0.39, wpb=3956, bsz=304, num_updates=3590, lr=2.50348e-05, gnorm=1.159, train_wall=5, gb_free=13.4, wall=12222
2025-04-03 08:27:44 | INFO | train_inner | epoch 029:     64 / 126 loss=4.93, nll_loss=1.176, ppl=2.26, wps=1503.2, ups=0.37, wpb=4052, bsz=368, num_updates=3592, lr=2.50278e-05, gnorm=1.088, train_wall=5, gb_free=11.8, wall=12228
2025-04-03 08:27:49 | INFO | train_inner | epoch 029:     66 / 126 loss=4.973, nll_loss=1.209, ppl=2.31, wps=1485.1, ups=0.35, wpb=4301, bsz=216, num_updates=3594, lr=2.50209e-05, gnorm=1.107, train_wall=6, gb_free=12.9, wall=12233
2025-04-03 08:27:55 | INFO | train_inner | epoch 029:     68 / 126 loss=5.021, nll_loss=1.289, ppl=2.44, wps=1730.8, ups=0.33, wpb=5197, bsz=312, num_updates=3596, lr=2.50139e-05, gnorm=1.157, train_wall=6, gb_free=9.8, wall=12239
2025-04-03 08:28:01 | INFO | train_inner | epoch 029:     70 / 126 loss=5.039, nll_loss=1.292, ppl=2.45, wps=1781.4, ups=0.39, wpb=4619.5, bsz=252, num_updates=3598, lr=2.50069e-05, gnorm=1.26, train_wall=5, gb_free=10.7, wall=12245
2025-04-03 08:28:06 | INFO | train_inner | epoch 029:     72 / 126 loss=5.025, nll_loss=1.27, ppl=2.41, wps=1560.8, ups=0.36, wpb=4288, bsz=268, num_updates=3600, lr=2.5e-05, gnorm=1.235, train_wall=5, gb_free=12.7, wall=12250
2025-04-03 08:28:12 | INFO | train_inner | epoch 029:     74 / 126 loss=5.127, nll_loss=1.393, ppl=2.63, wps=1726.7, ups=0.35, wpb=4923.5, bsz=248, num_updates=3602, lr=2.49931e-05, gnorm=1.284, train_wall=6, gb_free=12.9, wall=12256
2025-04-03 08:28:17 | INFO | train_inner | epoch 029:     76 / 126 loss=5.021, nll_loss=1.254, ppl=2.38, wps=1584.8, ups=0.37, wpb=4237.5, bsz=204, num_updates=3604, lr=2.49861e-05, gnorm=1.235, train_wall=5, gb_free=10.3, wall=12261
2025-04-03 08:28:22 | INFO | train_inner | epoch 029:     78 / 126 loss=5.061, nll_loss=1.308, ppl=2.48, wps=1511.2, ups=0.38, wpb=3990.5, bsz=136, num_updates=3606, lr=2.49792e-05, gnorm=1.35, train_wall=5, gb_free=11.8, wall=12267
2025-04-03 08:28:28 | INFO | train_inner | epoch 029:     80 / 126 loss=5.012, nll_loss=1.289, ppl=2.44, wps=1563.1, ups=0.38, wpb=4116.5, bsz=312, num_updates=3608, lr=2.49723e-05, gnorm=1.288, train_wall=5, gb_free=11.6, wall=12272
2025-04-03 08:28:33 | INFO | train_inner | epoch 029:     82 / 126 loss=5.043, nll_loss=1.308, ppl=2.48, wps=1684, ups=0.36, wpb=4616, bsz=252, num_updates=3610, lr=2.49653e-05, gnorm=1.187, train_wall=5, gb_free=12.6, wall=12277
2025-04-03 08:28:39 | INFO | train_inner | epoch 029:     84 / 126 loss=5.057, nll_loss=1.306, ppl=2.47, wps=1474.5, ups=0.37, wpb=4002, bsz=192, num_updates=3612, lr=2.49584e-05, gnorm=1.261, train_wall=5, gb_free=14.5, wall=12283
2025-04-03 08:28:44 | INFO | train_inner | epoch 029:     86 / 126 loss=5.089, nll_loss=1.345, ppl=2.54, wps=1537.5, ups=0.34, wpb=4542, bsz=296, num_updates=3614, lr=2.49515e-05, gnorm=1.36, train_wall=6, gb_free=11.5, wall=12289
2025-04-03 08:28:50 | INFO | train_inner | epoch 029:     88 / 126 loss=5.062, nll_loss=1.307, ppl=2.47, wps=1464.1, ups=0.36, wpb=4032.5, bsz=188, num_updates=3616, lr=2.49446e-05, gnorm=1.306, train_wall=5, gb_free=10.4, wall=12294
2025-04-03 08:28:56 | INFO | train_inner | epoch 029:     90 / 126 loss=5.076, nll_loss=1.341, ppl=2.53, wps=1630.2, ups=0.36, wpb=4554, bsz=208, num_updates=3618, lr=2.49377e-05, gnorm=1.16, train_wall=6, gb_free=13, wall=12300
2025-04-03 08:29:01 | INFO | train_inner | epoch 029:     92 / 126 loss=5.005, nll_loss=1.25, ppl=2.38, wps=1595.5, ups=0.36, wpb=4435, bsz=264, num_updates=3620, lr=2.49308e-05, gnorm=1.16, train_wall=6, gb_free=12.8, wall=12305
2025-04-03 08:29:07 | INFO | train_inner | epoch 029:     94 / 126 loss=5.083, nll_loss=1.352, ppl=2.55, wps=1645.7, ups=0.34, wpb=4826.5, bsz=212, num_updates=3622, lr=2.4924e-05, gnorm=1.339, train_wall=6, gb_free=12.4, wall=12311
2025-04-03 08:29:13 | INFO | train_inner | epoch 029:     96 / 126 loss=5.035, nll_loss=1.294, ppl=2.45, wps=1685.3, ups=0.36, wpb=4686.5, bsz=264, num_updates=3624, lr=2.49171e-05, gnorm=1.157, train_wall=6, gb_free=9.6, wall=12317
2025-04-03 08:29:18 | INFO | train_inner | epoch 029:     98 / 126 loss=5.046, nll_loss=1.303, ppl=2.47, wps=1674.9, ups=0.4, wpb=4201, bsz=184, num_updates=3626, lr=2.49102e-05, gnorm=1.322, train_wall=5, gb_free=12.7, wall=12322
2025-04-03 08:29:23 | INFO | train_inner | epoch 029:    100 / 126 loss=5.05, nll_loss=1.297, ppl=2.46, wps=1637.6, ups=0.39, wpb=4244.5, bsz=260, num_updates=3628, lr=2.49033e-05, gnorm=1.294, train_wall=5, gb_free=14.1, wall=12327
2025-04-03 08:29:29 | INFO | train_inner | epoch 029:    102 / 126 loss=5.052, nll_loss=1.285, ppl=2.44, wps=1424, ups=0.35, wpb=4125.5, bsz=240, num_updates=3630, lr=2.48965e-05, gnorm=1.228, train_wall=6, gb_free=10.9, wall=12333
2025-04-03 08:29:34 | INFO | train_inner | epoch 029:    104 / 126 loss=5.059, nll_loss=1.326, ppl=2.51, wps=1593.2, ups=0.38, wpb=4161.5, bsz=272, num_updates=3632, lr=2.48896e-05, gnorm=1.274, train_wall=5, gb_free=15.7, wall=12338
2025-04-03 08:29:39 | INFO | train_inner | epoch 029:    106 / 126 loss=5.034, nll_loss=1.3, ppl=2.46, wps=1681.1, ups=0.37, wpb=4492, bsz=264, num_updates=3634, lr=2.48828e-05, gnorm=1.216, train_wall=5, gb_free=13.2, wall=12343
2025-04-03 08:29:45 | INFO | train_inner | epoch 029:    108 / 126 loss=5.06, nll_loss=1.325, ppl=2.51, wps=1794, ups=0.35, wpb=5137, bsz=304, num_updates=3636, lr=2.48759e-05, gnorm=1.131, train_wall=6, gb_free=13.5, wall=12349
2025-04-03 08:29:51 | INFO | train_inner | epoch 029:    110 / 126 loss=5.121, nll_loss=1.409, ppl=2.66, wps=1611.1, ups=0.34, wpb=4738.5, bsz=260, num_updates=3638, lr=2.48691e-05, gnorm=1.189, train_wall=6, gb_free=11.7, wall=12355
2025-04-03 08:29:57 | INFO | train_inner | epoch 029:    112 / 126 loss=5.085, nll_loss=1.347, ppl=2.54, wps=1818.9, ups=0.33, wpb=5440, bsz=296, num_updates=3640, lr=2.48623e-05, gnorm=1.159, train_wall=6, gb_free=12.4, wall=12361
2025-04-03 08:30:02 | INFO | train_inner | epoch 029:    114 / 126 loss=5.031, nll_loss=1.266, ppl=2.4, wps=1815, ups=0.36, wpb=5049.5, bsz=292, num_updates=3642, lr=2.48554e-05, gnorm=1.145, train_wall=6, gb_free=11.8, wall=12366
2025-04-03 08:30:08 | INFO | train_inner | epoch 029:    116 / 126 loss=5.046, nll_loss=1.314, ppl=2.49, wps=1763, ups=0.35, wpb=5013, bsz=380, num_updates=3644, lr=2.48486e-05, gnorm=1.191, train_wall=6, gb_free=11.4, wall=12372
2025-04-03 08:30:14 | INFO | train_inner | epoch 029:    118 / 126 loss=5.107, nll_loss=1.393, ppl=2.63, wps=1689, ups=0.36, wpb=4734, bsz=240, num_updates=3646, lr=2.48418e-05, gnorm=1.225, train_wall=6, gb_free=12.4, wall=12378
2025-04-03 08:30:19 | INFO | train_inner | epoch 029:    120 / 126 loss=5.039, nll_loss=1.294, ppl=2.45, wps=1644.1, ups=0.35, wpb=4641, bsz=196, num_updates=3648, lr=2.4835e-05, gnorm=1.74, train_wall=6, gb_free=11.2, wall=12383
2025-04-03 08:30:25 | INFO | train_inner | epoch 029:    122 / 126 loss=5.019, nll_loss=1.255, ppl=2.39, wps=1400.6, ups=0.37, wpb=3741, bsz=204, num_updates=3650, lr=2.48282e-05, gnorm=1.277, train_wall=5, gb_free=14.7, wall=12389
2025-04-03 08:30:30 | INFO | train_inner | epoch 029:    124 / 126 loss=5.085, nll_loss=1.355, ppl=2.56, wps=1687.8, ups=0.37, wpb=4619, bsz=328, num_updates=3652, lr=2.48214e-05, gnorm=1.174, train_wall=5, gb_free=11.8, wall=12394
2025-04-03 08:30:34 | INFO | train_inner | epoch 029:    126 / 126 loss=5.072, nll_loss=1.319, ppl=2.5, wps=1748.1, ups=0.46, wpb=3771.5, bsz=188, num_updates=3654, lr=2.48146e-05, gnorm=1.427, train_wall=4, gb_free=17.8, wall=12398
2025-04-03 08:30:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-03 08:30:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=15985.45703125Mb; avail=239099.74609375Mb
2025-04-03 08:30:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000624
2025-04-03 08:30:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15985.45703125Mb; avail=239099.74609375Mb
2025-04-03 08:30:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012889
2025-04-03 08:30:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15985.45703125Mb; avail=239099.74609375Mb
2025-04-03 08:30:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.010885
2025-04-03 08:30:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024764
2025-04-03 08:30:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15985.45703125Mb; avail=239099.74609375Mb
2025-04-03 08:30:49 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 5.89 | nll_loss 2.17 | ppl 4.5 | wps 3863 | wpb 2070.5 | bsz 122.7 | num_updates 3654 | best_loss 5.874
2025-04-03 08:30:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 3654 updates
2025-04-03 08:30:49 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_last.pt
2025-04-03 08:31:28 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_last.pt
2025-04-03 08:31:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_last.pt (epoch 29 @ 3654 updates, score 5.89) (writing took 39.47767838893924 seconds)
2025-04-03 08:31:28 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2025-04-03 08:31:28 | INFO | train | epoch 029 | loss 5.059 | nll_loss 1.317 | ppl 2.49 | wps 1410.8 | ups 0.31 | wpb 4549.7 | bsz 252.8 | num_updates 3654 | lr 2.48146e-05 | gnorm 1.233 | train_wall 352 | gb_free 17.8 | wall 12452
2025-04-03 08:31:28 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:mr-hi': 31849}; raw total size: 31849
2025-04-03 08:31:28 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:mr-hi': 31849}; resampled total size: 31849
2025-04-03 08:31:28 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:mr-hi': 1.0}
2025-04-03 08:31:28 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001185
2025-04-03 08:31:28 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=26793.17578125Mb; avail=228291.96875Mb
2025-04-03 08:31:28 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000588
2025-04-03 08:31:28 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003797
2025-04-03 08:31:28 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26793.17578125Mb; avail=228291.96875Mb
2025-04-03 08:31:28 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000093
2025-04-03 08:31:28 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26793.17578125Mb; avail=228291.96875Mb
2025-04-03 08:31:28 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001132
2025-04-03 08:31:28 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.005357
2025-04-03 08:31:28 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26793.17578125Mb; avail=228291.96875Mb
2025-04-03 08:31:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 126
2025-04-03 08:31:28 | INFO | fairseq.trainer | begin training epoch 30
2025-04-03 08:31:28 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-03 08:31:34 | INFO | train_inner | epoch 030:      2 / 126 loss=5.101, nll_loss=1.355, ppl=2.56, wps=168.2, ups=0.03, wpb=5019.5, bsz=300, num_updates=3656, lr=2.48078e-05, gnorm=1.161, train_wall=6, gb_free=13.5, wall=12458
2025-04-03 08:31:40 | INFO | train_inner | epoch 030:      4 / 126 loss=4.99, nll_loss=1.248, ppl=2.37, wps=1903.3, ups=0.35, wpb=5446.5, bsz=340, num_updates=3658, lr=2.4801e-05, gnorm=1.162, train_wall=6, gb_free=13.5, wall=12464
2025-04-03 08:31:45 | INFO | train_inner | epoch 030:      6 / 126 loss=4.957, nll_loss=1.193, ppl=2.29, wps=1550.5, ups=0.37, wpb=4220.5, bsz=244, num_updates=3660, lr=2.47942e-05, gnorm=1.264, train_wall=5, gb_free=14.7, wall=12469
2025-04-03 08:31:51 | INFO | train_inner | epoch 030:      8 / 126 loss=4.952, nll_loss=1.186, ppl=2.27, wps=1457.2, ups=0.34, wpb=4312, bsz=244, num_updates=3662, lr=2.47875e-05, gnorm=1.146, train_wall=6, gb_free=10.3, wall=12475
2025-04-03 08:31:57 | INFO | train_inner | epoch 030:     10 / 126 loss=5.065, nll_loss=1.336, ppl=2.52, wps=1710.2, ups=0.35, wpb=4909, bsz=284, num_updates=3664, lr=2.47807e-05, gnorm=1.22, train_wall=6, gb_free=13.4, wall=12481
2025-04-03 08:32:02 | INFO | train_inner | epoch 030:     12 / 126 loss=5.025, nll_loss=1.267, ppl=2.41, wps=1793, ups=0.38, wpb=4716.5, bsz=252, num_updates=3666, lr=2.47739e-05, gnorm=1.185, train_wall=5, gb_free=9.2, wall=12486
2025-04-03 08:32:08 | INFO | train_inner | epoch 030:     14 / 126 loss=5.032, nll_loss=1.277, ppl=2.42, wps=1595.7, ups=0.34, wpb=4643, bsz=244, num_updates=3668, lr=2.47672e-05, gnorm=1.121, train_wall=6, gb_free=12.9, wall=12492
2025-04-03 08:32:13 | INFO | train_inner | epoch 030:     16 / 126 loss=5.133, nll_loss=1.409, ppl=2.65, wps=1734.4, ups=0.37, wpb=4673, bsz=228, num_updates=3670, lr=2.47604e-05, gnorm=1.256, train_wall=5, gb_free=12.1, wall=12497
2025-04-03 08:32:19 | INFO | train_inner | epoch 030:     18 / 126 loss=4.907, nll_loss=1.13, ppl=2.19, wps=1539.4, ups=0.37, wpb=4124, bsz=308, num_updates=3672, lr=2.47537e-05, gnorm=1.154, train_wall=5, gb_free=13.1, wall=12503
2025-04-03 08:32:24 | INFO | train_inner | epoch 030:     20 / 126 loss=4.979, nll_loss=1.227, ppl=2.34, wps=1781.8, ups=0.37, wpb=4836, bsz=304, num_updates=3674, lr=2.4747e-05, gnorm=1.111, train_wall=5, gb_free=12.2, wall=12508
2025-04-03 08:32:30 | INFO | train_inner | epoch 030:     22 / 126 loss=4.993, nll_loss=1.237, ppl=2.36, wps=1603.2, ups=0.36, wpb=4399.5, bsz=256, num_updates=3676, lr=2.47402e-05, gnorm=1.246, train_wall=5, gb_free=14.3, wall=12514
2025-04-03 08:32:35 | INFO | train_inner | epoch 030:     24 / 126 loss=5.026, nll_loss=1.252, ppl=2.38, wps=1683.2, ups=0.35, wpb=4860.5, bsz=184, num_updates=3678, lr=2.47335e-05, gnorm=1.24, train_wall=6, gb_free=13.8, wall=12519
2025-04-03 08:32:41 | INFO | train_inner | epoch 030:     26 / 126 loss=5.025, nll_loss=1.268, ppl=2.41, wps=1769.5, ups=0.36, wpb=4979.5, bsz=320, num_updates=3680, lr=2.47268e-05, gnorm=1.094, train_wall=6, gb_free=10.4, wall=12525
2025-04-03 08:32:46 | INFO | train_inner | epoch 030:     28 / 126 loss=5.021, nll_loss=1.271, ppl=2.41, wps=1666.6, ups=0.37, wpb=4475.5, bsz=224, num_updates=3682, lr=2.47201e-05, gnorm=1.171, train_wall=5, gb_free=13.9, wall=12530
2025-04-03 08:32:52 | INFO | train_inner | epoch 030:     30 / 126 loss=4.973, nll_loss=1.214, ppl=2.32, wps=1724.1, ups=0.35, wpb=4939, bsz=284, num_updates=3684, lr=2.47133e-05, gnorm=1.081, train_wall=6, gb_free=14, wall=12536
2025-04-03 08:32:58 | INFO | train_inner | epoch 030:     32 / 126 loss=4.955, nll_loss=1.199, ppl=2.3, wps=1449.5, ups=0.36, wpb=4052, bsz=228, num_updates=3686, lr=2.47066e-05, gnorm=1.22, train_wall=6, gb_free=9.4, wall=12542
2025-04-03 08:33:03 | INFO | train_inner | epoch 030:     34 / 126 loss=4.981, nll_loss=1.237, ppl=2.36, wps=1787.3, ups=0.35, wpb=5099.5, bsz=420, num_updates=3688, lr=2.46999e-05, gnorm=1.109, train_wall=6, gb_free=13.1, wall=12548
2025-04-03 08:33:08 | INFO | train_inner | epoch 030:     36 / 126 loss=5.015, nll_loss=1.242, ppl=2.37, wps=1513.1, ups=0.44, wpb=3450.5, bsz=148.5, num_updates=3690, lr=2.46932e-05, gnorm=1.454, train_wall=5, gb_free=9.2, wall=12552
2025-04-03 08:33:14 | INFO | train_inner | epoch 030:     38 / 126 loss=4.956, nll_loss=1.186, ppl=2.27, wps=1613.5, ups=0.35, wpb=4654, bsz=264, num_updates=3692, lr=2.46866e-05, gnorm=1.12, train_wall=6, gb_free=11.7, wall=12558
2025-04-03 08:33:19 | INFO | train_inner | epoch 030:     40 / 126 loss=5.03, nll_loss=1.299, ppl=2.46, wps=1602.4, ups=0.36, wpb=4403.5, bsz=320, num_updates=3694, lr=2.46799e-05, gnorm=1.254, train_wall=5, gb_free=12.6, wall=12563
2025-04-03 08:33:24 | INFO | train_inner | epoch 030:     42 / 126 loss=4.961, nll_loss=1.207, ppl=2.31, wps=1621.4, ups=0.39, wpb=4127.5, bsz=248, num_updates=3696, lr=2.46732e-05, gnorm=1.288, train_wall=5, gb_free=13.3, wall=12568
2025-04-03 08:33:30 | INFO | train_inner | epoch 030:     44 / 126 loss=5.067, nll_loss=1.322, ppl=2.5, wps=1906.2, ups=0.34, wpb=5595, bsz=320, num_updates=3698, lr=2.46665e-05, gnorm=1.166, train_wall=6, gb_free=9.5, wall=12574
2025-04-03 08:33:36 | INFO | train_inner | epoch 030:     46 / 126 loss=4.957, nll_loss=1.175, ppl=2.26, wps=1642.3, ups=0.37, wpb=4430, bsz=252, num_updates=3700, lr=2.46598e-05, gnorm=1.129, train_wall=5, gb_free=13.5, wall=12580
2025-04-03 08:33:41 | INFO | train_inner | epoch 030:     48 / 126 loss=4.969, nll_loss=1.199, ppl=2.3, wps=1379.9, ups=0.35, wpb=3966, bsz=244, num_updates=3702, lr=2.46532e-05, gnorm=1.247, train_wall=6, gb_free=10.4, wall=12585
2025-04-03 08:33:46 | INFO | train_inner | epoch 030:     50 / 126 loss=4.971, nll_loss=1.225, ppl=2.34, wps=1546.9, ups=0.4, wpb=3887, bsz=252, num_updates=3704, lr=2.46465e-05, gnorm=1.262, train_wall=5, gb_free=14.9, wall=12590
2025-04-03 08:33:52 | INFO | train_inner | epoch 030:     52 / 126 loss=5.009, nll_loss=1.281, ppl=2.43, wps=1652.5, ups=0.36, wpb=4583.5, bsz=256, num_updates=3706, lr=2.46399e-05, gnorm=1.207, train_wall=6, gb_free=9.4, wall=12596
2025-04-03 08:33:57 | INFO | train_inner | epoch 030:     54 / 126 loss=4.963, nll_loss=1.196, ppl=2.29, wps=1537.5, ups=0.36, wpb=4253, bsz=236, num_updates=3708, lr=2.46332e-05, gnorm=1.402, train_wall=6, gb_free=11.9, wall=12602
2025-04-03 08:34:03 | INFO | train_inner | epoch 030:     56 / 126 loss=4.995, nll_loss=1.212, ppl=2.32, wps=1667.3, ups=0.35, wpb=4803.5, bsz=192, num_updates=3710, lr=2.46266e-05, gnorm=1.217, train_wall=6, gb_free=11.4, wall=12607
2025-04-03 08:34:09 | INFO | train_inner | epoch 030:     58 / 126 loss=4.978, nll_loss=1.196, ppl=2.29, wps=1383.5, ups=0.35, wpb=3967.5, bsz=208, num_updates=3712, lr=2.462e-05, gnorm=1.157, train_wall=6, gb_free=11.1, wall=12613
2025-04-03 08:34:19 | INFO | train_inner | epoch 030:     60 / 126 loss=4.973, nll_loss=1.21, ppl=2.31, wps=820.4, ups=0.19, wpb=4269.5, bsz=220, num_updates=3714, lr=2.46133e-05, gnorm=1.189, train_wall=10, gb_free=10.7, wall=12623
2025-04-03 08:34:25 | INFO | train_inner | epoch 030:     62 / 126 loss=5.044, nll_loss=1.31, ppl=2.48, wps=1794.9, ups=0.34, wpb=5272.5, bsz=244, num_updates=3716, lr=2.46067e-05, gnorm=1.123, train_wall=6, gb_free=10.9, wall=12629
2025-04-03 08:34:31 | INFO | train_inner | epoch 030:     64 / 126 loss=5.047, nll_loss=1.322, ppl=2.5, wps=1689.1, ups=0.37, wpb=4588, bsz=248, num_updates=3718, lr=2.46001e-05, gnorm=1.414, train_wall=5, gb_free=12.1, wall=12635
2025-04-03 08:34:36 | INFO | train_inner | epoch 030:     66 / 126 loss=4.962, nll_loss=1.175, ppl=2.26, wps=1758.9, ups=0.35, wpb=4968, bsz=276, num_updates=3720, lr=2.45935e-05, gnorm=1.033, train_wall=6, gb_free=11.4, wall=12640
2025-04-03 08:34:42 | INFO | train_inner | epoch 030:     68 / 126 loss=5.007, nll_loss=1.226, ppl=2.34, wps=1590.4, ups=0.35, wpb=4599, bsz=160, num_updates=3722, lr=2.45869e-05, gnorm=1.345, train_wall=6, gb_free=9.1, wall=12646
2025-04-03 08:34:48 | INFO | train_inner | epoch 030:     70 / 126 loss=5.052, nll_loss=1.32, ppl=2.5, wps=1590.1, ups=0.36, wpb=4394, bsz=228, num_updates=3724, lr=2.45803e-05, gnorm=1.287, train_wall=6, gb_free=12.7, wall=12652
2025-04-03 08:34:53 | INFO | train_inner | epoch 030:     72 / 126 loss=5.092, nll_loss=1.378, ppl=2.6, wps=1554.8, ups=0.37, wpb=4199.5, bsz=204, num_updates=3726, lr=2.45737e-05, gnorm=1.3, train_wall=5, gb_free=13.9, wall=12657
2025-04-03 08:34:59 | INFO | train_inner | epoch 030:     74 / 126 loss=4.937, nll_loss=1.179, ppl=2.26, wps=1533.2, ups=0.36, wpb=4308, bsz=280, num_updates=3728, lr=2.45671e-05, gnorm=1.176, train_wall=6, gb_free=12.3, wall=12663
2025-04-03 08:35:04 | INFO | train_inner | epoch 030:     76 / 126 loss=5.06, nll_loss=1.299, ppl=2.46, wps=1694.4, ups=0.37, wpb=4638, bsz=204, num_updates=3730, lr=2.45605e-05, gnorm=1.291, train_wall=5, gb_free=14.5, wall=12668
2025-04-03 08:35:09 | INFO | train_inner | epoch 030:     78 / 126 loss=5.021, nll_loss=1.245, ppl=2.37, wps=1710.8, ups=0.37, wpb=4586, bsz=264, num_updates=3732, lr=2.45539e-05, gnorm=1.136, train_wall=5, gb_free=14.7, wall=12674
2025-04-03 08:35:15 | INFO | train_inner | epoch 030:     80 / 126 loss=4.989, nll_loss=1.221, ppl=2.33, wps=1557.3, ups=0.35, wpb=4454, bsz=284, num_updates=3734, lr=2.45473e-05, gnorm=1.151, train_wall=6, gb_free=12.4, wall=12679
2025-04-03 08:35:21 | INFO | train_inner | epoch 030:     82 / 126 loss=5.043, nll_loss=1.308, ppl=2.48, wps=1672.8, ups=0.36, wpb=4686, bsz=196, num_updates=3736, lr=2.45407e-05, gnorm=1.211, train_wall=6, gb_free=13.8, wall=12685
2025-04-03 08:35:27 | INFO | train_inner | epoch 030:     84 / 126 loss=5.042, nll_loss=1.303, ppl=2.47, wps=1613.3, ups=0.35, wpb=4591, bsz=212, num_updates=3738, lr=2.45342e-05, gnorm=1.229, train_wall=6, gb_free=9.9, wall=12691
2025-04-03 08:35:32 | INFO | train_inner | epoch 030:     86 / 126 loss=5.004, nll_loss=1.247, ppl=2.37, wps=1674, ups=0.34, wpb=4856.5, bsz=264, num_updates=3740, lr=2.45276e-05, gnorm=1.107, train_wall=6, gb_free=10.4, wall=12696
2025-04-03 08:35:38 | INFO | train_inner | epoch 030:     88 / 126 loss=4.975, nll_loss=1.199, ppl=2.3, wps=1610.9, ups=0.37, wpb=4389.5, bsz=220, num_updates=3742, lr=2.45211e-05, gnorm=1.155, train_wall=5, gb_free=14, wall=12702
2025-04-03 08:35:43 | INFO | train_inner | epoch 030:     90 / 126 loss=4.956, nll_loss=1.182, ppl=2.27, wps=1677.2, ups=0.37, wpb=4572, bsz=276, num_updates=3744, lr=2.45145e-05, gnorm=1.108, train_wall=5, gb_free=14.6, wall=12707
2025-04-03 08:35:48 | INFO | train_inner | epoch 030:     92 / 126 loss=5.011, nll_loss=1.26, ppl=2.39, wps=1679.6, ups=0.39, wpb=4357, bsz=272, num_updates=3746, lr=2.4508e-05, gnorm=1.197, train_wall=5, gb_free=12.3, wall=12713
2025-04-03 08:35:54 | INFO | train_inner | epoch 030:     94 / 126 loss=5.037, nll_loss=1.304, ppl=2.47, wps=1767.7, ups=0.35, wpb=5095, bsz=308, num_updates=3748, lr=2.45014e-05, gnorm=1.194, train_wall=6, gb_free=12, wall=12718
2025-04-03 08:36:00 | INFO | train_inner | epoch 030:     96 / 126 loss=5.018, nll_loss=1.264, ppl=2.4, wps=1654.7, ups=0.37, wpb=4503.5, bsz=280, num_updates=3750, lr=2.44949e-05, gnorm=1.164, train_wall=5, gb_free=11.6, wall=12724
2025-04-03 08:36:05 | INFO | train_inner | epoch 030:     98 / 126 loss=5.092, nll_loss=1.354, ppl=2.56, wps=1571.7, ups=0.37, wpb=4305.5, bsz=172, num_updates=3752, lr=2.44884e-05, gnorm=1.364, train_wall=5, gb_free=10.2, wall=12729
2025-04-03 08:36:11 | INFO | train_inner | epoch 030:    100 / 126 loss=5.194, nll_loss=1.498, ppl=2.82, wps=1832.9, ups=0.35, wpb=5192.5, bsz=324, num_updates=3754, lr=2.44818e-05, gnorm=1.287, train_wall=6, gb_free=11.1, wall=12735
2025-04-03 08:36:16 | INFO | train_inner | epoch 030:    102 / 126 loss=5.049, nll_loss=1.307, ppl=2.47, wps=1587.9, ups=0.35, wpb=4527, bsz=240, num_updates=3756, lr=2.44753e-05, gnorm=1.264, train_wall=6, gb_free=10.4, wall=12741
2025-04-03 08:36:22 | INFO | train_inner | epoch 030:    104 / 126 loss=4.932, nll_loss=1.144, ppl=2.21, wps=1325.4, ups=0.35, wpb=3766, bsz=224, num_updates=3758, lr=2.44688e-05, gnorm=1.322, train_wall=6, gb_free=12, wall=12746
2025-04-03 08:36:27 | INFO | train_inner | epoch 030:    106 / 126 loss=5.013, nll_loss=1.26, ppl=2.39, wps=1654.3, ups=0.42, wpb=3977.5, bsz=220, num_updates=3760, lr=2.44623e-05, gnorm=1.287, train_wall=5, gb_free=12.8, wall=12751
2025-04-03 08:36:33 | INFO | train_inner | epoch 030:    108 / 126 loss=5.011, nll_loss=1.264, ppl=2.4, wps=1663.7, ups=0.35, wpb=4803, bsz=232, num_updates=3762, lr=2.44558e-05, gnorm=1.188, train_wall=6, gb_free=8.9, wall=12757
2025-04-03 08:36:38 | INFO | train_inner | epoch 030:    110 / 126 loss=5.069, nll_loss=1.334, ppl=2.52, wps=1585.5, ups=0.35, wpb=4560, bsz=268, num_updates=3764, lr=2.44493e-05, gnorm=1.399, train_wall=6, gb_free=10.5, wall=12763
2025-04-03 08:36:44 | INFO | train_inner | epoch 030:    112 / 126 loss=5.196, nll_loss=1.474, ppl=2.78, wps=1642.8, ups=0.34, wpb=4798, bsz=160, num_updates=3766, lr=2.44428e-05, gnorm=1.792, train_wall=6, gb_free=9.8, wall=12768
2025-04-03 08:36:50 | INFO | train_inner | epoch 030:    114 / 126 loss=4.965, nll_loss=1.182, ppl=2.27, wps=1536.4, ups=0.36, wpb=4253.5, bsz=168, num_updates=3768, lr=2.44363e-05, gnorm=1.233, train_wall=6, gb_free=13.7, wall=12774
2025-04-03 08:36:56 | INFO | train_inner | epoch 030:    116 / 126 loss=5.023, nll_loss=1.272, ppl=2.42, wps=1714.6, ups=0.34, wpb=4991.5, bsz=276, num_updates=3770, lr=2.44298e-05, gnorm=1.173, train_wall=6, gb_free=12.9, wall=12780
2025-04-03 08:37:01 | INFO | train_inner | epoch 030:    118 / 126 loss=4.983, nll_loss=1.239, ppl=2.36, wps=1807, ups=0.36, wpb=5012.5, bsz=364, num_updates=3772, lr=2.44234e-05, gnorm=1.15, train_wall=6, gb_free=14.7, wall=12785
2025-04-03 08:37:06 | INFO | train_inner | epoch 030:    120 / 126 loss=5.005, nll_loss=1.247, ppl=2.37, wps=1675.2, ups=0.38, wpb=4406, bsz=252, num_updates=3774, lr=2.44169e-05, gnorm=1.218, train_wall=5, gb_free=11.9, wall=12791
2025-04-03 08:37:12 | INFO | train_inner | epoch 030:    122 / 126 loss=5.005, nll_loss=1.25, ppl=2.38, wps=1718.1, ups=0.35, wpb=4922, bsz=300, num_updates=3776, lr=2.44104e-05, gnorm=1.149, train_wall=6, gb_free=8.4, wall=12796
2025-04-03 08:37:18 | INFO | train_inner | epoch 030:    124 / 126 loss=5.034, nll_loss=1.279, ppl=2.43, wps=1744.9, ups=0.36, wpb=4820.5, bsz=276, num_updates=3778, lr=2.4404e-05, gnorm=1.154, train_wall=6, gb_free=13.4, wall=12802
2025-04-03 08:37:22 | INFO | train_inner | epoch 030:    126 / 126 loss=4.954, nll_loss=1.191, ppl=2.28, wps=1576.9, ups=0.5, wpb=3142.5, bsz=204, num_updates=3780, lr=2.43975e-05, gnorm=1.541, train_wall=4, gb_free=18.6, wall=12806
2025-04-03 08:37:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-03 08:37:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=15978.32421875Mb; avail=239106.87890625Mb
2025-04-03 08:37:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000628
2025-04-03 08:37:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15978.32421875Mb; avail=239106.87890625Mb
2025-04-03 08:37:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.013024
2025-04-03 08:37:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15978.32421875Mb; avail=239106.87890625Mb
2025-04-03 08:37:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.010887
2025-04-03 08:37:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024932
2025-04-03 08:37:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15978.32421875Mb; avail=239106.87890625Mb
2025-04-03 08:37:36 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 5.873 | nll_loss 2.166 | ppl 4.49 | wps 3869.3 | wpb 2070.5 | bsz 122.7 | num_updates 3780 | best_loss 5.873
2025-04-03 08:37:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 3780 updates
2025-04-03 08:37:36 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 08:38:16 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 08:38:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt (epoch 30 @ 3780 updates, score 5.873) (writing took 63.58588620100636 seconds)
2025-04-03 08:38:40 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2025-04-03 08:38:40 | INFO | train | epoch 030 | loss 5.015 | nll_loss 1.261 | ppl 2.4 | wps 1328.7 | ups 0.29 | wpb 4549.7 | bsz 252.8 | num_updates 3780 | lr 2.43975e-05 | gnorm 1.225 | train_wall 353 | gb_free 18.6 | wall 12884
2025-04-03 08:38:40 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:mr-hi': 31849}; raw total size: 31849
2025-04-03 08:38:40 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:mr-hi': 31849}; resampled total size: 31849
2025-04-03 08:38:40 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:mr-hi': 1.0}
2025-04-03 08:38:40 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001007
2025-04-03 08:38:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=26760.4609375Mb; avail=228324.62109375Mb
2025-04-03 08:38:40 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000532
2025-04-03 08:38:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003429
2025-04-03 08:38:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26760.953125Mb; avail=228324.12890625Mb
2025-04-03 08:38:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000091
2025-04-03 08:38:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26760.953125Mb; avail=228324.12890625Mb
2025-04-03 08:38:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001157
2025-04-03 08:38:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.004982
2025-04-03 08:38:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26760.953125Mb; avail=228324.12890625Mb
2025-04-03 08:38:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 126
2025-04-03 08:38:40 | INFO | fairseq.trainer | begin training epoch 31
2025-04-03 08:38:40 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-03 08:38:45 | INFO | train_inner | epoch 031:      2 / 126 loss=5.005, nll_loss=1.262, ppl=2.4, wps=99.2, ups=0.02, wpb=4134, bsz=288, num_updates=3782, lr=2.43911e-05, gnorm=1.39, train_wall=5, gb_free=11.9, wall=12889
2025-04-03 08:38:51 | INFO | train_inner | epoch 031:      4 / 126 loss=5.022, nll_loss=1.247, ppl=2.37, wps=1829.5, ups=0.34, wpb=5366, bsz=228, num_updates=3784, lr=2.43846e-05, gnorm=1.186, train_wall=6, gb_free=8.8, wall=12895
2025-04-03 08:38:57 | INFO | train_inner | epoch 031:      6 / 126 loss=4.973, nll_loss=1.197, ppl=2.29, wps=1605.6, ups=0.36, wpb=4479.5, bsz=260, num_updates=3786, lr=2.43782e-05, gnorm=1.132, train_wall=6, gb_free=10.2, wall=12901
2025-04-03 08:39:02 | INFO | train_inner | epoch 031:      8 / 126 loss=5.064, nll_loss=1.34, ppl=2.53, wps=1663.5, ups=0.35, wpb=4735.5, bsz=240, num_updates=3788, lr=2.43717e-05, gnorm=1.244, train_wall=6, gb_free=10, wall=12906
2025-04-03 08:39:08 | INFO | train_inner | epoch 031:     10 / 126 loss=4.948, nll_loss=1.18, ppl=2.27, wps=1487.6, ups=0.34, wpb=4356.5, bsz=156, num_updates=3790, lr=2.43653e-05, gnorm=1.217, train_wall=6, gb_free=12.8, wall=12912
2025-04-03 08:39:14 | INFO | train_inner | epoch 031:     12 / 126 loss=5.058, nll_loss=1.315, ppl=2.49, wps=1836.7, ups=0.36, wpb=5034, bsz=272, num_updates=3792, lr=2.43589e-05, gnorm=1.301, train_wall=5, gb_free=13.1, wall=12918
2025-04-03 08:39:19 | INFO | train_inner | epoch 031:     14 / 126 loss=4.865, nll_loss=1.04, ppl=2.06, wps=1562.2, ups=0.38, wpb=4105.5, bsz=216, num_updates=3794, lr=2.43524e-05, gnorm=1.092, train_wall=5, gb_free=13.2, wall=12923
2025-04-03 08:39:24 | INFO | train_inner | epoch 031:     16 / 126 loss=4.909, nll_loss=1.131, ppl=2.19, wps=1836.2, ups=0.37, wpb=4963, bsz=356, num_updates=3796, lr=2.4346e-05, gnorm=1.012, train_wall=5, gb_free=11.9, wall=12928
2025-04-03 08:39:30 | INFO | train_inner | epoch 031:     18 / 126 loss=4.975, nll_loss=1.209, ppl=2.31, wps=1701.3, ups=0.36, wpb=4702.5, bsz=184, num_updates=3798, lr=2.43396e-05, gnorm=1.143, train_wall=6, gb_free=12.8, wall=12934
2025-04-03 08:39:35 | INFO | train_inner | epoch 031:     20 / 126 loss=4.911, nll_loss=1.139, ppl=2.2, wps=1539.8, ups=0.37, wpb=4144, bsz=292, num_updates=3800, lr=2.43332e-05, gnorm=1.096, train_wall=5, gb_free=12.7, wall=12939
2025-04-03 08:39:41 | INFO | train_inner | epoch 031:     22 / 126 loss=4.911, nll_loss=1.133, ppl=2.19, wps=1645.7, ups=0.37, wpb=4492, bsz=248, num_updates=3802, lr=2.43268e-05, gnorm=1.186, train_wall=5, gb_free=12.7, wall=12945
2025-04-03 08:39:46 | INFO | train_inner | epoch 031:     24 / 126 loss=4.965, nll_loss=1.204, ppl=2.3, wps=1476.1, ups=0.36, wpb=4059.5, bsz=264, num_updates=3804, lr=2.43204e-05, gnorm=1.231, train_wall=5, gb_free=10.8, wall=12950
2025-04-03 08:39:52 | INFO | train_inner | epoch 031:     26 / 126 loss=5.015, nll_loss=1.237, ppl=2.36, wps=1472.8, ups=0.32, wpb=4551, bsz=140, num_updates=3806, lr=2.4314e-05, gnorm=1.195, train_wall=6, gb_free=8.4, wall=12956
2025-04-03 08:39:57 | INFO | train_inner | epoch 031:     28 / 126 loss=4.885, nll_loss=1.101, ppl=2.15, wps=1394.1, ups=0.39, wpb=3583, bsz=216, num_updates=3808, lr=2.43076e-05, gnorm=1.189, train_wall=5, gb_free=14.5, wall=12962
2025-04-03 08:40:03 | INFO | train_inner | epoch 031:     30 / 126 loss=4.899, nll_loss=1.139, ppl=2.2, wps=1725.1, ups=0.36, wpb=4760.5, bsz=372, num_updates=3810, lr=2.43013e-05, gnorm=1.064, train_wall=6, gb_free=11.4, wall=12967
2025-04-03 08:40:09 | INFO | train_inner | epoch 031:     32 / 126 loss=5.077, nll_loss=1.345, ppl=2.54, wps=1741.9, ups=0.35, wpb=4962, bsz=236, num_updates=3812, lr=2.42949e-05, gnorm=1.202, train_wall=6, gb_free=11.9, wall=12973
2025-04-03 08:40:14 | INFO | train_inner | epoch 031:     34 / 126 loss=4.941, nll_loss=1.161, ppl=2.24, wps=1661.2, ups=0.35, wpb=4732.5, bsz=216, num_updates=3814, lr=2.42885e-05, gnorm=1.09, train_wall=6, gb_free=10.5, wall=12978
2025-04-03 08:40:20 | INFO | train_inner | epoch 031:     36 / 126 loss=5.068, nll_loss=1.339, ppl=2.53, wps=1551.5, ups=0.36, wpb=4314, bsz=296, num_updates=3816, lr=2.42821e-05, gnorm=1.338, train_wall=6, gb_free=11.1, wall=12984
2025-04-03 08:40:25 | INFO | train_inner | epoch 031:     38 / 126 loss=4.944, nll_loss=1.165, ppl=2.24, wps=1612.8, ups=0.37, wpb=4399, bsz=288, num_updates=3818, lr=2.42758e-05, gnorm=1.135, train_wall=5, gb_free=9.4, wall=12989
2025-04-03 08:40:30 | INFO | train_inner | epoch 031:     40 / 126 loss=5.061, nll_loss=1.332, ppl=2.52, wps=1803.4, ups=0.42, wpb=4288, bsz=280.5, num_updates=3820, lr=2.42694e-05, gnorm=1.305, train_wall=5, gb_free=13.7, wall=12994
2025-04-03 08:40:36 | INFO | train_inner | epoch 031:     42 / 126 loss=5.012, nll_loss=1.256, ppl=2.39, wps=1706.2, ups=0.35, wpb=4914, bsz=212, num_updates=3822, lr=2.42631e-05, gnorm=1.139, train_wall=6, gb_free=8.8, wall=13000
2025-04-03 08:40:41 | INFO | train_inner | epoch 031:     44 / 126 loss=4.941, nll_loss=1.172, ppl=2.25, wps=1696.9, ups=0.38, wpb=4479.5, bsz=280, num_updates=3824, lr=2.42567e-05, gnorm=1.23, train_wall=5, gb_free=14.5, wall=13005
2025-04-03 08:40:47 | INFO | train_inner | epoch 031:     46 / 126 loss=4.973, nll_loss=1.198, ppl=2.29, wps=1416.9, ups=0.33, wpb=4271.5, bsz=220, num_updates=3826, lr=2.42504e-05, gnorm=1.23, train_wall=6, gb_free=10, wall=13011
2025-04-03 08:40:53 | INFO | train_inner | epoch 031:     48 / 126 loss=4.88, nll_loss=1.076, ppl=2.11, wps=1398, ups=0.36, wpb=3915, bsz=152, num_updates=3828, lr=2.42441e-05, gnorm=1.138, train_wall=6, gb_free=9.6, wall=13017
2025-04-03 08:40:58 | INFO | train_inner | epoch 031:     50 / 126 loss=4.97, nll_loss=1.211, ppl=2.32, wps=1788.9, ups=0.41, wpb=4375.5, bsz=240, num_updates=3830, lr=2.42377e-05, gnorm=1.268, train_wall=5, gb_free=11.9, wall=13022
2025-04-03 08:41:03 | INFO | train_inner | epoch 031:     52 / 126 loss=5.088, nll_loss=1.362, ppl=2.57, wps=1743.7, ups=0.37, wpb=4702.5, bsz=280, num_updates=3832, lr=2.42314e-05, gnorm=1.261, train_wall=5, gb_free=14.2, wall=13027
2025-04-03 08:41:08 | INFO | train_inner | epoch 031:     54 / 126 loss=5.03, nll_loss=1.29, ppl=2.45, wps=1467, ups=0.37, wpb=3939, bsz=232, num_updates=3834, lr=2.42251e-05, gnorm=1.331, train_wall=5, gb_free=12.9, wall=13033
2025-04-03 08:41:14 | INFO | train_inner | epoch 031:     56 / 126 loss=5.012, nll_loss=1.234, ppl=2.35, wps=1432.2, ups=0.36, wpb=3994, bsz=120, num_updates=3836, lr=2.42188e-05, gnorm=1.382, train_wall=6, gb_free=9.7, wall=13038
2025-04-03 08:41:20 | INFO | train_inner | epoch 031:     58 / 126 loss=5.029, nll_loss=1.27, ppl=2.41, wps=1673.2, ups=0.36, wpb=4685, bsz=272, num_updates=3838, lr=2.42125e-05, gnorm=1.171, train_wall=6, gb_free=11.1, wall=13044
2025-04-03 08:41:25 | INFO | train_inner | epoch 031:     60 / 126 loss=4.91, nll_loss=1.136, ppl=2.2, wps=1674.6, ups=0.36, wpb=4708, bsz=288, num_updates=3840, lr=2.42061e-05, gnorm=1.163, train_wall=6, gb_free=10.8, wall=13049
2025-04-03 08:41:31 | INFO | train_inner | epoch 031:     62 / 126 loss=5.022, nll_loss=1.289, ppl=2.44, wps=1681.9, ups=0.36, wpb=4683, bsz=312, num_updates=3842, lr=2.41998e-05, gnorm=1.157, train_wall=6, gb_free=14.2, wall=13055
2025-04-03 08:41:36 | INFO | train_inner | epoch 031:     64 / 126 loss=4.9, nll_loss=1.12, ppl=2.17, wps=1531.4, ups=0.38, wpb=4082.5, bsz=336, num_updates=3844, lr=2.41935e-05, gnorm=1.288, train_wall=5, gb_free=12.2, wall=13060
2025-04-03 08:41:42 | INFO | train_inner | epoch 031:     66 / 126 loss=5.022, nll_loss=1.282, ppl=2.43, wps=1643, ups=0.37, wpb=4473.5, bsz=240, num_updates=3846, lr=2.41873e-05, gnorm=1.262, train_wall=5, gb_free=11.5, wall=13066
2025-04-03 08:41:47 | INFO | train_inner | epoch 031:     68 / 126 loss=4.979, nll_loss=1.207, ppl=2.31, wps=1625.9, ups=0.36, wpb=4501, bsz=220, num_updates=3848, lr=2.4181e-05, gnorm=1.16, train_wall=6, gb_free=13.3, wall=13071
2025-04-03 08:41:53 | INFO | train_inner | epoch 031:     70 / 126 loss=4.954, nll_loss=1.176, ppl=2.26, wps=1726.9, ups=0.36, wpb=4801.5, bsz=216, num_updates=3850, lr=2.41747e-05, gnorm=1.085, train_wall=6, gb_free=12.4, wall=13077
2025-04-03 08:41:58 | INFO | train_inner | epoch 031:     72 / 126 loss=4.954, nll_loss=1.184, ppl=2.27, wps=1660.4, ups=0.35, wpb=4753.5, bsz=264, num_updates=3852, lr=2.41684e-05, gnorm=2.139, train_wall=6, gb_free=9.4, wall=13083
2025-04-03 08:42:04 | INFO | train_inner | epoch 031:     74 / 126 loss=5, nll_loss=1.248, ppl=2.37, wps=1570.5, ups=0.35, wpb=4431, bsz=220, num_updates=3854, lr=2.41621e-05, gnorm=1.176, train_wall=6, gb_free=12.4, wall=13088
2025-04-03 08:42:10 | INFO | train_inner | epoch 031:     76 / 126 loss=5.07, nll_loss=1.352, ppl=2.55, wps=1830.7, ups=0.34, wpb=5326.5, bsz=296, num_updates=3856, lr=2.41559e-05, gnorm=1.15, train_wall=6, gb_free=9.9, wall=13094
2025-04-03 08:42:16 | INFO | train_inner | epoch 031:     78 / 126 loss=4.979, nll_loss=1.214, ppl=2.32, wps=1762.4, ups=0.34, wpb=5254, bsz=352, num_updates=3858, lr=2.41496e-05, gnorm=1.041, train_wall=6, gb_free=10, wall=13100
2025-04-03 08:42:21 | INFO | train_inner | epoch 031:     80 / 126 loss=4.915, nll_loss=1.114, ppl=2.16, wps=1512.9, ups=0.37, wpb=4133, bsz=244, num_updates=3860, lr=2.41434e-05, gnorm=1.132, train_wall=5, gb_free=13.3, wall=13105
2025-04-03 08:42:26 | INFO | train_inner | epoch 031:     82 / 126 loss=4.989, nll_loss=1.23, ppl=2.35, wps=1597.9, ups=0.39, wpb=4141.5, bsz=228, num_updates=3862, lr=2.41371e-05, gnorm=1.261, train_wall=5, gb_free=11, wall=13111
2025-04-03 08:42:32 | INFO | train_inner | epoch 031:     84 / 126 loss=4.973, nll_loss=1.219, ppl=2.33, wps=1814.1, ups=0.36, wpb=4997.5, bsz=304, num_updates=3864, lr=2.41309e-05, gnorm=1.136, train_wall=6, gb_free=11.2, wall=13116
2025-04-03 08:42:43 | INFO | train_inner | epoch 031:     86 / 126 loss=4.903, nll_loss=1.123, ppl=2.18, wps=879.3, ups=0.19, wpb=4658, bsz=300, num_updates=3866, lr=2.41246e-05, gnorm=1.048, train_wall=11, gb_free=14.2, wall=13127
2025-04-03 08:42:48 | INFO | train_inner | epoch 031:     88 / 126 loss=4.911, nll_loss=1.132, ppl=2.19, wps=1699.6, ups=0.36, wpb=4706.5, bsz=284, num_updates=3868, lr=2.41184e-05, gnorm=1.159, train_wall=6, gb_free=12.3, wall=13132
2025-04-03 08:42:54 | INFO | train_inner | epoch 031:     90 / 126 loss=4.939, nll_loss=1.166, ppl=2.24, wps=1678, ups=0.36, wpb=4618, bsz=276, num_updates=3870, lr=2.41121e-05, gnorm=1.11, train_wall=5, gb_free=12.7, wall=13138
2025-04-03 08:42:59 | INFO | train_inner | epoch 031:     92 / 126 loss=4.891, nll_loss=1.096, ppl=2.14, wps=1560.7, ups=0.39, wpb=4006.5, bsz=224, num_updates=3872, lr=2.41059e-05, gnorm=1.178, train_wall=5, gb_free=13.3, wall=13143
2025-04-03 08:43:04 | INFO | train_inner | epoch 031:     94 / 126 loss=4.913, nll_loss=1.13, ppl=2.19, wps=1587.3, ups=0.39, wpb=4096, bsz=176, num_updates=3874, lr=2.40997e-05, gnorm=1.173, train_wall=5, gb_free=12, wall=13148
2025-04-03 08:43:10 | INFO | train_inner | epoch 031:     96 / 126 loss=5.037, nll_loss=1.307, ppl=2.47, wps=1859.6, ups=0.34, wpb=5468, bsz=420, num_updates=3876, lr=2.40935e-05, gnorm=1.086, train_wall=6, gb_free=10.7, wall=13154
2025-04-03 08:43:16 | INFO | train_inner | epoch 031:     98 / 126 loss=5.019, nll_loss=1.271, ppl=2.41, wps=1831.2, ups=0.35, wpb=5198, bsz=288, num_updates=3878, lr=2.40873e-05, gnorm=1.127, train_wall=6, gb_free=11.1, wall=13160
2025-04-03 08:43:21 | INFO | train_inner | epoch 031:    100 / 126 loss=4.971, nll_loss=1.198, ppl=2.29, wps=1664.1, ups=0.35, wpb=4801.5, bsz=172, num_updates=3880, lr=2.4081e-05, gnorm=1.164, train_wall=6, gb_free=12.4, wall=13165
2025-04-03 08:43:26 | INFO | train_inner | epoch 031:    102 / 126 loss=5.051, nll_loss=1.297, ppl=2.46, wps=1476.1, ups=0.39, wpb=3816.5, bsz=256, num_updates=3882, lr=2.40748e-05, gnorm=1.244, train_wall=5, gb_free=11.6, wall=13171
2025-04-03 08:43:32 | INFO | train_inner | epoch 031:    104 / 126 loss=5.008, nll_loss=1.239, ppl=2.36, wps=1551.5, ups=0.36, wpb=4346, bsz=204, num_updates=3884, lr=2.40686e-05, gnorm=1.231, train_wall=6, gb_free=8.4, wall=13176
2025-04-03 08:43:38 | INFO | train_inner | epoch 031:    106 / 126 loss=4.948, nll_loss=1.198, ppl=2.29, wps=1777.6, ups=0.37, wpb=4857, bsz=344, num_updates=3886, lr=2.40625e-05, gnorm=1.116, train_wall=5, gb_free=10.8, wall=13182
2025-04-03 08:43:43 | INFO | train_inner | epoch 031:    108 / 126 loss=4.987, nll_loss=1.222, ppl=2.33, wps=1515.1, ups=0.35, wpb=4320.5, bsz=168, num_updates=3888, lr=2.40563e-05, gnorm=1.186, train_wall=6, gb_free=9.4, wall=13187
2025-04-03 08:43:49 | INFO | train_inner | epoch 031:    110 / 126 loss=5.02, nll_loss=1.272, ppl=2.41, wps=1753.9, ups=0.34, wpb=5093.5, bsz=280, num_updates=3890, lr=2.40501e-05, gnorm=1.136, train_wall=6, gb_free=10.9, wall=13193
2025-04-03 08:43:55 | INFO | train_inner | epoch 031:    112 / 126 loss=4.938, nll_loss=1.144, ppl=2.21, wps=1503.6, ups=0.36, wpb=4162, bsz=140, num_updates=3892, lr=2.40439e-05, gnorm=1.392, train_wall=6, gb_free=14, wall=13199
2025-04-03 08:44:00 | INFO | train_inner | epoch 031:    114 / 126 loss=4.983, nll_loss=1.225, ppl=2.34, wps=1749.4, ups=0.35, wpb=4985.5, bsz=332, num_updates=3894, lr=2.40377e-05, gnorm=1.23, train_wall=6, gb_free=10.1, wall=13204
2025-04-03 08:44:06 | INFO | train_inner | epoch 031:    116 / 126 loss=5.041, nll_loss=1.287, ppl=2.44, wps=1568.2, ups=0.38, wpb=4130, bsz=192, num_updates=3896, lr=2.40316e-05, gnorm=1.292, train_wall=5, gb_free=11.3, wall=13210
2025-04-03 08:44:11 | INFO | train_inner | epoch 031:    118 / 126 loss=4.992, nll_loss=1.238, ppl=2.36, wps=1759, ups=0.37, wpb=4789, bsz=244, num_updates=3898, lr=2.40254e-05, gnorm=1.152, train_wall=5, gb_free=13.2, wall=13215
2025-04-03 08:44:17 | INFO | train_inner | epoch 031:    120 / 126 loss=4.931, nll_loss=1.151, ppl=2.22, wps=1824.3, ups=0.35, wpb=5257, bsz=320, num_updates=3900, lr=2.40192e-05, gnorm=1.134, train_wall=6, gb_free=12.8, wall=13221
2025-04-03 08:44:22 | INFO | train_inner | epoch 031:    122 / 126 loss=5.035, nll_loss=1.295, ppl=2.45, wps=1834.7, ups=0.36, wpb=5139, bsz=284, num_updates=3902, lr=2.40131e-05, gnorm=1.044, train_wall=6, gb_free=12.2, wall=13226
2025-04-03 08:44:28 | INFO | train_inner | epoch 031:    124 / 126 loss=5.011, nll_loss=1.255, ppl=2.39, wps=1683.6, ups=0.34, wpb=4907, bsz=232, num_updates=3904, lr=2.40069e-05, gnorm=1.19, train_wall=6, gb_free=10.2, wall=13232
2025-04-03 08:44:32 | INFO | train_inner | epoch 031:    126 / 126 loss=4.927, nll_loss=1.163, ppl=2.24, wps=1679.7, ups=0.47, wpb=3551.5, bsz=212, num_updates=3906, lr=2.40008e-05, gnorm=1.325, train_wall=4, gb_free=16.3, wall=13236
2025-04-03 08:44:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-03 08:44:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=15943.74609375Mb; avail=239141.453125Mb
2025-04-03 08:44:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000637
2025-04-03 08:44:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15943.74609375Mb; avail=239141.453125Mb
2025-04-03 08:44:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012941
2025-04-03 08:44:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15943.74609375Mb; avail=239141.453125Mb
2025-04-03 08:44:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.010939
2025-04-03 08:44:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024883
2025-04-03 08:44:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15943.74609375Mb; avail=239141.453125Mb
2025-04-03 08:44:47 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 5.87 | nll_loss 2.16 | ppl 4.47 | wps 3871.5 | wpb 2070.5 | bsz 122.7 | num_updates 3906 | best_loss 5.87
2025-04-03 08:44:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 3906 updates
2025-04-03 08:44:47 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 08:45:27 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt
2025-04-03 08:45:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_best.pt (epoch 31 @ 3906 updates, score 5.87) (writing took 64.31339535594452 seconds)
2025-04-03 08:45:51 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2025-04-03 08:45:51 | INFO | train | epoch 031 | loss 4.979 | nll_loss 1.216 | ppl 2.32 | wps 1328.8 | ups 0.29 | wpb 4549.7 | bsz 252.8 | num_updates 3906 | lr 2.40008e-05 | gnorm 1.203 | train_wall 352 | gb_free 16.3 | wall 13315
2025-04-03 08:45:51 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:mr-hi': 31849}; raw total size: 31849
2025-04-03 08:45:51 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:mr-hi': 31849}; resampled total size: 31849
2025-04-03 08:45:51 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:mr-hi': 1.0}
2025-04-03 08:45:51 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001213
2025-04-03 08:45:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=26732.08984375Mb; avail=228353.01953125Mb
2025-04-03 08:45:51 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000553
2025-04-03 08:45:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003505
2025-04-03 08:45:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26732.58203125Mb; avail=228352.52734375Mb
2025-04-03 08:45:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000095
2025-04-03 08:45:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26732.58203125Mb; avail=228352.52734375Mb
2025-04-03 08:45:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001183
2025-04-03 08:45:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.005099
2025-04-03 08:45:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26732.58203125Mb; avail=228352.52734375Mb
2025-04-03 08:45:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 126
2025-04-03 08:45:51 | INFO | fairseq.trainer | begin training epoch 32
2025-04-03 08:45:51 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-03 08:45:56 | INFO | train_inner | epoch 032:      2 / 126 loss=4.9, nll_loss=1.113, ppl=2.16, wps=107.8, ups=0.02, wpb=4527, bsz=304, num_updates=3908, lr=2.39946e-05, gnorm=1.289, train_wall=5, gb_free=12.8, wall=13320
2025-04-03 08:46:02 | INFO | train_inner | epoch 032:      4 / 126 loss=4.904, nll_loss=1.121, ppl=2.17, wps=1676.1, ups=0.37, wpb=4517.5, bsz=268, num_updates=3910, lr=2.39885e-05, gnorm=1.093, train_wall=5, gb_free=14, wall=13326
2025-04-03 08:46:07 | INFO | train_inner | epoch 032:      6 / 126 loss=4.984, nll_loss=1.229, ppl=2.34, wps=1696.5, ups=0.35, wpb=4784, bsz=232, num_updates=3912, lr=2.39824e-05, gnorm=1.228, train_wall=6, gb_free=8.8, wall=13332
2025-04-03 08:46:13 | INFO | train_inner | epoch 032:      8 / 126 loss=5.021, nll_loss=1.268, ppl=2.41, wps=1684.7, ups=0.37, wpb=4597.5, bsz=272, num_updates=3914, lr=2.39762e-05, gnorm=1.391, train_wall=5, gb_free=9.3, wall=13337
2025-04-03 08:46:18 | INFO | train_inner | epoch 032:     10 / 126 loss=4.895, nll_loss=1.11, ppl=2.16, wps=1621.6, ups=0.38, wpb=4272.5, bsz=296, num_updates=3916, lr=2.39701e-05, gnorm=1.117, train_wall=5, gb_free=12.1, wall=13342
2025-04-03 08:46:24 | INFO | train_inner | epoch 032:     12 / 126 loss=4.952, nll_loss=1.185, ppl=2.27, wps=1897.6, ups=0.35, wpb=5366, bsz=312, num_updates=3918, lr=2.3964e-05, gnorm=1.081, train_wall=6, gb_free=10.5, wall=13348
2025-04-03 08:46:29 | INFO | train_inner | epoch 032:     14 / 126 loss=4.899, nll_loss=1.113, ppl=2.16, wps=1579, ups=0.36, wpb=4400, bsz=272, num_updates=3920, lr=2.39579e-05, gnorm=1.184, train_wall=6, gb_free=12, wall=13353
2025-04-03 08:46:35 | INFO | train_inner | epoch 032:     16 / 126 loss=4.928, nll_loss=1.157, ppl=2.23, wps=1800.6, ups=0.34, wpb=5277.5, bsz=348, num_updates=3922, lr=2.39518e-05, gnorm=1.078, train_wall=6, gb_free=9.7, wall=13359
2025-04-03 08:46:41 | INFO | train_inner | epoch 032:     18 / 126 loss=4.873, nll_loss=1.099, ppl=2.14, wps=1649.3, ups=0.36, wpb=4569, bsz=284, num_updates=3924, lr=2.39457e-05, gnorm=1.128, train_wall=6, gb_free=9.5, wall=13365
2025-04-03 08:46:46 | INFO | train_inner | epoch 032:     20 / 126 loss=5, nll_loss=1.245, ppl=2.37, wps=1810.5, ups=0.35, wpb=5127, bsz=268, num_updates=3926, lr=2.39396e-05, gnorm=1.126, train_wall=6, gb_free=13.8, wall=13371
2025-04-03 08:46:52 | INFO | train_inner | epoch 032:     22 / 126 loss=5.015, nll_loss=1.251, ppl=2.38, wps=1746.7, ups=0.36, wpb=4807.5, bsz=200, num_updates=3928, lr=2.39335e-05, gnorm=1.168, train_wall=5, gb_free=10.2, wall=13376
2025-04-03 08:47:03 | INFO | train_inner | epoch 032:     24 / 126 loss=4.936, nll_loss=1.15, ppl=2.22, wps=875.5, ups=0.19, wpb=4662.5, bsz=244, num_updates=3930, lr=2.39274e-05, gnorm=1.328, train_wall=11, gb_free=12.9, wall=13387
2025-04-03 08:47:08 | INFO | train_inner | epoch 032:     26 / 126 loss=4.91, nll_loss=1.127, ppl=2.18, wps=1744.4, ups=0.36, wpb=4809.5, bsz=300, num_updates=3932, lr=2.39213e-05, gnorm=1.07, train_wall=6, gb_free=12.6, wall=13392
2025-04-03 08:47:14 | INFO | train_inner | epoch 032:     28 / 126 loss=4.891, nll_loss=1.123, ppl=2.18, wps=1763, ups=0.37, wpb=4751, bsz=344, num_updates=3934, lr=2.39152e-05, gnorm=1.178, train_wall=5, gb_free=13.5, wall=13398
2025-04-03 08:47:19 | INFO | train_inner | epoch 032:     30 / 126 loss=4.886, nll_loss=1.098, ppl=2.14, wps=1469, ups=0.35, wpb=4189.5, bsz=216, num_updates=3936, lr=2.39091e-05, gnorm=1.113, train_wall=6, gb_free=9, wall=13403
2025-04-03 08:47:25 | INFO | train_inner | epoch 032:     32 / 126 loss=4.892, nll_loss=1.108, ppl=2.16, wps=1603.2, ups=0.36, wpb=4396, bsz=212, num_updates=3938, lr=2.39031e-05, gnorm=1.162, train_wall=5, gb_free=13.7, wall=13409
2025-04-03 08:47:30 | INFO | train_inner | epoch 032:     34 / 126 loss=4.867, nll_loss=1.077, ppl=2.11, wps=1605.8, ups=0.37, wpb=4292.5, bsz=316, num_updates=3940, lr=2.3897e-05, gnorm=1.085, train_wall=5, gb_free=12.5, wall=13414
2025-04-03 08:47:36 | INFO | train_inner | epoch 032:     36 / 126 loss=4.992, nll_loss=1.235, ppl=2.35, wps=1691.5, ups=0.36, wpb=4737, bsz=284, num_updates=3942, lr=2.38909e-05, gnorm=1.207, train_wall=6, gb_free=13.3, wall=13420
2025-04-03 08:47:41 | INFO | train_inner | epoch 032:     38 / 126 loss=4.902, nll_loss=1.114, ppl=2.16, wps=1722.3, ups=0.36, wpb=4748.5, bsz=232, num_updates=3944, lr=2.38849e-05, gnorm=1.116, train_wall=6, gb_free=13.4, wall=13425
2025-04-03 08:47:47 | INFO | train_inner | epoch 032:     40 / 126 loss=4.875, nll_loss=1.076, ppl=2.11, wps=1645.2, ups=0.34, wpb=4817, bsz=224, num_updates=3946, lr=2.38788e-05, gnorm=1.159, train_wall=6, gb_free=11.9, wall=13431
2025-04-03 08:47:53 | INFO | train_inner | epoch 032:     42 / 126 loss=4.955, nll_loss=1.189, ppl=2.28, wps=1672.4, ups=0.36, wpb=4698.5, bsz=252, num_updates=3948, lr=2.38728e-05, gnorm=1.102, train_wall=6, gb_free=9.1, wall=13437
2025-04-03 08:47:58 | INFO | train_inner | epoch 032:     44 / 126 loss=4.986, nll_loss=1.24, ppl=2.36, wps=1624.9, ups=0.35, wpb=4662.5, bsz=188, num_updates=3950, lr=2.38667e-05, gnorm=1.186, train_wall=6, gb_free=11.3, wall=13442
2025-04-03 08:48:04 | INFO | train_inner | epoch 032:     46 / 126 loss=4.864, nll_loss=1.062, ppl=2.09, wps=1406.2, ups=0.34, wpb=4092, bsz=156, num_updates=3952, lr=2.38607e-05, gnorm=1.089, train_wall=6, gb_free=10.3, wall=13448
2025-04-03 08:48:10 | INFO | train_inner | epoch 032:     48 / 126 loss=5.002, nll_loss=1.238, ppl=2.36, wps=1763.4, ups=0.34, wpb=5232.5, bsz=204, num_updates=3954, lr=2.38546e-05, gnorm=1.133, train_wall=6, gb_free=10.8, wall=13454
2025-04-03 08:48:16 | INFO | train_inner | epoch 032:     50 / 126 loss=4.971, nll_loss=1.198, ppl=2.29, wps=1500.7, ups=0.36, wpb=4156.5, bsz=156, num_updates=3956, lr=2.38486e-05, gnorm=1.218, train_wall=6, gb_free=9.6, wall=13460
2025-04-03 08:48:21 | INFO | train_inner | epoch 032:     52 / 126 loss=4.901, nll_loss=1.121, ppl=2.18, wps=1643.9, ups=0.36, wpb=4562.5, bsz=292, num_updates=3958, lr=2.38426e-05, gnorm=1.098, train_wall=6, gb_free=14.8, wall=13465
2025-04-03 08:48:27 | INFO | train_inner | epoch 032:     54 / 126 loss=4.965, nll_loss=1.191, ppl=2.28, wps=1524.4, ups=0.36, wpb=4232, bsz=204, num_updates=3960, lr=2.38366e-05, gnorm=1.216, train_wall=6, gb_free=13.6, wall=13471
2025-04-03 08:48:32 | INFO | train_inner | epoch 032:     56 / 126 loss=4.894, nll_loss=1.103, ppl=2.15, wps=1631.9, ups=0.36, wpb=4551.5, bsz=216, num_updates=3962, lr=2.38305e-05, gnorm=1.188, train_wall=6, gb_free=12.8, wall=13476
2025-04-03 08:48:39 | INFO | train_inner | epoch 032:     58 / 126 loss=4.971, nll_loss=1.204, ppl=2.3, wps=1626.4, ups=0.32, wpb=5040, bsz=232, num_updates=3964, lr=2.38245e-05, gnorm=1.16, train_wall=6, gb_free=8.9, wall=13483
2025-04-03 08:48:45 | INFO | train_inner | epoch 032:     60 / 126 loss=4.963, nll_loss=1.194, ppl=2.29, wps=1655.7, ups=0.33, wpb=4993, bsz=260, num_updates=3966, lr=2.38185e-05, gnorm=1.189, train_wall=6, gb_free=10.6, wall=13489
2025-04-03 08:48:50 | INFO | train_inner | epoch 032:     62 / 126 loss=4.979, nll_loss=1.215, ppl=2.32, wps=1706.5, ups=0.35, wpb=4904.5, bsz=276, num_updates=3968, lr=2.38125e-05, gnorm=1.12, train_wall=6, gb_free=11.7, wall=13494
2025-04-03 08:48:56 | INFO | train_inner | epoch 032:     64 / 126 loss=4.931, nll_loss=1.182, ppl=2.27, wps=1757.3, ups=0.38, wpb=4622, bsz=360, num_updates=3970, lr=2.38065e-05, gnorm=1.411, train_wall=5, gb_free=12.7, wall=13500
2025-04-03 08:49:01 | INFO | train_inner | epoch 032:     66 / 126 loss=4.945, nll_loss=1.17, ppl=2.25, wps=1838.7, ups=0.36, wpb=5116, bsz=360, num_updates=3972, lr=2.38005e-05, gnorm=1.076, train_wall=6, gb_free=15.5, wall=13505
2025-04-03 08:49:07 | INFO | train_inner | epoch 032:     68 / 126 loss=4.81, nll_loss=1, ppl=2, wps=1463.3, ups=0.37, wpb=3994, bsz=284, num_updates=3974, lr=2.37945e-05, gnorm=1.043, train_wall=5, gb_free=10.1, wall=13511
2025-04-03 08:49:12 | INFO | train_inner | epoch 032:     70 / 126 loss=4.848, nll_loss=1.049, ppl=2.07, wps=1563.1, ups=0.39, wpb=3993.5, bsz=152, num_updates=3976, lr=2.37886e-05, gnorm=1.168, train_wall=5, gb_free=14.6, wall=13516
2025-04-03 08:49:17 | INFO | train_inner | epoch 032:     72 / 126 loss=4.93, nll_loss=1.173, ppl=2.26, wps=1580.5, ups=0.39, wpb=4053.5, bsz=308, num_updates=3978, lr=2.37826e-05, gnorm=1.189, train_wall=5, gb_free=14.4, wall=13521
2025-04-03 08:49:22 | INFO | train_inner | epoch 032:     74 / 126 loss=4.884, nll_loss=1.096, ppl=2.14, wps=1794.9, ups=0.37, wpb=4875.5, bsz=272, num_updates=3980, lr=2.37766e-05, gnorm=1.101, train_wall=5, gb_free=10.3, wall=13526
2025-04-03 08:49:28 | INFO | train_inner | epoch 032:     76 / 126 loss=4.924, nll_loss=1.15, ppl=2.22, wps=1804.6, ups=0.36, wpb=5017.5, bsz=340, num_updates=3982, lr=2.37706e-05, gnorm=1.125, train_wall=6, gb_free=11.5, wall=13532
2025-04-03 08:49:34 | INFO | train_inner | epoch 032:     78 / 126 loss=4.904, nll_loss=1.101, ppl=2.15, wps=1509.5, ups=0.35, wpb=4335.5, bsz=188, num_updates=3984, lr=2.37647e-05, gnorm=1.193, train_wall=6, gb_free=12.7, wall=13538
2025-04-03 08:49:39 | INFO | train_inner | epoch 032:     80 / 126 loss=4.907, nll_loss=1.143, ppl=2.21, wps=1706.5, ups=0.37, wpb=4670, bsz=260, num_updates=3986, lr=2.37587e-05, gnorm=1.191, train_wall=5, gb_free=12, wall=13543
2025-04-03 08:49:45 | INFO | train_inner | epoch 032:     82 / 126 loss=4.904, nll_loss=1.115, ppl=2.17, wps=1444.7, ups=0.34, wpb=4188, bsz=192, num_updates=3988, lr=2.37527e-05, gnorm=1.402, train_wall=6, gb_free=7.9, wall=13549
2025-04-03 08:49:50 | INFO | train_inner | epoch 032:     84 / 126 loss=5.002, nll_loss=1.257, ppl=2.39, wps=1781.4, ups=0.39, wpb=4529, bsz=328, num_updates=3990, lr=2.37468e-05, gnorm=1.158, train_wall=5, gb_free=14.7, wall=13554
2025-04-03 08:49:56 | INFO | train_inner | epoch 032:     86 / 126 loss=4.982, nll_loss=1.21, ppl=2.31, wps=1700.3, ups=0.36, wpb=4738.5, bsz=212, num_updates=3992, lr=2.37408e-05, gnorm=1.16, train_wall=6, gb_free=12.7, wall=13560
2025-04-03 08:50:01 | INFO | train_inner | epoch 032:     88 / 126 loss=4.949, nll_loss=1.163, ppl=2.24, wps=1628, ups=0.37, wpb=4418.5, bsz=248, num_updates=3994, lr=2.37349e-05, gnorm=1.204, train_wall=5, gb_free=14.3, wall=13565
2025-04-03 08:50:07 | INFO | train_inner | epoch 032:     90 / 126 loss=5.017, nll_loss=1.269, ppl=2.41, wps=1604.5, ups=0.36, wpb=4504.5, bsz=304, num_updates=3996, lr=2.37289e-05, gnorm=1.248, train_wall=6, gb_free=11.6, wall=13571
2025-04-03 08:50:12 | INFO | train_inner | epoch 032:     92 / 126 loss=4.945, nll_loss=1.169, ppl=2.25, wps=1632.4, ups=0.37, wpb=4391, bsz=228, num_updates=3998, lr=2.3723e-05, gnorm=1.252, train_wall=5, gb_free=14.7, wall=13576
2025-04-03 08:50:18 | INFO | train_inner | epoch 032:     94 / 126 loss=4.946, nll_loss=1.176, ppl=2.26, wps=1808.8, ups=0.35, wpb=5199, bsz=348, num_updates=4000, lr=2.37171e-05, gnorm=1.045, train_wall=6, gb_free=9.8, wall=13582
2025-04-03 08:50:23 | INFO | train_inner | epoch 032:     96 / 126 loss=4.857, nll_loss=1.063, ppl=2.09, wps=1362.1, ups=0.36, wpb=3767.5, bsz=216, num_updates=4002, lr=2.37112e-05, gnorm=1.177, train_wall=6, gb_free=14.1, wall=13587
2025-04-03 08:50:28 | INFO | train_inner | epoch 032:     98 / 126 loss=4.913, nll_loss=1.129, ppl=2.19, wps=1423.6, ups=0.38, wpb=3732.5, bsz=200, num_updates=4004, lr=2.37052e-05, gnorm=1.275, train_wall=5, gb_free=13, wall=13593
2025-04-03 08:50:34 | INFO | train_inner | epoch 032:    100 / 126 loss=4.969, nll_loss=1.218, ppl=2.33, wps=1721.9, ups=0.36, wpb=4737, bsz=304, num_updates=4006, lr=2.36993e-05, gnorm=1.132, train_wall=5, gb_free=11.7, wall=13598
2025-04-03 08:50:39 | INFO | train_inner | epoch 032:    102 / 126 loss=4.892, nll_loss=1.087, ppl=2.12, wps=1532.7, ups=0.4, wpb=3850.5, bsz=188, num_updates=4008, lr=2.36934e-05, gnorm=1.19, train_wall=5, gb_free=15.1, wall=13603
2025-04-03 08:50:45 | INFO | train_inner | epoch 032:    104 / 126 loss=5.04, nll_loss=1.296, ppl=2.46, wps=1684.8, ups=0.34, wpb=4984.5, bsz=244, num_updates=4010, lr=2.36875e-05, gnorm=1.177, train_wall=6, gb_free=12.8, wall=13609
2025-04-03 08:50:50 | INFO | train_inner | epoch 032:    106 / 126 loss=4.96, nll_loss=1.189, ppl=2.28, wps=1507.3, ups=0.36, wpb=4167.5, bsz=156, num_updates=4012, lr=2.36816e-05, gnorm=1.268, train_wall=6, gb_free=9.3, wall=13615
2025-04-03 08:50:56 | INFO | train_inner | epoch 032:    108 / 126 loss=5.098, nll_loss=1.373, ppl=2.59, wps=1748.7, ups=0.38, wpb=4611, bsz=200, num_updates=4014, lr=2.36757e-05, gnorm=1.25, train_wall=5, gb_free=13, wall=13620
2025-04-03 08:51:02 | INFO | train_inner | epoch 032:    110 / 126 loss=4.976, nll_loss=1.215, ppl=2.32, wps=1835.5, ups=0.34, wpb=5352.5, bsz=304, num_updates=4016, lr=2.36698e-05, gnorm=1.065, train_wall=6, gb_free=11.6, wall=13626
2025-04-03 08:51:07 | INFO | train_inner | epoch 032:    112 / 126 loss=5.123, nll_loss=1.397, ppl=2.63, wps=1636, ups=0.36, wpb=4535, bsz=264, num_updates=4018, lr=2.36639e-05, gnorm=1.24, train_wall=6, gb_free=11.6, wall=13631
2025-04-03 08:51:13 | INFO | train_inner | epoch 032:    114 / 126 loss=4.963, nll_loss=1.196, ppl=2.29, wps=1596.8, ups=0.36, wpb=4454.5, bsz=256, num_updates=4020, lr=2.3658e-05, gnorm=1.198, train_wall=6, gb_free=12.4, wall=13637
2025-04-03 08:51:18 | INFO | train_inner | epoch 032:    116 / 126 loss=4.912, nll_loss=1.116, ppl=2.17, wps=1596.4, ups=0.35, wpb=4571, bsz=208, num_updates=4022, lr=2.36521e-05, gnorm=1.084, train_wall=6, gb_free=12.2, wall=13642
2025-04-03 08:51:24 | INFO | train_inner | epoch 032:    118 / 126 loss=4.869, nll_loss=1.08, ppl=2.11, wps=1450.9, ups=0.35, wpb=4183, bsz=220, num_updates=4024, lr=2.36462e-05, gnorm=1.281, train_wall=6, gb_free=14.1, wall=13648
2025-04-03 08:51:30 | INFO | train_inner | epoch 032:    120 / 126 loss=4.929, nll_loss=1.161, ppl=2.24, wps=1468.8, ups=0.37, wpb=3967.5, bsz=200, num_updates=4026, lr=2.36404e-05, gnorm=1.281, train_wall=5, gb_free=10.4, wall=13654
2025-04-03 08:51:35 | INFO | train_inner | epoch 032:    122 / 126 loss=4.938, nll_loss=1.168, ppl=2.25, wps=1711.9, ups=0.35, wpb=4827, bsz=244, num_updates=4028, lr=2.36345e-05, gnorm=1.122, train_wall=6, gb_free=9.8, wall=13659
2025-04-03 08:51:40 | INFO | train_inner | epoch 032:    124 / 126 loss=4.91, nll_loss=1.139, ppl=2.2, wps=1477.5, ups=0.44, wpb=3359.5, bsz=224.5, num_updates=4030, lr=2.36286e-05, gnorm=1.34, train_wall=5, gb_free=15.4, wall=13664
2025-04-03 08:51:44 | INFO | train_inner | epoch 032:    126 / 126 loss=5.001, nll_loss=1.25, ppl=2.38, wps=1903.6, ups=0.46, wpb=4110.5, bsz=248, num_updates=4032, lr=2.36228e-05, gnorm=1.422, train_wall=4, gb_free=15.4, wall=13668
2025-04-03 08:51:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-03 08:51:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=15919.41015625Mb; avail=239165.79296875Mb
2025-04-03 08:51:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000644
2025-04-03 08:51:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15919.41015625Mb; avail=239165.79296875Mb
2025-04-03 08:51:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012859
2025-04-03 08:51:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15919.41015625Mb; avail=239165.79296875Mb
2025-04-03 08:51:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.011368
2025-04-03 08:51:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.025255
2025-04-03 08:51:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15919.41015625Mb; avail=239165.79296875Mb
2025-04-03 08:51:58 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 5.871 | nll_loss 2.16 | ppl 4.47 | wps 3867.8 | wpb 2070.5 | bsz 122.7 | num_updates 4032 | best_loss 5.87
2025-04-03 08:51:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 4032 updates
2025-04-03 08:51:58 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B_Mr-Hi/checkpoint_last.pt
