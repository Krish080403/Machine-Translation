2025-04-01 06:21:54 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 2, 'log_format': 'simple', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 222, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 3600, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 3600, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 40000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [2], 'lr': [3e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/home/krish/content/old_files/Version3/checkpoint1.2B', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': '/home/krish/content/1.2B_last_checkpoint.pt', 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 5000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': 10, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=2, log_format='simple', log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=222, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', scoring='bleu', task='translation_multi_simple_epoch', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=3600, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=3600, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='transformer_wmt_en_de_big', max_epoch=0, max_update=40000, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[2], lr=[3e-05], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='/home/krish/content/old_files/Version3/checkpoint1.2B', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model='/home/krish/content/1.2B_last_checkpoint.pt', reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=5000, keep_interval_updates=10, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=10, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, source_lang=None, target_lang=None, lang_pairs='hi-mr', keep_inference_langtok=False, sampling_method='temperature', sampling_temperature=1.5, data='/home/krish/content/old_files/Version3/wmt22_spm/wmt22_bin', langs=['hi', 'mr'], lang_dict=None, source_dict=None, target_dict=None, lang_tok_style='multilingual', load_alignments=False, left_pad_source='True', left_pad_target='False', upsample_primary=1, truncate_source=False, encoder_langtok='src', decoder_langtok=True, lang_tok_replacing_bos_eos=False, enable_lang_ids=False, enable_reservsed_directions_shared_datasets=False, extra_data=None, extra_lang_pairs=None, fixed_dictionary=None, langtoks_specs=['main'], langtoks=None, sampling_weights_from_file=None, sampling_weights=None, virtual_epoch_size=None, virtual_data_size=None, label_smoothing=0.2, report_accuracy=False, ignore_prefix_size=0, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.0, use_old_adam=False, fp16_adam_stats=False, warmup_updates=2500, warmup_init_lr=-1, pad=1, eos=2, unk=3, encoder_normalize_before=True, decoder_normalize_before=True, dropout=0.3, attention_dropout=0.1, encoder_layers=24, decoder_layers=24, encoder_ffn_embed_dim=8192, decoder_ffn_embed_dim=8192, encoder_layerdrop=0.05, decoder_layerdrop=0.05, share_decoder_input_output_embed=True, share_all_embeddings=True, no_seed_provided=False, encoder_embed_dim=1024, encoder_attention_heads=16, decoder_embed_dim=1024, decoder_attention_heads=16, encoder_embed_path=None, encoder_learned_pos=False, decoder_embed_path=None, decoder_learned_pos=False, activation_dropout=0.0, activation_fn='relu', adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, no_token_positional_embeddings=False, adaptive_input=False, no_cross_attention=False, cross_self_attention=False, decoder_output_dim=1024, decoder_input_dim=1024, no_scale_embedding=False, layernorm_embedding=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, _name='transformer_wmt_en_de_big'), 'task': Namespace(no_progress_bar=False, log_interval=2, log_format='simple', log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=222, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', scoring='bleu', task='translation_multi_simple_epoch', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=3600, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=3600, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='transformer_wmt_en_de_big', max_epoch=0, max_update=40000, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[2], lr=[3e-05], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='/home/krish/content/old_files/Version3/checkpoint1.2B', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model='/home/krish/content/1.2B_last_checkpoint.pt', reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=5000, keep_interval_updates=10, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=10, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, source_lang=None, target_lang=None, lang_pairs='hi-mr', keep_inference_langtok=False, sampling_method='temperature', sampling_temperature=1.5, data='/home/krish/content/old_files/Version3/wmt22_spm/wmt22_bin', langs=['hi', 'mr'], lang_dict=None, source_dict=None, target_dict=None, lang_tok_style='multilingual', load_alignments=False, left_pad_source='True', left_pad_target='False', upsample_primary=1, truncate_source=False, encoder_langtok='src', decoder_langtok=True, lang_tok_replacing_bos_eos=False, enable_lang_ids=False, enable_reservsed_directions_shared_datasets=False, extra_data=None, extra_lang_pairs=None, fixed_dictionary=None, langtoks_specs=['main'], langtoks=None, sampling_weights_from_file=None, sampling_weights=None, virtual_epoch_size=None, virtual_data_size=None, label_smoothing=0.2, report_accuracy=False, ignore_prefix_size=0, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.0, use_old_adam=False, fp16_adam_stats=False, warmup_updates=2500, warmup_init_lr=-1, pad=1, eos=2, unk=3, encoder_normalize_before=True, decoder_normalize_before=True, dropout=0.3, attention_dropout=0.1, encoder_layers=24, decoder_layers=24, encoder_ffn_embed_dim=8192, decoder_ffn_embed_dim=8192, encoder_layerdrop=0.05, decoder_layerdrop=0.05, share_decoder_input_output_embed=True, share_all_embeddings=True, no_seed_provided=False, encoder_embed_dim=1024, encoder_attention_heads=16, decoder_embed_dim=1024, decoder_attention_heads=16, encoder_embed_path=None, encoder_learned_pos=False, decoder_embed_path=None, decoder_learned_pos=False, activation_dropout=0.0, activation_fn='relu', adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, no_token_positional_embeddings=False, adaptive_input=False, no_cross_attention=False, cross_self_attention=False, decoder_output_dim=1024, decoder_input_dim=1024, no_scale_embedding=False, layernorm_embedding=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, max_source_positions=1024, max_target_positions=1024, _name='translation_multi_simple_epoch'), 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.2, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [3e-05]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 2500, 'warmup_init_lr': -1.0, 'lr': [3e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2025-04-01 06:21:54 | INFO | fairseq.data.multilingual.multilingual_data_manager | parsed the language list as they are ordered in the option: ['hi', 'mr']
2025-04-03 11:31:26 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 2, 'log_format': 'simple', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 222, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 3600, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 3600, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 40000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [2], 'lr': [3e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/home/krish/content/old_files/Version3/checkpoint1.2B', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': '/home/krish/content/1.2B_last_checkpoint.pt', 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 5000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': 10, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=2, log_format='simple', log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=222, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', scoring='bleu', task='translation_multi_simple_epoch', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=3600, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=3600, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='transformer_wmt_en_de_big', max_epoch=0, max_update=40000, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[2], lr=[3e-05], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='/home/krish/content/old_files/Version3/checkpoint1.2B', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model='/home/krish/content/1.2B_last_checkpoint.pt', reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=5000, keep_interval_updates=10, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=10, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, source_lang=None, target_lang=None, lang_pairs='hi-mr', keep_inference_langtok=False, sampling_method='temperature', sampling_temperature=1.5, data='/home/krish/content/old_files/Version3/wmt22_spm/wmt22_bin', langs=['hi', 'mr'], lang_dict=None, source_dict=None, target_dict=None, lang_tok_style='multilingual', load_alignments=False, left_pad_source='True', left_pad_target='False', upsample_primary=1, truncate_source=False, encoder_langtok='src', decoder_langtok=True, lang_tok_replacing_bos_eos=False, enable_lang_ids=False, enable_reservsed_directions_shared_datasets=False, extra_data=None, extra_lang_pairs=None, fixed_dictionary=None, langtoks_specs=['main'], langtoks=None, sampling_weights_from_file=None, sampling_weights=None, virtual_epoch_size=None, virtual_data_size=None, label_smoothing=0.2, report_accuracy=False, ignore_prefix_size=0, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.0, use_old_adam=False, fp16_adam_stats=False, warmup_updates=2500, warmup_init_lr=-1, pad=1, eos=2, unk=3, encoder_normalize_before=True, decoder_normalize_before=True, dropout=0.3, attention_dropout=0.1, encoder_layers=24, decoder_layers=24, encoder_ffn_embed_dim=8192, decoder_ffn_embed_dim=8192, encoder_layerdrop=0.05, decoder_layerdrop=0.05, share_decoder_input_output_embed=True, share_all_embeddings=True, no_seed_provided=False, encoder_embed_dim=1024, encoder_attention_heads=16, decoder_embed_dim=1024, decoder_attention_heads=16, encoder_embed_path=None, encoder_learned_pos=False, decoder_embed_path=None, decoder_learned_pos=False, activation_dropout=0.0, activation_fn='relu', adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, no_token_positional_embeddings=False, adaptive_input=False, no_cross_attention=False, cross_self_attention=False, decoder_output_dim=1024, decoder_input_dim=1024, no_scale_embedding=False, layernorm_embedding=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, _name='transformer_wmt_en_de_big'), 'task': Namespace(no_progress_bar=False, log_interval=2, log_format='simple', log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=222, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', scoring='bleu', task='translation_multi_simple_epoch', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=3600, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=3600, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='transformer_wmt_en_de_big', max_epoch=0, max_update=40000, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[2], lr=[3e-05], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='/home/krish/content/old_files/Version3/checkpoint1.2B', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model='/home/krish/content/1.2B_last_checkpoint.pt', reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=5000, keep_interval_updates=10, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=10, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, source_lang=None, target_lang=None, lang_pairs='hi-mr', keep_inference_langtok=False, sampling_method='temperature', sampling_temperature=1.5, data='/home/krish/content/old_files/Version3/wmt22_spm/wmt22_bin', langs=['hi', 'mr'], lang_dict=None, source_dict=None, target_dict=None, lang_tok_style='multilingual', load_alignments=False, left_pad_source='True', left_pad_target='False', upsample_primary=1, truncate_source=False, encoder_langtok='src', decoder_langtok=True, lang_tok_replacing_bos_eos=False, enable_lang_ids=False, enable_reservsed_directions_shared_datasets=False, extra_data=None, extra_lang_pairs=None, fixed_dictionary=None, langtoks_specs=['main'], langtoks=None, sampling_weights_from_file=None, sampling_weights=None, virtual_epoch_size=None, virtual_data_size=None, label_smoothing=0.2, report_accuracy=False, ignore_prefix_size=0, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.0, use_old_adam=False, fp16_adam_stats=False, warmup_updates=2500, warmup_init_lr=-1, pad=1, eos=2, unk=3, encoder_normalize_before=True, decoder_normalize_before=True, dropout=0.3, attention_dropout=0.1, encoder_layers=24, decoder_layers=24, encoder_ffn_embed_dim=8192, decoder_ffn_embed_dim=8192, encoder_layerdrop=0.05, decoder_layerdrop=0.05, share_decoder_input_output_embed=True, share_all_embeddings=True, no_seed_provided=False, encoder_embed_dim=1024, encoder_attention_heads=16, decoder_embed_dim=1024, decoder_attention_heads=16, encoder_embed_path=None, encoder_learned_pos=False, decoder_embed_path=None, decoder_learned_pos=False, activation_dropout=0.0, activation_fn='relu', adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, no_token_positional_embeddings=False, adaptive_input=False, no_cross_attention=False, cross_self_attention=False, decoder_output_dim=1024, decoder_input_dim=1024, no_scale_embedding=False, layernorm_embedding=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, max_source_positions=1024, max_target_positions=1024, _name='translation_multi_simple_epoch'), 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.2, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [3e-05]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 2500, 'warmup_init_lr': -1.0, 'lr': [3e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2025-04-03 11:31:26 | INFO | fairseq.data.multilingual.multilingual_data_manager | parsed the language list as they are ordered in the option: ['hi', 'mr']
2025-04-03 11:31:26 | INFO | fairseq.data.multilingual.multilingual_data_manager | [hi] dictionary: 128112 types
2025-04-03 11:31:26 | INFO | fairseq.data.multilingual.multilingual_data_manager | [mr] dictionary: 128112 types
2025-04-03 11:31:35 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(128112, 1024, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): LayerDropModuleList(
      (0-22): 23 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=8192, bias=True)
        (fc2): Linear(in_features=8192, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(128112, 1024, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): LayerDropModuleList(
      (0-20): 21 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=8192, bias=True)
        (fc2): Linear(in_features=8192, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=1024, out_features=128112, bias=False)
  )
)
2025-04-03 11:31:35 | INFO | fairseq_cli.train | task: TranslationMultiSimpleEpochTask
2025-04-03 11:31:35 | INFO | fairseq_cli.train | model: TransformerModel
2025-04-03 11:31:35 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2025-04-03 11:31:35 | INFO | fairseq_cli.train | num. shared model params: 1,743,106,048 (num. trained: 1,743,106,048)
2025-04-03 11:31:35 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2025-04-03 11:31:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | loading data for valid epoch=1/None
2025-04-03 11:31:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=10676.4140625Mb; avail=244424.8203125Mb
2025-04-03 11:31:35 | INFO | fairseq.data.multilingual.multilingual_data_manager | langtoks settings: {'main': ('src', 'tgt')}
2025-04-03 11:31:35 | INFO | fairseq.data.multilingual.multilingual_data_manager | [valid] num of shards: {'main:hi-mr': 1}
2025-04-03 11:31:35 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:hi-mr src_langtok: 128036; tgt_langtok: 128063
2025-04-03 11:31:35 | INFO | fairseq.data.data_utils | loaded 3,313 examples from: /home/krish/content/old_files/Version3/wmt22_spm/wmt22_bin/valid.hi-mr.hi
2025-04-03 11:31:35 | INFO | fairseq.data.data_utils | loaded 3,313 examples from: /home/krish/content/old_files/Version3/wmt22_spm/wmt22_bin/valid.hi-mr.mr
2025-04-03 11:31:35 | INFO | fairseq.data.multilingual.multilingual_data_manager | /home/krish/content/old_files/Version3/wmt22_spm/wmt22_bin valid hi-mr 3313 examples
2025-04-03 11:31:36 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2025-04-03 11:31:36 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2025-04-03 11:31:36 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2025-04-03 11:31:36 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
2025-04-03 11:31:36 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2025-04-03 11:31:36 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2025-04-03 11:31:36 | INFO | fairseq_cli.train | max tokens per device = 3600 and max sentences per device = None
2025-04-03 11:31:36 | INFO | fairseq.checkpoint_utils | loading pretrained model from /home/krish/content/1.2B_last_checkpoint.pt: optimizer, lr scheduler, meters, dataloader will be reset
2025-04-03 11:31:36 | INFO | fairseq.trainer | Preparing to load checkpoint /home/krish/content/1.2B_last_checkpoint.pt
2025-04-03 11:31:43 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2025-04-03 11:31:44 | INFO | fairseq.trainer | Loaded checkpoint /home/krish/content/1.2B_last_checkpoint.pt (epoch 81 @ 0 updates)
2025-04-03 11:31:44 | INFO | fairseq.trainer | loading train data for epoch 1
2025-04-03 11:31:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | loading data for train epoch=1/None
2025-04-03 11:31:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=7037.765625Mb; avail=248055.46484375Mb
2025-04-03 11:31:44 | INFO | fairseq.data.multilingual.multilingual_data_manager | langtoks settings: {'main': ('src', 'tgt')}
2025-04-03 11:31:44 | INFO | fairseq.data.multilingual.multilingual_data_manager | [train] num of shards: {'main:hi-mr': 1}
2025-04-03 11:31:44 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:hi-mr src_langtok: 128036; tgt_langtok: 128063
2025-04-03 11:31:44 | INFO | fairseq.data.data_utils | loaded 31,849 examples from: /home/krish/content/old_files/Version3/wmt22_spm/wmt22_bin/train.hi-mr.hi
2025-04-03 11:31:44 | INFO | fairseq.data.data_utils | loaded 31,849 examples from: /home/krish/content/old_files/Version3/wmt22_spm/wmt22_bin/train.hi-mr.mr
2025-04-03 11:31:44 | INFO | fairseq.data.multilingual.multilingual_data_manager | /home/krish/content/old_files/Version3/wmt22_spm/wmt22_bin train hi-mr 31849 examples
2025-04-03 11:31:44 | INFO | fairseq.data.multilingual.multilingual_data_manager | estimated total data sizes of all shards used in sampling ratios: [('main:hi-mr', 31849)]. Note that if the data a shard has not been loaded yet, use the max known data size to approximate
2025-04-03 11:31:44 | INFO | fairseq.data.multilingual.sampling_method | selected sampler: temperature
2025-04-03 11:31:44 | INFO | fairseq.data.multilingual.multilingual_data_manager | | Upsample ratios: [('main:hi-mr', 1.0)]
2025-04-03 11:31:44 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:hi-mr': 31849}; raw total size: 31849
2025-04-03 11:31:44 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:hi-mr': 31849}; resampled total size: 31849
2025-04-03 11:31:44 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:hi-mr': 1.0}
2025-04-03 11:31:44 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.000788
2025-04-03 11:31:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=7037.765625Mb; avail=248055.46484375Mb
2025-04-03 11:31:44 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000295
2025-04-03 11:31:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.002958
2025-04-03 11:31:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=7037.765625Mb; avail=248055.46484375Mb
2025-04-03 11:31:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000100
2025-04-03 11:31:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=7037.765625Mb; avail=248055.46484375Mb
2025-04-03 11:31:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001531
2025-04-03 11:31:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.004937
2025-04-03 11:31:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=7037.765625Mb; avail=248055.46484375Mb
2025-04-03 11:31:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 139
2025-04-03 11:31:44 | INFO | fairseq.trainer | begin training epoch 1
2025-04-03 11:31:44 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-03 11:31:50 | INFO | train_inner | epoch 001:      2 / 139 loss=11.88, nll_loss=9.81, ppl=897.61, wps=2671.2, ups=0.4, wpb=6812, bsz=260, num_updates=2, lr=2.4e-08, gnorm=14.219, train_wall=6, gb_free=12.2, wall=14
2025-04-03 11:31:54 | INFO | train_inner | epoch 001:      4 / 139 loss=11.894, nll_loss=9.826, ppl=907.67, wps=2100.4, ups=0.45, wpb=4627.5, bsz=156, num_updates=4, lr=4.8e-08, gnorm=13.139, train_wall=4, gb_free=12.7, wall=19
2025-04-03 11:32:00 | INFO | train_inner | epoch 001:      6 / 139 loss=11.627, nll_loss=9.483, ppl=715.52, wps=2324.3, ups=0.37, wpb=6237.5, bsz=324, num_updates=6, lr=7.2e-08, gnorm=12.546, train_wall=5, gb_free=11.3, wall=24
2025-04-03 11:32:04 | INFO | train_inner | epoch 001:      8 / 139 loss=11.734, nll_loss=9.622, ppl=787.82, wps=2221.7, ups=0.44, wpb=5095.5, bsz=104, num_updates=8, lr=9.6e-08, gnorm=13.879, train_wall=5, gb_free=13.6, wall=29
2025-04-03 11:32:09 | INFO | train_inner | epoch 001:     10 / 139 loss=11.629, nll_loss=9.486, ppl=717.23, wps=2447.6, ups=0.39, wpb=6320, bsz=188, num_updates=10, lr=1.2e-07, gnorm=13.794, train_wall=5, gb_free=11.3, wall=34
2025-04-03 11:32:14 | INFO | train_inner | epoch 001:     12 / 139 loss=11.696, nll_loss=9.573, ppl=761.55, wps=2437.2, ups=0.4, wpb=6062, bsz=176, num_updates=12, lr=1.44e-07, gnorm=14.101, train_wall=5, gb_free=9.7, wall=39
2025-04-03 11:32:19 | INFO | train_inner | epoch 001:     14 / 139 loss=11.502, nll_loss=9.331, ppl=643.9, wps=2099.6, ups=0.41, wpb=5073, bsz=168, num_updates=14, lr=1.68e-07, gnorm=12.544, train_wall=5, gb_free=12.5, wall=44
2025-04-03 11:32:24 | INFO | train_inner | epoch 001:     16 / 139 loss=11.808, nll_loss=9.715, ppl=840.38, wps=2521.5, ups=0.43, wpb=5891.5, bsz=172, num_updates=16, lr=1.92e-07, gnorm=13.419, train_wall=5, gb_free=11.7, wall=48
2025-04-03 11:32:29 | INFO | train_inner | epoch 001:     18 / 139 loss=11.635, nll_loss=9.493, ppl=720.57, wps=2227.1, ups=0.4, wpb=5499, bsz=152, num_updates=18, lr=2.16e-07, gnorm=12.099, train_wall=5, gb_free=12.6, wall=53
2025-04-03 11:32:34 | INFO | train_inner | epoch 001:     20 / 139 loss=11.733, nll_loss=9.615, ppl=784.04, wps=2424.5, ups=0.39, wpb=6186, bsz=284, num_updates=20, lr=2.4e-07, gnorm=13.25, train_wall=5, gb_free=14.1, wall=58
2025-04-03 11:32:39 | INFO | train_inner | epoch 001:     22 / 139 loss=11.548, nll_loss=9.389, ppl=670.49, wps=2318, ups=0.39, wpb=5904, bsz=220, num_updates=22, lr=2.64e-07, gnorm=11.713, train_wall=5, gb_free=14.4, wall=64
2025-04-03 11:32:44 | INFO | train_inner | epoch 001:     24 / 139 loss=11.691, nll_loss=9.565, ppl=757.71, wps=2461.3, ups=0.39, wpb=6265, bsz=180, num_updates=24, lr=2.88e-07, gnorm=12.662, train_wall=5, gb_free=12, wall=69
2025-04-03 11:32:49 | INFO | train_inner | epoch 001:     26 / 139 loss=11.444, nll_loss=9.263, ppl=614.19, wps=1936.8, ups=0.41, wpb=4727.5, bsz=176, num_updates=26, lr=3.12e-07, gnorm=11.003, train_wall=5, gb_free=13.2, wall=73
2025-04-03 11:32:54 | INFO | train_inner | epoch 001:     28 / 139 loss=11.471, nll_loss=9.292, ppl=626.79, wps=2461, ups=0.37, wpb=6571, bsz=256, num_updates=28, lr=3.36e-07, gnorm=11.612, train_wall=5, gb_free=11.9, wall=79
2025-04-03 11:33:00 | INFO | train_inner | epoch 001:     30 / 139 loss=11.307, nll_loss=9.081, ppl=541.58, wps=2293.8, ups=0.38, wpb=6013.5, bsz=204, num_updates=30, lr=3.6e-07, gnorm=10.322, train_wall=5, gb_free=11.1, wall=84
2025-04-03 11:33:05 | INFO | train_inner | epoch 001:     32 / 139 loss=11.488, nll_loss=9.312, ppl=635.7, wps=2506, ups=0.37, wpb=6795.5, bsz=292, num_updates=32, lr=3.84e-07, gnorm=12.131, train_wall=5, gb_free=12.1, wall=90
2025-04-03 11:33:10 | INFO | train_inner | epoch 001:     34 / 139 loss=11.146, nll_loss=8.883, ppl=472.26, wps=2278.7, ups=0.39, wpb=5884, bsz=220, num_updates=34, lr=4.08e-07, gnorm=10.423, train_wall=5, gb_free=10.8, wall=95
2025-04-03 11:33:16 | INFO | train_inner | epoch 001:     36 / 139 loss=11.093, nll_loss=8.818, ppl=451.17, wps=2332.2, ups=0.36, wpb=6488.5, bsz=232, num_updates=36, lr=4.32e-07, gnorm=9.589, train_wall=6, gb_free=10.3, wall=100
2025-04-03 11:33:21 | INFO | train_inner | epoch 001:     38 / 139 loss=11.186, nll_loss=8.935, ppl=489.59, wps=2239.2, ups=0.4, wpb=5659, bsz=176, num_updates=38, lr=4.56e-07, gnorm=9.125, train_wall=5, gb_free=12.9, wall=105
2025-04-03 11:33:26 | INFO | train_inner | epoch 001:     40 / 139 loss=11.27, nll_loss=9.045, ppl=528.13, wps=2586.6, ups=0.38, wpb=6758.5, bsz=248, num_updates=40, lr=4.8e-07, gnorm=9.551, train_wall=5, gb_free=12.1, wall=111
2025-04-03 11:33:31 | INFO | train_inner | epoch 001:     42 / 139 loss=11.054, nll_loss=8.767, ppl=435.52, wps=2212.6, ups=0.39, wpb=5639, bsz=260, num_updates=42, lr=5.04e-07, gnorm=8.414, train_wall=5, gb_free=12, wall=116
2025-04-03 11:33:37 | INFO | train_inner | epoch 001:     44 / 139 loss=11.215, nll_loss=8.975, ppl=503.38, wps=2508.6, ups=0.37, wpb=6794.5, bsz=296, num_updates=44, lr=5.28e-07, gnorm=9.225, train_wall=5, gb_free=10.8, wall=121
2025-04-03 11:33:42 | INFO | train_inner | epoch 001:     46 / 139 loss=11.155, nll_loss=8.9, ppl=477.87, wps=2414.2, ups=0.38, wpb=6351, bsz=272, num_updates=46, lr=5.52e-07, gnorm=8.943, train_wall=5, gb_free=10.4, wall=126
2025-04-03 11:33:47 | INFO | train_inner | epoch 001:     48 / 139 loss=11.064, nll_loss=8.787, ppl=441.62, wps=2045.5, ups=0.4, wpb=5131, bsz=204, num_updates=48, lr=5.76e-07, gnorm=8.181, train_wall=5, gb_free=12.2, wall=131
2025-04-03 11:33:52 | INFO | train_inner | epoch 001:     50 / 139 loss=11.022, nll_loss=8.734, ppl=425.77, wps=2116.7, ups=0.38, wpb=5571, bsz=180, num_updates=50, lr=6e-07, gnorm=6.928, train_wall=5, gb_free=11.4, wall=137
2025-04-03 11:33:57 | INFO | train_inner | epoch 001:     52 / 139 loss=10.889, nll_loss=8.57, ppl=380.12, wps=2555.5, ups=0.38, wpb=6804.5, bsz=268, num_updates=52, lr=6.24e-07, gnorm=7.419, train_wall=5, gb_free=10, wall=142
2025-04-03 11:34:03 | INFO | train_inner | epoch 001:     54 / 139 loss=10.84, nll_loss=8.514, ppl=365.66, wps=2257.1, ups=0.37, wpb=6045.5, bsz=300, num_updates=54, lr=6.48e-07, gnorm=7.169, train_wall=5, gb_free=10.3, wall=147
2025-04-03 11:34:08 | INFO | train_inner | epoch 001:     56 / 139 loss=10.627, nll_loss=8.249, ppl=304.18, wps=2261.2, ups=0.38, wpb=5983, bsz=180, num_updates=56, lr=6.72e-07, gnorm=5.704, train_wall=5, gb_free=9.5, wall=153
2025-04-03 11:34:13 | INFO | train_inner | epoch 001:     58 / 139 loss=10.712, nll_loss=8.356, ppl=327.56, wps=2262.4, ups=0.38, wpb=5933.5, bsz=240, num_updates=58, lr=6.96e-07, gnorm=6.312, train_wall=5, gb_free=13.5, wall=158
2025-04-03 11:34:19 | INFO | train_inner | epoch 001:     60 / 139 loss=10.69, nll_loss=8.326, ppl=320.87, wps=2271.2, ups=0.38, wpb=6044.5, bsz=248, num_updates=60, lr=7.2e-07, gnorm=5.792, train_wall=5, gb_free=11.4, wall=163
2025-04-03 11:34:24 | INFO | train_inner | epoch 001:     62 / 139 loss=10.728, nll_loss=8.381, ppl=333.4, wps=2460.4, ups=0.37, wpb=6655, bsz=232, num_updates=62, lr=7.44e-07, gnorm=5.35, train_wall=5, gb_free=10.1, wall=169
2025-04-03 11:34:29 | INFO | train_inner | epoch 001:     64 / 139 loss=10.67, nll_loss=8.306, ppl=316.55, wps=2260.9, ups=0.38, wpb=6016, bsz=280, num_updates=64, lr=7.68e-07, gnorm=5.92, train_wall=5, gb_free=11, wall=174
2025-04-03 11:34:35 | INFO | train_inner | epoch 001:     66 / 139 loss=10.521, nll_loss=8.124, ppl=278.99, wps=2293.1, ups=0.37, wpb=6238, bsz=224, num_updates=66, lr=7.92e-07, gnorm=4.838, train_wall=5, gb_free=12.1, wall=179
2025-04-03 11:34:40 | INFO | train_inner | epoch 001:     68 / 139 loss=10.463, nll_loss=8.06, ppl=266.93, wps=2330.9, ups=0.37, wpb=6300.5, bsz=240, num_updates=68, lr=8.16e-07, gnorm=4.878, train_wall=5, gb_free=12.3, wall=185
2025-04-03 11:34:46 | INFO | train_inner | epoch 001:     70 / 139 loss=10.224, nll_loss=7.742, ppl=214.09, wps=2211.3, ups=0.36, wpb=6099, bsz=336, num_updates=70, lr=8.4e-07, gnorm=5.075, train_wall=6, gb_free=12.8, wall=190
2025-04-03 11:34:51 | INFO | train_inner | epoch 001:     72 / 139 loss=10.259, nll_loss=7.798, ppl=222.56, wps=2244.5, ups=0.35, wpb=6325, bsz=280, num_updates=72, lr=8.64e-07, gnorm=4.406, train_wall=6, gb_free=10.2, wall=196
2025-04-03 11:34:56 | INFO | train_inner | epoch 001:     74 / 139 loss=10.564, nll_loss=8.194, ppl=292.78, wps=2443.3, ups=0.41, wpb=6014, bsz=192, num_updates=74, lr=8.88e-07, gnorm=4.611, train_wall=5, gb_free=12.2, wall=201
2025-04-03 11:35:02 | INFO | train_inner | epoch 001:     76 / 139 loss=10.239, nll_loss=7.777, ppl=219.27, wps=2277.9, ups=0.37, wpb=6136, bsz=248, num_updates=76, lr=9.12e-07, gnorm=4.246, train_wall=5, gb_free=12.5, wall=206
2025-04-03 11:35:07 | INFO | train_inner | epoch 001:     78 / 139 loss=10.233, nll_loss=7.772, ppl=218.6, wps=2402.2, ups=0.37, wpb=6487.5, bsz=284, num_updates=78, lr=9.36e-07, gnorm=4.013, train_wall=5, gb_free=11.1, wall=212
2025-04-03 11:35:12 | INFO | train_inner | epoch 001:     80 / 139 loss=10.278, nll_loss=7.831, ppl=227.63, wps=2057.2, ups=0.4, wpb=5141.5, bsz=164, num_updates=80, lr=9.6e-07, gnorm=3.847, train_wall=5, gb_free=10, wall=217
2025-04-03 11:35:17 | INFO | train_inner | epoch 001:     82 / 139 loss=10.219, nll_loss=7.753, ppl=215.73, wps=2231.2, ups=0.39, wpb=5703.5, bsz=272, num_updates=82, lr=9.84e-07, gnorm=4.228, train_wall=5, gb_free=13.5, wall=222
2025-04-03 11:35:22 | INFO | train_inner | epoch 001:     84 / 139 loss=10.372, nll_loss=7.961, ppl=249.19, wps=2317.2, ups=0.39, wpb=5939.5, bsz=148, num_updates=84, lr=1.008e-06, gnorm=3.787, train_wall=5, gb_free=12.6, wall=227
2025-04-03 11:35:27 | INFO | train_inner | epoch 001:     86 / 139 loss=10.287, nll_loss=7.845, ppl=229.9, wps=2144.7, ups=0.42, wpb=5121.5, bsz=160, num_updates=86, lr=1.032e-06, gnorm=3.633, train_wall=5, gb_free=13.7, wall=232
2025-04-03 11:35:32 | INFO | train_inner | epoch 001:     88 / 139 loss=10.315, nll_loss=7.896, ppl=238.26, wps=2369.5, ups=0.42, wpb=5583.5, bsz=204, num_updates=88, lr=1.056e-06, gnorm=3.642, train_wall=5, gb_free=12.3, wall=236
2025-04-03 11:35:37 | INFO | train_inner | epoch 001:     90 / 139 loss=10.16, nll_loss=7.695, ppl=207.24, wps=2518.3, ups=0.36, wpb=7011, bsz=332, num_updates=90, lr=1.08e-06, gnorm=3.708, train_wall=6, gb_free=10.9, wall=242
2025-04-03 11:35:43 | INFO | train_inner | epoch 001:     92 / 139 loss=10.013, nll_loss=7.506, ppl=181.73, wps=2387, ups=0.35, wpb=6874.5, bsz=284, num_updates=92, lr=1.104e-06, gnorm=3.295, train_wall=6, gb_free=10.7, wall=248
2025-04-03 11:35:49 | INFO | train_inner | epoch 001:     94 / 139 loss=10.078, nll_loss=7.601, ppl=194.09, wps=2182.6, ups=0.36, wpb=6004, bsz=152, num_updates=94, lr=1.128e-06, gnorm=3.193, train_wall=5, gb_free=10.8, wall=253
2025-04-03 11:35:54 | INFO | train_inner | epoch 001:     96 / 139 loss=9.854, nll_loss=7.294, ppl=156.9, wps=2188.5, ups=0.36, wpb=6002, bsz=300, num_updates=96, lr=1.152e-06, gnorm=3.732, train_wall=5, gb_free=13.4, wall=259
2025-04-03 11:35:59 | INFO | train_inner | epoch 001:     98 / 139 loss=10.016, nll_loss=7.523, ppl=183.98, wps=2256.7, ups=0.43, wpb=5264.5, bsz=192, num_updates=98, lr=1.176e-06, gnorm=3.115, train_wall=5, gb_free=11.5, wall=263
2025-04-03 11:36:04 | INFO | train_inner | epoch 001:    100 / 139 loss=9.993, nll_loss=7.497, ppl=180.7, wps=2543.5, ups=0.38, wpb=6754.5, bsz=252, num_updates=100, lr=1.2e-06, gnorm=3.284, train_wall=5, gb_free=12.1, wall=269
2025-04-03 11:36:10 | INFO | train_inner | epoch 001:    102 / 139 loss=9.904, nll_loss=7.377, ppl=166.18, wps=2325, ups=0.37, wpb=6328, bsz=240, num_updates=102, lr=1.224e-06, gnorm=2.793, train_wall=5, gb_free=11.1, wall=274
2025-04-03 11:36:15 | INFO | train_inner | epoch 001:    104 / 139 loss=9.946, nll_loss=7.436, ppl=173.19, wps=2275.8, ups=0.38, wpb=6039.5, bsz=244, num_updates=104, lr=1.248e-06, gnorm=2.767, train_wall=5, gb_free=10.1, wall=279
2025-04-03 11:36:20 | INFO | train_inner | epoch 001:    106 / 139 loss=9.912, nll_loss=7.395, ppl=168.33, wps=2387, ups=0.37, wpb=6534, bsz=240, num_updates=106, lr=1.272e-06, gnorm=2.791, train_wall=5, gb_free=10.4, wall=285
2025-04-03 11:36:26 | INFO | train_inner | epoch 001:    108 / 139 loss=9.692, nll_loss=7.112, ppl=138.32, wps=2249.5, ups=0.35, wpb=6460, bsz=276, num_updates=108, lr=1.296e-06, gnorm=2.763, train_wall=6, gb_free=10.7, wall=291
2025-04-03 11:36:31 | INFO | train_inner | epoch 001:    110 / 139 loss=10.025, nll_loss=7.546, ppl=186.89, wps=2409.5, ups=0.38, wpb=6307.5, bsz=204, num_updates=110, lr=1.32e-06, gnorm=2.678, train_wall=5, gb_free=11.7, wall=296
2025-04-03 11:36:37 | INFO | train_inner | epoch 001:    112 / 139 loss=9.856, nll_loss=7.325, ppl=160.29, wps=2320.8, ups=0.37, wpb=6254, bsz=252, num_updates=112, lr=1.344e-06, gnorm=2.646, train_wall=5, gb_free=10.7, wall=301
2025-04-03 11:36:42 | INFO | train_inner | epoch 001:    114 / 139 loss=9.972, nll_loss=7.476, ppl=178, wps=2476.9, ups=0.39, wpb=6321.5, bsz=204, num_updates=114, lr=1.368e-06, gnorm=2.907, train_wall=5, gb_free=12, wall=306
2025-04-03 11:36:47 | INFO | train_inner | epoch 001:    116 / 139 loss=9.731, nll_loss=7.172, ppl=144.24, wps=2284.6, ups=0.39, wpb=5905, bsz=224, num_updates=116, lr=1.392e-06, gnorm=2.752, train_wall=5, gb_free=13.9, wall=311
2025-04-03 11:36:52 | INFO | train_inner | epoch 001:    118 / 139 loss=9.591, nll_loss=6.997, ppl=127.75, wps=2218, ups=0.36, wpb=6129.5, bsz=248, num_updates=118, lr=1.416e-06, gnorm=2.409, train_wall=6, gb_free=10.8, wall=317
2025-04-03 11:36:58 | INFO | train_inner | epoch 001:    120 / 139 loss=9.722, nll_loss=7.176, ppl=144.6, wps=2208.4, ups=0.38, wpb=5835, bsz=168, num_updates=120, lr=1.44e-06, gnorm=2.931, train_wall=5, gb_free=12.3, wall=322
2025-04-03 11:37:03 | INFO | train_inner | epoch 001:    122 / 139 loss=9.602, nll_loss=7.013, ppl=129.17, wps=2366.5, ups=0.37, wpb=6462.5, bsz=248, num_updates=122, lr=1.464e-06, gnorm=2.569, train_wall=5, gb_free=11.4, wall=328
2025-04-03 11:37:08 | INFO | train_inner | epoch 001:    124 / 139 loss=9.697, nll_loss=7.138, ppl=140.89, wps=2084.6, ups=0.44, wpb=4767.5, bsz=184.5, num_updates=124, lr=1.488e-06, gnorm=3.061, train_wall=5, gb_free=9.4, wall=332
2025-04-03 11:37:13 | INFO | train_inner | epoch 001:    126 / 139 loss=9.612, nll_loss=7.039, ppl=131.54, wps=2251.6, ups=0.38, wpb=5858.5, bsz=196, num_updates=126, lr=1.512e-06, gnorm=2.23, train_wall=5, gb_free=13, wall=337
2025-04-03 11:37:18 | INFO | train_inner | epoch 001:    128 / 139 loss=9.653, nll_loss=7.075, ppl=134.8, wps=2388.5, ups=0.39, wpb=6054.5, bsz=320, num_updates=128, lr=1.536e-06, gnorm=2.58, train_wall=5, gb_free=10.6, wall=343
2025-04-03 11:37:23 | INFO | train_inner | epoch 001:    130 / 139 loss=9.641, nll_loss=7.084, ppl=135.65, wps=2181.9, ups=0.38, wpb=5784.5, bsz=168, num_updates=130, lr=1.56e-06, gnorm=2.363, train_wall=5, gb_free=10.4, wall=348
2025-04-17 09:56:38 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 2, 'log_format': 'simple', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 222, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 3600, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 3600, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 40000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [2], 'lr': [3e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/home/krish/content/old_files/Version3/checkpoint1.2B', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': '/home/krish/content/1.2B_last_checkpoint.pt', 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 5000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': 10, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=2, log_format='simple', log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=222, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', scoring='bleu', task='translation_multi_simple_epoch', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=3600, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=3600, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='transformer_wmt_en_de_big', max_epoch=0, max_update=40000, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[2], lr=[3e-05], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='/home/krish/content/old_files/Version3/checkpoint1.2B', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model='/home/krish/content/1.2B_last_checkpoint.pt', reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=5000, keep_interval_updates=10, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=10, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, source_lang=None, target_lang=None, lang_pairs='hi-mr', keep_inference_langtok=False, sampling_method='temperature', sampling_temperature=1.5, data='/home/krish/content/old_files/Version3/wmt22_spm/wmt22_bin', langs=['hi', 'mr'], lang_dict=None, source_dict=None, target_dict=None, lang_tok_style='multilingual', load_alignments=False, left_pad_source='True', left_pad_target='False', upsample_primary=1, truncate_source=False, encoder_langtok='src', decoder_langtok=True, lang_tok_replacing_bos_eos=False, enable_lang_ids=False, enable_reservsed_directions_shared_datasets=False, extra_data=None, extra_lang_pairs=None, fixed_dictionary=None, langtoks_specs=['main'], langtoks=None, sampling_weights_from_file=None, sampling_weights=None, virtual_epoch_size=None, virtual_data_size=None, label_smoothing=0.2, report_accuracy=False, ignore_prefix_size=0, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.0, use_old_adam=False, fp16_adam_stats=False, warmup_updates=2500, warmup_init_lr=-1, pad=1, eos=2, unk=3, encoder_normalize_before=True, decoder_normalize_before=True, dropout=0.3, attention_dropout=0.1, encoder_layers=24, decoder_layers=24, encoder_ffn_embed_dim=8192, decoder_ffn_embed_dim=8192, encoder_layerdrop=0.05, decoder_layerdrop=0.05, share_decoder_input_output_embed=True, share_all_embeddings=True, no_seed_provided=False, encoder_embed_dim=1024, encoder_attention_heads=16, decoder_embed_dim=1024, decoder_attention_heads=16, encoder_embed_path=None, encoder_learned_pos=False, decoder_embed_path=None, decoder_learned_pos=False, activation_dropout=0.0, activation_fn='relu', adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, no_token_positional_embeddings=False, adaptive_input=False, no_cross_attention=False, cross_self_attention=False, decoder_output_dim=1024, decoder_input_dim=1024, no_scale_embedding=False, layernorm_embedding=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, _name='transformer_wmt_en_de_big'), 'task': Namespace(no_progress_bar=False, log_interval=2, log_format='simple', log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=222, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', scoring='bleu', task='translation_multi_simple_epoch', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=3600, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=3600, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='transformer_wmt_en_de_big', max_epoch=0, max_update=40000, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[2], lr=[3e-05], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='/home/krish/content/old_files/Version3/checkpoint1.2B', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model='/home/krish/content/1.2B_last_checkpoint.pt', reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=5000, keep_interval_updates=10, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=10, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, source_lang=None, target_lang=None, lang_pairs='hi-mr', keep_inference_langtok=False, sampling_method='temperature', sampling_temperature=1.5, data='/home/krish/content/old_files/Version3/wmt22_spm/wmt22_bin', langs=['hi', 'mr'], lang_dict=None, source_dict=None, target_dict=None, lang_tok_style='multilingual', load_alignments=False, left_pad_source='True', left_pad_target='False', upsample_primary=1, truncate_source=False, encoder_langtok='src', decoder_langtok=True, lang_tok_replacing_bos_eos=False, enable_lang_ids=False, enable_reservsed_directions_shared_datasets=False, extra_data=None, extra_lang_pairs=None, fixed_dictionary=None, langtoks_specs=['main'], langtoks=None, sampling_weights_from_file=None, sampling_weights=None, virtual_epoch_size=None, virtual_data_size=None, label_smoothing=0.2, report_accuracy=False, ignore_prefix_size=0, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.0, use_old_adam=False, fp16_adam_stats=False, warmup_updates=2500, warmup_init_lr=-1, pad=1, eos=2, unk=3, encoder_normalize_before=True, decoder_normalize_before=True, dropout=0.3, attention_dropout=0.1, encoder_layers=24, decoder_layers=24, encoder_ffn_embed_dim=8192, decoder_ffn_embed_dim=8192, encoder_layerdrop=0.05, decoder_layerdrop=0.05, share_decoder_input_output_embed=True, share_all_embeddings=True, no_seed_provided=False, encoder_embed_dim=1024, encoder_attention_heads=16, decoder_embed_dim=1024, decoder_attention_heads=16, encoder_embed_path=None, encoder_learned_pos=False, decoder_embed_path=None, decoder_learned_pos=False, activation_dropout=0.0, activation_fn='relu', adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, no_token_positional_embeddings=False, adaptive_input=False, no_cross_attention=False, cross_self_attention=False, decoder_output_dim=1024, decoder_input_dim=1024, no_scale_embedding=False, layernorm_embedding=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, max_source_positions=1024, max_target_positions=1024, _name='translation_multi_simple_epoch'), 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.2, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [3e-05]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 2500, 'warmup_init_lr': -1.0, 'lr': [3e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2025-04-17 09:56:38 | INFO | fairseq.data.multilingual.multilingual_data_manager | parsed the language list as they are ordered in the option: ['hi', 'mr']
2025-04-17 09:56:38 | INFO | fairseq.data.multilingual.multilingual_data_manager | [hi] dictionary: 128112 types
2025-04-17 09:56:38 | INFO | fairseq.data.multilingual.multilingual_data_manager | [mr] dictionary: 128112 types
2025-04-17 09:56:47 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(128112, 1024, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): LayerDropModuleList(
      (0-22): 23 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=8192, bias=True)
        (fc2): Linear(in_features=8192, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(128112, 1024, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): LayerDropModuleList(
      (0-20): 21 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=8192, bias=True)
        (fc2): Linear(in_features=8192, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=1024, out_features=128112, bias=False)
  )
)
2025-04-17 09:56:47 | INFO | fairseq_cli.train | task: TranslationMultiSimpleEpochTask
2025-04-17 09:56:47 | INFO | fairseq_cli.train | model: TransformerModel
2025-04-17 09:56:47 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2025-04-17 09:56:47 | INFO | fairseq_cli.train | num. shared model params: 1,743,106,048 (num. trained: 1,743,106,048)
2025-04-17 09:56:47 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2025-04-17 09:56:47 | INFO | fairseq.tasks.translation_multi_simple_epoch | loading data for valid epoch=1/None
2025-04-17 09:56:47 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=9967.05078125Mb; avail=245189.796875Mb
2025-04-17 09:56:47 | INFO | fairseq.data.multilingual.multilingual_data_manager | langtoks settings: {'main': ('src', 'tgt')}
2025-04-17 09:56:47 | INFO | fairseq.data.multilingual.multilingual_data_manager | [valid] num of shards: {'main:hi-mr': 1}
2025-04-17 09:56:47 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:hi-mr src_langtok: 128036; tgt_langtok: 128063
2025-04-17 09:56:47 | INFO | fairseq.data.data_utils | loaded 3,313 examples from: /home/krish/content/old_files/Version3/wmt22_spm/wmt22_bin/valid.hi-mr.hi
2025-04-17 09:56:47 | INFO | fairseq.data.data_utils | loaded 3,313 examples from: /home/krish/content/old_files/Version3/wmt22_spm/wmt22_bin/valid.hi-mr.mr
2025-04-17 09:56:47 | INFO | fairseq.data.multilingual.multilingual_data_manager | /home/krish/content/old_files/Version3/wmt22_spm/wmt22_bin valid hi-mr 3313 examples
2025-04-17 09:56:48 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2025-04-17 09:56:48 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2025-04-17 09:56:48 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2025-04-17 09:56:48 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
2025-04-17 09:56:48 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2025-04-17 09:56:48 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2025-04-17 09:56:48 | INFO | fairseq_cli.train | max tokens per device = 3600 and max sentences per device = None
2025-04-17 09:56:48 | INFO | fairseq.checkpoint_utils | loading pretrained model from /home/krish/content/1.2B_last_checkpoint.pt: optimizer, lr scheduler, meters, dataloader will be reset
2025-04-17 09:56:48 | INFO | fairseq.trainer | Preparing to load checkpoint /home/krish/content/1.2B_last_checkpoint.pt
2025-04-17 09:56:54 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2025-04-17 09:56:54 | INFO | fairseq.trainer | Loaded checkpoint /home/krish/content/1.2B_last_checkpoint.pt (epoch 81 @ 0 updates)
2025-04-17 09:56:54 | INFO | fairseq.trainer | loading train data for epoch 1
2025-04-17 09:56:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | loading data for train epoch=1/None
2025-04-17 09:56:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=6306.6796875Mb; avail=248842.203125Mb
2025-04-17 09:56:54 | INFO | fairseq.data.multilingual.multilingual_data_manager | langtoks settings: {'main': ('src', 'tgt')}
2025-04-17 09:56:54 | INFO | fairseq.data.multilingual.multilingual_data_manager | [train] num of shards: {'main:hi-mr': 1}
2025-04-17 09:56:54 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:hi-mr src_langtok: 128036; tgt_langtok: 128063
2025-04-17 09:56:54 | INFO | fairseq.data.data_utils | loaded 31,849 examples from: /home/krish/content/old_files/Version3/wmt22_spm/wmt22_bin/train.hi-mr.hi
2025-04-17 09:56:54 | INFO | fairseq.data.data_utils | loaded 31,849 examples from: /home/krish/content/old_files/Version3/wmt22_spm/wmt22_bin/train.hi-mr.mr
2025-04-17 09:56:54 | INFO | fairseq.data.multilingual.multilingual_data_manager | /home/krish/content/old_files/Version3/wmt22_spm/wmt22_bin train hi-mr 31849 examples
2025-04-17 09:56:54 | INFO | fairseq.data.multilingual.multilingual_data_manager | estimated total data sizes of all shards used in sampling ratios: [('main:hi-mr', 31849)]. Note that if the data a shard has not been loaded yet, use the max known data size to approximate
2025-04-17 09:56:54 | INFO | fairseq.data.multilingual.sampling_method | selected sampler: temperature
2025-04-17 09:56:54 | INFO | fairseq.data.multilingual.multilingual_data_manager | | Upsample ratios: [('main:hi-mr', 1.0)]
2025-04-17 09:56:55 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:hi-mr': 31849}; raw total size: 31849
2025-04-17 09:56:55 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:hi-mr': 31849}; resampled total size: 31849
2025-04-17 09:56:55 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:hi-mr': 1.0}
2025-04-17 09:56:55 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.000866
2025-04-17 09:56:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=6300.7734375Mb; avail=248848.109375Mb
2025-04-17 09:56:55 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000307
2025-04-17 09:56:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.002961
2025-04-17 09:56:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=6300.7734375Mb; avail=248848.109375Mb
2025-04-17 09:56:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000092
2025-04-17 09:56:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=6300.7734375Mb; avail=248848.109375Mb
2025-04-17 09:56:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.002470
2025-04-17 09:56:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.005833
2025-04-17 09:56:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=6300.28125Mb; avail=248848.109375Mb
2025-04-17 09:56:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 139
2025-04-17 09:56:55 | INFO | fairseq.trainer | begin training epoch 1
2025-04-17 09:56:55 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-17 09:57:00 | INFO | train_inner | epoch 001:      2 / 139 loss=11.88, nll_loss=9.81, ppl=897.61, wps=2681.4, ups=0.4, wpb=6812, bsz=260, num_updates=2, lr=2.4e-08, gnorm=14.219, train_wall=6, gb_free=12.2, wall=13
2025-04-17 09:57:05 | INFO | train_inner | epoch 001:      4 / 139 loss=11.894, nll_loss=9.826, ppl=907.67, wps=2106.5, ups=0.46, wpb=4627.5, bsz=156, num_updates=4, lr=4.8e-08, gnorm=13.139, train_wall=4, gb_free=12.7, wall=17
2025-04-17 09:57:10 | INFO | train_inner | epoch 001:      6 / 139 loss=11.627, nll_loss=9.483, ppl=715.52, wps=2328.7, ups=0.37, wpb=6237.5, bsz=324, num_updates=6, lr=7.2e-08, gnorm=12.546, train_wall=5, gb_free=11.3, wall=23
2025-04-17 09:57:15 | INFO | train_inner | epoch 001:      8 / 139 loss=11.734, nll_loss=9.622, ppl=787.82, wps=2208.7, ups=0.43, wpb=5095.5, bsz=104, num_updates=8, lr=9.6e-08, gnorm=13.879, train_wall=5, gb_free=13.6, wall=27
2025-04-17 09:57:20 | INFO | train_inner | epoch 001:     10 / 139 loss=11.629, nll_loss=9.486, ppl=717.23, wps=2450.2, ups=0.39, wpb=6320, bsz=188, num_updates=10, lr=1.2e-07, gnorm=13.794, train_wall=5, gb_free=11.3, wall=32
2025-04-17 09:57:25 | INFO | train_inner | epoch 001:     12 / 139 loss=11.696, nll_loss=9.573, ppl=761.55, wps=2449.5, ups=0.4, wpb=6062, bsz=176, num_updates=12, lr=1.44e-07, gnorm=14.101, train_wall=5, gb_free=9.7, wall=37
2025-04-17 09:57:30 | INFO | train_inner | epoch 001:     14 / 139 loss=11.502, nll_loss=9.331, ppl=643.9, wps=2106.3, ups=0.42, wpb=5073, bsz=168, num_updates=14, lr=1.68e-07, gnorm=12.544, train_wall=5, gb_free=12.5, wall=42
2025-04-17 09:57:34 | INFO | train_inner | epoch 001:     16 / 139 loss=11.808, nll_loss=9.715, ppl=840.38, wps=2523.6, ups=0.43, wpb=5891.5, bsz=172, num_updates=16, lr=1.92e-07, gnorm=13.419, train_wall=5, gb_free=11.7, wall=47
2025-04-17 09:57:39 | INFO | train_inner | epoch 001:     18 / 139 loss=11.635, nll_loss=9.493, ppl=720.57, wps=2233.7, ups=0.41, wpb=5499, bsz=152, num_updates=18, lr=2.16e-07, gnorm=12.099, train_wall=5, gb_free=12.6, wall=52
2025-04-17 09:57:44 | INFO | train_inner | epoch 001:     20 / 139 loss=11.733, nll_loss=9.615, ppl=784.04, wps=2437.2, ups=0.39, wpb=6186, bsz=284, num_updates=20, lr=2.4e-07, gnorm=13.25, train_wall=5, gb_free=14.1, wall=57
2025-04-17 09:57:49 | INFO | train_inner | epoch 001:     22 / 139 loss=11.548, nll_loss=9.389, ppl=670.49, wps=2329, ups=0.39, wpb=5904, bsz=220, num_updates=22, lr=2.64e-07, gnorm=11.713, train_wall=5, gb_free=14.4, wall=62
2025-04-17 09:57:55 | INFO | train_inner | epoch 001:     24 / 139 loss=11.691, nll_loss=9.565, ppl=757.71, wps=2470, ups=0.39, wpb=6265, bsz=180, num_updates=24, lr=2.88e-07, gnorm=12.662, train_wall=5, gb_free=12, wall=67
2025-04-17 09:57:59 | INFO | train_inner | epoch 001:     26 / 139 loss=11.444, nll_loss=9.263, ppl=614.19, wps=1944.5, ups=0.41, wpb=4727.5, bsz=176, num_updates=26, lr=3.12e-07, gnorm=11.003, train_wall=5, gb_free=13.2, wall=72
2025-04-17 09:58:05 | INFO | train_inner | epoch 001:     28 / 139 loss=11.471, nll_loss=9.292, ppl=626.79, wps=2471.6, ups=0.38, wpb=6571, bsz=256, num_updates=28, lr=3.36e-07, gnorm=11.612, train_wall=5, gb_free=11.9, wall=77
2025-04-17 09:58:10 | INFO | train_inner | epoch 001:     30 / 139 loss=11.307, nll_loss=9.081, ppl=541.58, wps=2298.8, ups=0.38, wpb=6013.5, bsz=204, num_updates=30, lr=3.6e-07, gnorm=10.322, train_wall=5, gb_free=11.1, wall=82
2025-04-17 09:58:15 | INFO | train_inner | epoch 001:     32 / 139 loss=11.488, nll_loss=9.312, ppl=635.7, wps=2518.8, ups=0.37, wpb=6795.5, bsz=292, num_updates=32, lr=3.84e-07, gnorm=12.131, train_wall=5, gb_free=12.1, wall=88
2025-04-17 09:58:20 | INFO | train_inner | epoch 001:     34 / 139 loss=11.146, nll_loss=8.883, ppl=472.26, wps=2286.4, ups=0.39, wpb=5884, bsz=220, num_updates=34, lr=4.08e-07, gnorm=10.423, train_wall=5, gb_free=10.8, wall=93
2025-04-17 09:58:26 | INFO | train_inner | epoch 001:     36 / 139 loss=11.093, nll_loss=8.818, ppl=451.17, wps=2344.5, ups=0.36, wpb=6488.5, bsz=232, num_updates=36, lr=4.32e-07, gnorm=9.589, train_wall=6, gb_free=10.3, wall=99
2025-04-17 09:58:31 | INFO | train_inner | epoch 001:     38 / 139 loss=11.186, nll_loss=8.935, ppl=489.59, wps=2248.9, ups=0.4, wpb=5659, bsz=176, num_updates=38, lr=4.56e-07, gnorm=9.125, train_wall=5, gb_free=12.9, wall=104
2025-04-17 09:58:36 | INFO | train_inner | epoch 001:     40 / 139 loss=11.27, nll_loss=9.045, ppl=528.13, wps=2592.2, ups=0.38, wpb=6758.5, bsz=248, num_updates=40, lr=4.8e-07, gnorm=9.551, train_wall=5, gb_free=12.1, wall=109
2025-04-17 09:58:41 | INFO | train_inner | epoch 001:     42 / 139 loss=11.054, nll_loss=8.767, ppl=435.52, wps=2216.6, ups=0.39, wpb=5639, bsz=260, num_updates=42, lr=5.04e-07, gnorm=8.414, train_wall=5, gb_free=12, wall=114
2025-04-17 09:58:47 | INFO | train_inner | epoch 001:     44 / 139 loss=11.215, nll_loss=8.975, ppl=503.38, wps=2514.3, ups=0.37, wpb=6794.5, bsz=296, num_updates=44, lr=5.28e-07, gnorm=9.225, train_wall=5, gb_free=10.8, wall=119
2025-04-17 09:58:52 | INFO | train_inner | epoch 001:     46 / 139 loss=11.155, nll_loss=8.9, ppl=477.87, wps=2420.1, ups=0.38, wpb=6351, bsz=272, num_updates=46, lr=5.52e-07, gnorm=8.943, train_wall=5, gb_free=10.4, wall=125
2025-04-17 09:58:57 | INFO | train_inner | epoch 001:     48 / 139 loss=11.064, nll_loss=8.787, ppl=441.62, wps=2052.2, ups=0.4, wpb=5131, bsz=204, num_updates=48, lr=5.76e-07, gnorm=8.181, train_wall=5, gb_free=12.2, wall=130
2025-04-17 09:59:02 | INFO | train_inner | epoch 001:     50 / 139 loss=11.022, nll_loss=8.734, ppl=425.77, wps=2124.5, ups=0.38, wpb=5571, bsz=180, num_updates=50, lr=6e-07, gnorm=6.928, train_wall=5, gb_free=11.4, wall=135
2025-04-17 09:59:08 | INFO | train_inner | epoch 001:     52 / 139 loss=10.889, nll_loss=8.57, ppl=380.12, wps=2564.9, ups=0.38, wpb=6804.5, bsz=268, num_updates=52, lr=6.24e-07, gnorm=7.419, train_wall=5, gb_free=10, wall=140
2025-04-17 09:59:13 | INFO | train_inner | epoch 001:     54 / 139 loss=10.84, nll_loss=8.514, ppl=365.66, wps=2266.1, ups=0.37, wpb=6045.5, bsz=300, num_updates=54, lr=6.48e-07, gnorm=7.169, train_wall=5, gb_free=10.3, wall=145
2025-04-17 09:59:18 | INFO | train_inner | epoch 001:     56 / 139 loss=10.627, nll_loss=8.249, ppl=304.18, wps=2269.5, ups=0.38, wpb=5983, bsz=180, num_updates=56, lr=6.72e-07, gnorm=5.704, train_wall=5, gb_free=9.5, wall=151
2025-04-17 09:59:23 | INFO | train_inner | epoch 001:     58 / 139 loss=10.712, nll_loss=8.356, ppl=327.56, wps=2273.3, ups=0.38, wpb=5933.5, bsz=240, num_updates=58, lr=6.96e-07, gnorm=6.312, train_wall=5, gb_free=13.5, wall=156
2025-04-17 09:59:29 | INFO | train_inner | epoch 001:     60 / 139 loss=10.69, nll_loss=8.326, ppl=320.87, wps=2279.7, ups=0.38, wpb=6044.5, bsz=248, num_updates=60, lr=7.2e-07, gnorm=5.792, train_wall=5, gb_free=11.4, wall=161
2025-04-17 09:59:34 | INFO | train_inner | epoch 001:     62 / 139 loss=10.728, nll_loss=8.381, ppl=333.4, wps=2471.4, ups=0.37, wpb=6655, bsz=232, num_updates=62, lr=7.44e-07, gnorm=5.35, train_wall=5, gb_free=10.1, wall=167
2025-04-17 09:59:39 | INFO | train_inner | epoch 001:     64 / 139 loss=10.67, nll_loss=8.306, ppl=316.55, wps=2269.9, ups=0.38, wpb=6016, bsz=280, num_updates=64, lr=7.68e-07, gnorm=5.92, train_wall=5, gb_free=11, wall=172
2025-04-17 09:59:45 | INFO | train_inner | epoch 001:     66 / 139 loss=10.521, nll_loss=8.124, ppl=278.99, wps=2303.8, ups=0.37, wpb=6238, bsz=224, num_updates=66, lr=7.92e-07, gnorm=4.838, train_wall=5, gb_free=12.1, wall=177
2025-04-17 09:59:50 | INFO | train_inner | epoch 001:     68 / 139 loss=10.463, nll_loss=8.06, ppl=266.93, wps=2339.7, ups=0.37, wpb=6300.5, bsz=240, num_updates=68, lr=8.16e-07, gnorm=4.878, train_wall=5, gb_free=12.3, wall=183
2025-04-17 09:59:56 | INFO | train_inner | epoch 001:     70 / 139 loss=10.224, nll_loss=7.742, ppl=214.09, wps=2214, ups=0.36, wpb=6099, bsz=336, num_updates=70, lr=8.4e-07, gnorm=5.075, train_wall=6, gb_free=12.8, wall=188
2025-04-17 10:00:01 | INFO | train_inner | epoch 001:     72 / 139 loss=10.259, nll_loss=7.798, ppl=222.56, wps=2249.9, ups=0.36, wpb=6325, bsz=280, num_updates=72, lr=8.64e-07, gnorm=4.406, train_wall=6, gb_free=10.2, wall=194
2025-04-17 10:00:06 | INFO | train_inner | epoch 001:     74 / 139 loss=10.564, nll_loss=8.194, ppl=292.78, wps=2446.5, ups=0.41, wpb=6014, bsz=192, num_updates=74, lr=8.88e-07, gnorm=4.611, train_wall=5, gb_free=12.2, wall=199
2025-04-17 10:00:12 | INFO | train_inner | epoch 001:     76 / 139 loss=10.239, nll_loss=7.777, ppl=219.27, wps=2280.7, ups=0.37, wpb=6136, bsz=248, num_updates=76, lr=9.12e-07, gnorm=4.246, train_wall=5, gb_free=12.5, wall=204
2025-04-17 10:00:17 | INFO | train_inner | epoch 001:     78 / 139 loss=10.233, nll_loss=7.772, ppl=218.6, wps=2406.2, ups=0.37, wpb=6487.5, bsz=284, num_updates=78, lr=9.36e-07, gnorm=4.013, train_wall=5, gb_free=11.1, wall=209
2025-04-17 10:00:22 | INFO | train_inner | epoch 001:     80 / 139 loss=10.278, nll_loss=7.831, ppl=227.63, wps=2059.1, ups=0.4, wpb=5141.5, bsz=164, num_updates=80, lr=9.6e-07, gnorm=3.847, train_wall=5, gb_free=10, wall=214
2025-04-17 10:00:27 | INFO | train_inner | epoch 001:     82 / 139 loss=10.219, nll_loss=7.753, ppl=215.73, wps=2233, ups=0.39, wpb=5703.5, bsz=272, num_updates=82, lr=9.84e-07, gnorm=4.228, train_wall=5, gb_free=13.5, wall=220
2025-04-17 10:00:32 | INFO | train_inner | epoch 001:     84 / 139 loss=10.372, nll_loss=7.961, ppl=249.19, wps=2320.3, ups=0.39, wpb=5939.5, bsz=148, num_updates=84, lr=1.008e-06, gnorm=3.787, train_wall=5, gb_free=12.6, wall=225
2025-04-17 10:00:37 | INFO | train_inner | epoch 001:     86 / 139 loss=10.287, nll_loss=7.845, ppl=229.9, wps=2148.2, ups=0.42, wpb=5121.5, bsz=160, num_updates=86, lr=1.032e-06, gnorm=3.633, train_wall=5, gb_free=13.7, wall=229
2025-04-17 10:00:42 | INFO | train_inner | epoch 001:     88 / 139 loss=10.315, nll_loss=7.896, ppl=238.26, wps=2375, ups=0.43, wpb=5583.5, bsz=204, num_updates=88, lr=1.056e-06, gnorm=3.642, train_wall=5, gb_free=12.3, wall=234
2025-04-17 10:00:47 | INFO | train_inner | epoch 001:     90 / 139 loss=10.16, nll_loss=7.695, ppl=207.24, wps=2521.1, ups=0.36, wpb=7011, bsz=332, num_updates=90, lr=1.08e-06, gnorm=3.708, train_wall=6, gb_free=10.9, wall=240
2025-04-17 10:00:53 | INFO | train_inner | epoch 001:     92 / 139 loss=10.013, nll_loss=7.506, ppl=181.73, wps=2392.9, ups=0.35, wpb=6874.5, bsz=284, num_updates=92, lr=1.104e-06, gnorm=3.295, train_wall=6, gb_free=10.7, wall=245
2025-04-17 10:00:59 | INFO | train_inner | epoch 001:     94 / 139 loss=10.078, nll_loss=7.601, ppl=194.09, wps=2185.7, ups=0.36, wpb=6004, bsz=152, num_updates=94, lr=1.128e-06, gnorm=3.193, train_wall=5, gb_free=10.8, wall=251
2025-04-17 10:01:04 | INFO | train_inner | epoch 001:     96 / 139 loss=9.854, nll_loss=7.294, ppl=156.9, wps=2193.3, ups=0.37, wpb=6002, bsz=300, num_updates=96, lr=1.152e-06, gnorm=3.732, train_wall=5, gb_free=13.4, wall=256
2025-04-17 10:01:09 | INFO | train_inner | epoch 001:     98 / 139 loss=10.016, nll_loss=7.523, ppl=183.98, wps=2258.7, ups=0.43, wpb=5264.5, bsz=192, num_updates=98, lr=1.176e-06, gnorm=3.115, train_wall=5, gb_free=11.5, wall=261
2025-04-17 10:01:14 | INFO | train_inner | epoch 001:    100 / 139 loss=9.993, nll_loss=7.497, ppl=180.7, wps=2544.1, ups=0.38, wpb=6754.5, bsz=252, num_updates=100, lr=1.2e-06, gnorm=3.284, train_wall=5, gb_free=12.1, wall=266
2025-04-17 10:01:19 | INFO | train_inner | epoch 001:    102 / 139 loss=9.904, nll_loss=7.377, ppl=166.18, wps=2326, ups=0.37, wpb=6328, bsz=240, num_updates=102, lr=1.224e-06, gnorm=2.793, train_wall=5, gb_free=11.1, wall=272
2025-04-17 10:01:25 | INFO | train_inner | epoch 001:    104 / 139 loss=9.946, nll_loss=7.436, ppl=173.19, wps=2279.5, ups=0.38, wpb=6039.5, bsz=244, num_updates=104, lr=1.248e-06, gnorm=2.767, train_wall=5, gb_free=10.1, wall=277
2025-04-17 10:01:30 | INFO | train_inner | epoch 001:    106 / 139 loss=9.912, nll_loss=7.395, ppl=168.33, wps=2388.6, ups=0.37, wpb=6534, bsz=240, num_updates=106, lr=1.272e-06, gnorm=2.791, train_wall=5, gb_free=10.4, wall=283
2025-04-17 10:01:36 | INFO | train_inner | epoch 001:    108 / 139 loss=9.692, nll_loss=7.112, ppl=138.32, wps=2249.5, ups=0.35, wpb=6460, bsz=276, num_updates=108, lr=1.296e-06, gnorm=2.763, train_wall=6, gb_free=10.7, wall=288
2025-04-17 10:01:41 | INFO | train_inner | epoch 001:    110 / 139 loss=10.025, nll_loss=7.546, ppl=186.89, wps=2409, ups=0.38, wpb=6307.5, bsz=204, num_updates=110, lr=1.32e-06, gnorm=2.678, train_wall=5, gb_free=11.7, wall=294
2025-04-17 10:01:47 | INFO | train_inner | epoch 001:    112 / 139 loss=9.856, nll_loss=7.325, ppl=160.29, wps=2322.5, ups=0.37, wpb=6254, bsz=252, num_updates=112, lr=1.344e-06, gnorm=2.646, train_wall=5, gb_free=10.7, wall=299
2025-04-17 10:01:52 | INFO | train_inner | epoch 001:    114 / 139 loss=9.972, nll_loss=7.476, ppl=178, wps=2477.1, ups=0.39, wpb=6321.5, bsz=204, num_updates=114, lr=1.368e-06, gnorm=2.907, train_wall=5, gb_free=12, wall=304
2025-04-17 10:01:57 | INFO | train_inner | epoch 001:    116 / 139 loss=9.731, nll_loss=7.172, ppl=144.24, wps=2282.6, ups=0.39, wpb=5905, bsz=224, num_updates=116, lr=1.392e-06, gnorm=2.752, train_wall=5, gb_free=13.9, wall=309
2025-04-17 10:02:02 | INFO | train_inner | epoch 001:    118 / 139 loss=9.591, nll_loss=6.997, ppl=127.75, wps=2220, ups=0.36, wpb=6129.5, bsz=248, num_updates=118, lr=1.416e-06, gnorm=2.409, train_wall=6, gb_free=10.8, wall=315
2025-04-17 10:02:08 | INFO | train_inner | epoch 001:    120 / 139 loss=9.722, nll_loss=7.176, ppl=144.6, wps=2210, ups=0.38, wpb=5835, bsz=168, num_updates=120, lr=1.44e-06, gnorm=2.931, train_wall=5, gb_free=12.3, wall=320
2025-04-17 10:02:13 | INFO | train_inner | epoch 001:    122 / 139 loss=9.602, nll_loss=7.013, ppl=129.17, wps=2363.1, ups=0.37, wpb=6462.5, bsz=248, num_updates=122, lr=1.464e-06, gnorm=2.569, train_wall=5, gb_free=11.4, wall=326
2025-04-17 10:02:18 | INFO | train_inner | epoch 001:    124 / 139 loss=9.697, nll_loss=7.138, ppl=140.89, wps=2084.4, ups=0.44, wpb=4767.5, bsz=184.5, num_updates=124, lr=1.488e-06, gnorm=3.061, train_wall=5, gb_free=9.4, wall=330
2025-04-17 10:02:23 | INFO | train_inner | epoch 001:    126 / 139 loss=9.612, nll_loss=7.039, ppl=131.54, wps=2251.3, ups=0.38, wpb=5858.5, bsz=196, num_updates=126, lr=1.512e-06, gnorm=2.23, train_wall=5, gb_free=13, wall=335
2025-04-17 10:02:28 | INFO | train_inner | epoch 001:    128 / 139 loss=9.653, nll_loss=7.075, ppl=134.8, wps=2388.4, ups=0.39, wpb=6054.5, bsz=320, num_updates=128, lr=1.536e-06, gnorm=2.58, train_wall=5, gb_free=10.6, wall=340
2025-04-17 10:02:33 | INFO | train_inner | epoch 001:    130 / 139 loss=9.641, nll_loss=7.084, ppl=135.65, wps=2179.1, ups=0.38, wpb=5784.5, bsz=168, num_updates=130, lr=1.56e-06, gnorm=2.363, train_wall=5, gb_free=10.4, wall=346
2025-04-17 10:02:39 | INFO | train_inner | epoch 001:    132 / 139 loss=9.427, nll_loss=6.794, ppl=110.95, wps=2353.8, ups=0.35, wpb=6649, bsz=244, num_updates=132, lr=1.584e-06, gnorm=2.161, train_wall=6, gb_free=11.5, wall=351
2025-04-17 10:02:44 | INFO | train_inner | epoch 001:    134 / 139 loss=9.466, nll_loss=6.856, ppl=115.84, wps=2340.8, ups=0.37, wpb=6334, bsz=312, num_updates=134, lr=1.608e-06, gnorm=2.436, train_wall=5, gb_free=10, wall=357
2025-04-17 10:02:50 | INFO | train_inner | epoch 001:    136 / 139 loss=9.545, nll_loss=6.961, ppl=124.55, wps=2380.5, ups=0.38, wpb=6233.5, bsz=276, num_updates=136, lr=1.632e-06, gnorm=2.334, train_wall=5, gb_free=13.9, wall=362
2025-04-17 10:02:54 | INFO | train_inner | epoch 001:    138 / 139 loss=9.566, nll_loss=6.996, ppl=127.64, wps=1930.2, ups=0.41, wpb=4714, bsz=160, num_updates=138, lr=1.656e-06, gnorm=2.274, train_wall=5, gb_free=11.7, wall=367
2025-04-17 10:02:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-17 10:02:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=7640.578125Mb; avail=247499.25390625Mb
2025-04-17 10:02:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000616
2025-04-17 10:02:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=7640.578125Mb; avail=247499.25390625Mb
2025-04-17 10:02:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012734
2025-04-17 10:02:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=7640.578125Mb; avail=247499.25390625Mb
2025-04-17 10:02:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.011236
2025-04-17 10:02:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024945
2025-04-17 10:02:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=7640.578125Mb; avail=247499.25390625Mb
2025-04-17 10:03:11 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.353 | nll_loss 6.641 | ppl 99.8 | wps 5353 | wpb 2350.9 | bsz 94.7 | num_updates 139
2025-04-17 10:03:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 139 updates
2025-04-17 10:03:11 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt
2025-04-17 10:03:45 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt
2025-04-17 10:04:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt (epoch 1 @ 139 updates, score 9.353) (writing took 49.000228296004934 seconds)
2025-04-17 10:04:00 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2025-04-17 10:04:00 | INFO | train | epoch 001 | loss 10.572 | nll_loss 8.195 | ppl 292.95 | wps 1962.2 | ups 0.33 | wpb 6008.3 | bsz 229.1 | num_updates 139 | lr 1.668e-06 | gnorm 6.463 | train_wall 360 | gb_free 16.8 | wall 432
2025-04-17 10:04:00 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:hi-mr': 31849}; raw total size: 31849
2025-04-17 10:04:00 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:hi-mr': 31849}; resampled total size: 31849
2025-04-17 10:04:00 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:hi-mr': 1.0}
2025-04-17 10:04:00 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001207
2025-04-17 10:04:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=10573.765625Mb; avail=244508.375Mb
2025-04-17 10:04:00 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000418
2025-04-17 10:04:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003186
2025-04-17 10:04:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=10573.765625Mb; avail=244508.375Mb
2025-04-17 10:04:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000106
2025-04-17 10:04:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=10573.765625Mb; avail=244508.375Mb
2025-04-17 10:04:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001202
2025-04-17 10:04:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.004809
2025-04-17 10:04:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=10573.765625Mb; avail=244508.375Mb
2025-04-17 10:04:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 139
2025-04-17 10:04:00 | INFO | fairseq.trainer | begin training epoch 2
2025-04-17 10:04:00 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-17 10:04:03 | INFO | train_inner | epoch 002:      1 / 139 loss=9.626, nll_loss=7.057, ppl=133.2, wps=152, ups=0.03, wpb=5196.5, bsz=248, num_updates=140, lr=1.68e-06, gnorm=2.822, train_wall=4, gb_free=11, wall=435
2025-04-17 10:04:08 | INFO | train_inner | epoch 002:      3 / 139 loss=9.473, nll_loss=6.875, ppl=117.34, wps=2495.8, ups=0.39, wpb=6441, bsz=220, num_updates=142, lr=1.704e-06, gnorm=2.171, train_wall=5, gb_free=13.2, wall=440
2025-04-17 10:04:13 | INFO | train_inner | epoch 002:      5 / 139 loss=9.417, nll_loss=6.81, ppl=112.21, wps=2516.6, ups=0.39, wpb=6513, bsz=276, num_updates=144, lr=1.728e-06, gnorm=2.064, train_wall=5, gb_free=10.8, wall=446
2025-04-17 10:04:18 | INFO | train_inner | epoch 002:      7 / 139 loss=9.453, nll_loss=6.864, ppl=116.48, wps=2332, ups=0.41, wpb=5745, bsz=184, num_updates=146, lr=1.752e-06, gnorm=2.555, train_wall=5, gb_free=11, wall=451
2025-04-17 10:04:23 | INFO | train_inner | epoch 002:      9 / 139 loss=9.421, nll_loss=6.818, ppl=112.85, wps=2183.5, ups=0.38, wpb=5736.5, bsz=284, num_updates=148, lr=1.776e-06, gnorm=2.232, train_wall=5, gb_free=10.7, wall=456
2025-04-17 10:04:29 | INFO | train_inner | epoch 002:     11 / 139 loss=9.317, nll_loss=6.696, ppl=103.65, wps=2218.2, ups=0.38, wpb=5825, bsz=168, num_updates=150, lr=1.8e-06, gnorm=2.083, train_wall=5, gb_free=13.8, wall=461
2025-04-17 10:04:33 | INFO | train_inner | epoch 002:     13 / 139 loss=9.528, nll_loss=6.96, ppl=124.47, wps=2415.4, ups=0.42, wpb=5785, bsz=168, num_updates=152, lr=1.824e-06, gnorm=2.129, train_wall=5, gb_free=11.9, wall=466
2025-04-17 10:04:39 | INFO | train_inner | epoch 002:     15 / 139 loss=9.416, nll_loss=6.812, ppl=112.35, wps=2586.6, ups=0.38, wpb=6890, bsz=284, num_updates=154, lr=1.848e-06, gnorm=2.105, train_wall=5, gb_free=10.8, wall=471
2025-04-17 10:04:43 | INFO | train_inner | epoch 002:     17 / 139 loss=9.442, nll_loss=6.858, ppl=115.96, wps=2204.4, ups=0.42, wpb=5282.5, bsz=152, num_updates=156, lr=1.872e-06, gnorm=2.196, train_wall=5, gb_free=13.2, wall=476
2025-04-17 10:04:49 | INFO | train_inner | epoch 002:     19 / 139 loss=9.415, nll_loss=6.813, ppl=112.43, wps=2580.2, ups=0.38, wpb=6730.5, bsz=276, num_updates=158, lr=1.896e-06, gnorm=2.035, train_wall=5, gb_free=12.7, wall=481
2025-04-17 10:04:54 | INFO | train_inner | epoch 002:     21 / 139 loss=9.452, nll_loss=6.868, ppl=116.84, wps=2395.6, ups=0.37, wpb=6412, bsz=256, num_updates=160, lr=1.92e-06, gnorm=1.916, train_wall=5, gb_free=11.3, wall=487
2025-04-17 10:04:59 | INFO | train_inner | epoch 002:     23 / 139 loss=9.339, nll_loss=6.721, ppl=105.46, wps=2310.8, ups=0.39, wpb=5905.5, bsz=176, num_updates=162, lr=1.944e-06, gnorm=2.339, train_wall=5, gb_free=13, wall=492
2025-04-17 10:05:05 | INFO | train_inner | epoch 002:     25 / 139 loss=9.21, nll_loss=6.559, ppl=94.26, wps=2529, ups=0.37, wpb=6829.5, bsz=280, num_updates=164, lr=1.968e-06, gnorm=2.319, train_wall=5, gb_free=11.8, wall=497
2025-04-17 10:05:10 | INFO | train_inner | epoch 002:     27 / 139 loss=9.283, nll_loss=6.647, ppl=100.24, wps=2535.1, ups=0.36, wpb=6951, bsz=320, num_updates=166, lr=1.992e-06, gnorm=1.931, train_wall=5, gb_free=10.4, wall=503
2025-04-17 10:05:15 | INFO | train_inner | epoch 002:     29 / 139 loss=9.159, nll_loss=6.494, ppl=90.16, wps=2285.3, ups=0.37, wpb=6198.5, bsz=280, num_updates=168, lr=2.016e-06, gnorm=2.488, train_wall=5, gb_free=10, wall=508
2025-04-17 10:05:21 | INFO | train_inner | epoch 002:     31 / 139 loss=9.147, nll_loss=6.478, ppl=89.12, wps=2177.7, ups=0.38, wpb=5795.5, bsz=320, num_updates=170, lr=2.04e-06, gnorm=2.046, train_wall=5, gb_free=13.5, wall=513
2025-04-17 10:05:26 | INFO | train_inner | epoch 002:     33 / 139 loss=9.13, nll_loss=6.468, ppl=88.5, wps=2386.6, ups=0.37, wpb=6527.5, bsz=272, num_updates=172, lr=2.064e-06, gnorm=1.779, train_wall=5, gb_free=10.9, wall=519
2025-04-17 10:05:32 | INFO | train_inner | epoch 002:     35 / 139 loss=9.29, nll_loss=6.677, ppl=102.3, wps=2415.4, ups=0.37, wpb=6453, bsz=248, num_updates=174, lr=2.088e-06, gnorm=2.031, train_wall=5, gb_free=11, wall=524
2025-04-17 10:05:37 | INFO | train_inner | epoch 002:     37 / 139 loss=9.295, nll_loss=6.664, ppl=101.44, wps=2424.3, ups=0.38, wpb=6366, bsz=228, num_updates=176, lr=2.112e-06, gnorm=2.261, train_wall=5, gb_free=11.6, wall=529
2025-04-17 10:05:42 | INFO | train_inner | epoch 002:     39 / 139 loss=9.327, nll_loss=6.715, ppl=105.03, wps=2613.3, ups=0.4, wpb=6477.5, bsz=264, num_updates=178, lr=2.136e-06, gnorm=2.391, train_wall=5, gb_free=12.3, wall=534
2025-04-17 10:05:47 | INFO | train_inner | epoch 002:     41 / 139 loss=9.272, nll_loss=6.648, ppl=100.27, wps=1918.9, ups=0.41, wpb=4714.5, bsz=124, num_updates=180, lr=2.16e-06, gnorm=2.387, train_wall=5, gb_free=13.6, wall=539
2025-04-17 10:05:52 | INFO | train_inner | epoch 002:     43 / 139 loss=9.138, nll_loss=6.485, ppl=89.57, wps=2054.3, ups=0.4, wpb=5123.5, bsz=184, num_updates=182, lr=2.184e-06, gnorm=2.172, train_wall=5, gb_free=11.7, wall=544
2025-04-17 10:06:02 | INFO | train_inner | epoch 002:     45 / 139 loss=9.293, nll_loss=6.662, ppl=101.28, wps=1156.7, ups=0.2, wpb=5888, bsz=228, num_updates=184, lr=2.208e-06, gnorm=2.526, train_wall=10, gb_free=13.3, wall=554
2025-04-17 10:06:07 | INFO | train_inner | epoch 002:     47 / 139 loss=9.175, nll_loss=6.535, ppl=92.75, wps=2423.8, ups=0.36, wpb=6688.5, bsz=296, num_updates=186, lr=2.232e-06, gnorm=1.867, train_wall=6, gb_free=11.3, wall=560
2025-04-17 10:06:13 | INFO | train_inner | epoch 002:     49 / 139 loss=8.967, nll_loss=6.27, ppl=77.19, wps=2421.9, ups=0.36, wpb=6734, bsz=300, num_updates=188, lr=2.256e-06, gnorm=1.758, train_wall=6, gb_free=10.6, wall=565
2025-04-17 10:06:19 | INFO | train_inner | epoch 002:     51 / 139 loss=9.026, nll_loss=6.356, ppl=81.92, wps=2387.6, ups=0.35, wpb=6785, bsz=296, num_updates=190, lr=2.28e-06, gnorm=2.066, train_wall=6, gb_free=10.6, wall=571
2025-04-17 10:06:24 | INFO | train_inner | epoch 002:     53 / 139 loss=8.99, nll_loss=6.293, ppl=78.42, wps=2482.1, ups=0.37, wpb=6655.5, bsz=216, num_updates=192, lr=2.304e-06, gnorm=1.949, train_wall=5, gb_free=12.9, wall=576
2025-04-17 10:06:29 | INFO | train_inner | epoch 002:     55 / 139 loss=9.081, nll_loss=6.418, ppl=85.53, wps=2199.9, ups=0.39, wpb=5657.5, bsz=188, num_updates=194, lr=2.328e-06, gnorm=2.093, train_wall=5, gb_free=11.1, wall=582
2025-04-17 10:06:34 | INFO | train_inner | epoch 002:     57 / 139 loss=9.12, nll_loss=6.467, ppl=88.48, wps=2163.3, ups=0.39, wpb=5580.5, bsz=196, num_updates=196, lr=2.352e-06, gnorm=2.06, train_wall=5, gb_free=13.7, wall=587
2025-04-17 10:06:39 | INFO | train_inner | epoch 002:     59 / 139 loss=9.136, nll_loss=6.485, ppl=89.57, wps=2153.6, ups=0.4, wpb=5439.5, bsz=256, num_updates=198, lr=2.376e-06, gnorm=2.072, train_wall=5, gb_free=10.6, wall=592
2025-04-17 10:06:45 | INFO | train_inner | epoch 002:     61 / 139 loss=8.923, nll_loss=6.208, ppl=73.91, wps=2111.4, ups=0.37, wpb=5696.5, bsz=208, num_updates=200, lr=2.4e-06, gnorm=2.22, train_wall=5, gb_free=9.2, wall=597
2025-04-17 10:06:50 | INFO | train_inner | epoch 002:     63 / 139 loss=9.015, nll_loss=6.326, ppl=80.24, wps=2349.7, ups=0.4, wpb=5859.5, bsz=260, num_updates=202, lr=2.424e-06, gnorm=2.008, train_wall=5, gb_free=15.2, wall=602
2025-04-17 10:06:55 | INFO | train_inner | epoch 002:     65 / 139 loss=8.89, nll_loss=6.155, ppl=71.25, wps=2264.3, ups=0.38, wpb=5979.5, bsz=216, num_updates=204, lr=2.448e-06, gnorm=2.137, train_wall=5, gb_free=13.8, wall=608
2025-04-17 10:07:01 | INFO | train_inner | epoch 002:     67 / 139 loss=8.978, nll_loss=6.285, ppl=77.99, wps=2350.4, ups=0.36, wpb=6478.5, bsz=240, num_updates=206, lr=2.472e-06, gnorm=1.646, train_wall=6, gb_free=11.2, wall=613
2025-04-17 10:07:06 | INFO | train_inner | epoch 002:     69 / 139 loss=9.101, nll_loss=6.441, ppl=86.91, wps=2182.6, ups=0.4, wpb=5476, bsz=136, num_updates=208, lr=2.496e-06, gnorm=1.955, train_wall=5, gb_free=13.9, wall=618
2025-04-17 10:07:11 | INFO | train_inner | epoch 002:     71 / 139 loss=8.804, nll_loss=6.069, ppl=67.14, wps=2409.7, ups=0.36, wpb=6728.5, bsz=276, num_updates=210, lr=2.52e-06, gnorm=1.654, train_wall=6, gb_free=12, wall=624
2025-04-17 10:07:16 | INFO | train_inner | epoch 002:     73 / 139 loss=9.114, nll_loss=6.464, ppl=88.27, wps=2028, ups=0.39, wpb=5188, bsz=204, num_updates=212, lr=2.544e-06, gnorm=2.046, train_wall=5, gb_free=12, wall=629
2025-04-17 10:07:21 | INFO | train_inner | epoch 002:     75 / 139 loss=8.969, nll_loss=6.267, ppl=76.99, wps=2368.4, ups=0.38, wpb=6188, bsz=204, num_updates=214, lr=2.568e-06, gnorm=1.867, train_wall=5, gb_free=12.5, wall=634
2025-04-17 10:07:26 | INFO | train_inner | epoch 002:     77 / 139 loss=9.097, nll_loss=6.438, ppl=86.73, wps=2317.7, ups=0.4, wpb=5737.5, bsz=180, num_updates=216, lr=2.592e-06, gnorm=2.034, train_wall=5, gb_free=12.4, wall=639
2025-04-17 10:07:32 | INFO | train_inner | epoch 002:     79 / 139 loss=8.836, nll_loss=6.095, ppl=68.37, wps=2216.9, ups=0.37, wpb=5969, bsz=264, num_updates=218, lr=2.616e-06, gnorm=2.064, train_wall=5, gb_free=14.3, wall=644
2025-04-17 10:07:37 | INFO | train_inner | epoch 002:     81 / 139 loss=8.931, nll_loss=6.225, ppl=74.79, wps=2242.9, ups=0.41, wpb=5531.5, bsz=188, num_updates=220, lr=2.64e-06, gnorm=2.055, train_wall=5, gb_free=14.7, wall=649
2025-04-17 10:07:42 | INFO | train_inner | epoch 002:     83 / 139 loss=8.856, nll_loss=6.132, ppl=70.12, wps=2396.6, ups=0.39, wpb=6131.5, bsz=208, num_updates=222, lr=2.664e-06, gnorm=1.979, train_wall=5, gb_free=11.1, wall=654
2025-04-17 10:07:47 | INFO | train_inner | epoch 002:     85 / 139 loss=8.874, nll_loss=6.136, ppl=70.34, wps=2446.4, ups=0.37, wpb=6668.5, bsz=276, num_updates=224, lr=2.688e-06, gnorm=1.757, train_wall=5, gb_free=10.9, wall=660
2025-04-17 10:07:51 | INFO | train_inner | epoch 002:     87 / 139 loss=9.155, nll_loss=6.509, ppl=91.05, wps=1679.1, ups=0.51, wpb=3297.5, bsz=80.5, num_updates=226, lr=2.712e-06, gnorm=2.706, train_wall=4, gb_free=13.3, wall=664
2025-04-17 10:07:57 | INFO | train_inner | epoch 002:     89 / 139 loss=8.849, nll_loss=6.119, ppl=69.51, wps=2433.6, ups=0.36, wpb=6673.5, bsz=276, num_updates=228, lr=2.736e-06, gnorm=2.111, train_wall=5, gb_free=12.1, wall=669
2025-04-17 10:08:02 | INFO | train_inner | epoch 002:     91 / 139 loss=8.93, nll_loss=6.222, ppl=74.63, wps=2418.6, ups=0.37, wpb=6556, bsz=268, num_updates=230, lr=2.76e-06, gnorm=2.014, train_wall=5, gb_free=12.2, wall=675
2025-04-17 10:08:07 | INFO | train_inner | epoch 002:     93 / 139 loss=8.771, nll_loss=6.029, ppl=65.28, wps=2445.1, ups=0.39, wpb=6323, bsz=316, num_updates=232, lr=2.784e-06, gnorm=2.106, train_wall=5, gb_free=13.1, wall=680
2025-04-17 10:08:12 | INFO | train_inner | epoch 002:     95 / 139 loss=8.844, nll_loss=6.119, ppl=69.5, wps=1755.2, ups=0.39, wpb=4450.5, bsz=192, num_updates=234, lr=2.808e-06, gnorm=2.819, train_wall=5, gb_free=11.9, wall=685
2025-04-17 10:08:18 | INFO | train_inner | epoch 002:     97 / 139 loss=8.785, nll_loss=6.045, ppl=66.03, wps=2102.9, ups=0.37, wpb=5666, bsz=180, num_updates=236, lr=2.832e-06, gnorm=1.815, train_wall=5, gb_free=12, wall=690
2025-04-17 10:08:23 | INFO | train_inner | epoch 002:     99 / 139 loss=8.879, nll_loss=6.173, ppl=72.15, wps=2249.1, ups=0.41, wpb=5521.5, bsz=232, num_updates=238, lr=2.856e-06, gnorm=2.032, train_wall=5, gb_free=11.7, wall=695
2025-04-17 10:08:28 | INFO | train_inner | epoch 002:    101 / 139 loss=8.821, nll_loss=6.095, ppl=68.34, wps=2162.2, ups=0.36, wpb=5934, bsz=228, num_updates=240, lr=2.88e-06, gnorm=1.837, train_wall=5, gb_free=9.9, wall=701
2025-04-17 10:08:34 | INFO | train_inner | epoch 002:    103 / 139 loss=8.628, nll_loss=5.845, ppl=57.46, wps=2353.3, ups=0.35, wpb=6817, bsz=332, num_updates=242, lr=2.904e-06, gnorm=1.726, train_wall=6, gb_free=11.4, wall=706
2025-04-17 10:08:39 | INFO | train_inner | epoch 002:    105 / 139 loss=8.882, nll_loss=6.179, ppl=72.47, wps=2275.2, ups=0.4, wpb=5735.5, bsz=208, num_updates=244, lr=2.928e-06, gnorm=2.341, train_wall=5, gb_free=11.6, wall=712
2025-04-17 10:08:44 | INFO | train_inner | epoch 002:    107 / 139 loss=8.981, nll_loss=6.286, ppl=78.03, wps=1804.2, ups=0.41, wpb=4365.5, bsz=132, num_updates=246, lr=2.952e-06, gnorm=2.241, train_wall=5, gb_free=14.4, wall=716
2025-04-17 10:08:49 | INFO | train_inner | epoch 002:    109 / 139 loss=8.794, nll_loss=6.058, ppl=66.63, wps=2369.4, ups=0.38, wpb=6297, bsz=192, num_updates=248, lr=2.976e-06, gnorm=1.704, train_wall=5, gb_free=10.4, wall=722
2025-04-17 10:08:54 | INFO | train_inner | epoch 002:    111 / 139 loss=8.751, nll_loss=5.997, ppl=63.86, wps=2498.6, ups=0.39, wpb=6377, bsz=204, num_updates=250, lr=3e-06, gnorm=2.144, train_wall=5, gb_free=12.9, wall=727
2025-04-17 10:08:59 | INFO | train_inner | epoch 002:    113 / 139 loss=8.766, nll_loss=6.026, ppl=65.19, wps=2240.7, ups=0.39, wpb=5771, bsz=196, num_updates=252, lr=3.024e-06, gnorm=1.794, train_wall=5, gb_free=11.7, wall=732
2025-04-17 10:09:05 | INFO | train_inner | epoch 002:    115 / 139 loss=8.615, nll_loss=5.82, ppl=56.47, wps=2394, ups=0.35, wpb=6843.5, bsz=328, num_updates=254, lr=3.048e-06, gnorm=1.939, train_wall=6, gb_free=12.2, wall=738
2025-04-17 10:09:10 | INFO | train_inner | epoch 002:    117 / 139 loss=8.851, nll_loss=6.106, ppl=68.88, wps=2282, ups=0.4, wpb=5654.5, bsz=144, num_updates=256, lr=3.072e-06, gnorm=1.806, train_wall=5, gb_free=12, wall=743
2025-04-17 10:09:15 | INFO | train_inner | epoch 002:    119 / 139 loss=8.811, nll_loss=6.071, ppl=67.22, wps=2438, ups=0.39, wpb=6201.5, bsz=164, num_updates=258, lr=3.096e-06, gnorm=1.846, train_wall=5, gb_free=13.3, wall=748
2025-04-17 10:09:20 | INFO | train_inner | epoch 002:    121 / 139 loss=8.796, nll_loss=6.056, ppl=66.53, wps=2335.7, ups=0.4, wpb=5912.5, bsz=168, num_updates=260, lr=3.12e-06, gnorm=1.762, train_wall=5, gb_free=12.5, wall=753
2025-04-17 10:09:26 | INFO | train_inner | epoch 002:    123 / 139 loss=8.568, nll_loss=5.769, ppl=54.53, wps=2336.1, ups=0.35, wpb=6640.5, bsz=268, num_updates=262, lr=3.144e-06, gnorm=1.749, train_wall=6, gb_free=9.7, wall=758
2025-04-17 10:09:31 | INFO | train_inner | epoch 002:    125 / 139 loss=8.612, nll_loss=5.818, ppl=56.41, wps=2317, ups=0.37, wpb=6274, bsz=220, num_updates=264, lr=3.168e-06, gnorm=1.638, train_wall=5, gb_free=11, wall=764
2025-04-17 10:09:36 | INFO | train_inner | epoch 002:    127 / 139 loss=8.731, nll_loss=5.988, ppl=63.48, wps=2107.6, ups=0.41, wpb=5158.5, bsz=208, num_updates=266, lr=3.192e-06, gnorm=1.92, train_wall=5, gb_free=11.1, wall=769
2025-04-17 10:09:42 | INFO | train_inner | epoch 002:    129 / 139 loss=8.58, nll_loss=5.783, ppl=55.08, wps=2402, ups=0.35, wpb=6817.5, bsz=276, num_updates=268, lr=3.216e-06, gnorm=2.014, train_wall=6, gb_free=11.8, wall=774
2025-04-17 10:09:48 | INFO | train_inner | epoch 002:    131 / 139 loss=8.524, nll_loss=5.718, ppl=52.65, wps=2444, ups=0.36, wpb=6815, bsz=292, num_updates=270, lr=3.24e-06, gnorm=2.118, train_wall=6, gb_free=11.9, wall=780
2025-04-17 10:09:53 | INFO | train_inner | epoch 002:    133 / 139 loss=8.64, nll_loss=5.861, ppl=58.12, wps=2454.4, ups=0.38, wpb=6419, bsz=244, num_updates=272, lr=3.264e-06, gnorm=1.961, train_wall=5, gb_free=12.3, wall=785
2025-04-17 10:09:58 | INFO | train_inner | epoch 002:    135 / 139 loss=8.611, nll_loss=5.83, ppl=56.88, wps=2068, ups=0.42, wpb=4967, bsz=204, num_updates=274, lr=3.288e-06, gnorm=2.134, train_wall=5, gb_free=11.3, wall=790
2025-04-17 10:10:03 | INFO | train_inner | epoch 002:    137 / 139 loss=8.511, nll_loss=5.695, ppl=51.79, wps=2161.8, ups=0.35, wpb=6089.5, bsz=248, num_updates=276, lr=3.312e-06, gnorm=2.013, train_wall=6, gb_free=11.1, wall=796
2025-04-17 10:10:07 | INFO | train_inner | epoch 002:    139 / 139 loss=8.53, nll_loss=5.727, ppl=52.96, wps=2306.1, ups=0.48, wpb=4804, bsz=180, num_updates=278, lr=3.336e-06, gnorm=1.939, train_wall=4, gb_free=15.2, wall=800
2025-04-17 10:10:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-17 10:10:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=7819.3203125Mb; avail=247262.8359375Mb
2025-04-17 10:10:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000635
2025-04-17 10:10:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=7819.3203125Mb; avail=247262.8359375Mb
2025-04-17 10:10:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012767
2025-04-17 10:10:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=7819.3203125Mb; avail=247262.8359375Mb
2025-04-17 10:10:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.011016
2025-04-17 10:10:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024793
2025-04-17 10:10:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=7819.3203125Mb; avail=247262.8359375Mb
2025-04-17 10:10:23 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 8.433 | nll_loss 5.459 | ppl 43.98 | wps 5359.6 | wpb 2350.9 | bsz 94.7 | num_updates 278 | best_loss 8.433
2025-04-17 10:10:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 278 updates
2025-04-17 10:10:23 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt
2025-04-17 10:11:00 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt
2025-04-17 10:11:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt (epoch 2 @ 278 updates, score 8.433) (writing took 61.255616662005195 seconds)
2025-04-17 10:11:24 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2025-04-17 10:11:24 | INFO | train | epoch 002 | loss 9.008 | nll_loss 6.317 | ppl 79.71 | wps 1881.8 | ups 0.31 | wpb 6008.3 | bsz 229.1 | num_updates 278 | lr 3.336e-06 | gnorm 2.054 | train_wall 367 | gb_free 15.2 | wall 876
2025-04-17 10:11:24 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:hi-mr': 31849}; raw total size: 31849
2025-04-17 10:11:24 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:hi-mr': 31849}; resampled total size: 31849
2025-04-17 10:11:24 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:hi-mr': 1.0}
2025-04-17 10:11:24 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001034
2025-04-17 10:11:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13121.8046875Mb; avail=241960.26953125Mb
2025-04-17 10:11:24 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000545
2025-04-17 10:11:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003701
2025-04-17 10:11:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13121.8046875Mb; avail=241960.26953125Mb
2025-04-17 10:11:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000106
2025-04-17 10:11:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13121.8046875Mb; avail=241960.26953125Mb
2025-04-17 10:11:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001163
2025-04-17 10:11:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.005310
2025-04-17 10:11:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13121.8046875Mb; avail=241960.26953125Mb
2025-04-17 10:11:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 139
2025-04-17 10:11:24 | INFO | fairseq.trainer | begin training epoch 3
2025-04-17 10:11:24 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-17 10:11:29 | INFO | train_inner | epoch 003:      2 / 139 loss=8.57, nll_loss=5.776, ppl=54.8, wps=139.8, ups=0.02, wpb=5704.5, bsz=244, num_updates=280, lr=3.36e-06, gnorm=1.853, train_wall=5, gb_free=12.4, wall=881
2025-04-17 10:11:34 | INFO | train_inner | epoch 003:      4 / 139 loss=8.633, nll_loss=5.855, ppl=57.9, wps=2452.7, ups=0.39, wpb=6285.5, bsz=212, num_updates=282, lr=3.384e-06, gnorm=1.737, train_wall=5, gb_free=10.4, wall=887
2025-04-17 10:11:40 | INFO | train_inner | epoch 003:      6 / 139 loss=8.411, nll_loss=5.566, ppl=47.39, wps=2202.8, ups=0.36, wpb=6066, bsz=280, num_updates=284, lr=3.408e-06, gnorm=1.958, train_wall=5, gb_free=11.6, wall=892
2025-04-17 10:11:45 | INFO | train_inner | epoch 003:      8 / 139 loss=8.632, nll_loss=5.854, ppl=57.82, wps=2474.8, ups=0.39, wpb=6298.5, bsz=212, num_updates=286, lr=3.432e-06, gnorm=2.437, train_wall=5, gb_free=12.3, wall=897
2025-04-17 10:11:50 | INFO | train_inner | epoch 003:     10 / 139 loss=8.519, nll_loss=5.713, ppl=52.44, wps=2319.7, ups=0.39, wpb=5951.5, bsz=300, num_updates=288, lr=3.456e-06, gnorm=1.76, train_wall=5, gb_free=12.2, wall=902
2025-04-17 10:11:55 | INFO | train_inner | epoch 003:     12 / 139 loss=8.476, nll_loss=5.654, ppl=50.35, wps=2234.4, ups=0.38, wpb=5836.5, bsz=184, num_updates=290, lr=3.48e-06, gnorm=1.921, train_wall=5, gb_free=11.9, wall=908
2025-04-17 10:12:00 | INFO | train_inner | epoch 003:     14 / 139 loss=8.612, nll_loss=5.825, ppl=56.67, wps=2395.7, ups=0.39, wpb=6114, bsz=204, num_updates=292, lr=3.504e-06, gnorm=1.887, train_wall=5, gb_free=12.3, wall=913
2025-04-17 10:12:05 | INFO | train_inner | epoch 003:     16 / 139 loss=8.497, nll_loss=5.682, ppl=51.34, wps=2279.1, ups=0.38, wpb=6027, bsz=196, num_updates=294, lr=3.528e-06, gnorm=2.038, train_wall=5, gb_free=11.5, wall=918
2025-04-17 10:12:10 | INFO | train_inner | epoch 003:     18 / 139 loss=8.626, nll_loss=5.836, ppl=57.12, wps=2325.1, ups=0.4, wpb=5773, bsz=176, num_updates=296, lr=3.552e-06, gnorm=2.11, train_wall=5, gb_free=13.9, wall=923
2025-04-17 10:12:16 | INFO | train_inner | epoch 003:     20 / 139 loss=8.401, nll_loss=5.547, ppl=46.76, wps=2190.4, ups=0.38, wpb=5739.5, bsz=168, num_updates=298, lr=3.576e-06, gnorm=1.917, train_wall=5, gb_free=11.5, wall=928
2025-04-17 10:12:21 | INFO | train_inner | epoch 003:     22 / 139 loss=8.499, nll_loss=5.681, ppl=51.32, wps=2307.4, ups=0.38, wpb=6106, bsz=200, num_updates=300, lr=3.6e-06, gnorm=1.818, train_wall=5, gb_free=12.3, wall=933
2025-04-17 10:12:26 | INFO | train_inner | epoch 003:     24 / 139 loss=8.491, nll_loss=5.667, ppl=50.81, wps=2309.8, ups=0.38, wpb=6001, bsz=188, num_updates=302, lr=3.624e-06, gnorm=1.78, train_wall=5, gb_free=12.2, wall=939
2025-04-17 10:12:31 | INFO | train_inner | epoch 003:     26 / 139 loss=8.522, nll_loss=5.707, ppl=52.25, wps=2245, ups=0.38, wpb=5914.5, bsz=184, num_updates=304, lr=3.648e-06, gnorm=2.005, train_wall=5, gb_free=13.7, wall=944
2025-04-17 10:12:36 | INFO | train_inner | epoch 003:     28 / 139 loss=8.499, nll_loss=5.681, ppl=51.31, wps=2324.6, ups=0.46, wpb=5065, bsz=176.5, num_updates=306, lr=3.672e-06, gnorm=1.842, train_wall=4, gb_free=12, wall=948
2025-04-17 10:12:41 | INFO | train_inner | epoch 003:     30 / 139 loss=8.353, nll_loss=5.501, ppl=45.28, wps=2214.5, ups=0.38, wpb=5771.5, bsz=240, num_updates=308, lr=3.696e-06, gnorm=2.141, train_wall=5, gb_free=12.4, wall=953
2025-04-17 10:12:46 | INFO | train_inner | epoch 003:     32 / 139 loss=8.447, nll_loss=5.622, ppl=49.25, wps=2506.9, ups=0.38, wpb=6594, bsz=220, num_updates=310, lr=3.72e-06, gnorm=1.714, train_wall=5, gb_free=12.6, wall=959
2025-04-17 10:12:52 | INFO | train_inner | epoch 003:     34 / 139 loss=8.478, nll_loss=5.658, ppl=50.5, wps=2475.4, ups=0.38, wpb=6565.5, bsz=244, num_updates=312, lr=3.744e-06, gnorm=1.679, train_wall=5, gb_free=11.4, wall=964
2025-04-17 10:12:57 | INFO | train_inner | epoch 003:     36 / 139 loss=8.512, nll_loss=5.704, ppl=52.15, wps=2285.8, ups=0.4, wpb=5767.5, bsz=188, num_updates=314, lr=3.768e-06, gnorm=1.891, train_wall=5, gb_free=13.6, wall=969
2025-04-17 10:13:01 | INFO | train_inner | epoch 003:     38 / 139 loss=8.466, nll_loss=5.655, ppl=50.37, wps=2354.6, ups=0.41, wpb=5710.5, bsz=172, num_updates=316, lr=3.792e-06, gnorm=2.044, train_wall=5, gb_free=10.5, wall=974
2025-04-17 10:13:07 | INFO | train_inner | epoch 003:     40 / 139 loss=8.38, nll_loss=5.534, ppl=46.32, wps=2207.7, ups=0.39, wpb=5683, bsz=272, num_updates=318, lr=3.816e-06, gnorm=2.271, train_wall=5, gb_free=12, wall=979
2025-04-17 10:13:12 | INFO | train_inner | epoch 003:     42 / 139 loss=8.334, nll_loss=5.487, ppl=44.84, wps=2292.1, ups=0.34, wpb=6683, bsz=424, num_updates=320, lr=3.84e-06, gnorm=2.733, train_wall=6, gb_free=10, wall=985
2025-04-17 10:13:18 | INFO | train_inner | epoch 003:     44 / 139 loss=8.456, nll_loss=5.624, ppl=49.31, wps=2359.1, ups=0.39, wpb=6081.5, bsz=232, num_updates=322, lr=3.864e-06, gnorm=2.454, train_wall=5, gb_free=13.9, wall=990
2025-04-17 10:13:23 | INFO | train_inner | epoch 003:     46 / 139 loss=8.252, nll_loss=5.375, ppl=41.51, wps=2254.4, ups=0.39, wpb=5768.5, bsz=188, num_updates=324, lr=3.888e-06, gnorm=2.242, train_wall=5, gb_free=12.9, wall=995
2025-04-17 10:13:28 | INFO | train_inner | epoch 003:     48 / 139 loss=8.472, nll_loss=5.652, ppl=50.3, wps=2011.4, ups=0.39, wpb=5202.5, bsz=212, num_updates=326, lr=3.912e-06, gnorm=2.274, train_wall=5, gb_free=11.2, wall=1000
2025-04-17 10:13:33 | INFO | train_inner | epoch 003:     50 / 139 loss=8.481, nll_loss=5.666, ppl=50.78, wps=2348.5, ups=0.4, wpb=5919.5, bsz=176, num_updates=328, lr=3.936e-06, gnorm=2.012, train_wall=5, gb_free=12.1, wall=1005
2025-04-17 10:13:39 | INFO | train_inner | epoch 003:     52 / 139 loss=8.215, nll_loss=5.33, ppl=40.22, wps=2299.7, ups=0.35, wpb=6486, bsz=264, num_updates=330, lr=3.96e-06, gnorm=1.696, train_wall=6, gb_free=11.6, wall=1011
2025-04-17 10:13:44 | INFO | train_inner | epoch 003:     54 / 139 loss=8.417, nll_loss=5.581, ppl=47.87, wps=2287.6, ups=0.38, wpb=6044.5, bsz=216, num_updates=332, lr=3.984e-06, gnorm=1.84, train_wall=5, gb_free=12.4, wall=1016
2025-04-17 10:13:49 | INFO | train_inner | epoch 003:     56 / 139 loss=8.339, nll_loss=5.483, ppl=44.73, wps=2343.5, ups=0.37, wpb=6370.5, bsz=228, num_updates=334, lr=4.008e-06, gnorm=1.934, train_wall=5, gb_free=11.3, wall=1022
2025-04-17 10:13:55 | INFO | train_inner | epoch 003:     58 / 139 loss=8.264, nll_loss=5.372, ppl=41.41, wps=2315.3, ups=0.37, wpb=6274.5, bsz=284, num_updates=336, lr=4.032e-06, gnorm=2.496, train_wall=5, gb_free=14.2, wall=1027
2025-04-17 10:13:59 | INFO | train_inner | epoch 003:     60 / 139 loss=8.52, nll_loss=5.715, ppl=52.52, wps=2136.1, ups=0.43, wpb=4994, bsz=104, num_updates=338, lr=4.056e-06, gnorm=2.083, train_wall=5, gb_free=15, wall=1032
2025-04-17 10:14:05 | INFO | train_inner | epoch 003:     62 / 139 loss=8.196, nll_loss=5.306, ppl=39.57, wps=2130.8, ups=0.37, wpb=5765.5, bsz=272, num_updates=340, lr=4.08e-06, gnorm=1.684, train_wall=5, gb_free=10.4, wall=1037
2025-04-17 10:14:10 | INFO | train_inner | epoch 003:     64 / 139 loss=8.181, nll_loss=5.288, ppl=39.08, wps=2447.4, ups=0.35, wpb=6940, bsz=340, num_updates=342, lr=4.104e-06, gnorm=1.85, train_wall=6, gb_free=11.2, wall=1043
2025-04-17 10:14:15 | INFO | train_inner | epoch 003:     66 / 139 loss=8.342, nll_loss=5.477, ppl=44.55, wps=2068.3, ups=0.41, wpb=5094, bsz=148, num_updates=344, lr=4.128e-06, gnorm=2.109, train_wall=5, gb_free=11.7, wall=1048
2025-04-17 10:14:25 | INFO | train_inner | epoch 003:     68 / 139 loss=8.262, nll_loss=5.389, ppl=41.89, wps=1213.5, ups=0.2, wpb=6042.5, bsz=236, num_updates=346, lr=4.152e-06, gnorm=3.045, train_wall=10, gb_free=11.6, wall=1058
2025-04-17 10:14:31 | INFO | train_inner | epoch 003:     70 / 139 loss=8.26, nll_loss=5.377, ppl=41.57, wps=2312.4, ups=0.38, wpb=6078.5, bsz=180, num_updates=348, lr=4.176e-06, gnorm=1.822, train_wall=5, gb_free=13, wall=1063
2025-04-17 10:14:36 | INFO | train_inner | epoch 003:     72 / 139 loss=8.226, nll_loss=5.337, ppl=40.43, wps=2292.5, ups=0.37, wpb=6207.5, bsz=228, num_updates=350, lr=4.2e-06, gnorm=2.1, train_wall=5, gb_free=11.1, wall=1068
2025-04-17 10:14:41 | INFO | train_inner | epoch 003:     74 / 139 loss=8.201, nll_loss=5.302, ppl=39.46, wps=2390.4, ups=0.36, wpb=6568.5, bsz=244, num_updates=352, lr=4.224e-06, gnorm=2.212, train_wall=5, gb_free=10.6, wall=1074
2025-04-17 10:14:47 | INFO | train_inner | epoch 003:     76 / 139 loss=8.223, nll_loss=5.334, ppl=40.34, wps=2242.3, ups=0.4, wpb=5652, bsz=268, num_updates=354, lr=4.248e-06, gnorm=1.972, train_wall=5, gb_free=11.7, wall=1079
2025-04-17 10:14:52 | INFO | train_inner | epoch 003:     78 / 139 loss=8.183, nll_loss=5.285, ppl=38.99, wps=2232.5, ups=0.35, wpb=6327, bsz=292, num_updates=356, lr=4.272e-06, gnorm=2.285, train_wall=6, gb_free=14, wall=1085
2025-04-17 10:14:58 | INFO | train_inner | epoch 003:     80 / 139 loss=8.186, nll_loss=5.309, ppl=39.64, wps=2275.7, ups=0.36, wpb=6276.5, bsz=316, num_updates=358, lr=4.296e-06, gnorm=1.746, train_wall=6, gb_free=10.3, wall=1090
2025-04-17 10:15:03 | INFO | train_inner | epoch 003:     82 / 139 loss=8.093, nll_loss=5.182, ppl=36.3, wps=2463.5, ups=0.35, wpb=6991, bsz=308, num_updates=360, lr=4.32e-06, gnorm=1.874, train_wall=6, gb_free=11.5, wall=1096
2025-04-17 10:15:08 | INFO | train_inner | epoch 003:     84 / 139 loss=8.268, nll_loss=5.392, ppl=42, wps=1956, ups=0.4, wpb=4845.5, bsz=168, num_updates=362, lr=4.344e-06, gnorm=2.191, train_wall=5, gb_free=13.8, wall=1101
2025-04-17 10:15:14 | INFO | train_inner | epoch 003:     86 / 139 loss=8.264, nll_loss=5.395, ppl=42.09, wps=2422.9, ups=0.38, wpb=6361, bsz=248, num_updates=364, lr=4.368e-06, gnorm=1.967, train_wall=5, gb_free=12.6, wall=1106
2025-04-17 10:15:19 | INFO | train_inner | epoch 003:     88 / 139 loss=8.144, nll_loss=5.246, ppl=37.94, wps=2444.3, ups=0.39, wpb=6256.5, bsz=272, num_updates=366, lr=4.392e-06, gnorm=1.794, train_wall=5, gb_free=13.2, wall=1111
2025-04-17 10:15:23 | INFO | train_inner | epoch 003:     90 / 139 loss=8.426, nll_loss=5.579, ppl=47.8, wps=1978.3, ups=0.42, wpb=4701, bsz=112, num_updates=368, lr=4.416e-06, gnorm=1.986, train_wall=5, gb_free=14, wall=1116
2025-04-17 10:15:28 | INFO | train_inner | epoch 003:     92 / 139 loss=8.192, nll_loss=5.292, ppl=39.17, wps=2505, ups=0.41, wpb=6175, bsz=232, num_updates=370, lr=4.44e-06, gnorm=1.717, train_wall=5, gb_free=15.5, wall=1121
2025-04-17 10:15:34 | INFO | train_inner | epoch 003:     94 / 139 loss=8.199, nll_loss=5.301, ppl=39.42, wps=2157.9, ups=0.39, wpb=5536.5, bsz=228, num_updates=372, lr=4.464e-06, gnorm=2.77, train_wall=5, gb_free=11, wall=1126
2025-04-17 10:15:39 | INFO | train_inner | epoch 003:     96 / 139 loss=8.195, nll_loss=5.305, ppl=39.54, wps=2388.6, ups=0.38, wpb=6321.5, bsz=252, num_updates=374, lr=4.488e-06, gnorm=2.381, train_wall=5, gb_free=10.4, wall=1131
2025-04-17 10:15:45 | INFO | train_inner | epoch 003:     98 / 139 loss=8.003, nll_loss=5.064, ppl=33.46, wps=2406.8, ups=0.35, wpb=6923.5, bsz=336, num_updates=376, lr=4.512e-06, gnorm=1.826, train_wall=6, gb_free=11.5, wall=1137
2025-04-17 10:15:50 | INFO | train_inner | epoch 003:    100 / 139 loss=8.069, nll_loss=5.145, ppl=35.39, wps=2224.1, ups=0.37, wpb=5944.5, bsz=188, num_updates=378, lr=4.536e-06, gnorm=2, train_wall=5, gb_free=14.7, wall=1142
2025-04-17 10:15:55 | INFO | train_inner | epoch 003:    102 / 139 loss=8.027, nll_loss=5.089, ppl=34.03, wps=2441.8, ups=0.38, wpb=6485.5, bsz=248, num_updates=380, lr=4.56e-06, gnorm=2.52, train_wall=5, gb_free=14.2, wall=1148
2025-04-17 10:16:00 | INFO | train_inner | epoch 003:    104 / 139 loss=8.444, nll_loss=5.621, ppl=49.23, wps=2091.3, ups=0.4, wpb=5222.5, bsz=152, num_updates=382, lr=4.584e-06, gnorm=2.778, train_wall=5, gb_free=12.1, wall=1153
2025-04-17 10:16:06 | INFO | train_inner | epoch 003:    106 / 139 loss=8.127, nll_loss=5.207, ppl=36.94, wps=2299.2, ups=0.35, wpb=6505, bsz=212, num_updates=384, lr=4.608e-06, gnorm=1.635, train_wall=6, gb_free=10.7, wall=1158
2025-04-17 10:16:12 | INFO | train_inner | epoch 003:    108 / 139 loss=8.011, nll_loss=5.056, ppl=33.27, wps=2380, ups=0.35, wpb=6806, bsz=276, num_updates=386, lr=4.632e-06, gnorm=1.813, train_wall=6, gb_free=10, wall=1164
2025-04-17 10:16:17 | INFO | train_inner | epoch 003:    110 / 139 loss=8.058, nll_loss=5.125, ppl=34.89, wps=2433.4, ups=0.37, wpb=6582.5, bsz=288, num_updates=388, lr=4.656e-06, gnorm=1.557, train_wall=5, gb_free=14.4, wall=1169
2025-04-17 10:16:22 | INFO | train_inner | epoch 003:    112 / 139 loss=8.144, nll_loss=5.24, ppl=37.79, wps=2127.8, ups=0.4, wpb=5348, bsz=192, num_updates=390, lr=4.68e-06, gnorm=1.837, train_wall=5, gb_free=12.8, wall=1175
2025-04-17 10:16:28 | INFO | train_inner | epoch 003:    114 / 139 loss=8.095, nll_loss=5.18, ppl=36.24, wps=2179.5, ups=0.36, wpb=6068.5, bsz=224, num_updates=392, lr=4.704e-06, gnorm=2.244, train_wall=6, gb_free=10.9, wall=1180
2025-04-17 10:16:32 | INFO | train_inner | epoch 003:    116 / 139 loss=8.164, nll_loss=5.271, ppl=38.61, wps=2247.6, ups=0.44, wpb=5143, bsz=120, num_updates=394, lr=4.728e-06, gnorm=2.043, train_wall=5, gb_free=12.6, wall=1185
2025-04-17 10:16:37 | INFO | train_inner | epoch 003:    118 / 139 loss=8.209, nll_loss=5.332, ppl=40.29, wps=2354.3, ups=0.43, wpb=5536, bsz=200, num_updates=396, lr=4.752e-06, gnorm=2.379, train_wall=5, gb_free=14.9, wall=1189
2025-04-17 10:16:42 | INFO | train_inner | epoch 003:    120 / 139 loss=8.085, nll_loss=5.171, ppl=36.03, wps=2434, ups=0.37, wpb=6643.5, bsz=244, num_updates=398, lr=4.776e-06, gnorm=1.504, train_wall=5, gb_free=11.9, wall=1195
2025-04-17 10:16:48 | INFO | train_inner | epoch 003:    122 / 139 loss=8.062, nll_loss=5.137, ppl=35.19, wps=2365.2, ups=0.35, wpb=6755, bsz=268, num_updates=400, lr=4.8e-06, gnorm=1.697, train_wall=6, gb_free=10.7, wall=1201
2025-04-17 10:16:53 | INFO | train_inner | epoch 003:    124 / 139 loss=8.175, nll_loss=5.272, ppl=38.63, wps=2200.1, ups=0.39, wpb=5656.5, bsz=140, num_updates=402, lr=4.824e-06, gnorm=1.817, train_wall=5, gb_free=11.8, wall=1206
2025-04-17 10:16:59 | INFO | train_inner | epoch 003:    126 / 139 loss=8.024, nll_loss=5.089, ppl=34.03, wps=2488.7, ups=0.36, wpb=6846.5, bsz=260, num_updates=404, lr=4.848e-06, gnorm=1.639, train_wall=5, gb_free=11.3, wall=1211
2025-04-17 10:17:04 | INFO | train_inner | epoch 003:    128 / 139 loss=7.945, nll_loss=4.995, ppl=31.89, wps=2461.5, ups=0.36, wpb=6780.5, bsz=324, num_updates=406, lr=4.872e-06, gnorm=1.767, train_wall=5, gb_free=11.3, wall=1217
2025-04-17 10:17:09 | INFO | train_inner | epoch 003:    130 / 139 loss=8.15, nll_loss=5.253, ppl=38.13, wps=2354.4, ups=0.4, wpb=5901, bsz=216, num_updates=408, lr=4.896e-06, gnorm=1.774, train_wall=5, gb_free=13, wall=1222
2025-04-17 10:17:15 | INFO | train_inner | epoch 003:    132 / 139 loss=7.794, nll_loss=4.8, ppl=27.87, wps=2434.9, ups=0.35, wpb=6912.5, bsz=376, num_updates=410, lr=4.92e-06, gnorm=1.444, train_wall=6, gb_free=10.9, wall=1227
2025-04-17 10:17:20 | INFO | train_inner | epoch 003:    134 / 139 loss=8.008, nll_loss=5.064, ppl=33.45, wps=2160.1, ups=0.4, wpb=5407.5, bsz=180, num_updates=412, lr=4.944e-06, gnorm=2.2, train_wall=5, gb_free=12.4, wall=1232
2025-04-17 10:17:25 | INFO | train_inner | epoch 003:    136 / 139 loss=7.974, nll_loss=5.023, ppl=32.51, wps=2136.6, ups=0.39, wpb=5423, bsz=276, num_updates=414, lr=4.968e-06, gnorm=2.081, train_wall=5, gb_free=10.4, wall=1237
2025-04-17 10:17:30 | INFO | train_inner | epoch 003:    138 / 139 loss=7.91, nll_loss=4.934, ppl=30.57, wps=2221, ups=0.37, wpb=6080, bsz=212, num_updates=416, lr=4.992e-06, gnorm=1.762, train_wall=5, gb_free=11.4, wall=1243
2025-04-17 10:17:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-17 10:17:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=10336.32421875Mb; avail=244745.8203125Mb
2025-04-17 10:17:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000633
2025-04-17 10:17:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=10336.32421875Mb; avail=244745.8203125Mb
2025-04-17 10:17:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012802
2025-04-17 10:17:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=10336.32421875Mb; avail=244745.8203125Mb
2025-04-17 10:17:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.011127
2025-04-17 10:17:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024910
2025-04-17 10:17:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=10336.32421875Mb; avail=244745.8203125Mb
2025-04-17 10:17:47 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 7.84 | nll_loss 4.672 | ppl 25.49 | wps 5353.2 | wpb 2350.9 | bsz 94.7 | num_updates 417 | best_loss 7.84
2025-04-17 10:17:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 417 updates
2025-04-17 10:17:47 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt
2025-04-17 10:18:24 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt
2025-04-17 10:18:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt (epoch 3 @ 417 updates, score 7.84) (writing took 61.21155746599834 seconds)
2025-04-17 10:18:48 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2025-04-17 10:18:48 | INFO | train | epoch 003 | loss 8.272 | nll_loss 5.399 | ppl 42.18 | wps 1879 | ups 0.31 | wpb 6008.3 | bsz 229.1 | num_updates 417 | lr 5.004e-06 | gnorm 2.008 | train_wall 367 | gb_free 16.6 | wall 1321
2025-04-17 10:18:48 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:hi-mr': 31849}; raw total size: 31849
2025-04-17 10:18:48 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:hi-mr': 31849}; resampled total size: 31849
2025-04-17 10:18:48 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:hi-mr': 1.0}
2025-04-17 10:18:48 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001066
2025-04-17 10:18:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13418.7421875Mb; avail=241663.2734375Mb
2025-04-17 10:18:48 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000553
2025-04-17 10:18:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003620
2025-04-17 10:18:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13418.7421875Mb; avail=241663.2734375Mb
2025-04-17 10:18:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000092
2025-04-17 10:18:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13418.7421875Mb; avail=241663.2734375Mb
2025-04-17 10:18:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001179
2025-04-17 10:18:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.005217
2025-04-17 10:18:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13418.7421875Mb; avail=241663.2734375Mb
2025-04-17 10:18:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 139
2025-04-17 10:18:48 | INFO | fairseq.trainer | begin training epoch 4
2025-04-17 10:18:48 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-17 10:18:51 | INFO | train_inner | epoch 004:      1 / 139 loss=7.867, nll_loss=4.897, ppl=29.79, wps=124.3, ups=0.02, wpb=5015, bsz=272, num_updates=418, lr=5.016e-06, gnorm=2.229, train_wall=4, gb_free=11.8, wall=1324
2025-04-17 10:18:56 | INFO | train_inner | epoch 004:      3 / 139 loss=7.968, nll_loss=5.016, ppl=32.35, wps=2346.4, ups=0.39, wpb=6093, bsz=232, num_updates=420, lr=5.04e-06, gnorm=2.033, train_wall=5, gb_free=12.2, wall=1329
2025-04-17 10:19:01 | INFO | train_inner | epoch 004:      5 / 139 loss=8.135, nll_loss=5.221, ppl=37.3, wps=2386.9, ups=0.39, wpb=6068, bsz=188, num_updates=422, lr=5.064e-06, gnorm=1.894, train_wall=5, gb_free=11.7, wall=1334
2025-04-17 10:19:07 | INFO | train_inner | epoch 004:      7 / 139 loss=7.952, nll_loss=4.984, ppl=31.64, wps=2447.8, ups=0.39, wpb=6274, bsz=212, num_updates=424, lr=5.088e-06, gnorm=1.626, train_wall=5, gb_free=11.3, wall=1339
2025-04-17 10:19:12 | INFO | train_inner | epoch 004:      9 / 139 loss=7.943, nll_loss=4.987, ppl=31.71, wps=2472.4, ups=0.4, wpb=6161, bsz=268, num_updates=426, lr=5.112e-06, gnorm=1.689, train_wall=5, gb_free=13.5, wall=1344
2025-04-17 10:19:17 | INFO | train_inner | epoch 004:     11 / 139 loss=7.943, nll_loss=4.99, ppl=31.79, wps=2406.1, ups=0.37, wpb=6536, bsz=264, num_updates=428, lr=5.136e-06, gnorm=1.725, train_wall=5, gb_free=11.7, wall=1349
2025-04-17 10:19:23 | INFO | train_inner | epoch 004:     13 / 139 loss=7.84, nll_loss=4.853, ppl=28.9, wps=2285.8, ups=0.36, wpb=6331, bsz=296, num_updates=430, lr=5.16e-06, gnorm=2.748, train_wall=6, gb_free=9.5, wall=1355
2025-04-17 10:19:27 | INFO | train_inner | epoch 004:     15 / 139 loss=8.035, nll_loss=5.105, ppl=34.41, wps=2314.9, ups=0.41, wpb=5668, bsz=164, num_updates=432, lr=5.184e-06, gnorm=1.71, train_wall=5, gb_free=12.6, wall=1360
2025-04-17 10:19:33 | INFO | train_inner | epoch 004:     17 / 139 loss=7.847, nll_loss=4.864, ppl=29.12, wps=2396.3, ups=0.36, wpb=6688, bsz=300, num_updates=434, lr=5.208e-06, gnorm=1.838, train_wall=6, gb_free=10.4, wall=1365
2025-04-17 10:19:38 | INFO | train_inner | epoch 004:     19 / 139 loss=7.907, nll_loss=4.943, ppl=30.75, wps=2144.8, ups=0.37, wpb=5768.5, bsz=232, num_updates=436, lr=5.232e-06, gnorm=1.798, train_wall=5, gb_free=12, wall=1371
2025-04-17 10:19:43 | INFO | train_inner | epoch 004:     21 / 139 loss=8.052, nll_loss=5.131, ppl=35.05, wps=2177.3, ups=0.48, wpb=4575.5, bsz=120.5, num_updates=438, lr=5.256e-06, gnorm=2.801, train_wall=4, gb_free=11, wall=1375
2025-04-17 10:19:48 | INFO | train_inner | epoch 004:     23 / 139 loss=7.854, nll_loss=4.875, ppl=29.35, wps=2568.7, ups=0.37, wpb=6864, bsz=328, num_updates=440, lr=5.28e-06, gnorm=1.671, train_wall=5, gb_free=13.2, wall=1380
2025-04-17 10:19:53 | INFO | train_inner | epoch 004:     25 / 139 loss=7.794, nll_loss=4.79, ppl=27.67, wps=2420.6, ups=0.39, wpb=6226, bsz=240, num_updates=442, lr=5.304e-06, gnorm=1.744, train_wall=5, gb_free=10.9, wall=1386
2025-04-17 10:19:58 | INFO | train_inner | epoch 004:     27 / 139 loss=8.12, nll_loss=5.192, ppl=36.56, wps=1880, ups=0.41, wpb=4584.5, bsz=136, num_updates=444, lr=5.328e-06, gnorm=2.572, train_wall=5, gb_free=10.6, wall=1390
2025-04-17 10:20:03 | INFO | train_inner | epoch 004:     29 / 139 loss=7.929, nll_loss=4.964, ppl=31.21, wps=2302.1, ups=0.42, wpb=5542, bsz=168, num_updates=446, lr=5.352e-06, gnorm=1.884, train_wall=5, gb_free=12.1, wall=1395
2025-04-17 10:20:08 | INFO | train_inner | epoch 004:     31 / 139 loss=7.891, nll_loss=4.914, ppl=30.16, wps=2238.2, ups=0.42, wpb=5345.5, bsz=232, num_updates=448, lr=5.376e-06, gnorm=2.216, train_wall=5, gb_free=15.3, wall=1400
2025-04-17 10:20:13 | INFO | train_inner | epoch 004:     33 / 139 loss=7.773, nll_loss=4.772, ppl=27.32, wps=2355, ups=0.37, wpb=6351, bsz=272, num_updates=450, lr=5.4e-06, gnorm=2.023, train_wall=5, gb_free=10.9, wall=1405
2025-04-17 10:20:18 | INFO | train_inner | epoch 004:     35 / 139 loss=7.935, nll_loss=4.967, ppl=31.28, wps=1950.2, ups=0.41, wpb=4787.5, bsz=204, num_updates=452, lr=5.424e-06, gnorm=2.174, train_wall=5, gb_free=10.7, wall=1410
2025-04-17 10:20:23 | INFO | train_inner | epoch 004:     37 / 139 loss=7.831, nll_loss=4.863, ppl=29.11, wps=2364.1, ups=0.38, wpb=6166.5, bsz=284, num_updates=454, lr=5.448e-06, gnorm=2.198, train_wall=5, gb_free=11, wall=1416
2025-04-17 10:20:29 | INFO | train_inner | epoch 004:     39 / 139 loss=7.749, nll_loss=4.76, ppl=27.1, wps=2492.8, ups=0.36, wpb=6929, bsz=272, num_updates=456, lr=5.472e-06, gnorm=1.815, train_wall=6, gb_free=12.1, wall=1421
2025-04-17 10:20:34 | INFO | train_inner | epoch 004:     41 / 139 loss=7.85, nll_loss=4.888, ppl=29.62, wps=2500, ups=0.37, wpb=6837, bsz=304, num_updates=458, lr=5.496e-06, gnorm=1.93, train_wall=5, gb_free=11.1, wall=1427
2025-04-17 10:20:39 | INFO | train_inner | epoch 004:     43 / 139 loss=7.712, nll_loss=4.698, ppl=25.95, wps=2272, ups=0.37, wpb=6090.5, bsz=240, num_updates=460, lr=5.52e-06, gnorm=1.761, train_wall=5, gb_free=10.6, wall=1432
2025-04-17 10:20:45 | INFO | train_inner | epoch 004:     45 / 139 loss=7.997, nll_loss=5.034, ppl=32.76, wps=2104.6, ups=0.37, wpb=5618, bsz=152, num_updates=462, lr=5.544e-06, gnorm=2.223, train_wall=5, gb_free=12, wall=1437
2025-04-17 10:20:50 | INFO | train_inner | epoch 004:     47 / 139 loss=7.705, nll_loss=4.666, ppl=25.39, wps=2396.9, ups=0.38, wpb=6257.5, bsz=276, num_updates=464, lr=5.568e-06, gnorm=1.863, train_wall=5, gb_free=10.9, wall=1442
2025-04-17 10:20:55 | INFO | train_inner | epoch 004:     49 / 139 loss=7.845, nll_loss=4.836, ppl=28.57, wps=2430.3, ups=0.4, wpb=6052.5, bsz=176, num_updates=466, lr=5.592e-06, gnorm=1.818, train_wall=5, gb_free=11.9, wall=1447
2025-04-17 10:21:01 | INFO | train_inner | epoch 004:     51 / 139 loss=7.662, nll_loss=4.609, ppl=24.41, wps=2337.8, ups=0.34, wpb=6865, bsz=272, num_updates=468, lr=5.616e-06, gnorm=1.61, train_wall=6, gb_free=9.9, wall=1453
2025-04-17 10:21:06 | INFO | train_inner | epoch 004:     53 / 139 loss=7.926, nll_loss=4.953, ppl=30.96, wps=1930.2, ups=0.4, wpb=4786, bsz=112, num_updates=470, lr=5.64e-06, gnorm=1.877, train_wall=5, gb_free=11.8, wall=1458
2025-04-17 10:21:11 | INFO | train_inner | epoch 004:     55 / 139 loss=7.741, nll_loss=4.731, ppl=26.55, wps=2186.5, ups=0.38, wpb=5715, bsz=276, num_updates=472, lr=5.664e-06, gnorm=1.762, train_wall=5, gb_free=13.6, wall=1464
2025-04-17 10:21:16 | INFO | train_inner | epoch 004:     57 / 139 loss=7.747, nll_loss=4.745, ppl=26.82, wps=2462.4, ups=0.38, wpb=6413, bsz=256, num_updates=474, lr=5.688e-06, gnorm=1.893, train_wall=5, gb_free=12.8, wall=1469
2025-04-17 10:21:22 | INFO | train_inner | epoch 004:     59 / 139 loss=7.779, nll_loss=4.781, ppl=27.5, wps=2345.3, ups=0.35, wpb=6635.5, bsz=236, num_updates=476, lr=5.712e-06, gnorm=1.637, train_wall=6, gb_free=9.9, wall=1474
2025-04-17 10:21:27 | INFO | train_inner | epoch 004:     61 / 139 loss=7.95, nll_loss=5.012, ppl=32.26, wps=2023.7, ups=0.4, wpb=5122, bsz=188, num_updates=478, lr=5.736e-06, gnorm=1.828, train_wall=5, gb_free=14.6, wall=1479
2025-04-17 10:21:33 | INFO | train_inner | epoch 004:     63 / 139 loss=7.769, nll_loss=4.779, ppl=27.45, wps=2267, ups=0.34, wpb=6592, bsz=340, num_updates=480, lr=5.76e-06, gnorm=2.412, train_wall=6, gb_free=10.1, wall=1485
2025-04-17 10:21:38 | INFO | train_inner | epoch 004:     65 / 139 loss=7.803, nll_loss=4.821, ppl=28.26, wps=2414.5, ups=0.38, wpb=6384.5, bsz=228, num_updates=482, lr=5.784e-06, gnorm=1.714, train_wall=5, gb_free=12, wall=1491
2025-04-17 10:21:43 | INFO | train_inner | epoch 004:     67 / 139 loss=7.831, nll_loss=4.852, ppl=28.87, wps=2005.3, ups=0.39, wpb=5149.5, bsz=184, num_updates=484, lr=5.808e-06, gnorm=1.938, train_wall=5, gb_free=13.2, wall=1496
2025-04-17 10:21:48 | INFO | train_inner | epoch 004:     69 / 139 loss=7.666, nll_loss=4.649, ppl=25.1, wps=2156.9, ups=0.38, wpb=5679.5, bsz=216, num_updates=486, lr=5.832e-06, gnorm=1.667, train_wall=5, gb_free=13.2, wall=1501
2025-04-17 10:21:54 | INFO | train_inner | epoch 004:     71 / 139 loss=7.664, nll_loss=4.631, ppl=24.77, wps=2295.1, ups=0.38, wpb=6047, bsz=200, num_updates=488, lr=5.856e-06, gnorm=1.497, train_wall=5, gb_free=11.6, wall=1506
2025-04-17 10:21:59 | INFO | train_inner | epoch 004:     73 / 139 loss=7.7, nll_loss=4.68, ppl=25.63, wps=2274.3, ups=0.41, wpb=5607, bsz=216, num_updates=490, lr=5.88e-06, gnorm=2.092, train_wall=5, gb_free=9.5, wall=1511
2025-04-17 10:22:04 | INFO | train_inner | epoch 004:     75 / 139 loss=7.595, nll_loss=4.527, ppl=23.06, wps=2400.1, ups=0.36, wpb=6623.5, bsz=280, num_updates=492, lr=5.904e-06, gnorm=1.648, train_wall=6, gb_free=10.4, wall=1517
2025-04-17 10:22:09 | INFO | train_inner | epoch 004:     77 / 139 loss=7.723, nll_loss=4.682, ppl=25.68, wps=2176.3, ups=0.42, wpb=5130, bsz=132, num_updates=494, lr=5.928e-06, gnorm=1.866, train_wall=5, gb_free=16.1, wall=1521
2025-04-17 10:22:15 | INFO | train_inner | epoch 004:     79 / 139 loss=7.626, nll_loss=4.573, ppl=23.81, wps=2416.6, ups=0.35, wpb=6859.5, bsz=300, num_updates=496, lr=5.952e-06, gnorm=1.684, train_wall=6, gb_free=10.7, wall=1527
2025-04-17 10:22:20 | INFO | train_inner | epoch 004:     81 / 139 loss=7.829, nll_loss=4.844, ppl=28.71, wps=2292.8, ups=0.39, wpb=5826.5, bsz=180, num_updates=498, lr=5.976e-06, gnorm=1.723, train_wall=5, gb_free=12, wall=1532
2025-04-17 10:22:25 | INFO | train_inner | epoch 004:     83 / 139 loss=7.748, nll_loss=4.754, ppl=26.98, wps=2438.1, ups=0.39, wpb=6223, bsz=184, num_updates=500, lr=6e-06, gnorm=1.617, train_wall=5, gb_free=11.1, wall=1537
2025-04-17 10:22:30 | INFO | train_inner | epoch 004:     85 / 139 loss=7.64, nll_loss=4.616, ppl=24.52, wps=2330.3, ups=0.37, wpb=6316, bsz=240, num_updates=502, lr=6.024e-06, gnorm=1.525, train_wall=5, gb_free=10.6, wall=1543
2025-04-17 10:22:36 | INFO | train_inner | epoch 004:     87 / 139 loss=7.612, nll_loss=4.576, ppl=23.85, wps=2335.9, ups=0.36, wpb=6409, bsz=272, num_updates=504, lr=6.048e-06, gnorm=1.631, train_wall=5, gb_free=11.4, wall=1548
2025-04-17 10:22:41 | INFO | train_inner | epoch 004:     89 / 139 loss=7.886, nll_loss=4.918, ppl=30.23, wps=2053.5, ups=0.4, wpb=5154.5, bsz=108, num_updates=506, lr=6.072e-06, gnorm=1.872, train_wall=5, gb_free=12.2, wall=1553
2025-04-17 10:22:46 | INFO | train_inner | epoch 004:     91 / 139 loss=7.697, nll_loss=4.685, ppl=25.72, wps=2278.4, ups=0.39, wpb=5884.5, bsz=148, num_updates=508, lr=6.096e-06, gnorm=1.815, train_wall=5, gb_free=11.9, wall=1558
2025-04-17 10:22:55 | INFO | train_inner | epoch 004:     93 / 139 loss=7.747, nll_loss=4.753, ppl=26.97, wps=922.2, ups=0.21, wpb=4389, bsz=192, num_updates=510, lr=6.12e-06, gnorm=2.055, train_wall=10, gb_free=11.5, wall=1568
2025-04-17 10:23:00 | INFO | train_inner | epoch 004:     95 / 139 loss=7.866, nll_loss=4.883, ppl=29.5, wps=2237, ups=0.41, wpb=5394, bsz=124, num_updates=512, lr=6.144e-06, gnorm=1.955, train_wall=5, gb_free=11.6, wall=1573
2025-04-17 10:23:06 | INFO | train_inner | epoch 004:     97 / 139 loss=7.586, nll_loss=4.524, ppl=23.01, wps=2459.4, ups=0.36, wpb=6767, bsz=248, num_updates=514, lr=6.168e-06, gnorm=1.575, train_wall=5, gb_free=10.9, wall=1578
2025-04-17 10:23:11 | INFO | train_inner | epoch 004:     99 / 139 loss=7.678, nll_loss=4.645, ppl=25.02, wps=2304, ups=0.41, wpb=5684, bsz=168, num_updates=516, lr=6.192e-06, gnorm=1.742, train_wall=5, gb_free=12.7, wall=1583
2025-04-17 10:23:16 | INFO | train_inner | epoch 004:    101 / 139 loss=7.749, nll_loss=4.736, ppl=26.65, wps=2271.1, ups=0.4, wpb=5736.5, bsz=156, num_updates=518, lr=6.216e-06, gnorm=1.633, train_wall=5, gb_free=12.2, wall=1588
2025-04-17 10:23:21 | INFO | train_inner | epoch 004:    103 / 139 loss=7.528, nll_loss=4.464, ppl=22.07, wps=2313.7, ups=0.35, wpb=6596, bsz=260, num_updates=520, lr=6.24e-06, gnorm=1.654, train_wall=6, gb_free=11.5, wall=1594
2025-04-17 10:23:27 | INFO | train_inner | epoch 004:    105 / 139 loss=7.581, nll_loss=4.537, ppl=23.22, wps=2388.3, ups=0.35, wpb=6882, bsz=348, num_updates=522, lr=6.264e-06, gnorm=1.922, train_wall=6, gb_free=11, wall=1600
2025-04-17 10:23:32 | INFO | train_inner | epoch 004:    107 / 139 loss=7.742, nll_loss=4.752, ppl=26.94, wps=2571.6, ups=0.39, wpb=6554, bsz=208, num_updates=524, lr=6.288e-06, gnorm=2.291, train_wall=5, gb_free=11.5, wall=1605
2025-04-17 10:23:38 | INFO | train_inner | epoch 004:    109 / 139 loss=7.591, nll_loss=4.542, ppl=23.3, wps=2405, ups=0.35, wpb=6776.5, bsz=312, num_updates=526, lr=6.312e-06, gnorm=1.675, train_wall=6, gb_free=9.9, wall=1610
2025-04-17 10:23:43 | INFO | train_inner | epoch 004:    111 / 139 loss=7.644, nll_loss=4.607, ppl=24.38, wps=2202.7, ups=0.37, wpb=5951, bsz=192, num_updates=528, lr=6.336e-06, gnorm=1.988, train_wall=5, gb_free=10.9, wall=1616
2025-04-17 10:23:49 | INFO | train_inner | epoch 004:    113 / 139 loss=7.505, nll_loss=4.444, ppl=21.77, wps=2355, ups=0.38, wpb=6218, bsz=260, num_updates=530, lr=6.36e-06, gnorm=1.792, train_wall=5, gb_free=11.7, wall=1621
2025-04-17 10:23:54 | INFO | train_inner | epoch 004:    115 / 139 loss=7.675, nll_loss=4.646, ppl=25.04, wps=2226.1, ups=0.39, wpb=5720.5, bsz=180, num_updates=532, lr=6.384e-06, gnorm=1.588, train_wall=5, gb_free=10.9, wall=1626
2025-04-17 10:23:59 | INFO | train_inner | epoch 004:    117 / 139 loss=7.675, nll_loss=4.637, ppl=24.88, wps=2273.8, ups=0.4, wpb=5721, bsz=140, num_updates=534, lr=6.408e-06, gnorm=1.618, train_wall=5, gb_free=12.1, wall=1631
2025-04-17 10:24:04 | INFO | train_inner | epoch 004:    119 / 139 loss=7.461, nll_loss=4.386, ppl=20.91, wps=2445.9, ups=0.35, wpb=6913.5, bsz=308, num_updates=536, lr=6.432e-06, gnorm=1.568, train_wall=6, gb_free=10.6, wall=1637
2025-04-17 10:24:10 | INFO | train_inner | epoch 004:    121 / 139 loss=7.652, nll_loss=4.628, ppl=24.73, wps=2450.4, ups=0.38, wpb=6447, bsz=220, num_updates=538, lr=6.456e-06, gnorm=1.941, train_wall=5, gb_free=11.8, wall=1642
2025-04-17 10:24:15 | INFO | train_inner | epoch 004:    123 / 139 loss=7.67, nll_loss=4.641, ppl=24.95, wps=2283.6, ups=0.38, wpb=6013, bsz=192, num_updates=540, lr=6.48e-06, gnorm=1.721, train_wall=5, gb_free=12.5, wall=1647
2025-04-17 10:24:20 | INFO | train_inner | epoch 004:    125 / 139 loss=7.472, nll_loss=4.376, ppl=20.77, wps=2372.8, ups=0.37, wpb=6366, bsz=272, num_updates=542, lr=6.504e-06, gnorm=1.778, train_wall=5, gb_free=13.9, wall=1653
2025-04-17 10:24:26 | INFO | train_inner | epoch 004:    127 / 139 loss=7.52, nll_loss=4.445, ppl=21.78, wps=2509.9, ups=0.37, wpb=6719.5, bsz=288, num_updates=544, lr=6.528e-06, gnorm=1.839, train_wall=5, gb_free=11, wall=1658
2025-04-17 10:24:31 | INFO | train_inner | epoch 004:    129 / 139 loss=7.639, nll_loss=4.603, ppl=24.3, wps=2122.6, ups=0.4, wpb=5326, bsz=252, num_updates=546, lr=6.552e-06, gnorm=2.131, train_wall=5, gb_free=14.7, wall=1663
2025-04-17 10:24:36 | INFO | train_inner | epoch 004:    131 / 139 loss=7.521, nll_loss=4.464, ppl=22.08, wps=2270.2, ups=0.38, wpb=6019, bsz=268, num_updates=548, lr=6.576e-06, gnorm=1.888, train_wall=5, gb_free=13.3, wall=1668
2025-04-17 10:24:42 | INFO | train_inner | epoch 004:    133 / 139 loss=7.353, nll_loss=4.26, ppl=19.17, wps=2345.9, ups=0.34, wpb=6984.5, bsz=404, num_updates=550, lr=6.6e-06, gnorm=1.942, train_wall=6, gb_free=11, wall=1674
2025-04-17 10:24:47 | INFO | train_inner | epoch 004:    135 / 139 loss=7.458, nll_loss=4.397, ppl=21.07, wps=2065.4, ups=0.4, wpb=5173, bsz=276, num_updates=552, lr=6.624e-06, gnorm=2.283, train_wall=5, gb_free=12, wall=1679
2025-04-17 10:24:53 | INFO | train_inner | epoch 004:    137 / 139 loss=7.466, nll_loss=4.389, ppl=20.95, wps=2282.1, ups=0.36, wpb=6325, bsz=196, num_updates=554, lr=6.648e-06, gnorm=1.641, train_wall=6, gb_free=10.3, wall=1685
2025-04-17 10:24:56 | INFO | train_inner | epoch 004:    139 / 139 loss=7.74, nll_loss=4.737, ppl=26.67, wps=2282, ups=0.53, wpb=4315, bsz=120, num_updates=556, lr=6.672e-06, gnorm=2.325, train_wall=4, gb_free=16.6, wall=1689
2025-04-17 10:24:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-17 10:24:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=8117.6328125Mb; avail=246964.53125Mb
2025-04-17 10:24:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000645
2025-04-17 10:24:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=8117.6328125Mb; avail=246964.53125Mb
2025-04-17 10:24:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012697
2025-04-17 10:24:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=8117.6328125Mb; avail=246964.53125Mb
2025-04-17 10:24:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.011046
2025-04-17 10:24:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024725
2025-04-17 10:24:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=8117.6328125Mb; avail=246964.53125Mb
2025-04-17 10:25:12 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.439 | nll_loss 4.137 | ppl 17.59 | wps 5353.6 | wpb 2350.9 | bsz 94.7 | num_updates 556 | best_loss 7.439
2025-04-17 10:25:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 556 updates
2025-04-17 10:25:12 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt
2025-04-17 10:25:48 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt
2025-04-17 10:26:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt (epoch 4 @ 556 updates, score 7.439) (writing took 61.369698369991966 seconds)
2025-04-17 10:26:13 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2025-04-17 10:26:13 | INFO | train | epoch 004 | loss 7.743 | nll_loss 4.734 | ppl 26.61 | wps 1878.4 | ups 0.31 | wpb 6008.3 | bsz 229.1 | num_updates 556 | lr 6.672e-06 | gnorm 1.88 | train_wall 367 | gb_free 16.6 | wall 1765
2025-04-17 10:26:13 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:hi-mr': 31849}; raw total size: 31849
2025-04-17 10:26:13 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:hi-mr': 31849}; resampled total size: 31849
2025-04-17 10:26:13 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:hi-mr': 1.0}
2025-04-17 10:26:13 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001076
2025-04-17 10:26:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=11220.453125Mb; avail=243861.61328125Mb
2025-04-17 10:26:13 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000540
2025-04-17 10:26:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003659
2025-04-17 10:26:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=11220.453125Mb; avail=243861.61328125Mb
2025-04-17 10:26:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000095
2025-04-17 10:26:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=11220.453125Mb; avail=243861.61328125Mb
2025-04-17 10:26:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001180
2025-04-17 10:26:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.005245
2025-04-17 10:26:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=11220.453125Mb; avail=243861.61328125Mb
2025-04-17 10:26:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 139
2025-04-17 10:26:13 | INFO | fairseq.trainer | begin training epoch 5
2025-04-17 10:26:13 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-17 10:26:18 | INFO | train_inner | epoch 005:      2 / 139 loss=7.556, nll_loss=4.489, ppl=22.45, wps=151.6, ups=0.02, wpb=6187.5, bsz=176, num_updates=558, lr=6.696e-06, gnorm=1.777, train_wall=5, gb_free=10.4, wall=1770
2025-04-17 10:26:23 | INFO | train_inner | epoch 005:      4 / 139 loss=7.668, nll_loss=4.632, ppl=24.8, wps=2122.9, ups=0.39, wpb=5458.5, bsz=212, num_updates=560, lr=6.72e-06, gnorm=2.678, train_wall=5, gb_free=13.7, wall=1776
2025-04-17 10:26:28 | INFO | train_inner | epoch 005:      6 / 139 loss=7.43, nll_loss=4.324, ppl=20.03, wps=2438.5, ups=0.4, wpb=6136, bsz=244, num_updates=562, lr=6.744e-06, gnorm=1.799, train_wall=5, gb_free=11.9, wall=1781
2025-04-17 10:26:33 | INFO | train_inner | epoch 005:      8 / 139 loss=7.523, nll_loss=4.453, ppl=21.91, wps=2279.7, ups=0.41, wpb=5493.5, bsz=180, num_updates=564, lr=6.768e-06, gnorm=1.746, train_wall=5, gb_free=14.6, wall=1785
2025-04-17 10:26:38 | INFO | train_inner | epoch 005:     10 / 139 loss=7.521, nll_loss=4.457, ppl=21.97, wps=2508.5, ups=0.39, wpb=6408, bsz=188, num_updates=566, lr=6.792e-06, gnorm=1.85, train_wall=5, gb_free=12.7, wall=1790
2025-04-17 10:26:43 | INFO | train_inner | epoch 005:     12 / 139 loss=7.438, nll_loss=4.355, ppl=20.47, wps=2316.8, ups=0.39, wpb=5964, bsz=228, num_updates=568, lr=6.816e-06, gnorm=1.589, train_wall=5, gb_free=9.5, wall=1796
2025-04-17 10:26:48 | INFO | train_inner | epoch 005:     14 / 139 loss=7.429, nll_loss=4.361, ppl=20.54, wps=2386.1, ups=0.37, wpb=6367.5, bsz=300, num_updates=570, lr=6.84e-06, gnorm=1.463, train_wall=5, gb_free=11.4, wall=1801
2025-04-17 10:26:54 | INFO | train_inner | epoch 005:     16 / 139 loss=7.567, nll_loss=4.532, ppl=23.14, wps=2348.4, ups=0.39, wpb=6019, bsz=216, num_updates=572, lr=6.864e-06, gnorm=1.775, train_wall=5, gb_free=13.2, wall=1806
2025-04-17 10:26:59 | INFO | train_inner | epoch 005:     18 / 139 loss=7.572, nll_loss=4.529, ppl=23.08, wps=2391.7, ups=0.38, wpb=6282.5, bsz=172, num_updates=574, lr=6.888e-06, gnorm=1.85, train_wall=5, gb_free=11, wall=1811
2025-04-17 10:27:04 | INFO | train_inner | epoch 005:     20 / 139 loss=7.619, nll_loss=4.571, ppl=23.77, wps=2173.2, ups=0.42, wpb=5118, bsz=160, num_updates=576, lr=6.912e-06, gnorm=1.874, train_wall=5, gb_free=10.9, wall=1816
2025-04-17 10:27:09 | INFO | train_inner | epoch 005:     22 / 139 loss=7.387, nll_loss=4.277, ppl=19.38, wps=2405.6, ups=0.35, wpb=6803.5, bsz=360, num_updates=578, lr=6.936e-06, gnorm=2.045, train_wall=6, gb_free=11.8, wall=1822
2025-04-17 10:27:19 | INFO | train_inner | epoch 005:     24 / 139 loss=7.598, nll_loss=4.542, ppl=23.29, wps=1019.1, ups=0.21, wpb=4906.5, bsz=176, num_updates=580, lr=6.96e-06, gnorm=1.981, train_wall=10, gb_free=12.3, wall=1831
2025-04-17 10:27:24 | INFO | train_inner | epoch 005:     26 / 139 loss=7.34, nll_loss=4.231, ppl=18.78, wps=2243, ups=0.36, wpb=6202.5, bsz=328, num_updates=582, lr=6.984e-06, gnorm=1.481, train_wall=6, gb_free=12.3, wall=1837
2025-04-17 10:27:30 | INFO | train_inner | epoch 005:     28 / 139 loss=7.354, nll_loss=4.253, ppl=19.07, wps=2431.8, ups=0.35, wpb=6851, bsz=340, num_updates=584, lr=7.008e-06, gnorm=1.87, train_wall=6, gb_free=9.6, wall=1843
2025-04-17 10:27:35 | INFO | train_inner | epoch 005:     30 / 139 loss=7.377, nll_loss=4.286, ppl=19.51, wps=2462.4, ups=0.37, wpb=6570.5, bsz=292, num_updates=586, lr=7.032e-06, gnorm=1.698, train_wall=5, gb_free=11, wall=1848
2025-04-17 10:27:41 | INFO | train_inner | epoch 005:     32 / 139 loss=7.448, nll_loss=4.375, ppl=20.75, wps=2151.2, ups=0.38, wpb=5595, bsz=248, num_updates=588, lr=7.056e-06, gnorm=1.558, train_wall=5, gb_free=11.1, wall=1853
2025-04-17 10:27:45 | INFO | train_inner | epoch 005:     34 / 139 loss=7.5, nll_loss=4.435, ppl=21.62, wps=2320.4, ups=0.42, wpb=5546.5, bsz=184, num_updates=590, lr=7.08e-06, gnorm=1.799, train_wall=5, gb_free=13.3, wall=1858
2025-04-17 10:27:51 | INFO | train_inner | epoch 005:     36 / 139 loss=7.415, nll_loss=4.328, ppl=20.09, wps=2472.9, ups=0.38, wpb=6459.5, bsz=276, num_updates=592, lr=7.104e-06, gnorm=1.985, train_wall=5, gb_free=13.1, wall=1863
2025-04-17 10:27:56 | INFO | train_inner | epoch 005:     38 / 139 loss=7.445, nll_loss=4.356, ppl=20.48, wps=2521.5, ups=0.37, wpb=6740, bsz=268, num_updates=594, lr=7.128e-06, gnorm=1.683, train_wall=5, gb_free=10.4, wall=1868
2025-04-17 10:28:01 | INFO | train_inner | epoch 005:     40 / 139 loss=7.466, nll_loss=4.376, ppl=20.77, wps=2217.9, ups=0.38, wpb=5903, bsz=192, num_updates=596, lr=7.152e-06, gnorm=1.665, train_wall=5, gb_free=11.1, wall=1874
2025-04-17 10:28:06 | INFO | train_inner | epoch 005:     42 / 139 loss=7.439, nll_loss=4.333, ppl=20.16, wps=2081.2, ups=0.38, wpb=5433.5, bsz=200, num_updates=598, lr=7.176e-06, gnorm=1.656, train_wall=5, gb_free=12.5, wall=1879
2025-04-17 10:28:11 | INFO | train_inner | epoch 005:     44 / 139 loss=7.384, nll_loss=4.276, ppl=19.37, wps=2349.9, ups=0.46, wpb=5142.5, bsz=180.5, num_updates=600, lr=7.2e-06, gnorm=2.02, train_wall=4, gb_free=16.5, wall=1883
2025-04-17 10:28:16 | INFO | train_inner | epoch 005:     46 / 139 loss=7.356, nll_loss=4.256, ppl=19.1, wps=2471.7, ups=0.37, wpb=6748.5, bsz=260, num_updates=602, lr=7.224e-06, gnorm=1.86, train_wall=5, gb_free=11, wall=1889
2025-04-17 10:28:22 | INFO | train_inner | epoch 005:     48 / 139 loss=7.361, nll_loss=4.276, ppl=19.38, wps=2501.2, ups=0.37, wpb=6769, bsz=304, num_updates=604, lr=7.248e-06, gnorm=1.46, train_wall=5, gb_free=12.2, wall=1894
2025-04-17 10:28:27 | INFO | train_inner | epoch 005:     50 / 139 loss=7.678, nll_loss=4.667, ppl=25.4, wps=1752.7, ups=0.41, wpb=4289, bsz=112, num_updates=606, lr=7.272e-06, gnorm=2.223, train_wall=5, gb_free=12.7, wall=1899
2025-04-17 10:28:32 | INFO | train_inner | epoch 005:     52 / 139 loss=7.371, nll_loss=4.267, ppl=19.25, wps=2233.7, ups=0.38, wpb=5890.5, bsz=212, num_updates=608, lr=7.296e-06, gnorm=1.661, train_wall=5, gb_free=10.6, wall=1904
2025-04-17 10:28:37 | INFO | train_inner | epoch 005:     54 / 139 loss=7.451, nll_loss=4.369, ppl=20.66, wps=2447.6, ups=0.38, wpb=6376, bsz=200, num_updates=610, lr=7.32e-06, gnorm=1.666, train_wall=5, gb_free=12.3, wall=1910
2025-04-17 10:28:42 | INFO | train_inner | epoch 005:     56 / 139 loss=7.323, nll_loss=4.196, ppl=18.33, wps=2161.7, ups=0.38, wpb=5710, bsz=260, num_updates=612, lr=7.344e-06, gnorm=1.551, train_wall=5, gb_free=10.5, wall=1915
2025-04-17 10:28:48 | INFO | train_inner | epoch 005:     58 / 139 loss=7.295, nll_loss=4.16, ppl=17.87, wps=2250.3, ups=0.35, wpb=6425.5, bsz=268, num_updates=614, lr=7.368e-06, gnorm=1.665, train_wall=6, gb_free=9.9, wall=1921
2025-04-17 10:28:53 | INFO | train_inner | epoch 005:     60 / 139 loss=7.303, nll_loss=4.178, ppl=18.1, wps=2481.4, ups=0.39, wpb=6386, bsz=228, num_updates=616, lr=7.392e-06, gnorm=1.73, train_wall=5, gb_free=10.8, wall=1926
2025-04-17 10:28:59 | INFO | train_inner | epoch 005:     62 / 139 loss=7.424, nll_loss=4.333, ppl=20.15, wps=2018.8, ups=0.37, wpb=5391.5, bsz=220, num_updates=618, lr=7.416e-06, gnorm=1.969, train_wall=5, gb_free=9.3, wall=1931
2025-04-17 10:29:04 | INFO | train_inner | epoch 005:     64 / 139 loss=7.448, nll_loss=4.373, ppl=20.73, wps=2244.7, ups=0.4, wpb=5557.5, bsz=188, num_updates=620, lr=7.44e-06, gnorm=1.905, train_wall=5, gb_free=11.3, wall=1936
2025-04-17 10:29:09 | INFO | train_inner | epoch 005:     66 / 139 loss=7.349, nll_loss=4.251, ppl=19.04, wps=2447.2, ups=0.37, wpb=6683.5, bsz=256, num_updates=622, lr=7.464e-06, gnorm=1.551, train_wall=5, gb_free=12, wall=1941
2025-04-17 10:29:14 | INFO | train_inner | epoch 005:     68 / 139 loss=7.37, nll_loss=4.279, ppl=19.42, wps=2264.7, ups=0.37, wpb=6112.5, bsz=228, num_updates=624, lr=7.488e-06, gnorm=1.59, train_wall=5, gb_free=11.5, wall=1947
2025-04-17 10:29:20 | INFO | train_inner | epoch 005:     70 / 139 loss=7.347, nll_loss=4.23, ppl=18.77, wps=2260, ups=0.38, wpb=5967, bsz=172, num_updates=626, lr=7.512e-06, gnorm=1.602, train_wall=5, gb_free=11.1, wall=1952
2025-04-17 10:29:25 | INFO | train_inner | epoch 005:     72 / 139 loss=7.269, nll_loss=4.133, ppl=17.54, wps=2269.9, ups=0.36, wpb=6317, bsz=320, num_updates=628, lr=7.536e-06, gnorm=1.701, train_wall=6, gb_free=13, wall=1958
2025-04-17 10:29:30 | INFO | train_inner | epoch 005:     74 / 139 loss=7.314, nll_loss=4.189, ppl=18.23, wps=2260.3, ups=0.39, wpb=5786, bsz=208, num_updates=630, lr=7.56e-06, gnorm=1.657, train_wall=5, gb_free=12.2, wall=1963
2025-04-17 10:29:36 | INFO | train_inner | epoch 005:     76 / 139 loss=7.313, nll_loss=4.187, ppl=18.21, wps=2270.7, ups=0.37, wpb=6058.5, bsz=232, num_updates=632, lr=7.584e-06, gnorm=1.745, train_wall=5, gb_free=13, wall=1968
2025-04-17 10:29:41 | INFO | train_inner | epoch 005:     78 / 139 loss=7.395, nll_loss=4.294, ppl=19.62, wps=2299.3, ups=0.4, wpb=5817, bsz=212, num_updates=634, lr=7.608e-06, gnorm=1.631, train_wall=5, gb_free=11, wall=1973
2025-04-17 10:29:46 | INFO | train_inner | epoch 005:     80 / 139 loss=7.41, nll_loss=4.322, ppl=20.01, wps=2386, ups=0.4, wpb=5978.5, bsz=212, num_updates=636, lr=7.632e-06, gnorm=1.782, train_wall=5, gb_free=15.2, wall=1978
2025-04-17 10:29:51 | INFO | train_inner | epoch 005:     82 / 139 loss=7.169, nll_loss=4.017, ppl=16.18, wps=2328.2, ups=0.37, wpb=6222, bsz=304, num_updates=638, lr=7.656e-06, gnorm=1.57, train_wall=5, gb_free=11.9, wall=1984
2025-04-17 10:29:57 | INFO | train_inner | epoch 005:     84 / 139 loss=7.252, nll_loss=4.123, ppl=17.42, wps=2049.7, ups=0.36, wpb=5696, bsz=272, num_updates=640, lr=7.68e-06, gnorm=1.793, train_wall=6, gb_free=12.3, wall=1989
2025-04-17 10:30:02 | INFO | train_inner | epoch 005:     86 / 139 loss=7.205, nll_loss=4.088, ppl=17, wps=2592.5, ups=0.38, wpb=6860, bsz=332, num_updates=642, lr=7.704e-06, gnorm=2.081, train_wall=5, gb_free=12.7, wall=1994
2025-04-17 10:30:07 | INFO | train_inner | epoch 005:     88 / 139 loss=7.276, nll_loss=4.147, ppl=17.72, wps=2500.5, ups=0.37, wpb=6769, bsz=228, num_updates=644, lr=7.728e-06, gnorm=1.69, train_wall=5, gb_free=10.5, wall=2000
2025-04-17 10:30:13 | INFO | train_inner | epoch 005:     90 / 139 loss=7.39, nll_loss=4.274, ppl=19.35, wps=2274.7, ups=0.39, wpb=5906.5, bsz=256, num_updates=646, lr=7.752e-06, gnorm=1.798, train_wall=5, gb_free=10.9, wall=2005
2025-04-17 10:30:18 | INFO | train_inner | epoch 005:     92 / 139 loss=7.402, nll_loss=4.273, ppl=19.33, wps=2265.3, ups=0.37, wpb=6053, bsz=180, num_updates=648, lr=7.776e-06, gnorm=1.694, train_wall=5, gb_free=11.6, wall=2010
2025-04-17 10:30:23 | INFO | train_inner | epoch 005:     94 / 139 loss=7.325, nll_loss=4.196, ppl=18.33, wps=2505.5, ups=0.37, wpb=6780, bsz=252, num_updates=650, lr=7.8e-06, gnorm=1.427, train_wall=5, gb_free=10.7, wall=2016
2025-04-17 10:30:29 | INFO | train_inner | epoch 005:     96 / 139 loss=7.299, nll_loss=4.182, ppl=18.15, wps=2540.6, ups=0.37, wpb=6888, bsz=256, num_updates=652, lr=7.824e-06, gnorm=1.452, train_wall=5, gb_free=12, wall=2021
2025-04-17 10:30:34 | INFO | train_inner | epoch 005:     98 / 139 loss=7.37, nll_loss=4.295, ppl=19.63, wps=2533.2, ups=0.4, wpb=6330.5, bsz=240, num_updates=654, lr=7.848e-06, gnorm=1.612, train_wall=5, gb_free=13, wall=2026
2025-04-17 10:30:39 | INFO | train_inner | epoch 005:    100 / 139 loss=7.242, nll_loss=4.119, ppl=17.38, wps=2146.7, ups=0.36, wpb=5900.5, bsz=296, num_updates=656, lr=7.872e-06, gnorm=1.88, train_wall=5, gb_free=10.3, wall=2032
2025-04-17 10:30:45 | INFO | train_inner | epoch 005:    102 / 139 loss=7.224, nll_loss=4.097, ppl=17.11, wps=2307.2, ups=0.37, wpb=6232.5, bsz=308, num_updates=658, lr=7.896e-06, gnorm=1.475, train_wall=5, gb_free=13.2, wall=2037
2025-04-17 10:30:50 | INFO | train_inner | epoch 005:    104 / 139 loss=7.197, nll_loss=4.054, ppl=16.62, wps=2212.6, ups=0.38, wpb=5865.5, bsz=228, num_updates=660, lr=7.92e-06, gnorm=1.594, train_wall=5, gb_free=12.4, wall=2042
2025-04-17 10:30:55 | INFO | train_inner | epoch 005:    106 / 139 loss=7.42, nll_loss=4.327, ppl=20.07, wps=1814.2, ups=0.38, wpb=4799, bsz=176, num_updates=662, lr=7.944e-06, gnorm=1.98, train_wall=5, gb_free=10.3, wall=2048
2025-04-17 10:31:01 | INFO | train_inner | epoch 005:    108 / 139 loss=7.194, nll_loss=4.037, ppl=16.41, wps=2381.7, ups=0.36, wpb=6550.5, bsz=248, num_updates=664, lr=7.968e-06, gnorm=1.826, train_wall=5, gb_free=11.4, wall=2053
2025-04-17 10:31:06 | INFO | train_inner | epoch 005:    110 / 139 loss=7.193, nll_loss=4.029, ppl=16.33, wps=2323.2, ups=0.37, wpb=6359.5, bsz=228, num_updates=666, lr=7.992e-06, gnorm=1.564, train_wall=5, gb_free=11, wall=2059
2025-04-17 10:31:11 | INFO | train_inner | epoch 005:    112 / 139 loss=7.35, nll_loss=4.24, ppl=18.89, wps=2328.8, ups=0.39, wpb=6032, bsz=216, num_updates=668, lr=8.016e-06, gnorm=1.601, train_wall=5, gb_free=11.9, wall=2064
2025-04-17 10:31:17 | INFO | train_inner | epoch 005:    114 / 139 loss=7.368, nll_loss=4.266, ppl=19.24, wps=1940.8, ups=0.39, wpb=4998, bsz=180, num_updates=670, lr=8.04e-06, gnorm=2.109, train_wall=5, gb_free=12.6, wall=2069
2025-04-17 10:31:22 | INFO | train_inner | epoch 005:    116 / 139 loss=7.265, nll_loss=4.131, ppl=17.53, wps=2180.4, ups=0.38, wpb=5760, bsz=152, num_updates=672, lr=8.064e-06, gnorm=1.627, train_wall=5, gb_free=13.2, wall=2074
2025-04-17 10:31:27 | INFO | train_inner | epoch 005:    118 / 139 loss=7.298, nll_loss=4.186, ppl=18.2, wps=2336.1, ups=0.37, wpb=6265.5, bsz=172, num_updates=674, lr=8.088e-06, gnorm=1.53, train_wall=5, gb_free=12.4, wall=2080
2025-04-17 10:31:32 | INFO | train_inner | epoch 005:    120 / 139 loss=7.378, nll_loss=4.286, ppl=19.51, wps=2251.4, ups=0.43, wpb=5179.5, bsz=160, num_updates=676, lr=8.112e-06, gnorm=1.792, train_wall=5, gb_free=12.3, wall=2084
2025-04-17 10:31:37 | INFO | train_inner | epoch 005:    122 / 139 loss=7.213, nll_loss=4.066, ppl=16.75, wps=2348.6, ups=0.37, wpb=6426.5, bsz=220, num_updates=678, lr=8.136e-06, gnorm=1.538, train_wall=5, gb_free=10.9, wall=2090
2025-04-17 10:31:42 | INFO | train_inner | epoch 005:    124 / 139 loss=7.22, nll_loss=4.061, ppl=16.7, wps=2197.7, ups=0.41, wpb=5377.5, bsz=128, num_updates=680, lr=8.16e-06, gnorm=1.845, train_wall=5, gb_free=11.6, wall=2095
2025-04-17 10:31:48 | INFO | train_inner | epoch 005:    126 / 139 loss=7.144, nll_loss=3.974, ppl=15.72, wps=2352.3, ups=0.35, wpb=6708.5, bsz=324, num_updates=682, lr=8.184e-06, gnorm=1.688, train_wall=6, gb_free=11.4, wall=2100
2025-04-17 10:31:53 | INFO | train_inner | epoch 005:    128 / 139 loss=7.295, nll_loss=4.17, ppl=18, wps=2235.2, ups=0.38, wpb=5845, bsz=184, num_updates=684, lr=8.208e-06, gnorm=1.675, train_wall=5, gb_free=11.6, wall=2106
2025-04-17 10:31:59 | INFO | train_inner | epoch 005:    130 / 139 loss=7.118, nll_loss=3.953, ppl=15.49, wps=2354.5, ups=0.37, wpb=6407, bsz=264, num_updates=686, lr=8.232e-06, gnorm=1.662, train_wall=5, gb_free=11.8, wall=2111
2025-04-17 10:32:03 | INFO | train_inner | epoch 005:    132 / 139 loss=7.305, nll_loss=4.197, ppl=18.34, wps=2090.8, ups=0.41, wpb=5073.5, bsz=136, num_updates=688, lr=8.256e-06, gnorm=1.774, train_wall=5, gb_free=12.8, wall=2116
2025-04-17 10:32:09 | INFO | train_inner | epoch 005:    134 / 139 loss=7.155, nll_loss=3.992, ppl=15.91, wps=2383.6, ups=0.36, wpb=6710.5, bsz=248, num_updates=690, lr=8.28e-06, gnorm=1.452, train_wall=6, gb_free=10.4, wall=2122
2025-04-17 10:32:15 | INFO | train_inner | epoch 005:    136 / 139 loss=7.121, nll_loss=3.949, ppl=15.45, wps=2443.2, ups=0.36, wpb=6790, bsz=320, num_updates=692, lr=8.304e-06, gnorm=1.395, train_wall=6, gb_free=11.3, wall=2127
2025-04-17 10:32:19 | INFO | train_inner | epoch 005:    138 / 139 loss=7.247, nll_loss=4.094, ppl=17.08, wps=2229.5, ups=0.43, wpb=5243.5, bsz=124, num_updates=694, lr=8.328e-06, gnorm=1.756, train_wall=5, gb_free=11.2, wall=2132
2025-04-17 10:32:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-17 10:32:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=8145.91015625Mb; avail=246936.234375Mb
2025-04-17 10:32:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000638
2025-04-17 10:32:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=8145.91015625Mb; avail=246936.234375Mb
2025-04-17 10:32:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012684
2025-04-17 10:32:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=8145.91015625Mb; avail=246936.234375Mb
2025-04-17 10:32:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.011035
2025-04-17 10:32:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024710
2025-04-17 10:32:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=8145.91015625Mb; avail=246936.234375Mb
2025-04-17 10:32:36 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 7.114 | nll_loss 3.742 | ppl 13.38 | wps 5355.9 | wpb 2350.9 | bsz 94.7 | num_updates 695 | best_loss 7.114
2025-04-17 10:32:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 695 updates
2025-04-17 10:32:36 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt
2025-04-17 10:33:12 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt
2025-04-17 10:33:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt (epoch 5 @ 695 updates, score 7.114) (writing took 60.255397825007094 seconds)
2025-04-17 10:33:36 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2025-04-17 10:33:36 | INFO | train | epoch 005 | loss 7.354 | nll_loss 4.246 | ppl 18.97 | wps 1883.9 | ups 0.31 | wpb 6008.3 | bsz 229.1 | num_updates 695 | lr 8.34e-06 | gnorm 1.736 | train_wall 367 | gb_free 16.1 | wall 2209
2025-04-17 10:33:36 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:hi-mr': 31849}; raw total size: 31849
2025-04-17 10:33:36 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:hi-mr': 31849}; resampled total size: 31849
2025-04-17 10:33:36 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:hi-mr': 1.0}
2025-04-17 10:33:36 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001053
2025-04-17 10:33:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=12561.75Mb; avail=242520.296875Mb
2025-04-17 10:33:36 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000429
2025-04-17 10:33:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003548
2025-04-17 10:33:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=12562.2421875Mb; avail=242519.8046875Mb
2025-04-17 10:33:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000096
2025-04-17 10:33:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=12562.2421875Mb; avail=242519.8046875Mb
2025-04-17 10:33:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001220
2025-04-17 10:33:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.005168
2025-04-17 10:33:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=12562.2421875Mb; avail=242519.8046875Mb
2025-04-17 10:33:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 139
2025-04-17 10:33:36 | INFO | fairseq.trainer | begin training epoch 6
2025-04-17 10:33:36 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-17 10:33:39 | INFO | train_inner | epoch 006:      1 / 139 loss=7.093, nll_loss=3.917, ppl=15.11, wps=127, ups=0.03, wpb=5055, bsz=208, num_updates=696, lr=8.352e-06, gnorm=1.727, train_wall=4, gb_free=11.9, wall=2211
2025-04-17 10:33:44 | INFO | train_inner | epoch 006:      3 / 139 loss=7.196, nll_loss=4.057, ppl=16.64, wps=2340.5, ups=0.42, wpb=5635.5, bsz=212, num_updates=698, lr=8.376e-06, gnorm=1.836, train_wall=5, gb_free=11.1, wall=2216
2025-04-17 10:33:49 | INFO | train_inner | epoch 006:      5 / 139 loss=7.149, nll_loss=4.017, ppl=16.2, wps=2497.4, ups=0.37, wpb=6815.5, bsz=376, num_updates=700, lr=8.4e-06, gnorm=2.056, train_wall=5, gb_free=11.4, wall=2222
2025-04-17 10:33:54 | INFO | train_inner | epoch 006:      7 / 139 loss=7.137, nll_loss=3.985, ppl=15.84, wps=2416.8, ups=0.38, wpb=6298, bsz=216, num_updates=702, lr=8.424e-06, gnorm=1.74, train_wall=5, gb_free=11.3, wall=2227
2025-04-17 10:33:59 | INFO | train_inner | epoch 006:      9 / 139 loss=7.324, nll_loss=4.198, ppl=18.35, wps=2206.4, ups=0.4, wpb=5524.5, bsz=116, num_updates=704, lr=8.448e-06, gnorm=2.006, train_wall=5, gb_free=11.6, wall=2232
2025-04-17 10:34:05 | INFO | train_inner | epoch 006:     11 / 139 loss=7.169, nll_loss=4.011, ppl=16.12, wps=2087.2, ups=0.38, wpb=5536.5, bsz=244, num_updates=706, lr=8.472e-06, gnorm=1.717, train_wall=5, gb_free=10.8, wall=2237
2025-04-17 10:34:10 | INFO | train_inner | epoch 006:     13 / 139 loss=7.014, nll_loss=3.802, ppl=13.95, wps=2379.8, ups=0.39, wpb=6141.5, bsz=240, num_updates=708, lr=8.496e-06, gnorm=1.383, train_wall=5, gb_free=10.6, wall=2242
2025-04-17 10:34:15 | INFO | train_inner | epoch 006:     15 / 139 loss=7.246, nll_loss=4.116, ppl=17.34, wps=2383.2, ups=0.38, wpb=6265.5, bsz=300, num_updates=710, lr=8.52e-06, gnorm=1.624, train_wall=5, gb_free=13.6, wall=2248
2025-04-17 10:34:21 | INFO | train_inner | epoch 006:     17 / 139 loss=7.12, nll_loss=3.954, ppl=15.5, wps=2300.2, ups=0.36, wpb=6334, bsz=284, num_updates=712, lr=8.544e-06, gnorm=1.463, train_wall=5, gb_free=11.1, wall=2253
2025-04-17 10:34:26 | INFO | train_inner | epoch 006:     19 / 139 loss=7.328, nll_loss=4.219, ppl=18.62, wps=2227.4, ups=0.41, wpb=5471.5, bsz=124, num_updates=714, lr=8.568e-06, gnorm=1.97, train_wall=5, gb_free=13.6, wall=2258
2025-04-17 10:34:31 | INFO | train_inner | epoch 006:     21 / 139 loss=7.077, nll_loss=3.905, ppl=14.98, wps=2409.5, ups=0.38, wpb=6367, bsz=300, num_updates=716, lr=8.592e-06, gnorm=1.493, train_wall=5, gb_free=14.8, wall=2263
2025-04-17 10:34:36 | INFO | train_inner | epoch 006:     23 / 139 loss=7.236, nll_loss=4.107, ppl=17.23, wps=2210.5, ups=0.42, wpb=5269.5, bsz=160, num_updates=718, lr=8.616e-06, gnorm=1.573, train_wall=5, gb_free=14.1, wall=2268
2025-04-17 10:34:41 | INFO | train_inner | epoch 006:     25 / 139 loss=7.075, nll_loss=3.895, ppl=14.87, wps=2479.9, ups=0.38, wpb=6460, bsz=236, num_updates=720, lr=8.64e-06, gnorm=1.618, train_wall=5, gb_free=13.7, wall=2273
2025-04-17 10:34:46 | INFO | train_inner | epoch 006:     27 / 139 loss=7.005, nll_loss=3.81, ppl=14.02, wps=2478.6, ups=0.37, wpb=6727, bsz=352, num_updates=722, lr=8.664e-06, gnorm=1.37, train_wall=5, gb_free=11.7, wall=2279
2025-04-17 10:34:52 | INFO | train_inner | epoch 006:     29 / 139 loss=7.044, nll_loss=3.847, ppl=14.39, wps=2282.7, ups=0.36, wpb=6257, bsz=296, num_updates=724, lr=8.688e-06, gnorm=1.976, train_wall=5, gb_free=10.4, wall=2284
2025-04-17 10:35:02 | INFO | train_inner | epoch 006:     31 / 139 loss=7.183, nll_loss=4.026, ppl=16.29, wps=1205.7, ups=0.19, wpb=6347.5, bsz=228, num_updates=726, lr=8.712e-06, gnorm=1.503, train_wall=11, gb_free=9.9, wall=2295
2025-04-17 10:35:07 | INFO | train_inner | epoch 006:     33 / 139 loss=7.08, nll_loss=3.907, ppl=15, wps=2624.5, ups=0.39, wpb=6810, bsz=264, num_updates=728, lr=8.736e-06, gnorm=1.954, train_wall=5, gb_free=10.7, wall=2300
2025-04-17 10:35:13 | INFO | train_inner | epoch 006:     35 / 139 loss=7.145, nll_loss=3.981, ppl=15.79, wps=2386.3, ups=0.38, wpb=6344.5, bsz=252, num_updates=730, lr=8.76e-06, gnorm=1.807, train_wall=5, gb_free=11.9, wall=2305
2025-04-17 10:35:18 | INFO | train_inner | epoch 006:     37 / 139 loss=7.075, nll_loss=3.892, ppl=14.85, wps=2370.6, ups=0.36, wpb=6512, bsz=256, num_updates=732, lr=8.784e-06, gnorm=1.522, train_wall=5, gb_free=11.1, wall=2311
2025-04-17 10:35:23 | INFO | train_inner | epoch 006:     39 / 139 loss=7.058, nll_loss=3.869, ppl=14.61, wps=2449.5, ups=0.45, wpb=5434.5, bsz=188.5, num_updates=734, lr=8.808e-06, gnorm=1.664, train_wall=4, gb_free=16.2, wall=2315
2025-04-17 10:35:28 | INFO | train_inner | epoch 006:     41 / 139 loss=7.172, nll_loss=4.019, ppl=16.21, wps=2209.5, ups=0.37, wpb=5936.5, bsz=216, num_updates=736, lr=8.832e-06, gnorm=2.125, train_wall=5, gb_free=14.4, wall=2321
2025-04-17 10:35:33 | INFO | train_inner | epoch 006:     43 / 139 loss=7.03, nll_loss=3.837, ppl=14.29, wps=2273.4, ups=0.43, wpb=5324, bsz=208, num_updates=738, lr=8.856e-06, gnorm=1.712, train_wall=5, gb_free=10.8, wall=2325
2025-04-17 10:35:38 | INFO | train_inner | epoch 006:     45 / 139 loss=7.029, nll_loss=3.834, ppl=14.26, wps=2185.8, ups=0.4, wpb=5517.5, bsz=236, num_updates=740, lr=8.88e-06, gnorm=1.743, train_wall=5, gb_free=11.9, wall=2330
2025-04-17 10:35:43 | INFO | train_inner | epoch 006:     47 / 139 loss=7.107, nll_loss=3.926, ppl=15.2, wps=2470.7, ups=0.38, wpb=6443, bsz=240, num_updates=742, lr=8.904e-06, gnorm=2.384, train_wall=5, gb_free=11.9, wall=2335
2025-04-17 10:35:48 | INFO | train_inner | epoch 006:     49 / 139 loss=7.195, nll_loss=4.036, ppl=16.4, wps=2235.6, ups=0.39, wpb=5723, bsz=176, num_updates=744, lr=8.928e-06, gnorm=1.616, train_wall=5, gb_free=11.5, wall=2341
2025-04-17 10:35:53 | INFO | train_inner | epoch 006:     51 / 139 loss=7.096, nll_loss=3.921, ppl=15.15, wps=2120.7, ups=0.41, wpb=5161.5, bsz=156, num_updates=746, lr=8.952e-06, gnorm=1.899, train_wall=5, gb_free=13.3, wall=2345
2025-04-17 10:35:58 | INFO | train_inner | epoch 006:     53 / 139 loss=7.055, nll_loss=3.868, ppl=14.6, wps=2289.5, ups=0.4, wpb=5717, bsz=180, num_updates=748, lr=8.976e-06, gnorm=1.545, train_wall=5, gb_free=11.4, wall=2350
2025-04-17 10:36:03 | INFO | train_inner | epoch 006:     55 / 139 loss=7.054, nll_loss=3.882, ppl=14.75, wps=2456.6, ups=0.37, wpb=6728.5, bsz=268, num_updates=750, lr=9e-06, gnorm=1.734, train_wall=5, gb_free=10.8, wall=2356
2025-04-17 10:36:09 | INFO | train_inner | epoch 006:     57 / 139 loss=7.098, nll_loss=3.924, ppl=15.18, wps=2262.2, ups=0.37, wpb=6077.5, bsz=236, num_updates=752, lr=9.024e-06, gnorm=1.729, train_wall=5, gb_free=11.6, wall=2361
2025-04-17 10:36:14 | INFO | train_inner | epoch 006:     59 / 139 loss=7.172, nll_loss=4.035, ppl=16.39, wps=2328.8, ups=0.39, wpb=5913.5, bsz=200, num_updates=754, lr=9.048e-06, gnorm=1.755, train_wall=5, gb_free=11.2, wall=2366
2025-04-17 10:36:19 | INFO | train_inner | epoch 006:     61 / 139 loss=7.041, nll_loss=3.847, ppl=14.39, wps=2090, ups=0.38, wpb=5499, bsz=244, num_updates=756, lr=9.072e-06, gnorm=1.674, train_wall=5, gb_free=12.6, wall=2372
2025-04-17 10:36:25 | INFO | train_inner | epoch 006:     63 / 139 loss=7.05, nll_loss=3.859, ppl=14.51, wps=2362.1, ups=0.37, wpb=6340, bsz=248, num_updates=758, lr=9.096e-06, gnorm=1.691, train_wall=5, gb_free=12.5, wall=2377
2025-04-17 10:36:30 | INFO | train_inner | epoch 006:     65 / 139 loss=7.031, nll_loss=3.846, ppl=14.38, wps=2191.1, ups=0.39, wpb=5602.5, bsz=284, num_updates=760, lr=9.12e-06, gnorm=1.616, train_wall=5, gb_free=12.3, wall=2382
2025-04-17 10:36:35 | INFO | train_inner | epoch 006:     67 / 139 loss=7.091, nll_loss=3.912, ppl=15.05, wps=2197.5, ups=0.37, wpb=5919.5, bsz=232, num_updates=762, lr=9.144e-06, gnorm=1.692, train_wall=5, gb_free=10.5, wall=2388
2025-04-17 10:36:41 | INFO | train_inner | epoch 006:     69 / 139 loss=7.075, nll_loss=3.891, ppl=14.83, wps=2219.2, ups=0.35, wpb=6324.5, bsz=256, num_updates=764, lr=9.168e-06, gnorm=1.81, train_wall=6, gb_free=9.9, wall=2393
2025-04-17 10:36:47 | INFO | train_inner | epoch 006:     71 / 139 loss=7.047, nll_loss=3.872, ppl=14.64, wps=2357.5, ups=0.35, wpb=6787, bsz=328, num_updates=766, lr=9.192e-06, gnorm=2.105, train_wall=6, gb_free=10.5, wall=2399
2025-04-17 10:36:51 | INFO | train_inner | epoch 006:     73 / 139 loss=7.182, nll_loss=4.039, ppl=16.44, wps=2167.3, ups=0.42, wpb=5179.5, bsz=128, num_updates=768, lr=9.216e-06, gnorm=2.214, train_wall=5, gb_free=16.8, wall=2404
2025-04-17 10:36:57 | INFO | train_inner | epoch 006:     75 / 139 loss=6.88, nll_loss=3.654, ppl=12.59, wps=2396.6, ups=0.38, wpb=6304.5, bsz=276, num_updates=770, lr=9.24e-06, gnorm=1.802, train_wall=5, gb_free=11.6, wall=2409
2025-04-17 10:37:02 | INFO | train_inner | epoch 006:     77 / 139 loss=7.148, nll_loss=3.981, ppl=15.79, wps=2489.5, ups=0.39, wpb=6413.5, bsz=212, num_updates=772, lr=9.264e-06, gnorm=2.439, train_wall=5, gb_free=11.3, wall=2414
2025-04-17 10:37:07 | INFO | train_inner | epoch 006:     79 / 139 loss=7.068, nll_loss=3.866, ppl=14.58, wps=2154.8, ups=0.37, wpb=5819, bsz=196, num_updates=774, lr=9.288e-06, gnorm=1.746, train_wall=5, gb_free=9.5, wall=2420
2025-04-17 10:37:12 | INFO | train_inner | epoch 006:     81 / 139 loss=7.124, nll_loss=3.947, ppl=15.42, wps=2351.7, ups=0.39, wpb=6055, bsz=188, num_updates=776, lr=9.312e-06, gnorm=1.577, train_wall=5, gb_free=11, wall=2425
2025-04-17 10:37:18 | INFO | train_inner | epoch 006:     83 / 139 loss=7.191, nll_loss=4.03, ppl=16.34, wps=2120.5, ups=0.37, wpb=5676, bsz=164, num_updates=778, lr=9.336e-06, gnorm=2.76, train_wall=5, gb_free=10.1, wall=2430
2025-04-17 10:37:23 | INFO | train_inner | epoch 006:     85 / 139 loss=7.191, nll_loss=4.059, ppl=16.67, wps=2139.3, ups=0.39, wpb=5503, bsz=196, num_updates=780, lr=9.36e-06, gnorm=2.104, train_wall=5, gb_free=10.1, wall=2435
2025-04-17 10:37:28 | INFO | train_inner | epoch 006:     87 / 139 loss=7.028, nll_loss=3.861, ppl=14.53, wps=2399.4, ups=0.37, wpb=6458, bsz=256, num_updates=782, lr=9.384e-06, gnorm=1.577, train_wall=5, gb_free=11.9, wall=2441
2025-04-17 10:37:33 | INFO | train_inner | epoch 006:     89 / 139 loss=7.05, nll_loss=3.876, ppl=14.68, wps=2355, ups=0.37, wpb=6314.5, bsz=232, num_updates=784, lr=9.408e-06, gnorm=1.772, train_wall=5, gb_free=11.3, wall=2446
2025-04-17 10:37:39 | INFO | train_inner | epoch 006:     91 / 139 loss=6.969, nll_loss=3.768, ppl=13.62, wps=2272.3, ups=0.37, wpb=6068.5, bsz=292, num_updates=786, lr=9.432e-06, gnorm=1.888, train_wall=5, gb_free=12.3, wall=2451
2025-04-17 10:37:44 | INFO | train_inner | epoch 006:     93 / 139 loss=7.013, nll_loss=3.805, ppl=13.98, wps=2340.9, ups=0.4, wpb=5863, bsz=168, num_updates=788, lr=9.456e-06, gnorm=1.674, train_wall=5, gb_free=12.5, wall=2456
2025-04-17 10:37:50 | INFO | train_inner | epoch 006:     95 / 139 loss=7.017, nll_loss=3.815, ppl=14.08, wps=2210.6, ups=0.35, wpb=6328.5, bsz=340, num_updates=790, lr=9.48e-06, gnorm=1.966, train_wall=6, gb_free=11.9, wall=2462
2025-04-17 10:37:55 | INFO | train_inner | epoch 006:     97 / 139 loss=7.105, nll_loss=3.931, ppl=15.26, wps=2069.4, ups=0.39, wpb=5304, bsz=176, num_updates=792, lr=9.504e-06, gnorm=1.796, train_wall=5, gb_free=15.3, wall=2467
2025-04-17 10:38:00 | INFO | train_inner | epoch 006:     99 / 139 loss=7.051, nll_loss=3.872, ppl=14.64, wps=2376.8, ups=0.37, wpb=6388, bsz=204, num_updates=794, lr=9.528e-06, gnorm=1.739, train_wall=5, gb_free=11.2, wall=2473
2025-04-17 10:38:06 | INFO | train_inner | epoch 006:    101 / 139 loss=7.028, nll_loss=3.861, ppl=14.53, wps=2519.8, ups=0.37, wpb=6895, bsz=272, num_updates=796, lr=9.552e-06, gnorm=1.623, train_wall=5, gb_free=11.5, wall=2478
2025-04-17 10:38:10 | INFO | train_inner | epoch 006:    103 / 139 loss=7.095, nll_loss=3.92, ppl=15.14, wps=2173.8, ups=0.41, wpb=5356, bsz=132, num_updates=798, lr=9.576e-06, gnorm=1.766, train_wall=5, gb_free=12.9, wall=2483
2025-04-17 10:38:16 | INFO | train_inner | epoch 006:    105 / 139 loss=7.076, nll_loss=3.895, ppl=14.88, wps=2263.3, ups=0.38, wpb=5988, bsz=200, num_updates=800, lr=9.6e-06, gnorm=1.645, train_wall=5, gb_free=13.2, wall=2488
2025-04-17 10:38:21 | INFO | train_inner | epoch 006:    107 / 139 loss=7.088, nll_loss=3.897, ppl=14.9, wps=2307.3, ups=0.39, wpb=5939.5, bsz=172, num_updates=802, lr=9.624e-06, gnorm=1.664, train_wall=5, gb_free=11.2, wall=2493
2025-04-17 10:38:26 | INFO | train_inner | epoch 006:    109 / 139 loss=7.028, nll_loss=3.829, ppl=14.21, wps=2289.4, ups=0.4, wpb=5701, bsz=148, num_updates=804, lr=9.648e-06, gnorm=1.587, train_wall=5, gb_free=13, wall=2498
2025-04-17 10:38:31 | INFO | train_inner | epoch 006:    111 / 139 loss=7.203, nll_loss=4.064, ppl=16.73, wps=2325.8, ups=0.41, wpb=5730.5, bsz=148, num_updates=806, lr=9.672e-06, gnorm=1.662, train_wall=5, gb_free=11.1, wall=2503
2025-04-17 10:38:36 | INFO | train_inner | epoch 006:    113 / 139 loss=6.872, nll_loss=3.649, ppl=12.54, wps=2473.8, ups=0.36, wpb=6805, bsz=304, num_updates=808, lr=9.696e-06, gnorm=1.523, train_wall=5, gb_free=11.8, wall=2509
2025-04-17 10:38:42 | INFO | train_inner | epoch 006:    115 / 139 loss=7.136, nll_loss=3.975, ppl=15.72, wps=2218.5, ups=0.35, wpb=6264.5, bsz=220, num_updates=810, lr=9.72e-06, gnorm=1.883, train_wall=6, gb_free=11.6, wall=2514
2025-04-17 10:38:47 | INFO | train_inner | epoch 006:    117 / 139 loss=7.124, nll_loss=3.961, ppl=15.57, wps=2212.2, ups=0.38, wpb=5873, bsz=204, num_updates=812, lr=9.744e-06, gnorm=1.599, train_wall=5, gb_free=14.7, wall=2520
2025-04-17 10:38:53 | INFO | train_inner | epoch 006:    119 / 139 loss=6.917, nll_loss=3.695, ppl=12.96, wps=2417.2, ups=0.36, wpb=6667.5, bsz=296, num_updates=814, lr=9.768e-06, gnorm=1.635, train_wall=6, gb_free=11.9, wall=2525
2025-04-17 10:38:58 | INFO | train_inner | epoch 006:    121 / 139 loss=7.043, nll_loss=3.861, ppl=14.53, wps=2388.7, ups=0.39, wpb=6120, bsz=172, num_updates=816, lr=9.792e-06, gnorm=1.945, train_wall=5, gb_free=14.4, wall=2530
2025-04-17 10:39:03 | INFO | train_inner | epoch 006:    123 / 139 loss=7.024, nll_loss=3.843, ppl=14.35, wps=2210.7, ups=0.38, wpb=5798, bsz=300, num_updates=818, lr=9.816e-06, gnorm=1.749, train_wall=5, gb_free=16.3, wall=2536
2025-04-17 10:39:09 | INFO | train_inner | epoch 006:    125 / 139 loss=6.946, nll_loss=3.738, ppl=13.35, wps=2494.3, ups=0.37, wpb=6788.5, bsz=260, num_updates=820, lr=9.84e-06, gnorm=1.381, train_wall=5, gb_free=11.5, wall=2541
2025-04-17 10:39:14 | INFO | train_inner | epoch 006:    127 / 139 loss=6.898, nll_loss=3.676, ppl=12.79, wps=2098.5, ups=0.37, wpb=5670, bsz=268, num_updates=822, lr=9.864e-06, gnorm=1.576, train_wall=5, gb_free=11.4, wall=2546
2025-04-17 10:39:19 | INFO | train_inner | epoch 006:    129 / 139 loss=6.901, nll_loss=3.678, ppl=12.8, wps=2397.8, ups=0.38, wpb=6271.5, bsz=220, num_updates=824, lr=9.888e-06, gnorm=1.52, train_wall=5, gb_free=13.1, wall=2552
2025-04-17 10:39:24 | INFO | train_inner | epoch 006:    131 / 139 loss=7.105, nll_loss=3.947, ppl=15.42, wps=1481.6, ups=0.41, wpb=3609, bsz=172, num_updates=826, lr=9.912e-06, gnorm=2.478, train_wall=5, gb_free=12.7, wall=2557
2025-04-17 10:39:30 | INFO | train_inner | epoch 006:    133 / 139 loss=6.867, nll_loss=3.63, ppl=12.38, wps=2459.8, ups=0.37, wpb=6736, bsz=300, num_updates=828, lr=9.936e-06, gnorm=1.415, train_wall=5, gb_free=10.3, wall=2562
2025-04-17 10:39:35 | INFO | train_inner | epoch 006:    135 / 139 loss=6.787, nll_loss=3.516, ppl=11.44, wps=2140.2, ups=0.39, wpb=5546.5, bsz=232, num_updates=830, lr=9.96e-06, gnorm=2.037, train_wall=5, gb_free=11.4, wall=2567
2025-04-17 10:39:40 | INFO | train_inner | epoch 006:    137 / 139 loss=6.877, nll_loss=3.65, ppl=12.56, wps=2421.7, ups=0.37, wpb=6626, bsz=244, num_updates=832, lr=9.984e-06, gnorm=1.644, train_wall=5, gb_free=10.4, wall=2573
2025-04-17 10:39:44 | INFO | train_inner | epoch 006:    139 / 139 loss=6.905, nll_loss=3.686, ppl=12.87, wps=2355.8, ups=0.51, wpb=4590, bsz=152, num_updates=834, lr=1.0008e-05, gnorm=1.802, train_wall=4, gb_free=16.6, wall=2577
2025-04-17 10:39:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-17 10:39:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=9475.80078125Mb; avail=245606.3515625Mb
2025-04-17 10:39:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000621
2025-04-17 10:39:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=9475.80078125Mb; avail=245606.3515625Mb
2025-04-17 10:39:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012737
2025-04-17 10:39:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=9475.80078125Mb; avail=245606.3515625Mb
2025-04-17 10:39:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.011217
2025-04-17 10:39:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024926
2025-04-17 10:39:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=9475.80078125Mb; avail=245606.3515625Mb
2025-04-17 10:39:59 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 6.888 | nll_loss 3.477 | ppl 11.14 | wps 5351.4 | wpb 2350.9 | bsz 94.7 | num_updates 834 | best_loss 6.888
2025-04-17 10:39:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 834 updates
2025-04-17 10:39:59 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt
2025-04-17 10:40:37 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt
2025-04-17 10:41:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt (epoch 6 @ 834 updates, score 6.888) (writing took 62.03779523099365 seconds)
2025-04-17 10:41:01 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2025-04-17 10:41:01 | INFO | train | epoch 006 | loss 7.07 | nll_loss 3.89 | ppl 14.83 | wps 1875.8 | ups 0.31 | wpb 6008.3 | bsz 229.1 | num_updates 834 | lr 1.0008e-05 | gnorm 1.77 | train_wall 367 | gb_free 16.6 | wall 2654
2025-04-17 10:41:01 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:hi-mr': 31849}; raw total size: 31849
2025-04-17 10:41:01 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:hi-mr': 31849}; resampled total size: 31849
2025-04-17 10:41:01 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:hi-mr': 1.0}
2025-04-17 10:41:01 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001091
2025-04-17 10:41:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13081.97265625Mb; avail=242000.0859375Mb
2025-04-17 10:41:01 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000404
2025-04-17 10:41:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003562
2025-04-17 10:41:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13081.97265625Mb; avail=242000.0859375Mb
2025-04-17 10:41:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000098
2025-04-17 10:41:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13081.97265625Mb; avail=242000.0859375Mb
2025-04-17 10:41:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001193
2025-04-17 10:41:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.005157
2025-04-17 10:41:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13081.97265625Mb; avail=242000.0859375Mb
2025-04-17 10:41:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 139
2025-04-17 10:41:01 | INFO | fairseq.trainer | begin training epoch 7
2025-04-17 10:41:01 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-17 10:41:06 | INFO | train_inner | epoch 007:      2 / 139 loss=6.914, nll_loss=3.706, ppl=13.05, wps=144.9, ups=0.02, wpb=5949, bsz=204, num_updates=836, lr=1.0032e-05, gnorm=1.657, train_wall=5, gb_free=14, wall=2659
2025-04-17 10:41:11 | INFO | train_inner | epoch 007:      4 / 139 loss=7.088, nll_loss=3.909, ppl=15.02, wps=2320.3, ups=0.39, wpb=5949.5, bsz=160, num_updates=838, lr=1.0056e-05, gnorm=2.256, train_wall=5, gb_free=11.2, wall=2664
2025-04-17 10:41:17 | INFO | train_inner | epoch 007:      6 / 139 loss=7.023, nll_loss=3.826, ppl=14.18, wps=2480, ups=0.38, wpb=6581.5, bsz=256, num_updates=840, lr=1.008e-05, gnorm=1.973, train_wall=5, gb_free=11.4, wall=2669
2025-04-17 10:41:22 | INFO | train_inner | epoch 007:      8 / 139 loss=7.111, nll_loss=3.934, ppl=15.28, wps=2314.3, ups=0.39, wpb=5963, bsz=188, num_updates=842, lr=1.0104e-05, gnorm=1.761, train_wall=5, gb_free=12.7, wall=2674
2025-04-17 10:41:27 | INFO | train_inner | epoch 007:     10 / 139 loss=6.971, nll_loss=3.758, ppl=13.53, wps=2410, ups=0.39, wpb=6162, bsz=208, num_updates=844, lr=1.0128e-05, gnorm=1.868, train_wall=5, gb_free=10.2, wall=2679
2025-04-17 10:41:32 | INFO | train_inner | epoch 007:     12 / 139 loss=6.969, nll_loss=3.781, ppl=13.74, wps=2416.6, ups=0.4, wpb=5994, bsz=180, num_updates=846, lr=1.0152e-05, gnorm=1.773, train_wall=5, gb_free=11.7, wall=2684
2025-04-17 10:41:37 | INFO | train_inner | epoch 007:     14 / 139 loss=6.887, nll_loss=3.676, ppl=12.78, wps=2407.2, ups=0.39, wpb=6149, bsz=192, num_updates=848, lr=1.0176e-05, gnorm=1.509, train_wall=5, gb_free=12.1, wall=2689
2025-04-17 10:41:42 | INFO | train_inner | epoch 007:     16 / 139 loss=6.932, nll_loss=3.726, ppl=13.23, wps=2300.9, ups=0.39, wpb=5948, bsz=220, num_updates=850, lr=1.02e-05, gnorm=1.42, train_wall=5, gb_free=10.9, wall=2695
2025-04-17 10:41:47 | INFO | train_inner | epoch 007:     18 / 139 loss=7.023, nll_loss=3.83, ppl=14.22, wps=1914.6, ups=0.46, wpb=4207, bsz=156, num_updates=852, lr=1.0224e-05, gnorm=2.287, train_wall=4, gb_free=14.1, wall=2699
2025-04-17 10:41:52 | INFO | train_inner | epoch 007:     20 / 139 loss=6.893, nll_loss=3.662, ppl=12.66, wps=2314.8, ups=0.38, wpb=6051.5, bsz=244, num_updates=854, lr=1.0248e-05, gnorm=1.439, train_wall=5, gb_free=11.6, wall=2704
2025-04-17 10:41:57 | INFO | train_inner | epoch 007:     22 / 139 loss=6.857, nll_loss=3.609, ppl=12.2, wps=2350, ups=0.37, wpb=6435, bsz=260, num_updates=856, lr=1.0272e-05, gnorm=1.435, train_wall=5, gb_free=11.3, wall=2710
2025-04-17 10:42:02 | INFO | train_inner | epoch 007:     24 / 139 loss=6.955, nll_loss=3.754, ppl=13.49, wps=1767.4, ups=0.43, wpb=4098, bsz=180, num_updates=858, lr=1.0296e-05, gnorm=2.05, train_wall=5, gb_free=12.1, wall=2714
2025-04-17 10:42:07 | INFO | train_inner | epoch 007:     26 / 139 loss=6.881, nll_loss=3.657, ppl=12.61, wps=2449.7, ups=0.36, wpb=6736, bsz=252, num_updates=860, lr=1.032e-05, gnorm=1.581, train_wall=5, gb_free=10.8, wall=2720
2025-04-17 10:42:13 | INFO | train_inner | epoch 007:     28 / 139 loss=6.943, nll_loss=3.731, ppl=13.28, wps=2357.8, ups=0.37, wpb=6328.5, bsz=212, num_updates=862, lr=1.0344e-05, gnorm=1.425, train_wall=5, gb_free=10.2, wall=2725
2025-04-17 10:42:18 | INFO | train_inner | epoch 007:     30 / 139 loss=6.922, nll_loss=3.709, ppl=13.08, wps=2209.9, ups=0.42, wpb=5317, bsz=172, num_updates=864, lr=1.0368e-05, gnorm=1.648, train_wall=5, gb_free=13.7, wall=2730
2025-04-17 10:42:23 | INFO | train_inner | epoch 007:     32 / 139 loss=6.776, nll_loss=3.515, ppl=11.43, wps=2280.9, ups=0.39, wpb=5905, bsz=228, num_updates=866, lr=1.0392e-05, gnorm=1.527, train_wall=5, gb_free=10.6, wall=2735
2025-04-17 10:42:27 | INFO | train_inner | epoch 007:     34 / 139 loss=7.024, nll_loss=3.817, ppl=14.1, wps=2135.1, ups=0.45, wpb=4731.5, bsz=80, num_updates=868, lr=1.0416e-05, gnorm=1.869, train_wall=4, gb_free=13.7, wall=2740
2025-04-17 10:42:33 | INFO | train_inner | epoch 007:     36 / 139 loss=6.954, nll_loss=3.737, ppl=13.33, wps=2122, ups=0.34, wpb=6185, bsz=300, num_updates=870, lr=1.044e-05, gnorm=1.958, train_wall=6, gb_free=9.6, wall=2746
2025-04-17 10:42:38 | INFO | train_inner | epoch 007:     38 / 139 loss=6.92, nll_loss=3.712, ppl=13.1, wps=2316.6, ups=0.38, wpb=6162, bsz=228, num_updates=872, lr=1.0464e-05, gnorm=1.809, train_wall=5, gb_free=11.9, wall=2751
2025-04-17 10:42:44 | INFO | train_inner | epoch 007:     40 / 139 loss=6.906, nll_loss=3.693, ppl=12.93, wps=2170.8, ups=0.37, wpb=5870, bsz=168, num_updates=874, lr=1.0488e-05, gnorm=1.503, train_wall=5, gb_free=11, wall=2756
2025-04-17 10:42:50 | INFO | train_inner | epoch 007:     42 / 139 loss=6.693, nll_loss=3.429, ppl=10.77, wps=2252.6, ups=0.34, wpb=6544.5, bsz=380, num_updates=876, lr=1.0512e-05, gnorm=1.438, train_wall=6, gb_free=11.6, wall=2762
2025-04-17 10:42:55 | INFO | train_inner | epoch 007:     44 / 139 loss=6.753, nll_loss=3.502, ppl=11.33, wps=2123.2, ups=0.35, wpb=6067.5, bsz=388, num_updates=878, lr=1.0536e-05, gnorm=1.514, train_wall=6, gb_free=9.7, wall=2768
2025-04-17 10:43:05 | INFO | train_inner | epoch 007:     46 / 139 loss=6.641, nll_loss=3.354, ppl=10.23, wps=1236.9, ups=0.2, wpb=6151.5, bsz=340, num_updates=880, lr=1.056e-05, gnorm=1.472, train_wall=10, gb_free=14.6, wall=2778
2025-04-17 10:43:11 | INFO | train_inner | epoch 007:     48 / 139 loss=7.05, nll_loss=3.854, ppl=14.46, wps=1929.3, ups=0.38, wpb=5099.5, bsz=164, num_updates=882, lr=1.0584e-05, gnorm=1.647, train_wall=5, gb_free=12.5, wall=2783
2025-04-17 10:43:16 | INFO | train_inner | epoch 007:     50 / 139 loss=6.814, nll_loss=3.568, ppl=11.86, wps=2287.7, ups=0.38, wpb=6028.5, bsz=224, num_updates=884, lr=1.0608e-05, gnorm=1.52, train_wall=5, gb_free=11.1, wall=2788
2025-04-17 10:43:21 | INFO | train_inner | epoch 007:     52 / 139 loss=6.856, nll_loss=3.631, ppl=12.39, wps=2364.5, ups=0.36, wpb=6532.5, bsz=236, num_updates=886, lr=1.0632e-05, gnorm=1.551, train_wall=6, gb_free=9.5, wall=2794
2025-04-17 10:43:27 | INFO | train_inner | epoch 007:     54 / 139 loss=6.913, nll_loss=3.701, ppl=13.01, wps=2217.6, ups=0.39, wpb=5747.5, bsz=184, num_updates=888, lr=1.0656e-05, gnorm=1.522, train_wall=5, gb_free=11.7, wall=2799
2025-04-17 10:43:32 | INFO | train_inner | epoch 007:     56 / 139 loss=6.871, nll_loss=3.637, ppl=12.44, wps=2109.3, ups=0.38, wpb=5480.5, bsz=212, num_updates=890, lr=1.068e-05, gnorm=1.58, train_wall=5, gb_free=12.4, wall=2804
2025-04-17 10:43:37 | INFO | train_inner | epoch 007:     58 / 139 loss=6.831, nll_loss=3.58, ppl=11.96, wps=2345, ups=0.35, wpb=6687.5, bsz=304, num_updates=892, lr=1.0704e-05, gnorm=1.544, train_wall=6, gb_free=9.3, wall=2810
2025-04-17 10:43:42 | INFO | train_inner | epoch 007:     60 / 139 loss=7.047, nll_loss=3.854, ppl=14.46, wps=2154.3, ups=0.41, wpb=5224.5, bsz=124, num_updates=894, lr=1.0728e-05, gnorm=1.996, train_wall=5, gb_free=14.3, wall=2815
2025-04-17 10:43:47 | INFO | train_inner | epoch 007:     62 / 139 loss=6.751, nll_loss=3.476, ppl=11.13, wps=2187.8, ups=0.44, wpb=5015, bsz=176.5, num_updates=896, lr=1.0752e-05, gnorm=1.851, train_wall=5, gb_free=11.8, wall=2819
2025-04-17 10:43:52 | INFO | train_inner | epoch 007:     64 / 139 loss=6.841, nll_loss=3.611, ppl=12.22, wps=2449.2, ups=0.36, wpb=6734, bsz=292, num_updates=898, lr=1.0776e-05, gnorm=1.605, train_wall=5, gb_free=12, wall=2825
2025-04-17 10:43:57 | INFO | train_inner | epoch 007:     66 / 139 loss=6.879, nll_loss=3.655, ppl=12.6, wps=1984, ups=0.39, wpb=5062.5, bsz=172, num_updates=900, lr=1.08e-05, gnorm=1.755, train_wall=5, gb_free=10.1, wall=2830
2025-04-17 10:44:03 | INFO | train_inner | epoch 007:     68 / 139 loss=6.95, nll_loss=3.751, ppl=13.46, wps=2348.6, ups=0.37, wpb=6424, bsz=208, num_updates=902, lr=1.0824e-05, gnorm=1.406, train_wall=5, gb_free=9.3, wall=2835
2025-04-17 10:44:09 | INFO | train_inner | epoch 007:     70 / 139 loss=6.777, nll_loss=3.535, ppl=11.59, wps=2356.8, ups=0.35, wpb=6764, bsz=348, num_updates=904, lr=1.0848e-05, gnorm=1.652, train_wall=6, gb_free=10.1, wall=2841
2025-04-17 10:44:14 | INFO | train_inner | epoch 007:     72 / 139 loss=6.803, nll_loss=3.548, ppl=11.7, wps=2309.8, ups=0.4, wpb=5773.5, bsz=188, num_updates=906, lr=1.0872e-05, gnorm=1.437, train_wall=5, gb_free=11.9, wall=2846
2025-04-17 10:44:19 | INFO | train_inner | epoch 007:     74 / 139 loss=6.777, nll_loss=3.509, ppl=11.39, wps=2369.5, ups=0.36, wpb=6612.5, bsz=272, num_updates=908, lr=1.0896e-05, gnorm=1.57, train_wall=6, gb_free=11.5, wall=2852
2025-04-17 10:44:24 | INFO | train_inner | epoch 007:     76 / 139 loss=7.033, nll_loss=3.844, ppl=14.36, wps=2035.4, ups=0.4, wpb=5028, bsz=152, num_updates=910, lr=1.092e-05, gnorm=1.799, train_wall=5, gb_free=14.4, wall=2857
2025-04-17 10:44:29 | INFO | train_inner | epoch 007:     78 / 139 loss=6.918, nll_loss=3.691, ppl=12.92, wps=2114.4, ups=0.4, wpb=5231, bsz=104, num_updates=912, lr=1.0944e-05, gnorm=1.606, train_wall=5, gb_free=11.8, wall=2862
2025-04-17 10:44:34 | INFO | train_inner | epoch 007:     80 / 139 loss=6.771, nll_loss=3.529, ppl=11.55, wps=2124.4, ups=0.38, wpb=5554.5, bsz=252, num_updates=914, lr=1.0968e-05, gnorm=1.543, train_wall=5, gb_free=12.6, wall=2867
2025-04-17 10:44:40 | INFO | train_inner | epoch 007:     82 / 139 loss=6.917, nll_loss=3.691, ppl=12.92, wps=2029, ups=0.38, wpb=5285, bsz=100, num_updates=916, lr=1.0992e-05, gnorm=1.911, train_wall=5, gb_free=11.4, wall=2872
2025-04-17 10:44:45 | INFO | train_inner | epoch 007:     84 / 139 loss=6.911, nll_loss=3.689, ppl=12.9, wps=2089, ups=0.39, wpb=5304.5, bsz=168, num_updates=918, lr=1.1016e-05, gnorm=1.606, train_wall=5, gb_free=14.5, wall=2877
2025-04-17 10:44:50 | INFO | train_inner | epoch 007:     86 / 139 loss=7.021, nll_loss=3.822, ppl=14.15, wps=2185.5, ups=0.4, wpb=5506.5, bsz=112, num_updates=920, lr=1.104e-05, gnorm=1.639, train_wall=5, gb_free=12.7, wall=2882
2025-04-17 10:44:55 | INFO | train_inner | epoch 007:     88 / 139 loss=6.8, nll_loss=3.553, ppl=11.73, wps=2385.6, ups=0.36, wpb=6671.5, bsz=252, num_updates=922, lr=1.1064e-05, gnorm=1.314, train_wall=6, gb_free=10, wall=2888
2025-04-17 10:45:01 | INFO | train_inner | epoch 007:     90 / 139 loss=6.718, nll_loss=3.456, ppl=10.98, wps=2464.3, ups=0.36, wpb=6772, bsz=296, num_updates=924, lr=1.1088e-05, gnorm=1.393, train_wall=5, gb_free=12.7, wall=2893
2025-04-17 10:45:06 | INFO | train_inner | epoch 007:     92 / 139 loss=6.849, nll_loss=3.622, ppl=12.31, wps=2613, ups=0.39, wpb=6698, bsz=260, num_updates=926, lr=1.1112e-05, gnorm=1.514, train_wall=5, gb_free=11.6, wall=2898
2025-04-17 10:45:12 | INFO | train_inner | epoch 007:     94 / 139 loss=6.834, nll_loss=3.592, ppl=12.06, wps=2260.2, ups=0.34, wpb=6644, bsz=284, num_updates=928, lr=1.1136e-05, gnorm=1.672, train_wall=6, gb_free=9.9, wall=2904
2025-04-17 10:45:17 | INFO | train_inner | epoch 007:     96 / 139 loss=6.893, nll_loss=3.672, ppl=12.74, wps=2519, ups=0.38, wpb=6574.5, bsz=192, num_updates=930, lr=1.116e-05, gnorm=1.389, train_wall=5, gb_free=12.3, wall=2909
2025-04-17 10:45:22 | INFO | train_inner | epoch 007:     98 / 139 loss=6.768, nll_loss=3.52, ppl=11.47, wps=2523.2, ups=0.37, wpb=6754.5, bsz=292, num_updates=932, lr=1.1184e-05, gnorm=1.388, train_wall=5, gb_free=11.5, wall=2915
2025-04-17 10:45:27 | INFO | train_inner | epoch 007:    100 / 139 loss=6.739, nll_loss=3.461, ppl=11.01, wps=2140.2, ups=0.39, wpb=5456, bsz=204, num_updates=934, lr=1.1208e-05, gnorm=1.52, train_wall=5, gb_free=14.2, wall=2920
2025-04-17 10:45:33 | INFO | train_inner | epoch 007:    102 / 139 loss=6.557, nll_loss=3.249, ppl=9.5, wps=2447.2, ups=0.35, wpb=7026.5, bsz=376, num_updates=936, lr=1.1232e-05, gnorm=1.538, train_wall=6, gb_free=10.4, wall=2926
2025-04-17 10:45:38 | INFO | train_inner | epoch 007:    104 / 139 loss=6.686, nll_loss=3.413, ppl=10.65, wps=2427.8, ups=0.38, wpb=6325, bsz=248, num_updates=938, lr=1.1256e-05, gnorm=1.727, train_wall=5, gb_free=11.3, wall=2931
2025-04-17 10:45:44 | INFO | train_inner | epoch 007:    106 / 139 loss=6.801, nll_loss=3.552, ppl=11.73, wps=2398.7, ups=0.36, wpb=6697.5, bsz=260, num_updates=940, lr=1.128e-05, gnorm=1.455, train_wall=6, gb_free=10.6, wall=2936
2025-04-17 10:45:49 | INFO | train_inner | epoch 007:    108 / 139 loss=6.705, nll_loss=3.428, ppl=10.77, wps=2562.5, ups=0.37, wpb=6980.5, bsz=292, num_updates=942, lr=1.1304e-05, gnorm=1.426, train_wall=5, gb_free=10.7, wall=2942
2025-04-17 10:45:55 | INFO | train_inner | epoch 007:    110 / 139 loss=6.644, nll_loss=3.36, ppl=10.26, wps=2439.6, ups=0.36, wpb=6835, bsz=316, num_updates=944, lr=1.1328e-05, gnorm=1.392, train_wall=6, gb_free=12.2, wall=2948
2025-04-17 10:46:00 | INFO | train_inner | epoch 007:    112 / 139 loss=6.77, nll_loss=3.513, ppl=11.41, wps=2312.2, ups=0.39, wpb=5907.5, bsz=156, num_updates=946, lr=1.1352e-05, gnorm=1.467, train_wall=5, gb_free=11.9, wall=2953
2025-04-17 10:46:05 | INFO | train_inner | epoch 007:    114 / 139 loss=6.644, nll_loss=3.364, ppl=10.3, wps=2116.7, ups=0.41, wpb=5122, bsz=248, num_updates=948, lr=1.1376e-05, gnorm=1.701, train_wall=5, gb_free=15.3, wall=2957
2025-04-17 10:46:10 | INFO | train_inner | epoch 007:    116 / 139 loss=6.741, nll_loss=3.486, ppl=11.2, wps=2307.2, ups=0.37, wpb=6319, bsz=308, num_updates=950, lr=1.14e-05, gnorm=1.645, train_wall=5, gb_free=13.9, wall=2963
2025-04-17 10:46:16 | INFO | train_inner | epoch 007:    118 / 139 loss=6.957, nll_loss=3.763, ppl=13.57, wps=2415.1, ups=0.39, wpb=6128, bsz=212, num_updates=952, lr=1.1424e-05, gnorm=1.457, train_wall=5, gb_free=13.7, wall=2968
2025-04-17 10:46:21 | INFO | train_inner | epoch 007:    120 / 139 loss=6.72, nll_loss=3.446, ppl=10.9, wps=2396.4, ups=0.39, wpb=6067, bsz=260, num_updates=954, lr=1.1448e-05, gnorm=1.519, train_wall=5, gb_free=15.7, wall=2973
2025-04-17 10:46:26 | INFO | train_inner | epoch 007:    122 / 139 loss=6.898, nll_loss=3.678, ppl=12.8, wps=2388.3, ups=0.39, wpb=6103.5, bsz=204, num_updates=956, lr=1.1472e-05, gnorm=1.593, train_wall=5, gb_free=13.7, wall=2978
2025-04-17 10:46:31 | INFO | train_inner | epoch 007:    124 / 139 loss=6.754, nll_loss=3.477, ppl=11.14, wps=2264.5, ups=0.37, wpb=6071.5, bsz=248, num_updates=958, lr=1.1496e-05, gnorm=1.623, train_wall=5, gb_free=10.6, wall=2984
2025-04-17 10:46:36 | INFO | train_inner | epoch 007:    126 / 139 loss=6.88, nll_loss=3.647, ppl=12.53, wps=2097.2, ups=0.39, wpb=5415, bsz=152, num_updates=960, lr=1.152e-05, gnorm=1.569, train_wall=5, gb_free=12.1, wall=2989
2025-04-17 10:46:42 | INFO | train_inner | epoch 007:    128 / 139 loss=6.744, nll_loss=3.488, ppl=11.22, wps=2433.7, ups=0.36, wpb=6735, bsz=272, num_updates=962, lr=1.1544e-05, gnorm=1.457, train_wall=6, gb_free=9.9, wall=2994
2025-04-17 10:46:47 | INFO | train_inner | epoch 007:    130 / 139 loss=6.687, nll_loss=3.424, ppl=10.73, wps=2514.2, ups=0.37, wpb=6847.5, bsz=344, num_updates=964, lr=1.1568e-05, gnorm=1.386, train_wall=5, gb_free=11.4, wall=3000
2025-04-17 10:46:52 | INFO | train_inner | epoch 007:    132 / 139 loss=6.705, nll_loss=3.438, ppl=10.84, wps=2411, ups=0.4, wpb=6043, bsz=216, num_updates=966, lr=1.1592e-05, gnorm=1.696, train_wall=5, gb_free=12, wall=3005
2025-04-17 10:46:58 | INFO | train_inner | epoch 007:    134 / 139 loss=6.766, nll_loss=3.507, ppl=11.37, wps=2554.2, ups=0.37, wpb=6896.5, bsz=284, num_updates=968, lr=1.1616e-05, gnorm=1.376, train_wall=5, gb_free=12.1, wall=3010
2025-04-17 10:47:03 | INFO | train_inner | epoch 007:    136 / 139 loss=6.767, nll_loss=3.509, ppl=11.39, wps=2409.1, ups=0.35, wpb=6813.5, bsz=296, num_updates=970, lr=1.164e-05, gnorm=1.642, train_wall=6, gb_free=9.5, wall=3016
2025-04-17 10:47:09 | INFO | train_inner | epoch 007:    138 / 139 loss=6.802, nll_loss=3.559, ppl=11.78, wps=2421.7, ups=0.38, wpb=6397.5, bsz=232, num_updates=972, lr=1.1664e-05, gnorm=1.46, train_wall=5, gb_free=11.2, wall=3021
2025-04-17 10:47:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-17 10:47:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=8656.52734375Mb; avail=246425.625Mb
2025-04-17 10:47:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000645
2025-04-17 10:47:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=8656.52734375Mb; avail=246425.625Mb
2025-04-17 10:47:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012723
2025-04-17 10:47:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=8656.5234375Mb; avail=246425.625Mb
2025-04-17 10:47:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.011042
2025-04-17 10:47:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024761
2025-04-17 10:47:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=8656.5234375Mb; avail=246425.625Mb
2025-04-17 10:47:25 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 6.703 | nll_loss 3.244 | ppl 9.48 | wps 5348 | wpb 2350.9 | bsz 94.7 | num_updates 973 | best_loss 6.703
2025-04-17 10:47:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 973 updates
2025-04-17 10:47:25 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt
2025-04-17 10:48:02 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt
2025-04-17 10:48:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt (epoch 7 @ 973 updates, score 6.703) (writing took 61.167881315996055 seconds)
2025-04-17 10:48:26 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2025-04-17 10:48:26 | INFO | train | epoch 007 | loss 6.843 | nll_loss 3.607 | ppl 12.18 | wps 1877.4 | ups 0.31 | wpb 6008.3 | bsz 229.1 | num_updates 973 | lr 1.1676e-05 | gnorm 1.626 | train_wall 368 | gb_free 16.9 | wall 3099
2025-04-17 10:48:26 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:hi-mr': 31849}; raw total size: 31849
2025-04-17 10:48:26 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:hi-mr': 31849}; resampled total size: 31849
2025-04-17 10:48:26 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:hi-mr': 1.0}
2025-04-17 10:48:26 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001003
2025-04-17 10:48:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=15476.9140625Mb; avail=239605.19140625Mb
2025-04-17 10:48:26 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000436
2025-04-17 10:48:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003581
2025-04-17 10:48:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15477.40625Mb; avail=239604.69921875Mb
2025-04-17 10:48:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000082
2025-04-17 10:48:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15477.40625Mb; avail=239604.69921875Mb
2025-04-17 10:48:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001175
2025-04-17 10:48:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.005148
2025-04-17 10:48:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15477.40625Mb; avail=239604.72265625Mb
2025-04-17 10:48:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 139
2025-04-17 10:48:26 | INFO | fairseq.trainer | begin training epoch 8
2025-04-17 10:48:26 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-17 10:48:29 | INFO | train_inner | epoch 008:      1 / 139 loss=6.975, nll_loss=3.777, ppl=13.71, wps=84.1, ups=0.02, wpb=3368.5, bsz=100, num_updates=974, lr=1.1688e-05, gnorm=2.73, train_wall=4, gb_free=12.2, wall=3101
2025-04-17 10:48:34 | INFO | train_inner | epoch 008:      3 / 139 loss=6.796, nll_loss=3.554, ppl=11.74, wps=2427.6, ups=0.41, wpb=5876.5, bsz=160, num_updates=976, lr=1.1712e-05, gnorm=1.723, train_wall=5, gb_free=12.2, wall=3106
2025-04-17 10:48:39 | INFO | train_inner | epoch 008:      5 / 139 loss=6.481, nll_loss=3.15, ppl=8.88, wps=2463.2, ups=0.4, wpb=6212.5, bsz=288, num_updates=978, lr=1.1736e-05, gnorm=1.488, train_wall=5, gb_free=11.3, wall=3111
2025-04-17 10:48:44 | INFO | train_inner | epoch 008:      7 / 139 loss=6.67, nll_loss=3.377, ppl=10.39, wps=2456.8, ups=0.37, wpb=6571.5, bsz=256, num_updates=980, lr=1.176e-05, gnorm=1.359, train_wall=5, gb_free=10.4, wall=3116
2025-04-17 10:48:49 | INFO | train_inner | epoch 008:      9 / 139 loss=6.746, nll_loss=3.478, ppl=11.14, wps=2381.4, ups=0.4, wpb=5967.5, bsz=208, num_updates=982, lr=1.1784e-05, gnorm=1.617, train_wall=5, gb_free=12.6, wall=3121
2025-04-17 10:48:54 | INFO | train_inner | epoch 008:     11 / 139 loss=6.763, nll_loss=3.497, ppl=11.29, wps=2291.2, ups=0.39, wpb=5894.5, bsz=160, num_updates=984, lr=1.1808e-05, gnorm=1.536, train_wall=5, gb_free=11.6, wall=3127
2025-04-17 10:48:59 | INFO | train_inner | epoch 008:     13 / 139 loss=6.688, nll_loss=3.417, ppl=10.68, wps=2466.3, ups=0.38, wpb=6432.5, bsz=276, num_updates=986, lr=1.1832e-05, gnorm=1.537, train_wall=5, gb_free=14.4, wall=3132
2025-04-17 10:49:05 | INFO | train_inner | epoch 008:     15 / 139 loss=6.699, nll_loss=3.424, ppl=10.73, wps=2231.2, ups=0.38, wpb=5936.5, bsz=252, num_updates=988, lr=1.1856e-05, gnorm=1.471, train_wall=5, gb_free=10.3, wall=3137
2025-04-17 10:49:10 | INFO | train_inner | epoch 008:     17 / 139 loss=6.712, nll_loss=3.445, ppl=10.89, wps=2390.9, ups=0.38, wpb=6240, bsz=224, num_updates=990, lr=1.188e-05, gnorm=1.377, train_wall=5, gb_free=10.5, wall=3142
2025-04-17 10:49:15 | INFO | train_inner | epoch 008:     19 / 139 loss=6.61, nll_loss=3.314, ppl=9.94, wps=2114, ups=0.38, wpb=5614, bsz=276, num_updates=992, lr=1.1904e-05, gnorm=1.544, train_wall=5, gb_free=12, wall=3148
2025-04-17 10:49:20 | INFO | train_inner | epoch 008:     21 / 139 loss=6.868, nll_loss=3.65, ppl=12.55, wps=2264.3, ups=0.38, wpb=5907.5, bsz=224, num_updates=994, lr=1.1928e-05, gnorm=1.569, train_wall=5, gb_free=11.1, wall=3153
2025-04-17 10:49:25 | INFO | train_inner | epoch 008:     23 / 139 loss=6.768, nll_loss=3.499, ppl=11.3, wps=2182.9, ups=0.42, wpb=5180, bsz=148, num_updates=996, lr=1.1952e-05, gnorm=1.653, train_wall=5, gb_free=13.1, wall=3158
2025-04-17 10:49:30 | INFO | train_inner | epoch 008:     25 / 139 loss=6.952, nll_loss=3.734, ppl=13.31, wps=2097.5, ups=0.41, wpb=5169.5, bsz=120, num_updates=998, lr=1.1976e-05, gnorm=1.706, train_wall=5, gb_free=13.3, wall=3163
2025-04-17 10:49:35 | INFO | train_inner | epoch 008:     27 / 139 loss=6.725, nll_loss=3.456, ppl=10.97, wps=2385.1, ups=0.39, wpb=6103, bsz=216, num_updates=1000, lr=1.2e-05, gnorm=1.562, train_wall=5, gb_free=13.6, wall=3168
2025-04-17 10:49:41 | INFO | train_inner | epoch 008:     29 / 139 loss=6.761, nll_loss=3.508, ppl=11.38, wps=2105.8, ups=0.37, wpb=5662.5, bsz=212, num_updates=1002, lr=1.2024e-05, gnorm=1.687, train_wall=5, gb_free=11.4, wall=3173
2025-04-17 10:49:46 | INFO | train_inner | epoch 008:     31 / 139 loss=6.825, nll_loss=3.578, ppl=11.95, wps=1974.1, ups=0.38, wpb=5258.5, bsz=160, num_updates=1004, lr=1.2048e-05, gnorm=1.627, train_wall=5, gb_free=10.4, wall=3178
2025-04-17 10:49:51 | INFO | train_inner | epoch 008:     33 / 139 loss=6.654, nll_loss=3.373, ppl=10.36, wps=2231.8, ups=0.39, wpb=5778.5, bsz=220, num_updates=1006, lr=1.2072e-05, gnorm=1.528, train_wall=5, gb_free=10.7, wall=3184
2025-04-17 10:49:56 | INFO | train_inner | epoch 008:     35 / 139 loss=6.617, nll_loss=3.324, ppl=10.01, wps=2444.9, ups=0.38, wpb=6431.5, bsz=216, num_updates=1008, lr=1.2096e-05, gnorm=1.481, train_wall=5, gb_free=11.2, wall=3189
2025-04-17 10:50:01 | INFO | train_inner | epoch 008:     37 / 139 loss=6.757, nll_loss=3.482, ppl=11.17, wps=2339.4, ups=0.43, wpb=5386, bsz=132, num_updates=1010, lr=1.212e-05, gnorm=1.674, train_wall=5, gb_free=14.7, wall=3193
2025-04-17 10:50:06 | INFO | train_inner | epoch 008:     39 / 139 loss=6.69, nll_loss=3.389, ppl=10.48, wps=2289.3, ups=0.42, wpb=5497.5, bsz=140, num_updates=1012, lr=1.2144e-05, gnorm=1.592, train_wall=5, gb_free=11.5, wall=3198
2025-04-17 10:50:11 | INFO | train_inner | epoch 008:     41 / 139 loss=6.667, nll_loss=3.382, ppl=10.43, wps=2321.3, ups=0.39, wpb=6004, bsz=172, num_updates=1014, lr=1.2168e-05, gnorm=1.516, train_wall=5, gb_free=11.5, wall=3203
2025-04-17 10:50:16 | INFO | train_inner | epoch 008:     43 / 139 loss=6.593, nll_loss=3.307, ppl=9.9, wps=2461.7, ups=0.43, wpb=5671, bsz=224, num_updates=1016, lr=1.2192e-05, gnorm=1.565, train_wall=5, gb_free=12.6, wall=3208
2025-04-17 10:50:22 | INFO | train_inner | epoch 008:     45 / 139 loss=6.785, nll_loss=3.538, ppl=11.62, wps=2188.1, ups=0.33, wpb=6593, bsz=348, num_updates=1018, lr=1.2216e-05, gnorm=1.92, train_wall=6, gb_free=10.3, wall=3214
2025-04-17 10:50:27 | INFO | train_inner | epoch 008:     47 / 139 loss=6.717, nll_loss=3.472, ppl=11.1, wps=2502.6, ups=0.38, wpb=6517.5, bsz=256, num_updates=1020, lr=1.224e-05, gnorm=1.62, train_wall=5, gb_free=14.2, wall=3219
2025-04-17 10:50:32 | INFO | train_inner | epoch 008:     49 / 139 loss=6.705, nll_loss=3.425, ppl=10.74, wps=2281.5, ups=0.37, wpb=6134.5, bsz=220, num_updates=1022, lr=1.2264e-05, gnorm=1.789, train_wall=5, gb_free=11.9, wall=3225
2025-04-17 10:50:37 | INFO | train_inner | epoch 008:     51 / 139 loss=6.603, nll_loss=3.298, ppl=9.83, wps=2393.4, ups=0.38, wpb=6320.5, bsz=276, num_updates=1024, lr=1.2288e-05, gnorm=1.517, train_wall=5, gb_free=11.7, wall=3230
2025-04-17 10:50:43 | INFO | train_inner | epoch 008:     53 / 139 loss=6.775, nll_loss=3.504, ppl=11.34, wps=1995.4, ups=0.39, wpb=5089, bsz=112, num_updates=1026, lr=1.2312e-05, gnorm=1.77, train_wall=5, gb_free=12, wall=3235
2025-04-17 10:50:48 | INFO | train_inner | epoch 008:     55 / 139 loss=6.709, nll_loss=3.441, ppl=10.86, wps=2413.8, ups=0.38, wpb=6333.5, bsz=208, num_updates=1028, lr=1.2336e-05, gnorm=1.461, train_wall=5, gb_free=11.7, wall=3240
2025-04-17 10:50:53 | INFO | train_inner | epoch 008:     57 / 139 loss=6.803, nll_loss=3.564, ppl=11.83, wps=2133, ups=0.41, wpb=5174.5, bsz=180, num_updates=1030, lr=1.236e-05, gnorm=1.822, train_wall=5, gb_free=12.2, wall=3245
2025-04-17 10:50:58 | INFO | train_inner | epoch 008:     59 / 139 loss=6.581, nll_loss=3.279, ppl=9.71, wps=2430.7, ups=0.35, wpb=6859, bsz=276, num_updates=1032, lr=1.2384e-05, gnorm=1.578, train_wall=6, gb_free=10.8, wall=3251
2025-04-17 10:51:04 | INFO | train_inner | epoch 008:     61 / 139 loss=6.566, nll_loss=3.268, ppl=9.63, wps=2400.5, ups=0.35, wpb=6786, bsz=360, num_updates=1034, lr=1.2408e-05, gnorm=1.38, train_wall=6, gb_free=12.5, wall=3256
2025-04-17 10:51:09 | INFO | train_inner | epoch 008:     63 / 139 loss=6.586, nll_loss=3.29, ppl=9.78, wps=2277, ups=0.37, wpb=6179.5, bsz=312, num_updates=1036, lr=1.2432e-05, gnorm=1.673, train_wall=5, gb_free=11, wall=3262
2025-04-17 10:51:15 | INFO | train_inner | epoch 008:     65 / 139 loss=6.519, nll_loss=3.21, ppl=9.25, wps=2443.2, ups=0.36, wpb=6793.5, bsz=384, num_updates=1038, lr=1.2456e-05, gnorm=1.497, train_wall=6, gb_free=12.4, wall=3267
2025-04-17 10:51:20 | INFO | train_inner | epoch 008:     67 / 139 loss=6.628, nll_loss=3.349, ppl=10.19, wps=2276, ups=0.37, wpb=6123.5, bsz=308, num_updates=1040, lr=1.248e-05, gnorm=1.53, train_wall=5, gb_free=13.4, wall=3273
2025-04-17 10:51:26 | INFO | train_inner | epoch 008:     69 / 139 loss=6.759, nll_loss=3.481, ppl=11.17, wps=2257.7, ups=0.34, wpb=6612, bsz=272, num_updates=1042, lr=1.2504e-05, gnorm=1.595, train_wall=6, gb_free=10.2, wall=3279
2025-04-17 10:51:36 | INFO | train_inner | epoch 008:     71 / 139 loss=6.802, nll_loss=3.539, ppl=11.62, wps=1113.4, ups=0.2, wpb=5619, bsz=172, num_updates=1044, lr=1.2528e-05, gnorm=1.841, train_wall=10, gb_free=14, wall=3289
2025-04-17 10:51:42 | INFO | train_inner | epoch 008:     73 / 139 loss=6.721, nll_loss=3.45, ppl=10.93, wps=2134.5, ups=0.37, wpb=5844.5, bsz=240, num_updates=1046, lr=1.2552e-05, gnorm=1.732, train_wall=5, gb_free=10.3, wall=3294
2025-04-17 10:51:47 | INFO | train_inner | epoch 008:     75 / 139 loss=6.612, nll_loss=3.323, ppl=10.01, wps=2252.8, ups=0.41, wpb=5432, bsz=148, num_updates=1048, lr=1.2576e-05, gnorm=1.515, train_wall=5, gb_free=12.9, wall=3299
2025-04-17 10:51:52 | INFO | train_inner | epoch 008:     77 / 139 loss=6.569, nll_loss=3.287, ppl=9.76, wps=2578.3, ups=0.37, wpb=6919, bsz=316, num_updates=1050, lr=1.26e-05, gnorm=1.402, train_wall=5, gb_free=11.7, wall=3304
2025-04-17 10:51:57 | INFO | train_inner | epoch 008:     79 / 139 loss=6.532, nll_loss=3.214, ppl=9.28, wps=2545.8, ups=0.38, wpb=6623.5, bsz=280, num_updates=1052, lr=1.2624e-05, gnorm=1.363, train_wall=5, gb_free=12.3, wall=3310
2025-04-17 10:52:02 | INFO | train_inner | epoch 008:     81 / 139 loss=6.629, nll_loss=3.308, ppl=9.9, wps=2278.6, ups=0.38, wpb=6039, bsz=220, num_updates=1054, lr=1.2648e-05, gnorm=1.458, train_wall=5, gb_free=12.3, wall=3315
2025-04-17 10:52:07 | INFO | train_inner | epoch 008:     83 / 139 loss=6.567, nll_loss=3.24, ppl=9.45, wps=2162, ups=0.41, wpb=5306, bsz=184, num_updates=1056, lr=1.2672e-05, gnorm=1.479, train_wall=5, gb_free=14.2, wall=3320
2025-04-17 10:52:13 | INFO | train_inner | epoch 008:     85 / 139 loss=6.602, nll_loss=3.298, ppl=9.84, wps=2465.6, ups=0.36, wpb=6885, bsz=276, num_updates=1058, lr=1.2696e-05, gnorm=1.388, train_wall=6, gb_free=11.2, wall=3325
2025-04-17 10:52:18 | INFO | train_inner | epoch 008:     87 / 139 loss=6.737, nll_loss=3.489, ppl=11.23, wps=2308.6, ups=0.36, wpb=6370.5, bsz=220, num_updates=1060, lr=1.272e-05, gnorm=1.513, train_wall=6, gb_free=9.5, wall=3331
2025-04-17 10:52:24 | INFO | train_inner | epoch 008:     89 / 139 loss=6.616, nll_loss=3.341, ppl=10.14, wps=2168.7, ups=0.37, wpb=5904.5, bsz=340, num_updates=1062, lr=1.2744e-05, gnorm=1.709, train_wall=5, gb_free=13.9, wall=3336
2025-04-17 10:52:29 | INFO | train_inner | epoch 008:     91 / 139 loss=6.88, nll_loss=3.656, ppl=12.61, wps=1968.8, ups=0.4, wpb=4931.5, bsz=144, num_updates=1064, lr=1.2768e-05, gnorm=1.813, train_wall=5, gb_free=9.5, wall=3341
2025-04-17 10:52:35 | INFO | train_inner | epoch 008:     93 / 139 loss=6.606, nll_loss=3.317, ppl=9.97, wps=2380, ups=0.36, wpb=6677, bsz=280, num_updates=1066, lr=1.2792e-05, gnorm=1.496, train_wall=6, gb_free=12.3, wall=3347
2025-04-17 10:52:40 | INFO | train_inner | epoch 008:     95 / 139 loss=6.75, nll_loss=3.506, ppl=11.36, wps=2299.5, ups=0.38, wpb=6061.5, bsz=224, num_updates=1068, lr=1.2816e-05, gnorm=1.492, train_wall=5, gb_free=12.5, wall=3352
2025-04-17 10:52:45 | INFO | train_inner | epoch 008:     97 / 139 loss=6.439, nll_loss=3.101, ppl=8.58, wps=2413, ups=0.35, wpb=6830.5, bsz=376, num_updates=1070, lr=1.284e-05, gnorm=1.294, train_wall=6, gb_free=10.4, wall=3358
2025-04-17 10:52:51 | INFO | train_inner | epoch 008:     99 / 139 loss=6.625, nll_loss=3.322, ppl=10, wps=2345, ups=0.38, wpb=6228.5, bsz=212, num_updates=1072, lr=1.2864e-05, gnorm=1.451, train_wall=5, gb_free=11.6, wall=3363
2025-04-17 10:52:56 | INFO | train_inner | epoch 008:    101 / 139 loss=6.667, nll_loss=3.381, ppl=10.42, wps=2315, ups=0.38, wpb=6081, bsz=248, num_updates=1074, lr=1.2888e-05, gnorm=1.632, train_wall=5, gb_free=12, wall=3368
2025-04-17 10:53:01 | INFO | train_inner | epoch 008:    103 / 139 loss=6.718, nll_loss=3.444, ppl=10.88, wps=2253.6, ups=0.38, wpb=5906, bsz=184, num_updates=1076, lr=1.2912e-05, gnorm=1.697, train_wall=5, gb_free=11, wall=3374
2025-04-17 10:53:07 | INFO | train_inner | epoch 008:    105 / 139 loss=6.699, nll_loss=3.419, ppl=10.7, wps=2257.6, ups=0.38, wpb=5989.5, bsz=244, num_updates=1078, lr=1.2936e-05, gnorm=1.545, train_wall=5, gb_free=13.2, wall=3379
2025-04-17 10:53:12 | INFO | train_inner | epoch 008:    107 / 139 loss=6.734, nll_loss=3.483, ppl=11.18, wps=2337.7, ups=0.38, wpb=6083, bsz=224, num_updates=1080, lr=1.296e-05, gnorm=1.801, train_wall=5, gb_free=11, wall=3384
2025-04-17 10:53:17 | INFO | train_inner | epoch 008:    109 / 139 loss=6.599, nll_loss=3.319, ppl=9.98, wps=2549.8, ups=0.37, wpb=6841, bsz=240, num_updates=1082, lr=1.2984e-05, gnorm=1.671, train_wall=5, gb_free=11.2, wall=3390
2025-04-17 10:53:22 | INFO | train_inner | epoch 008:    111 / 139 loss=6.725, nll_loss=3.477, ppl=11.13, wps=2172.7, ups=0.38, wpb=5786, bsz=228, num_updates=1084, lr=1.3008e-05, gnorm=1.484, train_wall=5, gb_free=11.3, wall=3395
2025-04-17 10:53:28 | INFO | train_inner | epoch 008:    113 / 139 loss=6.622, nll_loss=3.322, ppl=10, wps=2376.4, ups=0.36, wpb=6555.5, bsz=312, num_updates=1086, lr=1.3032e-05, gnorm=1.83, train_wall=6, gb_free=11.7, wall=3400
2025-04-17 10:53:33 | INFO | train_inner | epoch 008:    115 / 139 loss=6.681, nll_loss=3.387, ppl=10.46, wps=2356.8, ups=0.39, wpb=6057.5, bsz=160, num_updates=1088, lr=1.3056e-05, gnorm=1.439, train_wall=5, gb_free=11, wall=3406
2025-04-17 10:53:38 | INFO | train_inner | epoch 008:    117 / 139 loss=6.789, nll_loss=3.533, ppl=11.58, wps=2129, ups=0.43, wpb=4947.5, bsz=148, num_updates=1090, lr=1.308e-05, gnorm=1.77, train_wall=5, gb_free=12.7, wall=3410
2025-04-17 10:53:43 | INFO | train_inner | epoch 008:    119 / 139 loss=6.568, nll_loss=3.252, ppl=9.53, wps=2218.5, ups=0.36, wpb=6217.5, bsz=280, num_updates=1092, lr=1.3104e-05, gnorm=1.351, train_wall=6, gb_free=10.5, wall=3416
2025-04-17 10:53:49 | INFO | train_inner | epoch 008:    121 / 139 loss=6.631, nll_loss=3.346, ppl=10.17, wps=2471.8, ups=0.36, wpb=6845.5, bsz=288, num_updates=1094, lr=1.3128e-05, gnorm=1.724, train_wall=6, gb_free=11.5, wall=3421
2025-04-17 10:53:54 | INFO | train_inner | epoch 008:    123 / 139 loss=6.804, nll_loss=3.57, ppl=11.88, wps=2346.2, ups=0.41, wpb=5780, bsz=168, num_updates=1096, lr=1.3152e-05, gnorm=1.911, train_wall=5, gb_free=13, wall=3426
2025-04-17 10:53:59 | INFO | train_inner | epoch 008:    125 / 139 loss=6.606, nll_loss=3.312, ppl=9.93, wps=2147.5, ups=0.38, wpb=5718, bsz=236, num_updates=1098, lr=1.3176e-05, gnorm=1.448, train_wall=5, gb_free=11.7, wall=3432
2025-04-17 10:54:05 | INFO | train_inner | epoch 008:    127 / 139 loss=6.527, nll_loss=3.216, ppl=9.29, wps=2446.5, ups=0.35, wpb=6953.5, bsz=364, num_updates=1100, lr=1.32e-05, gnorm=1.404, train_wall=6, gb_free=9.8, wall=3437
2025-04-17 10:54:10 | INFO | train_inner | epoch 008:    129 / 139 loss=6.55, nll_loss=3.236, ppl=9.42, wps=2299.6, ups=0.38, wpb=6011, bsz=264, num_updates=1102, lr=1.3224e-05, gnorm=1.435, train_wall=5, gb_free=11.4, wall=3443
2025-04-17 10:54:15 | INFO | train_inner | epoch 008:    131 / 139 loss=6.572, nll_loss=3.257, ppl=9.56, wps=2434.5, ups=0.38, wpb=6456, bsz=216, num_updates=1104, lr=1.3248e-05, gnorm=1.324, train_wall=5, gb_free=12.9, wall=3448
2025-04-17 10:54:21 | INFO | train_inner | epoch 008:    133 / 139 loss=6.701, nll_loss=3.426, ppl=10.75, wps=2349, ups=0.36, wpb=6489.5, bsz=276, num_updates=1106, lr=1.3272e-05, gnorm=1.605, train_wall=6, gb_free=12.3, wall=3453
2025-04-17 10:54:26 | INFO | train_inner | epoch 008:    135 / 139 loss=6.762, nll_loss=3.511, ppl=11.4, wps=2196.9, ups=0.4, wpb=5509.5, bsz=108, num_updates=1108, lr=1.3296e-05, gnorm=1.6, train_wall=5, gb_free=12.2, wall=3458
2025-04-17 10:54:31 | INFO | train_inner | epoch 008:    137 / 139 loss=6.675, nll_loss=3.395, ppl=10.52, wps=2061.3, ups=0.4, wpb=5171.5, bsz=144, num_updates=1110, lr=1.332e-05, gnorm=1.687, train_wall=5, gb_free=14.1, wall=3463
2025-04-17 10:54:34 | INFO | train_inner | epoch 008:    139 / 139 loss=6.864, nll_loss=3.65, ppl=12.56, wps=2325.7, ups=0.66, wpb=3519.5, bsz=96.5, num_updates=1112, lr=1.3344e-05, gnorm=2.598, train_wall=3, gb_free=16.3, wall=3466
2025-04-17 10:54:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-17 10:54:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=11877.87890625Mb; avail=243204.2734375Mb
2025-04-17 10:54:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000629
2025-04-17 10:54:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=11877.87890625Mb; avail=243204.2734375Mb
2025-04-17 10:54:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012705
2025-04-17 10:54:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=11877.875Mb; avail=243204.2734375Mb
2025-04-17 10:54:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.011154
2025-04-17 10:54:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024852
2025-04-17 10:54:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=11877.875Mb; avail=243204.2734375Mb
2025-04-17 10:54:49 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 6.564 | nll_loss 3.076 | ppl 8.43 | wps 5347.1 | wpb 2350.9 | bsz 94.7 | num_updates 1112 | best_loss 6.564
2025-04-17 10:54:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1112 updates
2025-04-17 10:54:49 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt
2025-04-17 10:55:27 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt
2025-04-17 10:55:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt (epoch 8 @ 1112 updates, score 6.564) (writing took 61.80995965701004 seconds)
2025-04-17 10:55:51 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2025-04-17 10:55:51 | INFO | train | epoch 008 | loss 6.676 | nll_loss 3.398 | ppl 10.54 | wps 1877.7 | ups 0.31 | wpb 6008.3 | bsz 229.1 | num_updates 1112 | lr 1.3344e-05 | gnorm 1.594 | train_wall 367 | gb_free 16.3 | wall 3544
2025-04-17 10:55:51 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:hi-mr': 31849}; raw total size: 31849
2025-04-17 10:55:51 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:hi-mr': 31849}; resampled total size: 31849
2025-04-17 10:55:51 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:hi-mr': 1.0}
2025-04-17 10:55:51 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001028
2025-04-17 10:55:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=21084.4453125Mb; avail=233997.65625Mb
2025-04-17 10:55:51 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000575
2025-04-17 10:55:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003320
2025-04-17 10:55:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21084.9375Mb; avail=233997.1640625Mb
2025-04-17 10:55:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000090
2025-04-17 10:55:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21084.9375Mb; avail=233997.1640625Mb
2025-04-17 10:55:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001231
2025-04-17 10:55:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.004940
2025-04-17 10:55:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21084.9375Mb; avail=233997.1640625Mb
2025-04-17 10:55:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 139
2025-04-17 10:55:51 | INFO | fairseq.trainer | begin training epoch 9
2025-04-17 10:55:51 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-17 10:55:56 | INFO | train_inner | epoch 009:      2 / 139 loss=6.652, nll_loss=3.364, ppl=10.29, wps=160.1, ups=0.02, wpb=6605.5, bsz=236, num_updates=1114, lr=1.3368e-05, gnorm=1.365, train_wall=5, gb_free=11.8, wall=3549
2025-04-17 10:56:02 | INFO | train_inner | epoch 009:      4 / 139 loss=6.484, nll_loss=3.143, ppl=8.83, wps=2558.9, ups=0.39, wpb=6623, bsz=244, num_updates=1116, lr=1.3392e-05, gnorm=1.333, train_wall=5, gb_free=11.3, wall=3554
2025-04-17 10:56:07 | INFO | train_inner | epoch 009:      6 / 139 loss=6.552, nll_loss=3.225, ppl=9.35, wps=2373.3, ups=0.37, wpb=6397.5, bsz=208, num_updates=1118, lr=1.3416e-05, gnorm=1.402, train_wall=5, gb_free=10.2, wall=3560
2025-04-17 10:56:12 | INFO | train_inner | epoch 009:      8 / 139 loss=6.579, nll_loss=3.279, ppl=9.7, wps=2361.9, ups=0.37, wpb=6428, bsz=300, num_updates=1120, lr=1.344e-05, gnorm=1.592, train_wall=5, gb_free=11.5, wall=3565
2025-04-17 10:56:17 | INFO | train_inner | epoch 009:     10 / 139 loss=6.564, nll_loss=3.273, ppl=9.67, wps=1827.7, ups=0.41, wpb=4460.5, bsz=260, num_updates=1122, lr=1.3464e-05, gnorm=1.656, train_wall=5, gb_free=10.2, wall=3570
2025-04-17 10:56:22 | INFO | train_inner | epoch 009:     12 / 139 loss=6.45, nll_loss=3.13, ppl=8.75, wps=2673.5, ups=0.39, wpb=6820.5, bsz=300, num_updates=1124, lr=1.3488e-05, gnorm=2.076, train_wall=5, gb_free=12.4, wall=3575
2025-04-17 10:56:27 | INFO | train_inner | epoch 009:     14 / 139 loss=6.601, nll_loss=3.295, ppl=9.82, wps=2022.8, ups=0.42, wpb=4867.5, bsz=176, num_updates=1126, lr=1.3512e-05, gnorm=1.774, train_wall=5, gb_free=10.1, wall=3580
2025-04-17 10:56:33 | INFO | train_inner | epoch 009:     16 / 139 loss=6.531, nll_loss=3.2, ppl=9.19, wps=2461.3, ups=0.37, wpb=6626, bsz=260, num_updates=1128, lr=1.3536e-05, gnorm=1.432, train_wall=5, gb_free=12.5, wall=3585
2025-04-17 10:56:38 | INFO | train_inner | epoch 009:     18 / 139 loss=6.643, nll_loss=3.349, ppl=10.19, wps=2444.8, ups=0.37, wpb=6573, bsz=248, num_updates=1130, lr=1.356e-05, gnorm=1.482, train_wall=5, gb_free=11.3, wall=3591
2025-04-17 10:56:43 | INFO | train_inner | epoch 009:     20 / 139 loss=6.54, nll_loss=3.212, ppl=9.26, wps=2301.7, ups=0.39, wpb=5919.5, bsz=200, num_updates=1132, lr=1.3584e-05, gnorm=1.476, train_wall=5, gb_free=12.4, wall=3596
2025-04-17 10:56:48 | INFO | train_inner | epoch 009:     22 / 139 loss=6.501, nll_loss=3.177, ppl=9.04, wps=2180.3, ups=0.39, wpb=5598, bsz=240, num_updates=1134, lr=1.3608e-05, gnorm=1.513, train_wall=5, gb_free=11.5, wall=3601
2025-04-17 10:56:53 | INFO | train_inner | epoch 009:     24 / 139 loss=6.693, nll_loss=3.427, ppl=10.76, wps=2131.4, ups=0.42, wpb=5059.5, bsz=144, num_updates=1136, lr=1.3632e-05, gnorm=1.57, train_wall=5, gb_free=14.4, wall=3606
2025-04-17 10:56:58 | INFO | train_inner | epoch 009:     26 / 139 loss=6.384, nll_loss=3.037, ppl=8.21, wps=2379.2, ups=0.4, wpb=5959.5, bsz=292, num_updates=1138, lr=1.3656e-05, gnorm=1.597, train_wall=5, gb_free=11.5, wall=3611
2025-04-17 10:57:03 | INFO | train_inner | epoch 009:     28 / 139 loss=6.404, nll_loss=3.069, ppl=8.39, wps=2272.5, ups=0.37, wpb=6112.5, bsz=356, num_updates=1140, lr=1.368e-05, gnorm=1.545, train_wall=5, gb_free=10.7, wall=3616
2025-04-17 10:57:09 | INFO | train_inner | epoch 009:     30 / 139 loss=6.663, nll_loss=3.372, ppl=10.35, wps=2238.5, ups=0.38, wpb=5947.5, bsz=216, num_updates=1142, lr=1.3704e-05, gnorm=1.683, train_wall=5, gb_free=10.4, wall=3621
2025-04-17 10:57:14 | INFO | train_inner | epoch 009:     32 / 139 loss=6.673, nll_loss=3.382, ppl=10.42, wps=2273.6, ups=0.4, wpb=5655, bsz=112, num_updates=1144, lr=1.3728e-05, gnorm=1.547, train_wall=5, gb_free=10.8, wall=3626
2025-04-17 10:57:19 | INFO | train_inner | epoch 009:     34 / 139 loss=6.631, nll_loss=3.331, ppl=10.07, wps=2270.4, ups=0.36, wpb=6361.5, bsz=284, num_updates=1146, lr=1.3752e-05, gnorm=1.74, train_wall=6, gb_free=10.1, wall=3632
2025-04-17 10:57:25 | INFO | train_inner | epoch 009:     36 / 139 loss=6.588, nll_loss=3.283, ppl=9.74, wps=2257.9, ups=0.38, wpb=5949, bsz=220, num_updates=1148, lr=1.3776e-05, gnorm=1.344, train_wall=5, gb_free=12.8, wall=3637
2025-04-17 10:57:30 | INFO | train_inner | epoch 009:     38 / 139 loss=6.653, nll_loss=3.383, ppl=10.44, wps=2201.6, ups=0.39, wpb=5613, bsz=208, num_updates=1150, lr=1.38e-05, gnorm=1.614, train_wall=5, gb_free=10.4, wall=3642
2025-04-17 10:57:35 | INFO | train_inner | epoch 009:     40 / 139 loss=6.517, nll_loss=3.209, ppl=9.25, wps=2429.2, ups=0.39, wpb=6223, bsz=232, num_updates=1152, lr=1.3824e-05, gnorm=1.487, train_wall=5, gb_free=11.1, wall=3647
2025-04-17 10:57:40 | INFO | train_inner | epoch 009:     42 / 139 loss=6.65, nll_loss=3.384, ppl=10.44, wps=2618.9, ups=0.38, wpb=6852.5, bsz=268, num_updates=1154, lr=1.3848e-05, gnorm=1.561, train_wall=5, gb_free=12, wall=3653
2025-04-17 10:57:45 | INFO | train_inner | epoch 009:     44 / 139 loss=6.649, nll_loss=3.342, ppl=10.14, wps=2262.5, ups=0.38, wpb=5910.5, bsz=188, num_updates=1156, lr=1.3872e-05, gnorm=1.61, train_wall=5, gb_free=10.6, wall=3658
2025-04-17 10:57:51 | INFO | train_inner | epoch 009:     46 / 139 loss=6.526, nll_loss=3.192, ppl=9.14, wps=2326.9, ups=0.36, wpb=6413.5, bsz=288, num_updates=1158, lr=1.3896e-05, gnorm=1.617, train_wall=6, gb_free=11.8, wall=3663
2025-04-17 10:57:56 | INFO | train_inner | epoch 009:     48 / 139 loss=6.465, nll_loss=3.117, ppl=8.68, wps=2030.3, ups=0.39, wpb=5158.5, bsz=256, num_updates=1160, lr=1.392e-05, gnorm=1.448, train_wall=5, gb_free=11.8, wall=3668
2025-04-17 10:58:01 | INFO | train_inner | epoch 009:     50 / 139 loss=6.505, nll_loss=3.17, ppl=9, wps=2207, ups=0.37, wpb=5908.5, bsz=204, num_updates=1162, lr=1.3944e-05, gnorm=1.405, train_wall=5, gb_free=11.5, wall=3674
2025-04-17 10:58:07 | INFO | train_inner | epoch 009:     52 / 139 loss=6.567, nll_loss=3.283, ppl=9.73, wps=2528.6, ups=0.37, wpb=6756, bsz=256, num_updates=1164, lr=1.3968e-05, gnorm=1.903, train_wall=5, gb_free=11.3, wall=3679
2025-04-17 10:58:12 | INFO | train_inner | epoch 009:     54 / 139 loss=6.537, nll_loss=3.233, ppl=9.4, wps=2427.7, ups=0.37, wpb=6555.5, bsz=244, num_updates=1166, lr=1.3992e-05, gnorm=1.289, train_wall=5, gb_free=12.5, wall=3684
2025-04-17 10:58:18 | INFO | train_inner | epoch 009:     56 / 139 loss=6.537, nll_loss=3.234, ppl=9.41, wps=2436.7, ups=0.36, wpb=6739.5, bsz=264, num_updates=1168, lr=1.4016e-05, gnorm=1.443, train_wall=6, gb_free=10.9, wall=3690
2025-04-17 10:58:23 | INFO | train_inner | epoch 009:     58 / 139 loss=6.557, nll_loss=3.237, ppl=9.43, wps=2428.4, ups=0.39, wpb=6258.5, bsz=220, num_updates=1170, lr=1.404e-05, gnorm=1.539, train_wall=5, gb_free=12.6, wall=3695
2025-04-17 10:58:28 | INFO | train_inner | epoch 009:     60 / 139 loss=6.487, nll_loss=3.125, ppl=8.72, wps=2428.4, ups=0.39, wpb=6202, bsz=200, num_updates=1172, lr=1.4064e-05, gnorm=1.37, train_wall=5, gb_free=11.3, wall=3700
2025-04-17 10:58:33 | INFO | train_inner | epoch 009:     62 / 139 loss=6.532, nll_loss=3.187, ppl=9.11, wps=2315.1, ups=0.37, wpb=6341.5, bsz=216, num_updates=1174, lr=1.4088e-05, gnorm=1.423, train_wall=5, gb_free=10.7, wall=3706
2025-04-17 10:58:39 | INFO | train_inner | epoch 009:     64 / 139 loss=6.525, nll_loss=3.204, ppl=9.21, wps=2283.4, ups=0.38, wpb=6010.5, bsz=196, num_updates=1176, lr=1.4112e-05, gnorm=1.443, train_wall=5, gb_free=13, wall=3711
2025-04-17 10:58:44 | INFO | train_inner | epoch 009:     66 / 139 loss=6.646, nll_loss=3.387, ppl=10.46, wps=2025.1, ups=0.37, wpb=5449, bsz=196, num_updates=1178, lr=1.4136e-05, gnorm=1.511, train_wall=5, gb_free=9.9, wall=3716
2025-04-17 10:58:50 | INFO | train_inner | epoch 009:     68 / 139 loss=6.565, nll_loss=3.283, ppl=9.73, wps=2205.8, ups=0.36, wpb=6193.5, bsz=268, num_updates=1180, lr=1.416e-05, gnorm=1.416, train_wall=6, gb_free=11, wall=3722
2025-04-17 10:58:55 | INFO | train_inner | epoch 009:     70 / 139 loss=6.507, nll_loss=3.183, ppl=9.08, wps=2376.2, ups=0.38, wpb=6257.5, bsz=192, num_updates=1182, lr=1.4184e-05, gnorm=1.481, train_wall=5, gb_free=12.8, wall=3727
2025-04-17 10:59:00 | INFO | train_inner | epoch 009:     72 / 139 loss=6.555, nll_loss=3.241, ppl=9.45, wps=2125.5, ups=0.37, wpb=5739.5, bsz=316, num_updates=1184, lr=1.4208e-05, gnorm=1.626, train_wall=5, gb_free=9.8, wall=3733
2025-04-17 10:59:05 | INFO | train_inner | epoch 009:     74 / 139 loss=6.649, nll_loss=3.338, ppl=10.11, wps=2283.1, ups=0.38, wpb=5985.5, bsz=192, num_updates=1186, lr=1.4232e-05, gnorm=1.523, train_wall=5, gb_free=12.2, wall=3738
2025-04-17 10:59:11 | INFO | train_inner | epoch 009:     76 / 139 loss=6.459, nll_loss=3.13, ppl=8.75, wps=2380.2, ups=0.38, wpb=6326.5, bsz=248, num_updates=1188, lr=1.4256e-05, gnorm=1.433, train_wall=5, gb_free=11.8, wall=3743
2025-04-17 10:59:16 | INFO | train_inner | epoch 009:     78 / 139 loss=6.512, nll_loss=3.206, ppl=9.23, wps=2326.3, ups=0.36, wpb=6537.5, bsz=284, num_updates=1190, lr=1.428e-05, gnorm=1.472, train_wall=6, gb_free=11, wall=3749
2025-04-17 10:59:21 | INFO | train_inner | epoch 009:     80 / 139 loss=6.464, nll_loss=3.142, ppl=8.83, wps=2501.8, ups=0.39, wpb=6396.5, bsz=260, num_updates=1192, lr=1.4304e-05, gnorm=1.396, train_wall=5, gb_free=11.8, wall=3754
2025-04-17 10:59:27 | INFO | train_inner | epoch 009:     82 / 139 loss=6.472, nll_loss=3.124, ppl=8.72, wps=2411.5, ups=0.35, wpb=6952.5, bsz=288, num_updates=1194, lr=1.4328e-05, gnorm=1.225, train_wall=6, gb_free=10.9, wall=3760
2025-04-17 10:59:32 | INFO | train_inner | epoch 009:     84 / 139 loss=6.603, nll_loss=3.286, ppl=9.75, wps=1987.3, ups=0.4, wpb=4916, bsz=168, num_updates=1196, lr=1.4352e-05, gnorm=1.545, train_wall=5, gb_free=12.8, wall=3765
2025-04-17 10:59:37 | INFO | train_inner | epoch 009:     86 / 139 loss=6.573, nll_loss=3.268, ppl=9.63, wps=2369.9, ups=0.38, wpb=6175, bsz=188, num_updates=1198, lr=1.4376e-05, gnorm=1.558, train_wall=5, gb_free=11.2, wall=3770
2025-04-17 10:59:43 | INFO | train_inner | epoch 009:     88 / 139 loss=6.348, nll_loss=3.01, ppl=8.06, wps=2187.9, ups=0.37, wpb=5893.5, bsz=244, num_updates=1200, lr=1.44e-05, gnorm=1.484, train_wall=5, gb_free=13.6, wall=3775
2025-04-17 10:59:48 | INFO | train_inner | epoch 009:     90 / 139 loss=6.544, nll_loss=3.249, ppl=9.51, wps=2211.3, ups=0.39, wpb=5635, bsz=176, num_updates=1202, lr=1.4424e-05, gnorm=1.554, train_wall=5, gb_free=11.5, wall=3780
2025-04-17 10:59:53 | INFO | train_inner | epoch 009:     92 / 139 loss=6.428, nll_loss=3.09, ppl=8.51, wps=2365.6, ups=0.39, wpb=6109, bsz=272, num_updates=1204, lr=1.4448e-05, gnorm=1.412, train_wall=5, gb_free=9.8, wall=3786
2025-04-17 10:59:58 | INFO | train_inner | epoch 009:     94 / 139 loss=6.477, nll_loss=3.133, ppl=8.78, wps=2475.7, ups=0.41, wpb=6003, bsz=208, num_updates=1206, lr=1.4472e-05, gnorm=1.539, train_wall=5, gb_free=14.4, wall=3790
2025-04-17 11:00:08 | INFO | train_inner | epoch 009:     96 / 139 loss=6.403, nll_loss=3.023, ppl=8.13, wps=1192.1, ups=0.19, wpb=6214, bsz=248, num_updates=1208, lr=1.4496e-05, gnorm=1.408, train_wall=10, gb_free=13.4, wall=3801
2025-04-17 11:00:14 | INFO | train_inner | epoch 009:     98 / 139 loss=6.543, nll_loss=3.227, ppl=9.36, wps=2089.8, ups=0.38, wpb=5492, bsz=212, num_updates=1210, lr=1.452e-05, gnorm=1.545, train_wall=5, gb_free=11.7, wall=3806
2025-04-17 11:00:19 | INFO | train_inner | epoch 009:    100 / 139 loss=6.406, nll_loss=3.083, ppl=8.48, wps=2429.7, ups=0.38, wpb=6325.5, bsz=244, num_updates=1212, lr=1.4544e-05, gnorm=1.346, train_wall=5, gb_free=10.9, wall=3811
2025-04-17 11:00:24 | INFO | train_inner | epoch 009:    102 / 139 loss=6.574, nll_loss=3.283, ppl=9.73, wps=2041.9, ups=0.37, wpb=5479, bsz=216, num_updates=1214, lr=1.4568e-05, gnorm=1.625, train_wall=5, gb_free=9.6, wall=3817
2025-04-17 11:00:29 | INFO | train_inner | epoch 009:    104 / 139 loss=6.531, nll_loss=3.215, ppl=9.29, wps=2630, ups=0.39, wpb=6792.5, bsz=264, num_updates=1216, lr=1.4592e-05, gnorm=1.51, train_wall=5, gb_free=12.4, wall=3822
2025-04-17 11:00:35 | INFO | train_inner | epoch 009:    106 / 139 loss=6.476, nll_loss=3.12, ppl=8.69, wps=2382.9, ups=0.38, wpb=6345.5, bsz=200, num_updates=1218, lr=1.4616e-05, gnorm=1.45, train_wall=5, gb_free=11.5, wall=3827
2025-04-17 11:00:40 | INFO | train_inner | epoch 009:    108 / 139 loss=6.55, nll_loss=3.212, ppl=9.27, wps=2376, ups=0.4, wpb=5982.5, bsz=188, num_updates=1220, lr=1.464e-05, gnorm=1.581, train_wall=5, gb_free=11, wall=3832
2025-04-17 11:00:45 | INFO | train_inner | epoch 009:    110 / 139 loss=6.646, nll_loss=3.363, ppl=10.29, wps=2224.4, ups=0.38, wpb=5905, bsz=220, num_updates=1222, lr=1.4664e-05, gnorm=1.533, train_wall=5, gb_free=14, wall=3837
2025-04-17 11:00:50 | INFO | train_inner | epoch 009:    112 / 139 loss=6.534, nll_loss=3.25, ppl=9.52, wps=2488.8, ups=0.4, wpb=6300, bsz=192, num_updates=1224, lr=1.4688e-05, gnorm=1.386, train_wall=5, gb_free=14.1, wall=3843
2025-04-17 11:00:56 | INFO | train_inner | epoch 009:    114 / 139 loss=6.435, nll_loss=3.11, ppl=8.63, wps=2423.7, ups=0.37, wpb=6595, bsz=304, num_updates=1226, lr=1.4712e-05, gnorm=1.204, train_wall=5, gb_free=11, wall=3848
2025-04-17 11:01:01 | INFO | train_inner | epoch 009:    116 / 139 loss=6.572, nll_loss=3.257, ppl=9.56, wps=2257, ups=0.35, wpb=6447.5, bsz=232, num_updates=1228, lr=1.4736e-05, gnorm=1.423, train_wall=6, gb_free=9.6, wall=3854
2025-04-17 11:01:06 | INFO | train_inner | epoch 009:    118 / 139 loss=6.528, nll_loss=3.196, ppl=9.16, wps=2350.3, ups=0.39, wpb=6076.5, bsz=208, num_updates=1230, lr=1.476e-05, gnorm=1.459, train_wall=5, gb_free=11.9, wall=3859
2025-04-17 11:01:11 | INFO | train_inner | epoch 009:    120 / 139 loss=6.652, nll_loss=3.354, ppl=10.23, wps=2124.3, ups=0.4, wpb=5364, bsz=128, num_updates=1232, lr=1.4784e-05, gnorm=1.53, train_wall=5, gb_free=12, wall=3864
2025-04-17 11:01:17 | INFO | train_inner | epoch 009:    122 / 139 loss=6.439, nll_loss=3.11, ppl=8.63, wps=2249.5, ups=0.35, wpb=6409, bsz=288, num_updates=1234, lr=1.4808e-05, gnorm=1.375, train_wall=6, gb_free=9.4, wall=3870
2025-04-17 11:01:21 | INFO | train_inner | epoch 009:    124 / 139 loss=6.766, nll_loss=3.509, ppl=11.38, wps=1929.2, ups=0.57, wpb=3412, bsz=48.5, num_updates=1236, lr=1.4832e-05, gnorm=2.383, train_wall=4, gb_free=12.8, wall=3873
2025-04-17 11:01:26 | INFO | train_inner | epoch 009:    126 / 139 loss=6.513, nll_loss=3.206, ppl=9.23, wps=2365.9, ups=0.39, wpb=6113, bsz=192, num_updates=1238, lr=1.4856e-05, gnorm=1.406, train_wall=5, gb_free=12, wall=3878
2025-04-17 11:01:31 | INFO | train_inner | epoch 009:    128 / 139 loss=6.495, nll_loss=3.174, ppl=9.03, wps=2371.6, ups=0.39, wpb=6042, bsz=244, num_updates=1240, lr=1.488e-05, gnorm=1.38, train_wall=5, gb_free=13.2, wall=3883
2025-04-17 11:01:37 | INFO | train_inner | epoch 009:    130 / 139 loss=6.47, nll_loss=3.126, ppl=8.73, wps=2245.6, ups=0.35, wpb=6376, bsz=268, num_updates=1242, lr=1.4904e-05, gnorm=1.618, train_wall=6, gb_free=11.3, wall=3889
2025-04-17 11:01:42 | INFO | train_inner | epoch 009:    132 / 139 loss=6.578, nll_loss=3.268, ppl=9.64, wps=2335.6, ups=0.37, wpb=6248, bsz=252, num_updates=1244, lr=1.4928e-05, gnorm=1.582, train_wall=5, gb_free=11.8, wall=3894
2025-04-17 11:01:47 | INFO | train_inner | epoch 009:    134 / 139 loss=6.533, nll_loss=3.236, ppl=9.42, wps=2358.3, ups=0.39, wpb=6093, bsz=288, num_updates=1246, lr=1.4952e-05, gnorm=1.442, train_wall=5, gb_free=11.3, wall=3900
2025-04-17 11:01:52 | INFO | train_inner | epoch 009:    136 / 139 loss=6.371, nll_loss=3.02, ppl=8.11, wps=2322.3, ups=0.45, wpb=5186.5, bsz=220, num_updates=1248, lr=1.4976e-05, gnorm=1.679, train_wall=4, gb_free=18.1, wall=3904
2025-04-17 11:01:57 | INFO | train_inner | epoch 009:    138 / 139 loss=6.583, nll_loss=3.277, ppl=9.7, wps=2090.7, ups=0.4, wpb=5165.5, bsz=164, num_updates=1250, lr=1.5e-05, gnorm=1.825, train_wall=5, gb_free=14.4, wall=3909
2025-04-17 11:01:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-17 11:01:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=14301.1953125Mb; avail=240780.94921875Mb
2025-04-17 11:01:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000639
2025-04-17 11:01:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=14301.1953125Mb; avail=240780.94921875Mb
2025-04-17 11:01:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012646
2025-04-17 11:01:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=14301.1953125Mb; avail=240780.94921875Mb
2025-04-17 11:01:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.011231
2025-04-17 11:01:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024874
2025-04-17 11:01:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=14301.19140625Mb; avail=240780.94921875Mb
2025-04-17 11:02:13 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 6.473 | nll_loss 2.94 | ppl 7.67 | wps 5367.1 | wpb 2350.9 | bsz 94.7 | num_updates 1251 | best_loss 6.473
2025-04-17 11:02:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1251 updates
2025-04-17 11:02:13 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt
2025-04-17 11:02:51 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt
2025-04-17 11:03:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt (epoch 9 @ 1251 updates, score 6.473) (writing took 61.70494354500261 seconds)
2025-04-17 11:03:15 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2025-04-17 11:03:15 | INFO | train | epoch 009 | loss 6.536 | nll_loss 3.22 | ppl 9.32 | wps 1881.3 | ups 0.31 | wpb 6008.3 | bsz 229.1 | num_updates 1251 | lr 1.5012e-05 | gnorm 1.525 | train_wall 366 | gb_free 15.6 | wall 3987
2025-04-17 11:03:15 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:hi-mr': 31849}; raw total size: 31849
2025-04-17 11:03:15 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:hi-mr': 31849}; resampled total size: 31849
2025-04-17 11:03:15 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:hi-mr': 1.0}
2025-04-17 11:03:15 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001113
2025-04-17 11:03:15 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=24431.1484375Mb; avail=230650.99609375Mb
2025-04-17 11:03:15 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000554
2025-04-17 11:03:15 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003485
2025-04-17 11:03:15 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=24431.1484375Mb; avail=230650.99609375Mb
2025-04-17 11:03:15 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000105
2025-04-17 11:03:15 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=24431.1484375Mb; avail=230650.99609375Mb
2025-04-17 11:03:15 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001195
2025-04-17 11:03:15 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.005123
2025-04-17 11:03:15 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=24431.1484375Mb; avail=230650.99609375Mb
2025-04-17 11:03:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 139
2025-04-17 11:03:15 | INFO | fairseq.trainer | begin training epoch 10
2025-04-17 11:03:15 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-17 11:03:18 | INFO | train_inner | epoch 010:      1 / 139 loss=6.451, nll_loss=3.089, ppl=8.51, wps=119.9, ups=0.02, wpb=4861, bsz=156, num_updates=1252, lr=1.5024e-05, gnorm=1.527, train_wall=4, gb_free=12.1, wall=3990
2025-04-17 11:03:23 | INFO | train_inner | epoch 010:      3 / 139 loss=6.44, nll_loss=3.074, ppl=8.42, wps=2134.2, ups=0.38, wpb=5642.5, bsz=176, num_updates=1254, lr=1.5048e-05, gnorm=1.505, train_wall=5, gb_free=11.7, wall=3995
2025-04-17 11:03:28 | INFO | train_inner | epoch 010:      5 / 139 loss=6.326, nll_loss=2.967, ppl=7.82, wps=2440.4, ups=0.39, wpb=6266, bsz=332, num_updates=1256, lr=1.5072e-05, gnorm=1.525, train_wall=5, gb_free=10.7, wall=4001
2025-04-17 11:03:33 | INFO | train_inner | epoch 010:      7 / 139 loss=6.518, nll_loss=3.23, ppl=9.38, wps=2563.4, ups=0.38, wpb=6693.5, bsz=244, num_updates=1258, lr=1.5096e-05, gnorm=1.391, train_wall=5, gb_free=13, wall=4006
2025-04-17 11:03:38 | INFO | train_inner | epoch 010:      9 / 139 loss=6.315, nll_loss=2.959, ppl=7.78, wps=2488.3, ups=0.38, wpb=6487.5, bsz=288, num_updates=1260, lr=1.512e-05, gnorm=1.46, train_wall=5, gb_free=12.3, wall=4011
2025-04-17 11:03:43 | INFO | train_inner | epoch 010:     11 / 139 loss=6.429, nll_loss=3.084, ppl=8.48, wps=2171.5, ups=0.4, wpb=5364.5, bsz=196, num_updates=1262, lr=1.5144e-05, gnorm=1.586, train_wall=5, gb_free=10.5, wall=4016
2025-04-17 11:03:48 | INFO | train_inner | epoch 010:     13 / 139 loss=6.551, nll_loss=3.224, ppl=9.34, wps=2355.8, ups=0.39, wpb=5974.5, bsz=180, num_updates=1264, lr=1.5168e-05, gnorm=1.394, train_wall=5, gb_free=11.6, wall=4021
2025-04-17 11:03:59 | INFO | train_inner | epoch 010:     15 / 139 loss=6.428, nll_loss=3.064, ppl=8.36, wps=1307.7, ups=0.19, wpb=6770, bsz=276, num_updates=1266, lr=1.5192e-05, gnorm=1.374, train_wall=10, gb_free=12.6, wall=4031
2025-04-17 11:04:04 | INFO | train_inner | epoch 010:     17 / 139 loss=6.569, nll_loss=3.241, ppl=9.46, wps=2138.6, ups=0.41, wpb=5218, bsz=80, num_updates=1268, lr=1.5216e-05, gnorm=1.562, train_wall=5, gb_free=14.8, wall=4036
2025-04-17 11:04:09 | INFO | train_inner | epoch 010:     19 / 139 loss=6.341, nll_loss=2.978, ppl=7.88, wps=2171.6, ups=0.38, wpb=5641, bsz=240, num_updates=1270, lr=1.524e-05, gnorm=1.457, train_wall=5, gb_free=12, wall=4041
2025-04-17 11:04:14 | INFO | train_inner | epoch 010:     21 / 139 loss=6.52, nll_loss=3.218, ppl=9.3, wps=2254.9, ups=0.4, wpb=5640.5, bsz=192, num_updates=1272, lr=1.5264e-05, gnorm=1.522, train_wall=5, gb_free=12.1, wall=4046
2025-04-17 11:04:19 | INFO | train_inner | epoch 010:     23 / 139 loss=6.416, nll_loss=3.094, ppl=8.54, wps=2386.7, ups=0.41, wpb=5869.5, bsz=284, num_updates=1274, lr=1.5288e-05, gnorm=1.461, train_wall=5, gb_free=9.8, wall=4051
2025-04-17 11:04:24 | INFO | train_inner | epoch 010:     25 / 139 loss=6.553, nll_loss=3.237, ppl=9.43, wps=2247.4, ups=0.36, wpb=6299.5, bsz=232, num_updates=1276, lr=1.5312e-05, gnorm=1.358, train_wall=6, gb_free=10.6, wall=4057
2025-04-17 11:04:29 | INFO | train_inner | epoch 010:     27 / 139 loss=6.415, nll_loss=3.059, ppl=8.33, wps=2306.5, ups=0.44, wpb=5222.5, bsz=184.5, num_updates=1278, lr=1.5336e-05, gnorm=1.544, train_wall=5, gb_free=14.7, wall=4061
2025-04-17 11:04:35 | INFO | train_inner | epoch 010:     29 / 139 loss=6.413, nll_loss=3.043, ppl=8.24, wps=2379.6, ups=0.35, wpb=6858, bsz=284, num_updates=1280, lr=1.536e-05, gnorm=1.379, train_wall=6, gb_free=9.7, wall=4067
2025-04-17 11:04:40 | INFO | train_inner | epoch 010:     31 / 139 loss=6.341, nll_loss=2.979, ppl=7.88, wps=2464.9, ups=0.37, wpb=6590, bsz=272, num_updates=1282, lr=1.5384e-05, gnorm=1.307, train_wall=5, gb_free=10.6, wall=4073
2025-04-17 11:04:45 | INFO | train_inner | epoch 010:     33 / 139 loss=6.313, nll_loss=2.954, ppl=7.75, wps=2518, ups=0.37, wpb=6773, bsz=264, num_updates=1284, lr=1.5408e-05, gnorm=1.319, train_wall=5, gb_free=11.3, wall=4078
2025-04-17 11:04:51 | INFO | train_inner | epoch 010:     35 / 139 loss=6.412, nll_loss=3.078, ppl=8.44, wps=2528.9, ups=0.38, wpb=6732.5, bsz=232, num_updates=1286, lr=1.5432e-05, gnorm=1.315, train_wall=5, gb_free=12.1, wall=4083
2025-04-17 11:04:56 | INFO | train_inner | epoch 010:     37 / 139 loss=6.595, nll_loss=3.313, ppl=9.94, wps=2461.9, ups=0.38, wpb=6522, bsz=260, num_updates=1288, lr=1.5456e-05, gnorm=1.663, train_wall=5, gb_free=11, wall=4089
2025-04-17 11:05:01 | INFO | train_inner | epoch 010:     39 / 139 loss=6.542, nll_loss=3.205, ppl=9.22, wps=2142.8, ups=0.4, wpb=5418, bsz=188, num_updates=1290, lr=1.548e-05, gnorm=1.571, train_wall=5, gb_free=10.6, wall=4094
2025-04-17 11:05:07 | INFO | train_inner | epoch 010:     41 / 139 loss=6.322, nll_loss=2.928, ppl=7.61, wps=2432.4, ups=0.36, wpb=6679, bsz=256, num_updates=1292, lr=1.5504e-05, gnorm=1.416, train_wall=5, gb_free=13, wall=4099
2025-04-17 11:05:12 | INFO | train_inner | epoch 010:     43 / 139 loss=6.35, nll_loss=2.99, ppl=7.95, wps=2441.5, ups=0.36, wpb=6836, bsz=304, num_updates=1294, lr=1.5528e-05, gnorm=1.314, train_wall=6, gb_free=9.8, wall=4105
2025-04-17 11:05:17 | INFO | train_inner | epoch 010:     45 / 139 loss=6.454, nll_loss=3.14, ppl=8.82, wps=2476.8, ups=0.38, wpb=6453, bsz=212, num_updates=1296, lr=1.5552e-05, gnorm=1.412, train_wall=5, gb_free=11.8, wall=4110
2025-04-17 11:05:23 | INFO | train_inner | epoch 010:     47 / 139 loss=6.413, nll_loss=3.067, ppl=8.38, wps=2341.8, ups=0.36, wpb=6523, bsz=236, num_updates=1298, lr=1.5576e-05, gnorm=1.371, train_wall=6, gb_free=11.5, wall=4116
2025-04-17 11:05:28 | INFO | train_inner | epoch 010:     49 / 139 loss=6.584, nll_loss=3.285, ppl=9.75, wps=2187.5, ups=0.42, wpb=5191, bsz=100, num_updates=1300, lr=1.56e-05, gnorm=1.975, train_wall=5, gb_free=12.9, wall=4120
2025-04-17 11:05:33 | INFO | train_inner | epoch 010:     51 / 139 loss=6.522, nll_loss=3.197, ppl=9.17, wps=2294.2, ups=0.38, wpb=5980, bsz=192, num_updates=1302, lr=1.5624e-05, gnorm=1.492, train_wall=5, gb_free=11.5, wall=4125
2025-04-17 11:05:38 | INFO | train_inner | epoch 010:     53 / 139 loss=6.482, nll_loss=3.143, ppl=8.83, wps=1750.2, ups=0.38, wpb=4622, bsz=260, num_updates=1304, lr=1.5648e-05, gnorm=2.367, train_wall=5, gb_free=13.2, wall=4131
2025-04-17 11:05:44 | INFO | train_inner | epoch 010:     55 / 139 loss=6.486, nll_loss=3.156, ppl=8.91, wps=2402.9, ups=0.38, wpb=6289.5, bsz=200, num_updates=1306, lr=1.5672e-05, gnorm=1.58, train_wall=5, gb_free=12.2, wall=4136
2025-04-17 11:05:49 | INFO | train_inner | epoch 010:     57 / 139 loss=6.464, nll_loss=3.135, ppl=8.79, wps=2023.5, ups=0.39, wpb=5244.5, bsz=220, num_updates=1308, lr=1.5696e-05, gnorm=1.586, train_wall=5, gb_free=12.5, wall=4141
2025-04-17 11:05:54 | INFO | train_inner | epoch 010:     59 / 139 loss=6.54, nll_loss=3.233, ppl=9.4, wps=2528.5, ups=0.37, wpb=6884, bsz=240, num_updates=1310, lr=1.572e-05, gnorm=1.829, train_wall=5, gb_free=11.8, wall=4147
2025-04-17 11:06:00 | INFO | train_inner | epoch 010:     61 / 139 loss=6.325, nll_loss=2.947, ppl=7.71, wps=2398, ups=0.37, wpb=6543.5, bsz=256, num_updates=1312, lr=1.5744e-05, gnorm=1.481, train_wall=5, gb_free=11.1, wall=4152
2025-04-17 11:06:05 | INFO | train_inner | epoch 010:     63 / 139 loss=6.475, nll_loss=3.125, ppl=8.72, wps=2255, ups=0.39, wpb=5722, bsz=156, num_updates=1314, lr=1.5768e-05, gnorm=1.797, train_wall=5, gb_free=11.7, wall=4157
2025-04-17 11:06:10 | INFO | train_inner | epoch 010:     65 / 139 loss=6.366, nll_loss=2.997, ppl=7.98, wps=2376, ups=0.36, wpb=6618, bsz=292, num_updates=1316, lr=1.5792e-05, gnorm=1.707, train_wall=6, gb_free=11.5, wall=4163
2025-04-17 11:06:15 | INFO | train_inner | epoch 010:     67 / 139 loss=6.505, nll_loss=3.198, ppl=9.18, wps=1998.6, ups=0.41, wpb=4834, bsz=152, num_updates=1318, lr=1.5816e-05, gnorm=1.6, train_wall=5, gb_free=14.2, wall=4168
2025-04-17 11:06:21 | INFO | train_inner | epoch 010:     69 / 139 loss=6.358, nll_loss=3.015, ppl=8.09, wps=2263, ups=0.36, wpb=6248, bsz=316, num_updates=1320, lr=1.584e-05, gnorm=1.455, train_wall=6, gb_free=12.7, wall=4173
2025-04-17 11:06:26 | INFO | train_inner | epoch 010:     71 / 139 loss=6.179, nll_loss=2.789, ppl=6.91, wps=2513.1, ups=0.36, wpb=6991.5, bsz=368, num_updates=1322, lr=1.5864e-05, gnorm=1.21, train_wall=6, gb_free=12.4, wall=4179
2025-04-17 11:06:31 | INFO | train_inner | epoch 010:     73 / 139 loss=6.5, nll_loss=3.166, ppl=8.97, wps=2122.3, ups=0.38, wpb=5556.5, bsz=152, num_updates=1324, lr=1.5888e-05, gnorm=1.782, train_wall=5, gb_free=11.1, wall=4184
2025-04-17 11:06:36 | INFO | train_inner | epoch 010:     75 / 139 loss=6.66, nll_loss=3.38, ppl=10.41, wps=2104.9, ups=0.43, wpb=4904, bsz=176, num_updates=1326, lr=1.5912e-05, gnorm=1.597, train_wall=5, gb_free=13.2, wall=4189
2025-04-17 11:06:41 | INFO | train_inner | epoch 010:     77 / 139 loss=6.473, nll_loss=3.142, ppl=8.83, wps=2335.3, ups=0.38, wpb=6125, bsz=260, num_updates=1328, lr=1.5936e-05, gnorm=1.434, train_wall=5, gb_free=11.3, wall=4194
2025-04-17 11:06:47 | INFO | train_inner | epoch 010:     79 / 139 loss=6.379, nll_loss=3.014, ppl=8.08, wps=2093.6, ups=0.37, wpb=5622, bsz=164, num_updates=1330, lr=1.596e-05, gnorm=1.629, train_wall=5, gb_free=13.7, wall=4199
2025-04-17 11:06:52 | INFO | train_inner | epoch 010:     81 / 139 loss=6.387, nll_loss=3.047, ppl=8.27, wps=2414.8, ups=0.38, wpb=6355.5, bsz=248, num_updates=1332, lr=1.5984e-05, gnorm=1.34, train_wall=5, gb_free=12.8, wall=4204
2025-04-17 11:06:57 | INFO | train_inner | epoch 010:     83 / 139 loss=6.396, nll_loss=3.047, ppl=8.27, wps=2254.6, ups=0.38, wpb=6008, bsz=180, num_updates=1334, lr=1.6008e-05, gnorm=1.349, train_wall=5, gb_free=11.1, wall=4210
2025-04-17 11:07:02 | INFO | train_inner | epoch 010:     85 / 139 loss=6.473, nll_loss=3.147, ppl=8.86, wps=2409.8, ups=0.39, wpb=6178, bsz=188, num_updates=1336, lr=1.6032e-05, gnorm=1.318, train_wall=5, gb_free=11.6, wall=4215
2025-04-17 11:07:07 | INFO | train_inner | epoch 010:     87 / 139 loss=6.4, nll_loss=3.045, ppl=8.25, wps=2187.2, ups=0.4, wpb=5489.5, bsz=240, num_updates=1338, lr=1.6056e-05, gnorm=1.536, train_wall=5, gb_free=13, wall=4220
2025-04-17 11:07:12 | INFO | train_inner | epoch 010:     89 / 139 loss=6.416, nll_loss=3.055, ppl=8.31, wps=2050.8, ups=0.4, wpb=5146, bsz=236, num_updates=1340, lr=1.608e-05, gnorm=1.696, train_wall=5, gb_free=13.7, wall=4225
2025-04-17 11:07:17 | INFO | train_inner | epoch 010:     91 / 139 loss=6.374, nll_loss=3.016, ppl=8.09, wps=2312.3, ups=0.4, wpb=5782, bsz=188, num_updates=1342, lr=1.6104e-05, gnorm=1.383, train_wall=5, gb_free=11.7, wall=4230
2025-04-17 11:07:23 | INFO | train_inner | epoch 010:     93 / 139 loss=6.294, nll_loss=2.93, ppl=7.62, wps=2357.2, ups=0.35, wpb=6728, bsz=316, num_updates=1344, lr=1.6128e-05, gnorm=1.257, train_wall=6, gb_free=10.7, wall=4236
2025-04-17 11:07:28 | INFO | train_inner | epoch 010:     95 / 139 loss=6.3, nll_loss=2.946, ppl=7.71, wps=2374.2, ups=0.38, wpb=6223, bsz=288, num_updates=1346, lr=1.6152e-05, gnorm=1.344, train_wall=5, gb_free=12.3, wall=4241
2025-04-17 11:07:34 | INFO | train_inner | epoch 010:     97 / 139 loss=6.275, nll_loss=2.898, ppl=7.46, wps=2370.6, ups=0.37, wpb=6458, bsz=284, num_updates=1348, lr=1.6176e-05, gnorm=1.263, train_wall=5, gb_free=12, wall=4246
2025-04-17 11:07:38 | INFO | train_inner | epoch 010:     99 / 139 loss=6.328, nll_loss=2.939, ppl=7.67, wps=1900.7, ups=0.43, wpb=4430.5, bsz=152, num_updates=1350, lr=1.62e-05, gnorm=1.669, train_wall=5, gb_free=12, wall=4251
2025-04-17 11:07:44 | INFO | train_inner | epoch 010:    101 / 139 loss=6.483, nll_loss=3.146, ppl=8.85, wps=2234.5, ups=0.37, wpb=6049.5, bsz=252, num_updates=1352, lr=1.6224e-05, gnorm=1.668, train_wall=5, gb_free=10.2, wall=4256
2025-04-17 11:07:49 | INFO | train_inner | epoch 010:    103 / 139 loss=6.319, nll_loss=2.949, ppl=7.72, wps=2335.7, ups=0.4, wpb=5818.5, bsz=204, num_updates=1354, lr=1.6248e-05, gnorm=1.287, train_wall=5, gb_free=14.8, wall=4261
2025-04-17 11:07:54 | INFO | train_inner | epoch 010:    105 / 139 loss=6.446, nll_loss=3.126, ppl=8.73, wps=2206.1, ups=0.41, wpb=5439.5, bsz=220, num_updates=1356, lr=1.6272e-05, gnorm=1.574, train_wall=5, gb_free=10.6, wall=4266
2025-04-17 11:07:59 | INFO | train_inner | epoch 010:    107 / 139 loss=6.524, nll_loss=3.205, ppl=9.22, wps=2149.7, ups=0.36, wpb=5940, bsz=196, num_updates=1358, lr=1.6296e-05, gnorm=1.407, train_wall=6, gb_free=9.2, wall=4272
2025-04-17 11:08:05 | INFO | train_inner | epoch 010:    109 / 139 loss=6.355, nll_loss=2.992, ppl=7.95, wps=2444.9, ups=0.38, wpb=6369, bsz=264, num_updates=1360, lr=1.632e-05, gnorm=1.287, train_wall=5, gb_free=12.4, wall=4277
2025-04-17 11:08:10 | INFO | train_inner | epoch 010:    111 / 139 loss=6.366, nll_loss=2.986, ppl=7.92, wps=2276.9, ups=0.38, wpb=5933.5, bsz=236, num_updates=1362, lr=1.6344e-05, gnorm=1.401, train_wall=5, gb_free=11.4, wall=4282
2025-04-17 11:08:15 | INFO | train_inner | epoch 010:    113 / 139 loss=6.32, nll_loss=2.942, ppl=7.69, wps=2300.3, ups=0.41, wpb=5674, bsz=160, num_updates=1364, lr=1.6368e-05, gnorm=1.349, train_wall=5, gb_free=13.8, wall=4287
2025-04-17 11:08:20 | INFO | train_inner | epoch 010:    115 / 139 loss=6.258, nll_loss=2.883, ppl=7.38, wps=2445.3, ups=0.41, wpb=5991.5, bsz=216, num_updates=1366, lr=1.6392e-05, gnorm=1.354, train_wall=5, gb_free=12.9, wall=4292
2025-04-17 11:08:25 | INFO | train_inner | epoch 010:    117 / 139 loss=6.413, nll_loss=3.073, ppl=8.41, wps=2081.9, ups=0.4, wpb=5263, bsz=160, num_updates=1368, lr=1.6416e-05, gnorm=1.39, train_wall=5, gb_free=12.1, wall=4297
2025-04-17 11:08:30 | INFO | train_inner | epoch 010:    119 / 139 loss=6.441, nll_loss=3.093, ppl=8.54, wps=2264, ups=0.39, wpb=5734.5, bsz=120, num_updates=1370, lr=1.644e-05, gnorm=1.439, train_wall=5, gb_free=12.1, wall=4302
2025-04-17 11:08:35 | INFO | train_inner | epoch 010:    121 / 139 loss=6.447, nll_loss=3.116, ppl=8.67, wps=2305.1, ups=0.38, wpb=5997.5, bsz=232, num_updates=1372, lr=1.6464e-05, gnorm=1.556, train_wall=5, gb_free=11.5, wall=4307
2025-04-17 11:08:40 | INFO | train_inner | epoch 010:    123 / 139 loss=6.327, nll_loss=2.962, ppl=7.79, wps=2374.7, ups=0.37, wpb=6428.5, bsz=284, num_updates=1374, lr=1.6488e-05, gnorm=1.385, train_wall=5, gb_free=11.4, wall=4313
2025-04-17 11:08:46 | INFO | train_inner | epoch 010:    125 / 139 loss=6.438, nll_loss=3.106, ppl=8.61, wps=2465, ups=0.35, wpb=6962, bsz=300, num_updates=1376, lr=1.6512e-05, gnorm=1.313, train_wall=6, gb_free=10.9, wall=4318
2025-04-17 11:08:52 | INFO | train_inner | epoch 010:    127 / 139 loss=6.233, nll_loss=2.829, ppl=7.11, wps=2421.2, ups=0.35, wpb=6911, bsz=284, num_updates=1378, lr=1.6536e-05, gnorm=1.344, train_wall=6, gb_free=11, wall=4324
2025-04-17 11:08:57 | INFO | train_inner | epoch 010:    129 / 139 loss=6.334, nll_loss=2.967, ppl=7.82, wps=2351.9, ups=0.35, wpb=6793.5, bsz=300, num_updates=1380, lr=1.656e-05, gnorm=1.287, train_wall=6, gb_free=10.4, wall=4330
2025-04-17 11:09:03 | INFO | train_inner | epoch 010:    131 / 139 loss=6.497, nll_loss=3.199, ppl=9.18, wps=2297.5, ups=0.34, wpb=6733.5, bsz=368, num_updates=1382, lr=1.6584e-05, gnorm=1.608, train_wall=6, gb_free=10.3, wall=4336
2025-04-17 11:09:09 | INFO | train_inner | epoch 010:    133 / 139 loss=6.381, nll_loss=3.04, ppl=8.23, wps=2274, ups=0.39, wpb=5870, bsz=196, num_updates=1384, lr=1.6608e-05, gnorm=1.513, train_wall=5, gb_free=11.8, wall=4341
2025-04-17 11:09:14 | INFO | train_inner | epoch 010:    135 / 139 loss=6.343, nll_loss=2.961, ppl=7.79, wps=2294, ups=0.38, wpb=6017, bsz=204, num_updates=1386, lr=1.6632e-05, gnorm=1.451, train_wall=5, gb_free=13.8, wall=4346
2025-04-17 11:09:19 | INFO | train_inner | epoch 010:    137 / 139 loss=6.43, nll_loss=3.064, ppl=8.36, wps=2075.5, ups=0.4, wpb=5250.5, bsz=184, num_updates=1388, lr=1.6656e-05, gnorm=1.476, train_wall=5, gb_free=12.3, wall=4351
2025-04-17 11:09:23 | INFO | train_inner | epoch 010:    139 / 139 loss=6.112, nll_loss=2.691, ppl=6.46, wps=2331.6, ups=0.5, wpb=4627.5, bsz=220, num_updates=1390, lr=1.668e-05, gnorm=1.361, train_wall=4, gb_free=15.9, wall=4355
2025-04-17 11:09:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-17 11:09:23 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=15222.26171875Mb; avail=239859.87890625Mb
2025-04-17 11:09:23 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000632
2025-04-17 11:09:23 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15222.26171875Mb; avail=239859.87890625Mb
2025-04-17 11:09:23 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012691
2025-04-17 11:09:23 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15222.26171875Mb; avail=239859.87890625Mb
2025-04-17 11:09:23 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.011129
2025-04-17 11:09:23 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024809
2025-04-17 11:09:23 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15222.26171875Mb; avail=239859.87890625Mb
2025-04-17 11:09:38 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 6.364 | nll_loss 2.865 | ppl 7.28 | wps 5350.2 | wpb 2350.9 | bsz 94.7 | num_updates 1390 | best_loss 6.364
2025-04-17 11:09:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1390 updates
2025-04-17 11:09:38 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt
2025-04-17 11:10:16 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt
2025-04-17 11:10:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt (epoch 10 @ 1390 updates, score 6.364) (writing took 61.62000081400038 seconds)
2025-04-17 11:10:40 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2025-04-17 11:10:40 | INFO | train | epoch 010 | loss 6.41 | nll_loss 3.063 | ppl 8.36 | wps 1877.9 | ups 0.31 | wpb 6008.3 | bsz 229.1 | num_updates 1390 | lr 1.668e-05 | gnorm 1.482 | train_wall 367 | gb_free 15.9 | wall 4432
2025-04-17 11:10:40 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:hi-mr': 31849}; raw total size: 31849
2025-04-17 11:10:40 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:hi-mr': 31849}; resampled total size: 31849
2025-04-17 11:10:40 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:hi-mr': 1.0}
2025-04-17 11:10:40 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001070
2025-04-17 11:10:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=25347.9375Mb; avail=229734.1484375Mb
2025-04-17 11:10:40 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000573
2025-04-17 11:10:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003310
2025-04-17 11:10:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=25348.4296875Mb; avail=229733.65625Mb
2025-04-17 11:10:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000087
2025-04-17 11:10:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=25348.4296875Mb; avail=229733.65625Mb
2025-04-17 11:10:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001179
2025-04-17 11:10:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.004883
2025-04-17 11:10:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=25348.4296875Mb; avail=229733.65625Mb
2025-04-17 11:10:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 139
2025-04-17 11:10:40 | INFO | fairseq.trainer | begin training epoch 11
2025-04-17 11:10:40 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-17 11:10:45 | INFO | train_inner | epoch 011:      2 / 139 loss=6.444, nll_loss=3.132, ppl=8.76, wps=146.5, ups=0.02, wpb=6012.5, bsz=168, num_updates=1392, lr=1.6704e-05, gnorm=1.49, train_wall=5, gb_free=13.3, wall=4437
2025-04-17 11:10:50 | INFO | train_inner | epoch 011:      4 / 139 loss=6.309, nll_loss=2.955, ppl=7.75, wps=2329.6, ups=0.39, wpb=5943, bsz=216, num_updates=1394, lr=1.6728e-05, gnorm=1.569, train_wall=5, gb_free=12.4, wall=4442
2025-04-17 11:10:55 | INFO | train_inner | epoch 011:      6 / 139 loss=6.252, nll_loss=2.856, ppl=7.24, wps=2694.2, ups=0.39, wpb=6868.5, bsz=276, num_updates=1396, lr=1.6752e-05, gnorm=1.555, train_wall=5, gb_free=11, wall=4448
2025-04-17 11:11:00 | INFO | train_inner | epoch 011:      8 / 139 loss=6.288, nll_loss=2.874, ppl=7.33, wps=2410.5, ups=0.37, wpb=6498, bsz=220, num_updates=1398, lr=1.6776e-05, gnorm=1.281, train_wall=5, gb_free=11.4, wall=4453
2025-04-17 11:11:06 | INFO | train_inner | epoch 011:     10 / 139 loss=6.245, nll_loss=2.842, ppl=7.17, wps=2510.9, ups=0.37, wpb=6765, bsz=308, num_updates=1400, lr=1.68e-05, gnorm=1.287, train_wall=5, gb_free=12.4, wall=4458
2025-04-17 11:11:11 | INFO | train_inner | epoch 011:     12 / 139 loss=6.206, nll_loss=2.823, ppl=7.07, wps=2335, ups=0.37, wpb=6392, bsz=292, num_updates=1402, lr=1.6824e-05, gnorm=1.203, train_wall=5, gb_free=9.8, wall=4464
2025-04-17 11:11:16 | INFO | train_inner | epoch 011:     14 / 139 loss=6.244, nll_loss=2.881, ppl=7.37, wps=2533.1, ups=0.39, wpb=6540.5, bsz=324, num_updates=1404, lr=1.6848e-05, gnorm=1.222, train_wall=5, gb_free=13.1, wall=4469
2025-04-17 11:11:22 | INFO | train_inner | epoch 011:     16 / 139 loss=6.203, nll_loss=2.798, ppl=6.95, wps=2300.5, ups=0.36, wpb=6307, bsz=260, num_updates=1406, lr=1.6872e-05, gnorm=1.265, train_wall=5, gb_free=12.5, wall=4474
2025-04-17 11:11:27 | INFO | train_inner | epoch 011:     18 / 139 loss=6.353, nll_loss=2.972, ppl=7.85, wps=2180.1, ups=0.39, wpb=5652, bsz=232, num_updates=1408, lr=1.6896e-05, gnorm=1.573, train_wall=5, gb_free=13.5, wall=4480
2025-04-17 11:11:33 | INFO | train_inner | epoch 011:     20 / 139 loss=6.129, nll_loss=2.698, ppl=6.49, wps=2511.3, ups=0.36, wpb=6907, bsz=304, num_updates=1410, lr=1.692e-05, gnorm=1.173, train_wall=5, gb_free=10.7, wall=4485
2025-04-17 11:11:38 | INFO | train_inner | epoch 011:     22 / 139 loss=6.221, nll_loss=2.832, ppl=7.12, wps=2397, ups=0.38, wpb=6329.5, bsz=200, num_updates=1412, lr=1.6944e-05, gnorm=1.357, train_wall=5, gb_free=11.6, wall=4490
2025-04-17 11:11:42 | INFO | train_inner | epoch 011:     24 / 139 loss=6.255, nll_loss=2.897, ppl=7.45, wps=2403.8, ups=0.44, wpb=5460.5, bsz=180, num_updates=1414, lr=1.6968e-05, gnorm=1.533, train_wall=5, gb_free=15.8, wall=4495
2025-04-17 11:11:47 | INFO | train_inner | epoch 011:     26 / 139 loss=6.196, nll_loss=2.793, ppl=6.93, wps=2388.1, ups=0.4, wpb=5940.5, bsz=272, num_updates=1416, lr=1.6992e-05, gnorm=1.367, train_wall=5, gb_free=11.8, wall=4500
2025-04-17 11:11:53 | INFO | train_inner | epoch 011:     28 / 139 loss=6.313, nll_loss=2.919, ppl=7.56, wps=2451.3, ups=0.36, wpb=6799.5, bsz=268, num_updates=1418, lr=1.7016e-05, gnorm=1.343, train_wall=6, gb_free=10.5, wall=4505
2025-04-17 11:11:58 | INFO | train_inner | epoch 011:     30 / 139 loss=6.315, nll_loss=2.929, ppl=7.61, wps=1941.8, ups=0.37, wpb=5244, bsz=224, num_updates=1420, lr=1.704e-05, gnorm=1.545, train_wall=5, gb_free=9.6, wall=4511
2025-04-17 11:12:04 | INFO | train_inner | epoch 011:     32 / 139 loss=6.209, nll_loss=2.82, ppl=7.06, wps=2422.5, ups=0.35, wpb=6899.5, bsz=348, num_updates=1422, lr=1.7064e-05, gnorm=1.302, train_wall=6, gb_free=10, wall=4517
2025-04-17 11:12:09 | INFO | train_inner | epoch 011:     34 / 139 loss=6.465, nll_loss=3.149, ppl=8.87, wps=2098.8, ups=0.38, wpb=5492, bsz=176, num_updates=1424, lr=1.7088e-05, gnorm=1.627, train_wall=5, gb_free=12.8, wall=4522
2025-04-17 11:12:14 | INFO | train_inner | epoch 011:     36 / 139 loss=6.341, nll_loss=2.979, ppl=7.88, wps=2374.1, ups=0.39, wpb=6059, bsz=136, num_updates=1426, lr=1.7112e-05, gnorm=1.486, train_wall=5, gb_free=14, wall=4527
2025-04-17 11:12:20 | INFO | train_inner | epoch 011:     38 / 139 loss=6.275, nll_loss=2.888, ppl=7.4, wps=2447.8, ups=0.38, wpb=6428.5, bsz=220, num_updates=1428, lr=1.7136e-05, gnorm=1.282, train_wall=5, gb_free=12.1, wall=4532
2025-04-17 11:12:25 | INFO | train_inner | epoch 011:     40 / 139 loss=6.357, nll_loss=2.979, ppl=7.88, wps=2178.8, ups=0.38, wpb=5712, bsz=208, num_updates=1430, lr=1.716e-05, gnorm=1.617, train_wall=5, gb_free=11.2, wall=4537
2025-04-17 11:12:30 | INFO | train_inner | epoch 011:     42 / 139 loss=6.38, nll_loss=3.028, ppl=8.16, wps=2115, ups=0.38, wpb=5512, bsz=196, num_updates=1432, lr=1.7184e-05, gnorm=1.491, train_wall=5, gb_free=11.4, wall=4543
2025-04-17 11:12:35 | INFO | train_inner | epoch 011:     44 / 139 loss=6.396, nll_loss=3.054, ppl=8.31, wps=2062.7, ups=0.38, wpb=5388, bsz=196, num_updates=1434, lr=1.7208e-05, gnorm=1.353, train_wall=5, gb_free=13, wall=4548
2025-04-17 11:12:40 | INFO | train_inner | epoch 011:     46 / 139 loss=6.447, nll_loss=3.125, ppl=8.72, wps=2356.5, ups=0.39, wpb=6060, bsz=152, num_updates=1436, lr=1.7232e-05, gnorm=1.503, train_wall=5, gb_free=10.5, wall=4553
2025-04-17 11:12:51 | INFO | train_inner | epoch 011:     48 / 139 loss=6.355, nll_loss=3.005, ppl=8.03, wps=1185.6, ups=0.19, wpb=6359.5, bsz=308, num_updates=1438, lr=1.7256e-05, gnorm=1.409, train_wall=11, gb_free=10.3, wall=4564
2025-04-17 11:12:56 | INFO | train_inner | epoch 011:     50 / 139 loss=6.289, nll_loss=2.88, ppl=7.36, wps=2346.1, ups=0.39, wpb=6008.5, bsz=176, num_updates=1440, lr=1.728e-05, gnorm=1.537, train_wall=5, gb_free=15.3, wall=4569
2025-04-17 11:13:01 | INFO | train_inner | epoch 011:     52 / 139 loss=6.343, nll_loss=2.956, ppl=7.76, wps=2390.2, ups=0.44, wpb=5433.5, bsz=208.5, num_updates=1442, lr=1.7304e-05, gnorm=1.605, train_wall=5, gb_free=16.1, wall=4573
2025-04-17 11:13:06 | INFO | train_inner | epoch 011:     54 / 139 loss=6.4, nll_loss=3.044, ppl=8.25, wps=2215.1, ups=0.37, wpb=5975.5, bsz=184, num_updates=1444, lr=1.7328e-05, gnorm=1.553, train_wall=5, gb_free=11.8, wall=4579
2025-04-17 11:13:12 | INFO | train_inner | epoch 011:     56 / 139 loss=6.184, nll_loss=2.815, ppl=7.03, wps=2318.4, ups=0.37, wpb=6334.5, bsz=288, num_updates=1446, lr=1.7352e-05, gnorm=1.51, train_wall=5, gb_free=10.5, wall=4584
2025-04-17 11:13:17 | INFO | train_inner | epoch 011:     58 / 139 loss=6.273, nll_loss=2.91, ppl=7.51, wps=2348.7, ups=0.36, wpb=6512.5, bsz=296, num_updates=1448, lr=1.7376e-05, gnorm=1.457, train_wall=6, gb_free=10.5, wall=4590
2025-04-17 11:13:23 | INFO | train_inner | epoch 011:     60 / 139 loss=6.271, nll_loss=2.873, ppl=7.32, wps=2181.9, ups=0.38, wpb=5695, bsz=192, num_updates=1450, lr=1.74e-05, gnorm=1.362, train_wall=5, gb_free=13.9, wall=4595
2025-04-17 11:13:28 | INFO | train_inner | epoch 011:     62 / 139 loss=6.373, nll_loss=3.006, ppl=8.04, wps=2135.1, ups=0.39, wpb=5484.5, bsz=232, num_updates=1452, lr=1.7424e-05, gnorm=1.674, train_wall=5, gb_free=12.6, wall=4600
2025-04-17 11:13:33 | INFO | train_inner | epoch 011:     64 / 139 loss=6.291, nll_loss=2.912, ppl=7.53, wps=2376.7, ups=0.37, wpb=6449.5, bsz=296, num_updates=1454, lr=1.7448e-05, gnorm=1.558, train_wall=5, gb_free=12.2, wall=4606
2025-04-17 11:13:38 | INFO | train_inner | epoch 011:     66 / 139 loss=6.325, nll_loss=2.971, ppl=7.84, wps=2556.1, ups=0.38, wpb=6687.5, bsz=304, num_updates=1456, lr=1.7472e-05, gnorm=1.389, train_wall=5, gb_free=10.3, wall=4611
2025-04-17 11:13:44 | INFO | train_inner | epoch 011:     68 / 139 loss=6.365, nll_loss=3.01, ppl=8.06, wps=2359.4, ups=0.38, wpb=6150.5, bsz=188, num_updates=1458, lr=1.7496e-05, gnorm=1.458, train_wall=5, gb_free=12.9, wall=4616
2025-04-17 11:13:49 | INFO | train_inner | epoch 011:     70 / 139 loss=6.292, nll_loss=2.928, ppl=7.61, wps=2260.1, ups=0.37, wpb=6148, bsz=248, num_updates=1460, lr=1.752e-05, gnorm=1.703, train_wall=5, gb_free=11, wall=4621
2025-04-17 11:13:54 | INFO | train_inner | epoch 011:     72 / 139 loss=6.275, nll_loss=2.891, ppl=7.42, wps=2296.4, ups=0.37, wpb=6248.5, bsz=228, num_updates=1462, lr=1.7544e-05, gnorm=1.485, train_wall=5, gb_free=11, wall=4627
2025-04-17 11:14:00 | INFO | train_inner | epoch 011:     74 / 139 loss=6.234, nll_loss=2.834, ppl=7.13, wps=2502.9, ups=0.37, wpb=6786.5, bsz=232, num_updates=1464, lr=1.7568e-05, gnorm=1.458, train_wall=5, gb_free=11.7, wall=4632
2025-04-17 11:14:05 | INFO | train_inner | epoch 011:     76 / 139 loss=6.219, nll_loss=2.817, ppl=7.05, wps=2109.7, ups=0.42, wpb=5042.5, bsz=168, num_updates=1466, lr=1.7592e-05, gnorm=1.486, train_wall=5, gb_free=11, wall=4637
2025-04-17 11:14:10 | INFO | train_inner | epoch 011:     78 / 139 loss=6.173, nll_loss=2.776, ppl=6.85, wps=2366, ups=0.35, wpb=6739.5, bsz=356, num_updates=1468, lr=1.7616e-05, gnorm=1.179, train_wall=6, gb_free=11.3, wall=4643
2025-04-17 11:14:16 | INFO | train_inner | epoch 011:     80 / 139 loss=6.35, nll_loss=2.994, ppl=7.97, wps=2438.7, ups=0.37, wpb=6522.5, bsz=220, num_updates=1470, lr=1.764e-05, gnorm=1.324, train_wall=5, gb_free=11.3, wall=4648
2025-04-17 11:14:21 | INFO | train_inner | epoch 011:     82 / 139 loss=6.364, nll_loss=3.011, ppl=8.06, wps=2199.2, ups=0.38, wpb=5811.5, bsz=204, num_updates=1472, lr=1.7664e-05, gnorm=1.356, train_wall=5, gb_free=12.9, wall=4653
2025-04-17 11:14:26 | INFO | train_inner | epoch 011:     84 / 139 loss=6.187, nll_loss=2.789, ppl=6.91, wps=2207.6, ups=0.38, wpb=5797, bsz=276, num_updates=1474, lr=1.7688e-05, gnorm=1.308, train_wall=5, gb_free=11.3, wall=4659
2025-04-17 11:14:31 | INFO | train_inner | epoch 011:     86 / 139 loss=6.214, nll_loss=2.824, ppl=7.08, wps=2404, ups=0.38, wpb=6332, bsz=268, num_updates=1476, lr=1.7712e-05, gnorm=1.252, train_wall=5, gb_free=11.2, wall=4664
2025-04-17 11:14:37 | INFO | train_inner | epoch 011:     88 / 139 loss=6.283, nll_loss=2.892, ppl=7.43, wps=2320, ups=0.37, wpb=6299, bsz=224, num_updates=1478, lr=1.7736e-05, gnorm=1.334, train_wall=5, gb_free=11.2, wall=4669
2025-04-17 11:14:42 | INFO | train_inner | epoch 011:     90 / 139 loss=6.25, nll_loss=2.854, ppl=7.23, wps=2286.6, ups=0.37, wpb=6180, bsz=232, num_updates=1480, lr=1.776e-05, gnorm=1.278, train_wall=5, gb_free=10.7, wall=4675
2025-04-17 11:14:47 | INFO | train_inner | epoch 011:     92 / 139 loss=6.258, nll_loss=2.879, ppl=7.36, wps=2186.6, ups=0.39, wpb=5579.5, bsz=216, num_updates=1482, lr=1.7784e-05, gnorm=1.386, train_wall=5, gb_free=12, wall=4680
2025-04-17 11:14:53 | INFO | train_inner | epoch 011:     94 / 139 loss=6.342, nll_loss=2.987, ppl=7.93, wps=2255.2, ups=0.33, wpb=6735.5, bsz=332, num_updates=1484, lr=1.7808e-05, gnorm=1.491, train_wall=6, gb_free=10.4, wall=4686
2025-04-17 11:14:58 | INFO | train_inner | epoch 011:     96 / 139 loss=6.156, nll_loss=2.748, ppl=6.72, wps=2145.9, ups=0.41, wpb=5286.5, bsz=244, num_updates=1486, lr=1.7832e-05, gnorm=1.457, train_wall=5, gb_free=10.7, wall=4691
2025-04-17 11:15:03 | INFO | train_inner | epoch 011:     98 / 139 loss=6.382, nll_loss=3.032, ppl=8.18, wps=2176, ups=0.4, wpb=5377, bsz=140, num_updates=1488, lr=1.7856e-05, gnorm=1.435, train_wall=5, gb_free=11.4, wall=4696
2025-04-17 11:15:08 | INFO | train_inner | epoch 011:    100 / 139 loss=6.274, nll_loss=2.901, ppl=7.47, wps=2264.7, ups=0.38, wpb=5922, bsz=212, num_updates=1490, lr=1.788e-05, gnorm=1.321, train_wall=5, gb_free=13.1, wall=4701
2025-04-17 11:15:13 | INFO | train_inner | epoch 011:    102 / 139 loss=6.406, nll_loss=3.058, ppl=8.33, wps=2022.1, ups=0.44, wpb=4607.5, bsz=80, num_updates=1492, lr=1.7904e-05, gnorm=1.64, train_wall=5, gb_free=12.8, wall=4706
2025-04-17 11:15:18 | INFO | train_inner | epoch 011:    104 / 139 loss=6.365, nll_loss=3.008, ppl=8.04, wps=2440, ups=0.38, wpb=6372, bsz=172, num_updates=1494, lr=1.7928e-05, gnorm=1.241, train_wall=5, gb_free=11.8, wall=4711
2025-04-17 11:15:23 | INFO | train_inner | epoch 011:    106 / 139 loss=6.41, nll_loss=3.058, ppl=8.33, wps=1915.8, ups=0.39, wpb=4871, bsz=124, num_updates=1496, lr=1.7952e-05, gnorm=1.568, train_wall=5, gb_free=11.2, wall=4716
2025-04-17 11:15:28 | INFO | train_inner | epoch 011:    108 / 139 loss=6.359, nll_loss=2.986, ppl=7.92, wps=2109.8, ups=0.4, wpb=5339.5, bsz=196, num_updates=1498, lr=1.7976e-05, gnorm=1.313, train_wall=5, gb_free=11.7, wall=4721
2025-04-17 11:15:34 | INFO | train_inner | epoch 011:    110 / 139 loss=6.288, nll_loss=2.903, ppl=7.48, wps=2454.7, ups=0.39, wpb=6305, bsz=212, num_updates=1500, lr=1.8e-05, gnorm=1.274, train_wall=5, gb_free=12.3, wall=4726
2025-04-17 11:15:39 | INFO | train_inner | epoch 011:    112 / 139 loss=6.289, nll_loss=2.913, ppl=7.53, wps=2257.3, ups=0.39, wpb=5862.5, bsz=196, num_updates=1502, lr=1.8024e-05, gnorm=1.455, train_wall=5, gb_free=14.3, wall=4731
2025-04-17 11:15:44 | INFO | train_inner | epoch 011:    114 / 139 loss=6.278, nll_loss=2.914, ppl=7.54, wps=2297.1, ups=0.37, wpb=6196.5, bsz=324, num_updates=1504, lr=1.8048e-05, gnorm=1.666, train_wall=5, gb_free=10.5, wall=4737
2025-04-17 11:15:49 | INFO | train_inner | epoch 011:    116 / 139 loss=6.246, nll_loss=2.853, ppl=7.23, wps=2448.8, ups=0.37, wpb=6536.5, bsz=216, num_updates=1506, lr=1.8072e-05, gnorm=1.324, train_wall=5, gb_free=11.6, wall=4742
2025-04-17 11:15:55 | INFO | train_inner | epoch 011:    118 / 139 loss=6.342, nll_loss=2.972, ppl=7.85, wps=2357.9, ups=0.36, wpb=6592, bsz=296, num_updates=1508, lr=1.8096e-05, gnorm=1.362, train_wall=6, gb_free=13.5, wall=4748
2025-04-17 11:16:00 | INFO | train_inner | epoch 011:    120 / 139 loss=6.472, nll_loss=3.155, ppl=8.91, wps=2306.1, ups=0.4, wpb=5826, bsz=176, num_updates=1510, lr=1.812e-05, gnorm=1.411, train_wall=5, gb_free=10.8, wall=4753
2025-04-17 11:16:06 | INFO | train_inner | epoch 011:    122 / 139 loss=6.322, nll_loss=2.958, ppl=7.77, wps=2013.2, ups=0.35, wpb=5695.5, bsz=260, num_updates=1512, lr=1.8144e-05, gnorm=1.363, train_wall=6, gb_free=13.4, wall=4758
2025-04-17 11:16:11 | INFO | train_inner | epoch 011:    124 / 139 loss=6.312, nll_loss=2.947, ppl=7.71, wps=2413.1, ups=0.39, wpb=6252.5, bsz=184, num_updates=1514, lr=1.8168e-05, gnorm=1.354, train_wall=5, gb_free=11.7, wall=4763
2025-04-17 11:16:16 | INFO | train_inner | epoch 011:    126 / 139 loss=6.115, nll_loss=2.672, ppl=6.37, wps=2503.8, ups=0.37, wpb=6759, bsz=280, num_updates=1516, lr=1.8192e-05, gnorm=1.169, train_wall=5, gb_free=11.6, wall=4769
2025-04-17 11:16:22 | INFO | train_inner | epoch 011:    128 / 139 loss=6.377, nll_loss=3.008, ppl=8.04, wps=2147.2, ups=0.37, wpb=5835, bsz=220, num_updates=1518, lr=1.8216e-05, gnorm=1.526, train_wall=5, gb_free=11.2, wall=4774
2025-04-17 11:16:27 | INFO | train_inner | epoch 011:    130 / 139 loss=6.349, nll_loss=2.997, ppl=7.98, wps=2053.6, ups=0.38, wpb=5406.5, bsz=160, num_updates=1520, lr=1.824e-05, gnorm=1.54, train_wall=5, gb_free=11.9, wall=4780
2025-04-17 11:16:32 | INFO | train_inner | epoch 011:    132 / 139 loss=6.294, nll_loss=2.936, ppl=7.65, wps=2118.9, ups=0.37, wpb=5745.5, bsz=224, num_updates=1522, lr=1.8264e-05, gnorm=1.477, train_wall=5, gb_free=9.7, wall=4785
2025-04-17 11:16:38 | INFO | train_inner | epoch 011:    134 / 139 loss=6.253, nll_loss=2.883, ppl=7.38, wps=2263.5, ups=0.38, wpb=6030, bsz=296, num_updates=1524, lr=1.8288e-05, gnorm=1.606, train_wall=5, gb_free=11.6, wall=4790
2025-04-17 11:16:43 | INFO | train_inner | epoch 011:    136 / 139 loss=6.193, nll_loss=2.784, ppl=6.89, wps=2241.9, ups=0.41, wpb=5523.5, bsz=232, num_updates=1526, lr=1.8312e-05, gnorm=1.645, train_wall=5, gb_free=12.4, wall=4795
2025-04-17 11:16:48 | INFO | train_inner | epoch 011:    138 / 139 loss=6.373, nll_loss=3.002, ppl=8.01, wps=2042.9, ups=0.41, wpb=5019.5, bsz=144, num_updates=1528, lr=1.8336e-05, gnorm=1.49, train_wall=5, gb_free=12.6, wall=4800
2025-04-17 11:16:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-17 11:16:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=15229.26953125Mb; avail=239852.87109375Mb
2025-04-17 11:16:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000644
2025-04-17 11:16:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15229.26953125Mb; avail=239852.87109375Mb
2025-04-17 11:16:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012737
2025-04-17 11:16:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15229.26953125Mb; avail=239852.87109375Mb
2025-04-17 11:16:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.011162
2025-04-17 11:16:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024887
2025-04-17 11:16:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15229.26953125Mb; avail=239852.87109375Mb
2025-04-17 11:17:04 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 6.285 | nll_loss 2.758 | ppl 6.77 | wps 5350 | wpb 2350.9 | bsz 94.7 | num_updates 1529 | best_loss 6.285
2025-04-17 11:17:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1529 updates
2025-04-17 11:17:04 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt
2025-04-17 11:17:42 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt
2025-04-17 11:18:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt (epoch 11 @ 1529 updates, score 6.285) (writing took 61.6404347409989 seconds)
2025-04-17 11:18:06 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2025-04-17 11:18:06 | INFO | train | epoch 011 | loss 6.296 | nll_loss 2.921 | ppl 7.57 | wps 1870.7 | ups 0.31 | wpb 6008.3 | bsz 229.1 | num_updates 1529 | lr 1.8348e-05 | gnorm 1.436 | train_wall 369 | gb_free 14.9 | wall 4879
2025-04-17 11:18:06 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:hi-mr': 31849}; raw total size: 31849
2025-04-17 11:18:06 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:hi-mr': 31849}; resampled total size: 31849
2025-04-17 11:18:06 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:hi-mr': 1.0}
2025-04-17 11:18:06 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.000969
2025-04-17 11:18:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=25354.8671875Mb; avail=229727.2734375Mb
2025-04-17 11:18:06 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000703
2025-04-17 11:18:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003938
2025-04-17 11:18:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=25355.359375Mb; avail=229726.78125Mb
2025-04-17 11:18:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000089
2025-04-17 11:18:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=25355.359375Mb; avail=229726.78125Mb
2025-04-17 11:18:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001191
2025-04-17 11:18:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.005534
2025-04-17 11:18:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=25355.359375Mb; avail=229726.78125Mb
2025-04-17 11:18:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 139
2025-04-17 11:18:06 | INFO | fairseq.trainer | begin training epoch 12
2025-04-17 11:18:06 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-17 11:18:09 | INFO | train_inner | epoch 012:      1 / 139 loss=6.308, nll_loss=2.938, ppl=7.66, wps=124.1, ups=0.02, wpb=5037, bsz=184, num_updates=1530, lr=1.836e-05, gnorm=1.79, train_wall=4, gb_free=12.4, wall=4881
2025-04-17 11:18:14 | INFO | train_inner | epoch 012:      3 / 139 loss=6.186, nll_loss=2.786, ppl=6.9, wps=2570.4, ups=0.39, wpb=6644, bsz=248, num_updates=1532, lr=1.8384e-05, gnorm=1.332, train_wall=5, gb_free=11.6, wall=4887
2025-04-17 11:18:19 | INFO | train_inner | epoch 012:      5 / 139 loss=6.273, nll_loss=2.89, ppl=7.41, wps=2491, ups=0.39, wpb=6386.5, bsz=188, num_updates=1534, lr=1.8408e-05, gnorm=1.342, train_wall=5, gb_free=11.2, wall=4892
2025-04-17 11:18:24 | INFO | train_inner | epoch 012:      7 / 139 loss=6.139, nll_loss=2.713, ppl=6.56, wps=2560.6, ups=0.39, wpb=6506, bsz=232, num_updates=1536, lr=1.8432e-05, gnorm=1.268, train_wall=5, gb_free=12.7, wall=4897
2025-04-17 11:18:30 | INFO | train_inner | epoch 012:      9 / 139 loss=6.233, nll_loss=2.839, ppl=7.15, wps=2356.2, ups=0.37, wpb=6290, bsz=316, num_updates=1538, lr=1.8456e-05, gnorm=1.507, train_wall=5, gb_free=10.1, wall=4902
2025-04-17 11:18:34 | INFO | train_inner | epoch 012:     11 / 139 loss=6.298, nll_loss=2.93, ppl=7.62, wps=2094.3, ups=0.43, wpb=4913.5, bsz=128, num_updates=1540, lr=1.848e-05, gnorm=1.533, train_wall=5, gb_free=12.1, wall=4907
2025-04-17 11:18:39 | INFO | train_inner | epoch 012:     13 / 139 loss=6.146, nll_loss=2.745, ppl=6.71, wps=2361.8, ups=0.39, wpb=5991.5, bsz=292, num_updates=1542, lr=1.8504e-05, gnorm=1.341, train_wall=5, gb_free=12.8, wall=4912
2025-04-17 11:18:45 | INFO | train_inner | epoch 012:     15 / 139 loss=6.225, nll_loss=2.809, ppl=7.01, wps=2455.6, ups=0.37, wpb=6592, bsz=224, num_updates=1544, lr=1.8528e-05, gnorm=1.264, train_wall=5, gb_free=10.6, wall=4917
2025-04-17 11:18:50 | INFO | train_inner | epoch 012:     17 / 139 loss=6.196, nll_loss=2.779, ppl=6.87, wps=2212.3, ups=0.36, wpb=6084, bsz=256, num_updates=1546, lr=1.8552e-05, gnorm=1.313, train_wall=5, gb_free=9.9, wall=4923
2025-04-17 11:18:55 | INFO | train_inner | epoch 012:     19 / 139 loss=6.284, nll_loss=2.918, ppl=7.56, wps=2098.4, ups=0.44, wpb=4779, bsz=132, num_updates=1548, lr=1.8576e-05, gnorm=1.513, train_wall=5, gb_free=13.9, wall=4927
2025-04-17 11:19:00 | INFO | train_inner | epoch 012:     21 / 139 loss=6.228, nll_loss=2.87, ppl=7.31, wps=2443.5, ups=0.36, wpb=6828, bsz=328, num_updates=1550, lr=1.86e-05, gnorm=1.367, train_wall=6, gb_free=10.9, wall=4933
2025-04-17 11:19:05 | INFO | train_inner | epoch 012:     23 / 139 loss=6.201, nll_loss=2.807, ppl=7, wps=2389.8, ups=0.4, wpb=5977.5, bsz=200, num_updates=1552, lr=1.8624e-05, gnorm=1.289, train_wall=5, gb_free=14, wall=4938
2025-04-17 11:19:10 | INFO | train_inner | epoch 012:     25 / 139 loss=6.193, nll_loss=2.749, ppl=6.72, wps=2206.4, ups=0.39, wpb=5590.5, bsz=188, num_updates=1554, lr=1.8648e-05, gnorm=1.358, train_wall=5, gb_free=14.7, wall=4943
2025-04-17 11:19:15 | INFO | train_inner | epoch 012:     27 / 139 loss=6.346, nll_loss=2.954, ppl=7.75, wps=2141.2, ups=0.4, wpb=5381.5, bsz=188, num_updates=1556, lr=1.8672e-05, gnorm=1.442, train_wall=5, gb_free=10.4, wall=4948
2025-04-17 11:19:21 | INFO | train_inner | epoch 012:     29 / 139 loss=6.175, nll_loss=2.773, ppl=6.83, wps=2363.6, ups=0.36, wpb=6593, bsz=244, num_updates=1558, lr=1.8696e-05, gnorm=1.301, train_wall=6, gb_free=11.7, wall=4954
2025-04-17 11:19:26 | INFO | train_inner | epoch 012:     31 / 139 loss=6.198, nll_loss=2.812, ppl=7.02, wps=2448.8, ups=0.4, wpb=6074.5, bsz=180, num_updates=1560, lr=1.872e-05, gnorm=1.284, train_wall=5, gb_free=12.6, wall=4958
2025-04-17 11:19:31 | INFO | train_inner | epoch 012:     33 / 139 loss=6.28, nll_loss=2.907, ppl=7.5, wps=2286.1, ups=0.39, wpb=5879.5, bsz=172, num_updates=1562, lr=1.8744e-05, gnorm=1.36, train_wall=5, gb_free=13, wall=4964
2025-04-17 11:19:36 | INFO | train_inner | epoch 012:     35 / 139 loss=6.34, nll_loss=2.965, ppl=7.81, wps=2054.6, ups=0.38, wpb=5354.5, bsz=184, num_updates=1564, lr=1.8768e-05, gnorm=1.547, train_wall=5, gb_free=13.4, wall=4969
2025-04-17 11:19:41 | INFO | train_inner | epoch 012:     37 / 139 loss=6.217, nll_loss=2.808, ppl=7, wps=2206.6, ups=0.39, wpb=5652.5, bsz=140, num_updates=1566, lr=1.8792e-05, gnorm=1.274, train_wall=5, gb_free=12.2, wall=4974
2025-04-17 11:19:47 | INFO | train_inner | epoch 012:     39 / 139 loss=6.15, nll_loss=2.727, ppl=6.62, wps=2271, ups=0.35, wpb=6524, bsz=276, num_updates=1568, lr=1.8816e-05, gnorm=1.415, train_wall=6, gb_free=10, wall=4980
2025-04-17 11:19:53 | INFO | train_inner | epoch 012:     41 / 139 loss=6.123, nll_loss=2.707, ppl=6.53, wps=2497.7, ups=0.37, wpb=6681.5, bsz=264, num_updates=1570, lr=1.884e-05, gnorm=1.306, train_wall=5, gb_free=11.6, wall=4985
2025-04-17 11:19:58 | INFO | train_inner | epoch 012:     43 / 139 loss=6.175, nll_loss=2.783, ppl=6.88, wps=2248, ups=0.36, wpb=6164.5, bsz=324, num_updates=1572, lr=1.8864e-05, gnorm=1.279, train_wall=5, gb_free=12.4, wall=4991
2025-04-17 11:20:03 | INFO | train_inner | epoch 012:     45 / 139 loss=6.142, nll_loss=2.741, ppl=6.69, wps=2247.5, ups=0.39, wpb=5814.5, bsz=324, num_updates=1574, lr=1.8888e-05, gnorm=1.287, train_wall=5, gb_free=12.2, wall=4996
2025-04-17 11:20:08 | INFO | train_inner | epoch 012:     47 / 139 loss=6.119, nll_loss=2.679, ppl=6.4, wps=2241.2, ups=0.39, wpb=5679.5, bsz=212, num_updates=1576, lr=1.8912e-05, gnorm=1.418, train_wall=5, gb_free=16.1, wall=5001
2025-04-17 11:20:14 | INFO | train_inner | epoch 012:     49 / 139 loss=6.203, nll_loss=2.793, ppl=6.93, wps=2161.9, ups=0.36, wpb=6008, bsz=248, num_updates=1578, lr=1.8936e-05, gnorm=1.36, train_wall=6, gb_free=9.9, wall=5006
2025-04-17 11:20:19 | INFO | train_inner | epoch 012:     51 / 139 loss=6.281, nll_loss=2.902, ppl=7.48, wps=2299, ups=0.41, wpb=5614, bsz=152, num_updates=1580, lr=1.896e-05, gnorm=1.521, train_wall=5, gb_free=11.4, wall=5011
2025-04-17 11:20:24 | INFO | train_inner | epoch 012:     53 / 139 loss=6.338, nll_loss=2.991, ppl=7.95, wps=2204.5, ups=0.4, wpb=5538.5, bsz=160, num_updates=1582, lr=1.8984e-05, gnorm=1.527, train_wall=5, gb_free=11.4, wall=5016
2025-04-17 11:20:29 | INFO | train_inner | epoch 012:     55 / 139 loss=6.238, nll_loss=2.862, ppl=7.27, wps=2335.7, ups=0.38, wpb=6212, bsz=236, num_updates=1584, lr=1.9008e-05, gnorm=1.366, train_wall=5, gb_free=12.3, wall=5022
2025-04-17 11:20:35 | INFO | train_inner | epoch 012:     57 / 139 loss=6.141, nll_loss=2.721, ppl=6.59, wps=2418.2, ups=0.36, wpb=6811.5, bsz=316, num_updates=1586, lr=1.9032e-05, gnorm=1.318, train_wall=6, gb_free=13, wall=5027
2025-04-17 11:20:40 | INFO | train_inner | epoch 012:     59 / 139 loss=6.268, nll_loss=2.87, ppl=7.31, wps=2347.8, ups=0.38, wpb=6236, bsz=240, num_updates=1588, lr=1.9056e-05, gnorm=1.276, train_wall=5, gb_free=11.9, wall=5033
2025-04-17 11:20:46 | INFO | train_inner | epoch 012:     61 / 139 loss=6.16, nll_loss=2.753, ppl=6.74, wps=2176.7, ups=0.36, wpb=6094.5, bsz=284, num_updates=1590, lr=1.908e-05, gnorm=1.342, train_wall=6, gb_free=12.9, wall=5038
2025-04-17 11:20:51 | INFO | train_inner | epoch 012:     63 / 139 loss=6.21, nll_loss=2.82, ppl=7.06, wps=2282.7, ups=0.39, wpb=5813, bsz=232, num_updates=1592, lr=1.9104e-05, gnorm=1.62, train_wall=5, gb_free=12.1, wall=5043
2025-04-17 11:20:56 | INFO | train_inner | epoch 012:     65 / 139 loss=6.193, nll_loss=2.792, ppl=6.93, wps=2368.4, ups=0.35, wpb=6720.5, bsz=244, num_updates=1594, lr=1.9128e-05, gnorm=1.292, train_wall=6, gb_free=10, wall=5049
2025-04-17 11:21:02 | INFO | train_inner | epoch 012:     67 / 139 loss=6.176, nll_loss=2.769, ppl=6.82, wps=2193.5, ups=0.38, wpb=5774, bsz=244, num_updates=1596, lr=1.9152e-05, gnorm=1.336, train_wall=5, gb_free=10.3, wall=5054
2025-04-17 11:21:07 | INFO | train_inner | epoch 012:     69 / 139 loss=6.204, nll_loss=2.804, ppl=6.99, wps=2492, ups=0.35, wpb=7061.5, bsz=308, num_updates=1598, lr=1.9176e-05, gnorm=1.201, train_wall=6, gb_free=10.5, wall=5060
2025-04-17 11:21:13 | INFO | train_inner | epoch 012:     71 / 139 loss=6.142, nll_loss=2.727, ppl=6.62, wps=2319.8, ups=0.38, wpb=6069, bsz=240, num_updates=1600, lr=1.92e-05, gnorm=1.354, train_wall=5, gb_free=10.7, wall=5065
2025-04-17 11:21:17 | INFO | train_inner | epoch 012:     73 / 139 loss=6.145, nll_loss=2.738, ppl=6.67, wps=2356.6, ups=0.46, wpb=5154, bsz=176.5, num_updates=1602, lr=1.9224e-05, gnorm=1.653, train_wall=4, gb_free=10.9, wall=5069
2025-04-17 11:21:22 | INFO | train_inner | epoch 012:     75 / 139 loss=6.239, nll_loss=2.858, ppl=7.25, wps=2322.3, ups=0.4, wpb=5825.5, bsz=212, num_updates=1604, lr=1.9248e-05, gnorm=1.376, train_wall=5, gb_free=10.4, wall=5074
2025-04-17 11:21:32 | INFO | train_inner | epoch 012:     77 / 139 loss=6.293, nll_loss=2.912, ppl=7.53, wps=974.8, ups=0.2, wpb=4893.5, bsz=108, num_updates=1606, lr=1.9272e-05, gnorm=1.655, train_wall=10, gb_free=12.5, wall=5084
2025-04-17 11:21:37 | INFO | train_inner | epoch 012:     79 / 139 loss=6.192, nll_loss=2.79, ppl=6.92, wps=2126.9, ups=0.41, wpb=5179, bsz=216, num_updates=1608, lr=1.9296e-05, gnorm=1.377, train_wall=5, gb_free=11.7, wall=5089
2025-04-17 11:21:42 | INFO | train_inner | epoch 012:     81 / 139 loss=6.258, nll_loss=2.859, ppl=7.26, wps=2179.8, ups=0.38, wpb=5757, bsz=164, num_updates=1610, lr=1.932e-05, gnorm=1.392, train_wall=5, gb_free=11.7, wall=5095
2025-04-17 11:21:48 | INFO | train_inner | epoch 012:     83 / 139 loss=6.048, nll_loss=2.619, ppl=6.14, wps=2343.5, ups=0.34, wpb=6860, bsz=320, num_updates=1612, lr=1.9344e-05, gnorm=1.169, train_wall=6, gb_free=10.3, wall=5100
2025-04-17 11:21:53 | INFO | train_inner | epoch 012:     85 / 139 loss=6.149, nll_loss=2.748, ppl=6.72, wps=2357.5, ups=0.37, wpb=6341, bsz=292, num_updates=1614, lr=1.9368e-05, gnorm=1.315, train_wall=5, gb_free=11.7, wall=5106
2025-04-17 11:21:59 | INFO | train_inner | epoch 012:     87 / 139 loss=6.137, nll_loss=2.726, ppl=6.62, wps=2469.2, ups=0.36, wpb=6786.5, bsz=292, num_updates=1616, lr=1.9392e-05, gnorm=1.33, train_wall=5, gb_free=10, wall=5111
2025-04-17 11:22:04 | INFO | train_inner | epoch 012:     89 / 139 loss=6.185, nll_loss=2.772, ppl=6.83, wps=2145.4, ups=0.4, wpb=5333, bsz=188, num_updates=1618, lr=1.9416e-05, gnorm=1.35, train_wall=5, gb_free=11.5, wall=5116
2025-04-17 11:22:09 | INFO | train_inner | epoch 012:     91 / 139 loss=6.263, nll_loss=2.879, ppl=7.36, wps=2284.7, ups=0.37, wpb=6153.5, bsz=244, num_updates=1620, lr=1.944e-05, gnorm=1.404, train_wall=5, gb_free=11.3, wall=5122
2025-04-17 11:22:15 | INFO | train_inner | epoch 012:     93 / 139 loss=6.155, nll_loss=2.746, ppl=6.71, wps=2327.6, ups=0.35, wpb=6725.5, bsz=284, num_updates=1622, lr=1.9464e-05, gnorm=1.185, train_wall=6, gb_free=10.1, wall=5127
2025-04-17 11:22:20 | INFO | train_inner | epoch 012:     95 / 139 loss=6.017, nll_loss=2.588, ppl=6.01, wps=2317.2, ups=0.38, wpb=6092.5, bsz=308, num_updates=1624, lr=1.9488e-05, gnorm=1.269, train_wall=5, gb_free=13, wall=5133
2025-04-17 11:22:25 | INFO | train_inner | epoch 012:     97 / 139 loss=6.106, nll_loss=2.69, ppl=6.46, wps=2390.8, ups=0.39, wpb=6115, bsz=232, num_updates=1626, lr=1.9512e-05, gnorm=1.483, train_wall=5, gb_free=13, wall=5138
2025-04-17 11:22:31 | INFO | train_inner | epoch 012:     99 / 139 loss=6.215, nll_loss=2.805, ppl=6.99, wps=2378.5, ups=0.35, wpb=6723.5, bsz=292, num_updates=1628, lr=1.9536e-05, gnorm=1.232, train_wall=6, gb_free=10.9, wall=5144
2025-04-17 11:22:37 | INFO | train_inner | epoch 012:    101 / 139 loss=6.089, nll_loss=2.641, ppl=6.24, wps=2214.6, ups=0.36, wpb=6089, bsz=208, num_updates=1630, lr=1.956e-05, gnorm=1.214, train_wall=5, gb_free=12.8, wall=5149
2025-04-17 11:22:42 | INFO | train_inner | epoch 012:    103 / 139 loss=6.245, nll_loss=2.869, ppl=7.3, wps=2288.4, ups=0.39, wpb=5859, bsz=168, num_updates=1632, lr=1.9584e-05, gnorm=1.417, train_wall=5, gb_free=11.4, wall=5154
2025-04-17 11:22:47 | INFO | train_inner | epoch 012:    105 / 139 loss=6.138, nll_loss=2.723, ppl=6.6, wps=2411.2, ups=0.36, wpb=6651, bsz=328, num_updates=1634, lr=1.9608e-05, gnorm=1.239, train_wall=6, gb_free=10.6, wall=5160
2025-04-17 11:22:53 | INFO | train_inner | epoch 012:    107 / 139 loss=6.205, nll_loss=2.812, ppl=7.02, wps=2307.5, ups=0.37, wpb=6291, bsz=212, num_updates=1636, lr=1.9632e-05, gnorm=1.239, train_wall=5, gb_free=11.2, wall=5165
2025-04-17 11:22:58 | INFO | train_inner | epoch 012:    109 / 139 loss=6.227, nll_loss=2.832, ppl=7.12, wps=2088.1, ups=0.39, wpb=5353, bsz=204, num_updates=1638, lr=1.9656e-05, gnorm=1.345, train_wall=5, gb_free=10.1, wall=5170
2025-04-17 11:23:03 | INFO | train_inner | epoch 012:    111 / 139 loss=6.269, nll_loss=2.885, ppl=7.39, wps=2385, ups=0.41, wpb=5793, bsz=140, num_updates=1640, lr=1.968e-05, gnorm=1.323, train_wall=5, gb_free=16.1, wall=5175
2025-04-17 11:23:08 | INFO | train_inner | epoch 012:    113 / 139 loss=6.174, nll_loss=2.751, ppl=6.73, wps=2403.9, ups=0.36, wpb=6737, bsz=260, num_updates=1642, lr=1.9704e-05, gnorm=1.352, train_wall=6, gb_free=10.8, wall=5181
2025-04-17 11:23:14 | INFO | train_inner | epoch 012:    115 / 139 loss=6.325, nll_loss=2.95, ppl=7.73, wps=2233.1, ups=0.38, wpb=5939, bsz=204, num_updates=1644, lr=1.9728e-05, gnorm=1.518, train_wall=5, gb_free=12.4, wall=5186
2025-04-17 11:23:19 | INFO | train_inner | epoch 012:    117 / 139 loss=6.084, nll_loss=2.666, ppl=6.35, wps=2461.5, ups=0.38, wpb=6451.5, bsz=276, num_updates=1646, lr=1.9752e-05, gnorm=1.198, train_wall=5, gb_free=11.7, wall=5191
2025-04-17 11:23:24 | INFO | train_inner | epoch 012:    119 / 139 loss=6.257, nll_loss=2.878, ppl=7.35, wps=2290.3, ups=0.38, wpb=5966.5, bsz=164, num_updates=1648, lr=1.9776e-05, gnorm=1.343, train_wall=5, gb_free=10, wall=5196
2025-04-17 11:23:29 | INFO | train_inner | epoch 012:    121 / 139 loss=6.12, nll_loss=2.695, ppl=6.47, wps=1957.6, ups=0.43, wpb=4537, bsz=136, num_updates=1650, lr=1.98e-05, gnorm=1.562, train_wall=5, gb_free=18, wall=5201
2025-04-17 11:23:34 | INFO | train_inner | epoch 012:    123 / 139 loss=6.182, nll_loss=2.773, ppl=6.84, wps=2092.9, ups=0.35, wpb=5930.5, bsz=276, num_updates=1652, lr=1.9824e-05, gnorm=1.306, train_wall=6, gb_free=10.7, wall=5207
2025-04-17 11:23:39 | INFO | train_inner | epoch 012:    125 / 139 loss=6.333, nll_loss=2.967, ppl=7.82, wps=2298.6, ups=0.39, wpb=5863, bsz=192, num_updates=1654, lr=1.9848e-05, gnorm=1.476, train_wall=5, gb_free=13.5, wall=5212
2025-04-17 11:23:45 | INFO | train_inner | epoch 012:    127 / 139 loss=5.991, nll_loss=2.528, ppl=5.77, wps=2331, ups=0.37, wpb=6249.5, bsz=248, num_updates=1656, lr=1.9872e-05, gnorm=1.242, train_wall=5, gb_free=10.8, wall=5217
2025-04-17 11:23:50 | INFO | train_inner | epoch 012:    129 / 139 loss=6.339, nll_loss=2.975, ppl=7.86, wps=1987.5, ups=0.4, wpb=5016, bsz=228, num_updates=1658, lr=1.9896e-05, gnorm=1.447, train_wall=5, gb_free=10, wall=5222
2025-04-17 11:23:55 | INFO | train_inner | epoch 012:    131 / 139 loss=6.164, nll_loss=2.768, ppl=6.81, wps=2491.8, ups=0.38, wpb=6635, bsz=252, num_updates=1660, lr=1.992e-05, gnorm=1.191, train_wall=5, gb_free=12.3, wall=5228
2025-04-17 11:24:00 | INFO | train_inner | epoch 012:    133 / 139 loss=6.233, nll_loss=2.851, ppl=7.21, wps=2447.5, ups=0.41, wpb=5911.5, bsz=220, num_updates=1662, lr=1.9944e-05, gnorm=1.34, train_wall=5, gb_free=15.6, wall=5232
2025-04-17 11:24:05 | INFO | train_inner | epoch 012:    135 / 139 loss=6.212, nll_loss=2.817, ppl=7.04, wps=2358, ups=0.38, wpb=6177.5, bsz=256, num_updates=1664, lr=1.9968e-05, gnorm=1.24, train_wall=5, gb_free=11.6, wall=5238
2025-04-17 11:24:11 | INFO | train_inner | epoch 012:    137 / 139 loss=6.175, nll_loss=2.749, ppl=6.72, wps=2403.8, ups=0.37, wpb=6456, bsz=204, num_updates=1666, lr=1.9992e-05, gnorm=1.231, train_wall=5, gb_free=13.3, wall=5243
2025-04-17 11:24:15 | INFO | train_inner | epoch 012:    139 / 139 loss=6.258, nll_loss=2.879, ppl=7.35, wps=2055.2, ups=0.51, wpb=4051.5, bsz=176, num_updates=1668, lr=2.0016e-05, gnorm=1.602, train_wall=4, gb_free=16, wall=5247
2025-04-17 11:24:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-17 11:24:15 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=15237.9375Mb; avail=239844.2109375Mb
2025-04-17 11:24:15 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000635
2025-04-17 11:24:15 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15237.9375Mb; avail=239844.2109375Mb
2025-04-17 11:24:15 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012737
2025-04-17 11:24:15 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15237.9375Mb; avail=239844.2109375Mb
2025-04-17 11:24:15 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.010984
2025-04-17 11:24:15 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024722
2025-04-17 11:24:15 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15237.9375Mb; avail=239844.2109375Mb
2025-04-17 11:24:30 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 6.212 | nll_loss 2.67 | ppl 6.36 | wps 5360.9 | wpb 2350.9 | bsz 94.7 | num_updates 1668 | best_loss 6.212
2025-04-17 11:24:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1668 updates
2025-04-17 11:24:30 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt
2025-04-17 11:25:08 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt
2025-04-17 11:25:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt (epoch 12 @ 1668 updates, score 6.212) (writing took 62.1862019830005 seconds)
2025-04-17 11:25:32 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2025-04-17 11:25:32 | INFO | train | epoch 012 | loss 6.198 | nll_loss 2.798 | ppl 6.95 | wps 1873.2 | ups 0.31 | wpb 6008.3 | bsz 229.1 | num_updates 1668 | lr 2.0016e-05 | gnorm 1.36 | train_wall 368 | gb_free 16 | wall 5324
2025-04-17 11:25:32 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:hi-mr': 31849}; raw total size: 31849
2025-04-17 11:25:32 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:hi-mr': 31849}; resampled total size: 31849
2025-04-17 11:25:32 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:hi-mr': 1.0}
2025-04-17 11:25:32 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001107
2025-04-17 11:25:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=25359.21484375Mb; avail=229722.8828125Mb
2025-04-17 11:25:32 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000583
2025-04-17 11:25:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003691
2025-04-17 11:25:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=25359.21484375Mb; avail=229722.8828125Mb
2025-04-17 11:25:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000091
2025-04-17 11:25:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=25359.21484375Mb; avail=229722.8828125Mb
2025-04-17 11:25:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001209
2025-04-17 11:25:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.005296
2025-04-17 11:25:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=25359.21484375Mb; avail=229722.8828125Mb
2025-04-17 11:25:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 139
2025-04-17 11:25:32 | INFO | fairseq.trainer | begin training epoch 13
2025-04-17 11:25:32 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-17 11:25:38 | INFO | train_inner | epoch 013:      2 / 139 loss=6.065, nll_loss=2.641, ppl=6.24, wps=163, ups=0.02, wpb=6775.5, bsz=340, num_updates=1670, lr=2.004e-05, gnorm=1.206, train_wall=6, gb_free=9.8, wall=5330
2025-04-17 11:25:48 | INFO | train_inner | epoch 013:      4 / 139 loss=6.055, nll_loss=2.622, ppl=6.16, wps=1313.8, ups=0.2, wpb=6653, bsz=252, num_updates=1672, lr=2.0064e-05, gnorm=1.238, train_wall=10, gb_free=11.1, wall=5340
2025-04-17 11:25:53 | INFO | train_inner | epoch 013:      6 / 139 loss=6.153, nll_loss=2.746, ppl=6.71, wps=2605, ups=0.39, wpb=6737.5, bsz=240, num_updates=1674, lr=2.0088e-05, gnorm=1.221, train_wall=5, gb_free=12.1, wall=5345
2025-04-17 11:25:58 | INFO | train_inner | epoch 013:      8 / 139 loss=6.134, nll_loss=2.707, ppl=6.53, wps=2428.5, ups=0.39, wpb=6305, bsz=204, num_updates=1676, lr=2.0112e-05, gnorm=1.334, train_wall=5, gb_free=11.8, wall=5351
2025-04-17 11:26:03 | INFO | train_inner | epoch 013:     10 / 139 loss=6.091, nll_loss=2.668, ppl=6.36, wps=2352.1, ups=0.39, wpb=6073, bsz=212, num_updates=1678, lr=2.0136e-05, gnorm=1.333, train_wall=5, gb_free=11.6, wall=5356
2025-04-17 11:26:08 | INFO | train_inner | epoch 013:     12 / 139 loss=6.103, nll_loss=2.69, ppl=6.45, wps=2364.5, ups=0.39, wpb=6008.5, bsz=220, num_updates=1680, lr=2.016e-05, gnorm=1.296, train_wall=5, gb_free=11.6, wall=5361
2025-04-17 11:26:14 | INFO | train_inner | epoch 013:     14 / 139 loss=6.176, nll_loss=2.778, ppl=6.86, wps=2371, ups=0.39, wpb=6072.5, bsz=180, num_updates=1682, lr=2.0184e-05, gnorm=1.334, train_wall=5, gb_free=13.6, wall=5366
2025-04-17 11:26:18 | INFO | train_inner | epoch 013:     16 / 139 loss=6.143, nll_loss=2.696, ppl=6.48, wps=2176, ups=0.41, wpb=5347.5, bsz=172, num_updates=1684, lr=2.0208e-05, gnorm=1.393, train_wall=5, gb_free=11.1, wall=5371
2025-04-17 11:26:24 | INFO | train_inner | epoch 013:     18 / 139 loss=6.164, nll_loss=2.752, ppl=6.74, wps=2524.9, ups=0.37, wpb=6734, bsz=288, num_updates=1686, lr=2.0232e-05, gnorm=1.405, train_wall=5, gb_free=10.6, wall=5376
2025-04-17 11:26:29 | INFO | train_inner | epoch 013:     20 / 139 loss=6.078, nll_loss=2.65, ppl=6.28, wps=2343.4, ups=0.37, wpb=6299.5, bsz=252, num_updates=1688, lr=2.0256e-05, gnorm=1.398, train_wall=5, gb_free=10.8, wall=5382
2025-04-17 11:26:34 | INFO | train_inner | epoch 013:     22 / 139 loss=6.168, nll_loss=2.775, ppl=6.84, wps=2192.7, ups=0.38, wpb=5726.5, bsz=228, num_updates=1690, lr=2.028e-05, gnorm=1.313, train_wall=5, gb_free=13.6, wall=5387
2025-04-17 11:26:40 | INFO | train_inner | epoch 013:     24 / 139 loss=5.952, nll_loss=2.506, ppl=5.68, wps=2567.1, ups=0.37, wpb=6897, bsz=340, num_updates=1692, lr=2.0304e-05, gnorm=1.269, train_wall=5, gb_free=11.5, wall=5392
2025-04-17 11:26:45 | INFO | train_inner | epoch 013:     26 / 139 loss=6.305, nll_loss=2.923, ppl=7.58, wps=2227.1, ups=0.42, wpb=5360.5, bsz=140, num_updates=1694, lr=2.0328e-05, gnorm=1.429, train_wall=5, gb_free=12.6, wall=5397
2025-04-17 11:26:50 | INFO | train_inner | epoch 013:     28 / 139 loss=6.015, nll_loss=2.56, ppl=5.9, wps=2349.6, ups=0.37, wpb=6344, bsz=216, num_updates=1696, lr=2.0352e-05, gnorm=1.212, train_wall=5, gb_free=11.3, wall=5402
2025-04-17 11:26:55 | INFO | train_inner | epoch 013:     30 / 139 loss=6.106, nll_loss=2.684, ppl=6.43, wps=2205.1, ups=0.38, wpb=5837.5, bsz=296, num_updates=1698, lr=2.0376e-05, gnorm=1.352, train_wall=5, gb_free=10.4, wall=5408
2025-04-17 11:27:01 | INFO | train_inner | epoch 013:     32 / 139 loss=6.138, nll_loss=2.712, ppl=6.55, wps=2086.9, ups=0.38, wpb=5474, bsz=208, num_updates=1700, lr=2.04e-05, gnorm=1.317, train_wall=5, gb_free=10.4, wall=5413
2025-04-17 11:27:05 | INFO | train_inner | epoch 013:     34 / 139 loss=6.292, nll_loss=2.91, ppl=7.52, wps=1891.3, ups=0.44, wpb=4340, bsz=64, num_updates=1702, lr=2.0424e-05, gnorm=1.645, train_wall=5, gb_free=13.4, wall=5418
2025-04-17 11:27:11 | INFO | train_inner | epoch 013:     36 / 139 loss=5.942, nll_loss=2.496, ppl=5.64, wps=2253.2, ups=0.37, wpb=6104, bsz=364, num_updates=1704, lr=2.0448e-05, gnorm=1.287, train_wall=5, gb_free=13, wall=5423
2025-04-17 11:27:16 | INFO | train_inner | epoch 013:     38 / 139 loss=6.01, nll_loss=2.566, ppl=5.92, wps=2151.4, ups=0.39, wpb=5535, bsz=240, num_updates=1706, lr=2.0472e-05, gnorm=1.475, train_wall=5, gb_free=11.8, wall=5428
2025-04-17 11:27:21 | INFO | train_inner | epoch 013:     40 / 139 loss=6.168, nll_loss=2.74, ppl=6.68, wps=2228.9, ups=0.4, wpb=5583.5, bsz=168, num_updates=1708, lr=2.0496e-05, gnorm=1.353, train_wall=5, gb_free=12.9, wall=5433
2025-04-17 11:27:26 | INFO | train_inner | epoch 013:     42 / 139 loss=6.169, nll_loss=2.743, ppl=6.69, wps=2401.4, ups=0.39, wpb=6213.5, bsz=220, num_updates=1710, lr=2.052e-05, gnorm=1.296, train_wall=5, gb_free=12.2, wall=5438
2025-04-17 11:27:30 | INFO | train_inner | epoch 013:     44 / 139 loss=6.058, nll_loss=2.622, ppl=6.16, wps=2477, ups=0.43, wpb=5709, bsz=200, num_updates=1712, lr=2.0544e-05, gnorm=1.382, train_wall=5, gb_free=17.5, wall=5443
2025-04-17 11:27:36 | INFO | train_inner | epoch 013:     46 / 139 loss=6.101, nll_loss=2.689, ppl=6.45, wps=2287.5, ups=0.36, wpb=6342.5, bsz=284, num_updates=1714, lr=2.0568e-05, gnorm=1.46, train_wall=6, gb_free=10.7, wall=5448
2025-04-17 11:27:41 | INFO | train_inner | epoch 013:     48 / 139 loss=6.072, nll_loss=2.655, ppl=6.3, wps=2251.9, ups=0.37, wpb=6120, bsz=292, num_updates=1716, lr=2.0592e-05, gnorm=1.325, train_wall=5, gb_free=10.5, wall=5454
2025-04-17 11:27:47 | INFO | train_inner | epoch 013:     50 / 139 loss=6.118, nll_loss=2.687, ppl=6.44, wps=2120.1, ups=0.35, wpb=6022, bsz=336, num_updates=1718, lr=2.0616e-05, gnorm=1.501, train_wall=6, gb_free=9.8, wall=5460
2025-04-17 11:27:53 | INFO | train_inner | epoch 013:     52 / 139 loss=6.175, nll_loss=2.771, ppl=6.82, wps=2358.1, ups=0.37, wpb=6410.5, bsz=220, num_updates=1720, lr=2.064e-05, gnorm=1.557, train_wall=5, gb_free=11.4, wall=5465
2025-04-17 11:27:58 | INFO | train_inner | epoch 013:     54 / 139 loss=6.165, nll_loss=2.752, ppl=6.74, wps=2254.6, ups=0.37, wpb=6144, bsz=200, num_updates=1722, lr=2.0664e-05, gnorm=1.326, train_wall=5, gb_free=10.6, wall=5470
2025-04-17 11:28:03 | INFO | train_inner | epoch 013:     56 / 139 loss=6.246, nll_loss=2.864, ppl=7.28, wps=2387.3, ups=0.41, wpb=5854.5, bsz=136, num_updates=1724, lr=2.0688e-05, gnorm=1.339, train_wall=5, gb_free=13.3, wall=5475
2025-04-17 11:28:08 | INFO | train_inner | epoch 013:     58 / 139 loss=6.031, nll_loss=2.593, ppl=6.03, wps=2229, ups=0.36, wpb=6181.5, bsz=320, num_updates=1726, lr=2.0712e-05, gnorm=1.512, train_wall=6, gb_free=10.5, wall=5481
2025-04-17 11:28:14 | INFO | train_inner | epoch 013:     60 / 139 loss=6.154, nll_loss=2.745, ppl=6.7, wps=2168.4, ups=0.36, wpb=5959, bsz=188, num_updates=1728, lr=2.0736e-05, gnorm=1.496, train_wall=5, gb_free=10.3, wall=5486
2025-04-17 11:28:20 | INFO | train_inner | epoch 013:     62 / 139 loss=6.204, nll_loss=2.8, ppl=6.96, wps=2210.7, ups=0.36, wpb=6177, bsz=228, num_updates=1730, lr=2.076e-05, gnorm=1.282, train_wall=6, gb_free=11.3, wall=5492
2025-04-17 11:28:25 | INFO | train_inner | epoch 013:     64 / 139 loss=6.124, nll_loss=2.69, ppl=6.45, wps=2281, ups=0.38, wpb=6082.5, bsz=220, num_updates=1732, lr=2.0784e-05, gnorm=1.382, train_wall=5, gb_free=11.6, wall=5497
2025-04-17 11:28:30 | INFO | train_inner | epoch 013:     66 / 139 loss=6.063, nll_loss=2.628, ppl=6.18, wps=2249.9, ups=0.38, wpb=5961.5, bsz=276, num_updates=1734, lr=2.0808e-05, gnorm=1.458, train_wall=5, gb_free=13.3, wall=5503
2025-04-17 11:28:36 | INFO | train_inner | epoch 013:     68 / 139 loss=6.053, nll_loss=2.624, ppl=6.16, wps=2307.6, ups=0.37, wpb=6264, bsz=248, num_updates=1736, lr=2.0832e-05, gnorm=1.239, train_wall=5, gb_free=11, wall=5508
2025-04-17 11:28:41 | INFO | train_inner | epoch 013:     70 / 139 loss=6.089, nll_loss=2.673, ppl=6.38, wps=2056.8, ups=0.4, wpb=5185, bsz=248, num_updates=1738, lr=2.0856e-05, gnorm=1.506, train_wall=5, gb_free=11.6, wall=5513
2025-04-17 11:28:46 | INFO | train_inner | epoch 013:     72 / 139 loss=6.128, nll_loss=2.712, ppl=6.55, wps=2357.5, ups=0.37, wpb=6337.5, bsz=184, num_updates=1740, lr=2.088e-05, gnorm=1.264, train_wall=5, gb_free=12.4, wall=5519
2025-04-17 11:28:51 | INFO | train_inner | epoch 013:     74 / 139 loss=6.04, nll_loss=2.603, ppl=6.08, wps=2295, ups=0.38, wpb=6088.5, bsz=228, num_updates=1742, lr=2.0904e-05, gnorm=1.266, train_wall=5, gb_free=12.4, wall=5524
2025-04-17 11:28:56 | INFO | train_inner | epoch 013:     76 / 139 loss=6.132, nll_loss=2.712, ppl=6.55, wps=2133.5, ups=0.39, wpb=5494.5, bsz=188, num_updates=1744, lr=2.0928e-05, gnorm=1.281, train_wall=5, gb_free=11.4, wall=5529
2025-04-17 11:29:01 | INFO | train_inner | epoch 013:     78 / 139 loss=6.154, nll_loss=2.743, ppl=6.7, wps=2388.9, ups=0.44, wpb=5441, bsz=160, num_updates=1746, lr=2.0952e-05, gnorm=1.441, train_wall=5, gb_free=12.1, wall=5534
2025-04-17 11:29:06 | INFO | train_inner | epoch 013:     80 / 139 loss=6.117, nll_loss=2.691, ppl=6.46, wps=2210.2, ups=0.37, wpb=6033.5, bsz=276, num_updates=1748, lr=2.0976e-05, gnorm=1.23, train_wall=5, gb_free=9.8, wall=5539
2025-04-17 11:29:12 | INFO | train_inner | epoch 013:     82 / 139 loss=6.038, nll_loss=2.603, ppl=6.07, wps=2404.6, ups=0.36, wpb=6607, bsz=276, num_updates=1750, lr=2.1e-05, gnorm=1.314, train_wall=5, gb_free=11.4, wall=5544
2025-04-17 11:29:16 | INFO | train_inner | epoch 013:     84 / 139 loss=6.163, nll_loss=2.765, ppl=6.8, wps=2405.9, ups=0.46, wpb=5216.5, bsz=152.5, num_updates=1752, lr=2.1024e-05, gnorm=1.695, train_wall=4, gb_free=13.1, wall=5549
2025-04-17 11:29:22 | INFO | train_inner | epoch 013:     86 / 139 loss=6.109, nll_loss=2.691, ppl=6.46, wps=2271.1, ups=0.37, wpb=6095.5, bsz=296, num_updates=1754, lr=2.1048e-05, gnorm=1.382, train_wall=5, gb_free=11.3, wall=5554
2025-04-17 11:29:27 | INFO | train_inner | epoch 013:     88 / 139 loss=6.012, nll_loss=2.56, ppl=5.9, wps=2425.5, ups=0.35, wpb=6884, bsz=320, num_updates=1756, lr=2.1072e-05, gnorm=1.114, train_wall=6, gb_free=11.1, wall=5560
2025-04-17 11:29:33 | INFO | train_inner | epoch 013:     90 / 139 loss=6.163, nll_loss=2.762, ppl=6.78, wps=2310.1, ups=0.38, wpb=6106, bsz=180, num_updates=1758, lr=2.1096e-05, gnorm=1.263, train_wall=5, gb_free=11.9, wall=5565
2025-04-17 11:29:38 | INFO | train_inner | epoch 013:     92 / 139 loss=6.106, nll_loss=2.69, ppl=6.45, wps=2279.1, ups=0.34, wpb=6612, bsz=296, num_updates=1760, lr=2.112e-05, gnorm=1.243, train_wall=6, gb_free=9.4, wall=5571
2025-04-17 11:29:44 | INFO | train_inner | epoch 013:     94 / 139 loss=6.026, nll_loss=2.587, ppl=6.01, wps=2525.3, ups=0.37, wpb=6834.5, bsz=268, num_updates=1762, lr=2.1144e-05, gnorm=1.194, train_wall=5, gb_free=11.4, wall=5576
2025-04-17 11:29:48 | INFO | train_inner | epoch 013:     96 / 139 loss=5.967, nll_loss=2.509, ppl=5.69, wps=2291.9, ups=0.44, wpb=5203.5, bsz=220, num_updates=1764, lr=2.1168e-05, gnorm=1.415, train_wall=5, gb_free=14.1, wall=5581
2025-04-17 11:29:54 | INFO | train_inner | epoch 013:     98 / 139 loss=6.158, nll_loss=2.722, ppl=6.6, wps=2374.1, ups=0.36, wpb=6610.5, bsz=264, num_updates=1766, lr=2.1192e-05, gnorm=1.341, train_wall=6, gb_free=9.8, wall=5586
2025-04-17 11:29:59 | INFO | train_inner | epoch 013:    100 / 139 loss=6.062, nll_loss=2.614, ppl=6.12, wps=2369.4, ups=0.39, wpb=6110.5, bsz=208, num_updates=1768, lr=2.1216e-05, gnorm=1.279, train_wall=5, gb_free=12, wall=5592
2025-04-17 11:30:05 | INFO | train_inner | epoch 013:    102 / 139 loss=6.152, nll_loss=2.754, ppl=6.75, wps=2239.5, ups=0.36, wpb=6233.5, bsz=232, num_updates=1770, lr=2.124e-05, gnorm=1.366, train_wall=6, gb_free=11.6, wall=5597
2025-04-17 11:30:10 | INFO | train_inner | epoch 013:    104 / 139 loss=6.08, nll_loss=2.672, ppl=6.37, wps=2385.4, ups=0.35, wpb=6773, bsz=300, num_updates=1772, lr=2.1264e-05, gnorm=1.297, train_wall=6, gb_free=12.1, wall=5603
2025-04-17 11:30:16 | INFO | train_inner | epoch 013:    106 / 139 loss=6.203, nll_loss=2.805, ppl=6.99, wps=2427.4, ups=0.38, wpb=6322, bsz=168, num_updates=1774, lr=2.1288e-05, gnorm=1.412, train_wall=5, gb_free=12, wall=5608
2025-04-17 11:30:21 | INFO | train_inner | epoch 013:    108 / 139 loss=6.108, nll_loss=2.672, ppl=6.37, wps=2133.1, ups=0.39, wpb=5451.5, bsz=200, num_updates=1776, lr=2.1312e-05, gnorm=1.367, train_wall=5, gb_free=11.5, wall=5613
2025-04-17 11:30:25 | INFO | train_inner | epoch 013:    110 / 139 loss=6.295, nll_loss=2.921, ppl=7.57, wps=1850.2, ups=0.42, wpb=4382.5, bsz=96, num_updates=1778, lr=2.1336e-05, gnorm=1.719, train_wall=5, gb_free=11.5, wall=5618
2025-04-17 11:30:31 | INFO | train_inner | epoch 013:    112 / 139 loss=6.103, nll_loss=2.695, ppl=6.48, wps=2436.1, ups=0.38, wpb=6340, bsz=232, num_updates=1780, lr=2.136e-05, gnorm=1.263, train_wall=5, gb_free=11.1, wall=5623
2025-04-17 11:30:36 | INFO | train_inner | epoch 013:    114 / 139 loss=6.159, nll_loss=2.755, ppl=6.75, wps=2118.6, ups=0.39, wpb=5435, bsz=180, num_updates=1782, lr=2.1384e-05, gnorm=1.409, train_wall=5, gb_free=13.3, wall=5628
2025-04-17 11:30:41 | INFO | train_inner | epoch 013:    116 / 139 loss=6.229, nll_loss=2.817, ppl=7.05, wps=2147.8, ups=0.4, wpb=5396.5, bsz=108, num_updates=1784, lr=2.1408e-05, gnorm=1.525, train_wall=5, gb_free=12.9, wall=5633
2025-04-17 11:30:46 | INFO | train_inner | epoch 013:    118 / 139 loss=6.131, nll_loss=2.719, ppl=6.59, wps=2357.6, ups=0.37, wpb=6334, bsz=284, num_updates=1786, lr=2.1432e-05, gnorm=1.227, train_wall=5, gb_free=12.3, wall=5639
2025-04-17 11:30:52 | INFO | train_inner | epoch 013:    120 / 139 loss=6.114, nll_loss=2.683, ppl=6.42, wps=2275.1, ups=0.36, wpb=6284, bsz=244, num_updates=1788, lr=2.1456e-05, gnorm=1.267, train_wall=6, gb_free=13.8, wall=5644
2025-04-17 11:30:57 | INFO | train_inner | epoch 013:    122 / 139 loss=6.024, nll_loss=2.582, ppl=5.99, wps=2170.4, ups=0.38, wpb=5772.5, bsz=268, num_updates=1790, lr=2.148e-05, gnorm=1.389, train_wall=5, gb_free=11.4, wall=5650
2025-04-17 11:31:02 | INFO | train_inner | epoch 013:    124 / 139 loss=6.056, nll_loss=2.633, ppl=6.2, wps=2446.9, ups=0.38, wpb=6369.5, bsz=240, num_updates=1792, lr=2.1504e-05, gnorm=1.214, train_wall=5, gb_free=14.2, wall=5655
2025-04-17 11:31:08 | INFO | train_inner | epoch 013:    126 / 139 loss=6.041, nll_loss=2.605, ppl=6.08, wps=2408.1, ups=0.38, wpb=6355, bsz=248, num_updates=1794, lr=2.1528e-05, gnorm=1.22, train_wall=5, gb_free=11.8, wall=5660
2025-04-17 11:31:13 | INFO | train_inner | epoch 013:    128 / 139 loss=6.133, nll_loss=2.73, ppl=6.63, wps=2274.5, ups=0.39, wpb=5848, bsz=252, num_updates=1796, lr=2.1552e-05, gnorm=1.353, train_wall=5, gb_free=12.2, wall=5665
2025-04-17 11:31:18 | INFO | train_inner | epoch 013:    130 / 139 loss=6.012, nll_loss=2.57, ppl=5.94, wps=2500, ups=0.37, wpb=6831.5, bsz=280, num_updates=1798, lr=2.1576e-05, gnorm=1.202, train_wall=5, gb_free=10.2, wall=5671
2025-04-17 11:31:23 | INFO | train_inner | epoch 013:    132 / 139 loss=6.042, nll_loss=2.599, ppl=6.06, wps=2353.9, ups=0.42, wpb=5585.5, bsz=176, num_updates=1800, lr=2.16e-05, gnorm=1.3, train_wall=5, gb_free=14.1, wall=5675
2025-04-17 11:31:28 | INFO | train_inner | epoch 013:    134 / 139 loss=6.11, nll_loss=2.676, ppl=6.39, wps=2353.5, ups=0.37, wpb=6305.5, bsz=232, num_updates=1802, lr=2.1624e-05, gnorm=1.454, train_wall=5, gb_free=13.5, wall=5681
2025-04-17 11:31:33 | INFO | train_inner | epoch 013:    136 / 139 loss=6.168, nll_loss=2.754, ppl=6.74, wps=2151.6, ups=0.39, wpb=5567.5, bsz=184, num_updates=1804, lr=2.1648e-05, gnorm=1.571, train_wall=5, gb_free=12.6, wall=5686
2025-04-17 11:31:39 | INFO | train_inner | epoch 013:    138 / 139 loss=6.145, nll_loss=2.729, ppl=6.63, wps=2201.8, ups=0.38, wpb=5828.5, bsz=152, num_updates=1806, lr=2.1672e-05, gnorm=1.411, train_wall=5, gb_free=11.9, wall=5691
2025-04-17 11:31:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-17 11:31:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=15261.4140625Mb; avail=239820.7578125Mb
2025-04-17 11:31:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000633
2025-04-17 11:31:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15261.4140625Mb; avail=239820.7578125Mb
2025-04-17 11:31:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012659
2025-04-17 11:31:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15261.4140625Mb; avail=239820.7578125Mb
2025-04-17 11:31:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.011129
2025-04-17 11:31:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024764
2025-04-17 11:31:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15261.4140625Mb; avail=239820.7578125Mb
2025-04-17 11:31:55 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 6.164 | nll_loss 2.62 | ppl 6.15 | wps 5374.5 | wpb 2350.9 | bsz 94.7 | num_updates 1807 | best_loss 6.164
2025-04-17 11:31:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 1807 updates
2025-04-17 11:31:55 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt
2025-04-17 11:32:33 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt
2025-04-17 11:32:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt (epoch 13 @ 1807 updates, score 6.164) (writing took 61.6219187300012 seconds)
2025-04-17 11:32:57 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2025-04-17 11:32:57 | INFO | train | epoch 013 | loss 6.109 | nll_loss 2.687 | ppl 6.44 | wps 1876.2 | ups 0.31 | wpb 6008.3 | bsz 229.1 | num_updates 1807 | lr 2.1684e-05 | gnorm 1.357 | train_wall 368 | gb_free 14.8 | wall 5770
2025-04-17 11:32:57 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:hi-mr': 31849}; raw total size: 31849
2025-04-17 11:32:57 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:hi-mr': 31849}; resampled total size: 31849
2025-04-17 11:32:57 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:hi-mr': 1.0}
2025-04-17 11:32:57 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001088
2025-04-17 11:32:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=25392.28125Mb; avail=229689.87109375Mb
2025-04-17 11:32:57 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000591
2025-04-17 11:32:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003389
2025-04-17 11:32:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=25392.7734375Mb; avail=229689.37890625Mb
2025-04-17 11:32:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000097
2025-04-17 11:32:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=25392.7734375Mb; avail=229689.37890625Mb
2025-04-17 11:32:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001240
2025-04-17 11:32:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.005031
2025-04-17 11:32:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=25392.7734375Mb; avail=229689.37890625Mb
2025-04-17 11:32:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 139
2025-04-17 11:32:57 | INFO | fairseq.trainer | begin training epoch 14
2025-04-17 11:32:57 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-17 11:33:00 | INFO | train_inner | epoch 014:      1 / 139 loss=5.978, nll_loss=2.535, ppl=5.8, wps=111.6, ups=0.02, wpb=4516.5, bsz=204, num_updates=1808, lr=2.1696e-05, gnorm=1.478, train_wall=4, gb_free=11.3, wall=5772
2025-04-17 11:33:05 | INFO | train_inner | epoch 014:      3 / 139 loss=6.001, nll_loss=2.555, ppl=5.88, wps=2394.6, ups=0.38, wpb=6235, bsz=272, num_updates=1810, lr=2.172e-05, gnorm=1.274, train_wall=5, gb_free=11.8, wall=5777
2025-04-17 11:33:10 | INFO | train_inner | epoch 014:      5 / 139 loss=5.935, nll_loss=2.463, ppl=5.51, wps=2226.5, ups=0.37, wpb=6089, bsz=328, num_updates=1812, lr=2.1744e-05, gnorm=1.199, train_wall=5, gb_free=10.1, wall=5783
2025-04-17 11:33:15 | INFO | train_inner | epoch 014:      7 / 139 loss=6.111, nll_loss=2.683, ppl=6.42, wps=2470.5, ups=0.41, wpb=6095, bsz=184, num_updates=1814, lr=2.1768e-05, gnorm=1.419, train_wall=5, gb_free=11.2, wall=5788
2025-04-17 11:33:21 | INFO | train_inner | epoch 014:      9 / 139 loss=6.057, nll_loss=2.602, ppl=6.07, wps=2458.9, ups=0.35, wpb=6932, bsz=312, num_updates=1816, lr=2.1792e-05, gnorm=1.263, train_wall=6, gb_free=11.8, wall=5793
2025-04-17 11:33:26 | INFO | train_inner | epoch 014:     11 / 139 loss=6.037, nll_loss=2.6, ppl=6.06, wps=2507, ups=0.38, wpb=6630, bsz=256, num_updates=1818, lr=2.1816e-05, gnorm=1.277, train_wall=5, gb_free=11.1, wall=5799
2025-04-17 11:33:31 | INFO | train_inner | epoch 014:     13 / 139 loss=5.944, nll_loss=2.486, ppl=5.6, wps=2442.2, ups=0.4, wpb=6170, bsz=200, num_updates=1820, lr=2.184e-05, gnorm=1.157, train_wall=5, gb_free=11.7, wall=5804
2025-04-17 11:33:37 | INFO | train_inner | epoch 014:     15 / 139 loss=5.992, nll_loss=2.538, ppl=5.81, wps=2228.4, ups=0.37, wpb=5972.5, bsz=248, num_updates=1822, lr=2.1864e-05, gnorm=1.396, train_wall=5, gb_free=11.2, wall=5809
2025-04-17 11:33:42 | INFO | train_inner | epoch 014:     17 / 139 loss=5.979, nll_loss=2.514, ppl=5.71, wps=2447.2, ups=0.38, wpb=6381, bsz=268, num_updates=1824, lr=2.1888e-05, gnorm=1.218, train_wall=5, gb_free=10.3, wall=5814
2025-04-17 11:33:48 | INFO | train_inner | epoch 014:     19 / 139 loss=5.993, nll_loss=2.539, ppl=5.81, wps=2364.1, ups=0.35, wpb=6774, bsz=388, num_updates=1826, lr=2.1912e-05, gnorm=1.278, train_wall=6, gb_free=10.3, wall=5820
2025-04-17 11:33:53 | INFO | train_inner | epoch 014:     21 / 139 loss=6.022, nll_loss=2.574, ppl=5.95, wps=2119.5, ups=0.4, wpb=5344, bsz=224, num_updates=1828, lr=2.1936e-05, gnorm=1.362, train_wall=5, gb_free=11, wall=5825
2025-04-17 11:33:58 | INFO | train_inner | epoch 014:     23 / 139 loss=6.073, nll_loss=2.645, ppl=6.26, wps=2478.4, ups=0.37, wpb=6776, bsz=264, num_updates=1830, lr=2.196e-05, gnorm=1.339, train_wall=5, gb_free=10.9, wall=5831
2025-04-17 11:34:03 | INFO | train_inner | epoch 014:     25 / 139 loss=6.103, nll_loss=2.688, ppl=6.44, wps=2420.4, ups=0.38, wpb=6294.5, bsz=208, num_updates=1832, lr=2.1984e-05, gnorm=1.349, train_wall=5, gb_free=10.7, wall=5836
2025-04-17 11:34:09 | INFO | train_inner | epoch 014:     27 / 139 loss=6.068, nll_loss=2.637, ppl=6.22, wps=2360.8, ups=0.38, wpb=6266.5, bsz=200, num_updates=1834, lr=2.2008e-05, gnorm=1.164, train_wall=5, gb_free=12.2, wall=5841
2025-04-17 11:34:14 | INFO | train_inner | epoch 014:     29 / 139 loss=6.053, nll_loss=2.612, ppl=6.11, wps=2323.2, ups=0.39, wpb=5967.5, bsz=204, num_updates=1836, lr=2.2032e-05, gnorm=1.204, train_wall=5, gb_free=12.4, wall=5846
2025-04-17 11:34:19 | INFO | train_inner | epoch 014:     31 / 139 loss=6.046, nll_loss=2.601, ppl=6.07, wps=2291.8, ups=0.38, wpb=6061, bsz=200, num_updates=1838, lr=2.2056e-05, gnorm=1.286, train_wall=5, gb_free=12.5, wall=5851
2025-04-17 11:34:29 | INFO | train_inner | epoch 014:     33 / 139 loss=6.042, nll_loss=2.59, ppl=6.02, wps=1149.6, ups=0.19, wpb=5898.5, bsz=204, num_updates=1840, lr=2.208e-05, gnorm=1.267, train_wall=10, gb_free=12.6, wall=5862
2025-04-17 11:34:34 | INFO | train_inner | epoch 014:     35 / 139 loss=6.085, nll_loss=2.671, ppl=6.37, wps=2347.1, ups=0.4, wpb=5819, bsz=240, num_updates=1842, lr=2.2104e-05, gnorm=1.401, train_wall=5, gb_free=12, wall=5867
2025-04-17 11:34:40 | INFO | train_inner | epoch 014:     37 / 139 loss=6.142, nll_loss=2.707, ppl=6.53, wps=2275.9, ups=0.36, wpb=6336, bsz=188, num_updates=1844, lr=2.2128e-05, gnorm=1.429, train_wall=6, gb_free=10, wall=5872
2025-04-17 11:34:45 | INFO | train_inner | epoch 014:     39 / 139 loss=6.154, nll_loss=2.734, ppl=6.65, wps=2034.5, ups=0.4, wpb=5085.5, bsz=128, num_updates=1846, lr=2.2152e-05, gnorm=1.491, train_wall=5, gb_free=10.7, wall=5877
2025-04-17 11:34:50 | INFO | train_inner | epoch 014:     41 / 139 loss=5.868, nll_loss=2.383, ppl=5.22, wps=2444.1, ups=0.36, wpb=6865.5, bsz=336, num_updates=1848, lr=2.2176e-05, gnorm=1.174, train_wall=6, gb_free=10.9, wall=5883
2025-04-17 11:34:55 | INFO | train_inner | epoch 014:     43 / 139 loss=6.034, nll_loss=2.597, ppl=6.05, wps=2257.3, ups=0.43, wpb=5298.5, bsz=140, num_updates=1850, lr=2.22e-05, gnorm=1.28, train_wall=5, gb_free=12.7, wall=5888
2025-04-17 11:35:00 | INFO | train_inner | epoch 014:     45 / 139 loss=6.107, nll_loss=2.697, ppl=6.48, wps=2207, ups=0.41, wpb=5324, bsz=120, num_updates=1852, lr=2.2224e-05, gnorm=1.35, train_wall=5, gb_free=13.6, wall=5892
2025-04-17 11:35:05 | INFO | train_inner | epoch 014:     47 / 139 loss=6.097, nll_loss=2.668, ppl=6.36, wps=2192.3, ups=0.38, wpb=5783, bsz=268, num_updates=1854, lr=2.2248e-05, gnorm=1.345, train_wall=5, gb_free=10.7, wall=5898
2025-04-17 11:35:11 | INFO | train_inner | epoch 014:     49 / 139 loss=6.044, nll_loss=2.577, ppl=5.97, wps=2115.5, ups=0.37, wpb=5667.5, bsz=232, num_updates=1856, lr=2.2272e-05, gnorm=1.336, train_wall=5, gb_free=11.5, wall=5903
2025-04-17 11:35:15 | INFO | train_inner | epoch 014:     51 / 139 loss=6.004, nll_loss=2.546, ppl=5.84, wps=2011.6, ups=0.41, wpb=4851, bsz=128, num_updates=1858, lr=2.2296e-05, gnorm=1.574, train_wall=5, gb_free=12.1, wall=5908
2025-04-17 11:35:20 | INFO | train_inner | epoch 014:     53 / 139 loss=5.88, nll_loss=2.42, ppl=5.35, wps=2374.9, ups=0.4, wpb=5870.5, bsz=248, num_updates=1860, lr=2.232e-05, gnorm=1.268, train_wall=5, gb_free=10.9, wall=5913
2025-04-17 11:35:26 | INFO | train_inner | epoch 014:     55 / 139 loss=5.994, nll_loss=2.553, ppl=5.87, wps=2472.6, ups=0.37, wpb=6698, bsz=228, num_updates=1862, lr=2.2344e-05, gnorm=1.185, train_wall=5, gb_free=11.3, wall=5918
2025-04-17 11:35:31 | INFO | train_inner | epoch 014:     57 / 139 loss=6.148, nll_loss=2.725, ppl=6.61, wps=2133.1, ups=0.38, wpb=5571, bsz=216, num_updates=1864, lr=2.2368e-05, gnorm=1.64, train_wall=5, gb_free=11.2, wall=5923
2025-04-17 11:35:36 | INFO | train_inner | epoch 014:     59 / 139 loss=6.09, nll_loss=2.649, ppl=6.27, wps=2240.1, ups=0.4, wpb=5571, bsz=116, num_updates=1866, lr=2.2392e-05, gnorm=1.491, train_wall=5, gb_free=13.1, wall=5928
2025-04-17 11:35:41 | INFO | train_inner | epoch 014:     61 / 139 loss=6.018, nll_loss=2.595, ppl=6.04, wps=2108.9, ups=0.4, wpb=5330.5, bsz=268, num_updates=1868, lr=2.2416e-05, gnorm=1.301, train_wall=5, gb_free=11.9, wall=5933
2025-04-17 11:35:46 | INFO | train_inner | epoch 014:     63 / 139 loss=6.093, nll_loss=2.651, ppl=6.28, wps=2221, ups=0.41, wpb=5420, bsz=140, num_updates=1870, lr=2.244e-05, gnorm=1.517, train_wall=5, gb_free=15.1, wall=5938
2025-04-17 11:35:51 | INFO | train_inner | epoch 014:     65 / 139 loss=6.001, nll_loss=2.539, ppl=5.81, wps=2434.9, ups=0.37, wpb=6603.5, bsz=232, num_updates=1872, lr=2.2464e-05, gnorm=1.2, train_wall=5, gb_free=10.8, wall=5944
2025-04-17 11:35:57 | INFO | train_inner | epoch 014:     67 / 139 loss=6.113, nll_loss=2.684, ppl=6.43, wps=2073.8, ups=0.36, wpb=5713, bsz=220, num_updates=1874, lr=2.2488e-05, gnorm=1.319, train_wall=6, gb_free=9.9, wall=5949
2025-04-17 11:36:02 | INFO | train_inner | epoch 014:     69 / 139 loss=6.134, nll_loss=2.708, ppl=6.53, wps=1920.2, ups=0.41, wpb=4691.5, bsz=156, num_updates=1876, lr=2.2512e-05, gnorm=1.575, train_wall=5, gb_free=13.8, wall=5954
2025-04-17 11:36:07 | INFO | train_inner | epoch 014:     71 / 139 loss=6.157, nll_loss=2.754, ppl=6.75, wps=2158.2, ups=0.37, wpb=5759.5, bsz=156, num_updates=1878, lr=2.2536e-05, gnorm=1.311, train_wall=5, gb_free=10.9, wall=5960
2025-04-17 11:36:13 | INFO | train_inner | epoch 014:     73 / 139 loss=5.869, nll_loss=2.41, ppl=5.31, wps=2232, ups=0.36, wpb=6223, bsz=344, num_updates=1880, lr=2.256e-05, gnorm=1.219, train_wall=6, gb_free=12.4, wall=5965
2025-04-17 11:36:18 | INFO | train_inner | epoch 014:     75 / 139 loss=6.092, nll_loss=2.677, ppl=6.39, wps=2279.1, ups=0.39, wpb=5908.5, bsz=216, num_updates=1882, lr=2.2584e-05, gnorm=1.247, train_wall=5, gb_free=12.6, wall=5970
2025-04-17 11:36:23 | INFO | train_inner | epoch 014:     77 / 139 loss=6.039, nll_loss=2.589, ppl=6.02, wps=2419.6, ups=0.38, wpb=6431, bsz=264, num_updates=1884, lr=2.2608e-05, gnorm=1.301, train_wall=5, gb_free=11.3, wall=5976
2025-04-17 11:36:29 | INFO | train_inner | epoch 014:     79 / 139 loss=6.009, nll_loss=2.553, ppl=5.87, wps=2326.3, ups=0.37, wpb=6316, bsz=244, num_updates=1886, lr=2.2632e-05, gnorm=1.231, train_wall=5, gb_free=10.3, wall=5981
2025-04-17 11:36:34 | INFO | train_inner | epoch 014:     81 / 139 loss=5.976, nll_loss=2.517, ppl=5.72, wps=2290.6, ups=0.39, wpb=5911.5, bsz=228, num_updates=1888, lr=2.2656e-05, gnorm=1.318, train_wall=5, gb_free=11.5, wall=5986
2025-04-17 11:36:39 | INFO | train_inner | epoch 014:     83 / 139 loss=6.046, nll_loss=2.627, ppl=6.18, wps=2463.9, ups=0.4, wpb=6221.5, bsz=208, num_updates=1890, lr=2.268e-05, gnorm=1.44, train_wall=5, gb_free=12.3, wall=5991
2025-04-17 11:36:44 | INFO | train_inner | epoch 014:     85 / 139 loss=6.065, nll_loss=2.641, ppl=6.24, wps=2225.1, ups=0.38, wpb=5875.5, bsz=256, num_updates=1892, lr=2.2704e-05, gnorm=1.264, train_wall=5, gb_free=9.5, wall=5997
2025-04-17 11:36:49 | INFO | train_inner | epoch 014:     87 / 139 loss=6.01, nll_loss=2.55, ppl=5.86, wps=2449.2, ups=0.43, wpb=5749, bsz=208, num_updates=1894, lr=2.2728e-05, gnorm=1.255, train_wall=5, gb_free=16.4, wall=6001
2025-04-17 11:36:54 | INFO | train_inner | epoch 014:     89 / 139 loss=6.02, nll_loss=2.565, ppl=5.92, wps=2490, ups=0.37, wpb=6642.5, bsz=228, num_updates=1896, lr=2.2752e-05, gnorm=1.199, train_wall=5, gb_free=11.4, wall=6007
2025-04-17 11:37:00 | INFO | train_inner | epoch 014:     91 / 139 loss=6.02, nll_loss=2.578, ppl=5.97, wps=2314.7, ups=0.34, wpb=6786, bsz=264, num_updates=1898, lr=2.2776e-05, gnorm=1.188, train_wall=6, gb_free=11.4, wall=6012
2025-04-17 11:37:05 | INFO | train_inner | epoch 014:     93 / 139 loss=6.069, nll_loss=2.641, ppl=6.24, wps=2220.7, ups=0.38, wpb=5894, bsz=224, num_updates=1900, lr=2.28e-05, gnorm=1.404, train_wall=5, gb_free=12.6, wall=6018
2025-04-17 11:37:10 | INFO | train_inner | epoch 014:     95 / 139 loss=6.031, nll_loss=2.595, ppl=6.04, wps=2388.9, ups=0.39, wpb=6166.5, bsz=236, num_updates=1902, lr=2.2824e-05, gnorm=1.284, train_wall=5, gb_free=10.2, wall=6023
2025-04-17 11:37:15 | INFO | train_inner | epoch 014:     97 / 139 loss=6.077, nll_loss=2.647, ppl=6.26, wps=2030.8, ups=0.4, wpb=5116.5, bsz=152, num_updates=1904, lr=2.2848e-05, gnorm=1.333, train_wall=5, gb_free=12.6, wall=6028
2025-04-17 11:37:21 | INFO | train_inner | epoch 014:     99 / 139 loss=5.954, nll_loss=2.494, ppl=5.63, wps=2254.3, ups=0.37, wpb=6091.5, bsz=308, num_updates=1906, lr=2.2872e-05, gnorm=1.39, train_wall=5, gb_free=12.4, wall=6033
2025-04-17 11:37:26 | INFO | train_inner | epoch 014:    101 / 139 loss=5.962, nll_loss=2.503, ppl=5.67, wps=2445.1, ups=0.37, wpb=6584, bsz=256, num_updates=1908, lr=2.2896e-05, gnorm=1.194, train_wall=5, gb_free=11, wall=6039
2025-04-17 11:37:31 | INFO | train_inner | epoch 014:    103 / 139 loss=6.116, nll_loss=2.672, ppl=6.37, wps=2036.3, ups=0.38, wpb=5297.5, bsz=188, num_updates=1910, lr=2.292e-05, gnorm=1.354, train_wall=5, gb_free=12.9, wall=6044
2025-04-17 11:37:36 | INFO | train_inner | epoch 014:    105 / 139 loss=6.187, nll_loss=2.778, ppl=6.86, wps=2217, ups=0.4, wpb=5579, bsz=144, num_updates=1912, lr=2.2944e-05, gnorm=1.403, train_wall=5, gb_free=11.2, wall=6049
2025-04-17 11:37:42 | INFO | train_inner | epoch 014:    107 / 139 loss=5.98, nll_loss=2.521, ppl=5.74, wps=2390.9, ups=0.36, wpb=6677.5, bsz=228, num_updates=1914, lr=2.2968e-05, gnorm=1.244, train_wall=6, gb_free=10.9, wall=6055
2025-04-17 11:37:48 | INFO | train_inner | epoch 014:    109 / 139 loss=5.907, nll_loss=2.446, ppl=5.45, wps=2322.1, ups=0.36, wpb=6380, bsz=292, num_updates=1916, lr=2.2992e-05, gnorm=1.14, train_wall=5, gb_free=9.7, wall=6060
2025-04-17 11:37:53 | INFO | train_inner | epoch 014:    111 / 139 loss=5.927, nll_loss=2.456, ppl=5.49, wps=2425.7, ups=0.38, wpb=6313, bsz=216, num_updates=1918, lr=2.3016e-05, gnorm=1.167, train_wall=5, gb_free=11.8, wall=6065
2025-04-17 11:37:58 | INFO | train_inner | epoch 014:    113 / 139 loss=6.056, nll_loss=2.631, ppl=6.19, wps=2252.7, ups=0.37, wpb=6028, bsz=352, num_updates=1920, lr=2.304e-05, gnorm=1.379, train_wall=5, gb_free=10.9, wall=6071
2025-04-17 11:38:03 | INFO | train_inner | epoch 014:    115 / 139 loss=6.063, nll_loss=2.637, ppl=6.22, wps=2256.3, ups=0.4, wpb=5576, bsz=164, num_updates=1922, lr=2.3064e-05, gnorm=1.258, train_wall=5, gb_free=14, wall=6076
2025-04-17 11:38:08 | INFO | train_inner | epoch 014:    117 / 139 loss=5.96, nll_loss=2.506, ppl=5.68, wps=2323.6, ups=0.38, wpb=6180, bsz=220, num_updates=1924, lr=2.3088e-05, gnorm=1.137, train_wall=5, gb_free=14.2, wall=6081
2025-04-17 11:38:14 | INFO | train_inner | epoch 014:    119 / 139 loss=5.794, nll_loss=2.303, ppl=4.93, wps=2252.2, ups=0.36, wpb=6219.5, bsz=380, num_updates=1926, lr=2.3112e-05, gnorm=1.079, train_wall=6, gb_free=10.8, wall=6086
2025-04-17 11:38:18 | INFO | train_inner | epoch 014:    121 / 139 loss=5.997, nll_loss=2.542, ppl=5.82, wps=2192, ups=0.44, wpb=4989.5, bsz=176.5, num_updates=1928, lr=2.3136e-05, gnorm=1.589, train_wall=5, gb_free=13.2, wall=6091
2025-04-17 11:38:24 | INFO | train_inner | epoch 014:    123 / 139 loss=6.015, nll_loss=2.576, ppl=5.96, wps=2310.9, ups=0.35, wpb=6676, bsz=276, num_updates=1930, lr=2.316e-05, gnorm=1.437, train_wall=6, gb_free=9, wall=6097
2025-04-17 11:38:30 | INFO | train_inner | epoch 014:    125 / 139 loss=6.135, nll_loss=2.73, ppl=6.64, wps=2150.4, ups=0.38, wpb=5732.5, bsz=184, num_updates=1932, lr=2.3184e-05, gnorm=1.364, train_wall=5, gb_free=13.9, wall=6102
2025-04-17 11:38:35 | INFO | train_inner | epoch 014:    127 / 139 loss=6.05, nll_loss=2.617, ppl=6.14, wps=2288.7, ups=0.39, wpb=5837.5, bsz=172, num_updates=1934, lr=2.3208e-05, gnorm=1.328, train_wall=5, gb_free=10.7, wall=6107
2025-04-17 11:38:40 | INFO | train_inner | epoch 014:    129 / 139 loss=6.035, nll_loss=2.573, ppl=5.95, wps=2484.9, ups=0.38, wpb=6587.5, bsz=240, num_updates=1936, lr=2.3232e-05, gnorm=1.23, train_wall=5, gb_free=14.4, wall=6112
2025-04-17 11:38:45 | INFO | train_inner | epoch 014:    131 / 139 loss=6.008, nll_loss=2.552, ppl=5.87, wps=2572.5, ups=0.38, wpb=6808.5, bsz=288, num_updates=1938, lr=2.3256e-05, gnorm=1.261, train_wall=5, gb_free=12.2, wall=6118
2025-04-17 11:38:51 | INFO | train_inner | epoch 014:    133 / 139 loss=5.918, nll_loss=2.462, ppl=5.51, wps=2442.2, ups=0.37, wpb=6612.5, bsz=292, num_updates=1940, lr=2.328e-05, gnorm=1.128, train_wall=5, gb_free=11.3, wall=6123
2025-04-17 11:38:56 | INFO | train_inner | epoch 014:    135 / 139 loss=6.058, nll_loss=2.651, ppl=6.28, wps=2461.5, ups=0.36, wpb=6888, bsz=344, num_updates=1942, lr=2.3304e-05, gnorm=1.281, train_wall=6, gb_free=11.4, wall=6129
2025-04-17 11:39:01 | INFO | train_inner | epoch 014:    137 / 139 loss=6.11, nll_loss=2.694, ppl=6.47, wps=2412.6, ups=0.39, wpb=6162.5, bsz=200, num_updates=1944, lr=2.3328e-05, gnorm=1.305, train_wall=5, gb_free=13.8, wall=6134
2025-04-17 11:39:05 | INFO | train_inner | epoch 014:    139 / 139 loss=6.152, nll_loss=2.719, ppl=6.59, wps=2235.8, ups=0.54, wpb=4104.5, bsz=100, num_updates=1946, lr=2.3352e-05, gnorm=1.535, train_wall=4, gb_free=17.2, wall=6138
2025-04-17 11:39:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-17 11:39:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=15265.79296875Mb; avail=239816.33984375Mb
2025-04-17 11:39:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000642
2025-04-17 11:39:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15265.79296875Mb; avail=239816.33984375Mb
2025-04-17 11:39:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012814
2025-04-17 11:39:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15265.79296875Mb; avail=239816.33984375Mb
2025-04-17 11:39:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.011123
2025-04-17 11:39:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024932
2025-04-17 11:39:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15265.79296875Mb; avail=239816.33984375Mb
2025-04-17 11:39:20 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 6.115 | nll_loss 2.506 | ppl 5.68 | wps 5373.6 | wpb 2350.9 | bsz 94.7 | num_updates 1946 | best_loss 6.115
2025-04-17 11:39:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 1946 updates
2025-04-17 11:39:20 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt
2025-04-17 11:39:58 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt
2025-04-17 11:40:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt (epoch 14 @ 1946 updates, score 6.115) (writing took 62.20278272900032 seconds)
2025-04-17 11:40:22 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2025-04-17 11:40:22 | INFO | train | epoch 014 | loss 6.03 | nll_loss 2.588 | ppl 6.01 | wps 1875.1 | ups 0.31 | wpb 6008.3 | bsz 229.1 | num_updates 1946 | lr 2.3352e-05 | gnorm 1.312 | train_wall 367 | gb_free 17.2 | wall 6215
2025-04-17 11:40:22 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:hi-mr': 31849}; raw total size: 31849
2025-04-17 11:40:22 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:hi-mr': 31849}; resampled total size: 31849
2025-04-17 11:40:22 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:hi-mr': 1.0}
2025-04-17 11:40:22 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001241
2025-04-17 11:40:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=25402.91015625Mb; avail=229679.234375Mb
2025-04-17 11:40:22 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000551
2025-04-17 11:40:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003276
2025-04-17 11:40:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=25402.91015625Mb; avail=229679.234375Mb
2025-04-17 11:40:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000094
2025-04-17 11:40:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=25402.91015625Mb; avail=229679.234375Mb
2025-04-17 11:40:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001172
2025-04-17 11:40:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.004842
2025-04-17 11:40:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=25402.91015625Mb; avail=229679.234375Mb
2025-04-17 11:40:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 139
2025-04-17 11:40:23 | INFO | fairseq.trainer | begin training epoch 15
2025-04-17 11:40:23 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-17 11:40:28 | INFO | train_inner | epoch 015:      2 / 139 loss=5.898, nll_loss=2.404, ppl=5.29, wps=138.8, ups=0.02, wpb=5734, bsz=272, num_updates=1948, lr=2.3376e-05, gnorm=1.228, train_wall=5, gb_free=10.9, wall=6220
2025-04-17 11:40:32 | INFO | train_inner | epoch 015:      4 / 139 loss=5.934, nll_loss=2.472, ppl=5.55, wps=2073.1, ups=0.44, wpb=4673.5, bsz=160, num_updates=1950, lr=2.34e-05, gnorm=1.41, train_wall=4, gb_free=14.9, wall=6225
2025-04-17 11:40:37 | INFO | train_inner | epoch 015:      6 / 139 loss=5.958, nll_loss=2.524, ppl=5.75, wps=2430.2, ups=0.41, wpb=5972, bsz=248, num_updates=1952, lr=2.3424e-05, gnorm=1.389, train_wall=5, gb_free=10.9, wall=6230
2025-04-17 11:40:42 | INFO | train_inner | epoch 015:      8 / 139 loss=6.07, nll_loss=2.623, ppl=6.16, wps=2247.5, ups=0.41, wpb=5517.5, bsz=120, num_updates=1954, lr=2.3448e-05, gnorm=1.421, train_wall=5, gb_free=12.9, wall=6234
2025-04-17 11:40:47 | INFO | train_inner | epoch 015:     10 / 139 loss=5.971, nll_loss=2.501, ppl=5.66, wps=2381.9, ups=0.37, wpb=6418, bsz=268, num_updates=1956, lr=2.3472e-05, gnorm=1.271, train_wall=5, gb_free=11.5, wall=6240
2025-04-17 11:40:53 | INFO | train_inner | epoch 015:     12 / 139 loss=5.964, nll_loss=2.495, ppl=5.64, wps=2289.3, ups=0.37, wpb=6253.5, bsz=236, num_updates=1958, lr=2.3496e-05, gnorm=1.209, train_wall=5, gb_free=11.7, wall=6245
2025-04-17 11:40:58 | INFO | train_inner | epoch 015:     14 / 139 loss=5.948, nll_loss=2.492, ppl=5.63, wps=2545.3, ups=0.37, wpb=6811, bsz=280, num_updates=1960, lr=2.352e-05, gnorm=1.353, train_wall=5, gb_free=12, wall=6251
2025-04-17 11:41:03 | INFO | train_inner | epoch 015:     16 / 139 loss=5.963, nll_loss=2.489, ppl=5.62, wps=2204.5, ups=0.38, wpb=5760.5, bsz=216, num_updates=1962, lr=2.3544e-05, gnorm=1.358, train_wall=5, gb_free=12.1, wall=6256
2025-04-17 11:41:09 | INFO | train_inner | epoch 015:     18 / 139 loss=5.951, nll_loss=2.491, ppl=5.62, wps=2376.4, ups=0.39, wpb=6117.5, bsz=248, num_updates=1964, lr=2.3568e-05, gnorm=1.249, train_wall=5, gb_free=12.9, wall=6261
2025-04-17 11:41:14 | INFO | train_inner | epoch 015:     20 / 139 loss=6.001, nll_loss=2.563, ppl=5.91, wps=2285.3, ups=0.39, wpb=5856, bsz=224, num_updates=1966, lr=2.3592e-05, gnorm=1.824, train_wall=5, gb_free=11.8, wall=6266
2025-04-17 11:41:19 | INFO | train_inner | epoch 015:     22 / 139 loss=5.949, nll_loss=2.491, ppl=5.62, wps=2244.7, ups=0.38, wpb=5863, bsz=196, num_updates=1968, lr=2.3616e-05, gnorm=1.288, train_wall=5, gb_free=12.3, wall=6271
2025-04-17 11:41:24 | INFO | train_inner | epoch 015:     24 / 139 loss=6.113, nll_loss=2.684, ppl=6.42, wps=2245.2, ups=0.42, wpb=5405, bsz=104, num_updates=1970, lr=2.364e-05, gnorm=1.526, train_wall=5, gb_free=12.4, wall=6276
2025-04-17 11:41:29 | INFO | train_inner | epoch 015:     26 / 139 loss=5.84, nll_loss=2.347, ppl=5.09, wps=2399.7, ups=0.38, wpb=6359.5, bsz=296, num_updates=1972, lr=2.3664e-05, gnorm=1.222, train_wall=5, gb_free=12.1, wall=6281
2025-04-17 11:41:34 | INFO | train_inner | epoch 015:     28 / 139 loss=5.91, nll_loss=2.44, ppl=5.43, wps=2434.4, ups=0.4, wpb=6154, bsz=272, num_updates=1974, lr=2.3688e-05, gnorm=1.157, train_wall=5, gb_free=11.1, wall=6287
2025-04-17 11:41:39 | INFO | train_inner | epoch 015:     30 / 139 loss=5.969, nll_loss=2.506, ppl=5.68, wps=2333.8, ups=0.4, wpb=5885.5, bsz=236, num_updates=1976, lr=2.3712e-05, gnorm=1.524, train_wall=5, gb_free=11.6, wall=6292
2025-04-17 11:41:44 | INFO | train_inner | epoch 015:     32 / 139 loss=5.959, nll_loss=2.509, ppl=5.69, wps=2163.6, ups=0.39, wpb=5551.5, bsz=220, num_updates=1978, lr=2.3736e-05, gnorm=1.248, train_wall=5, gb_free=11.5, wall=6297
2025-04-17 11:41:50 | INFO | train_inner | epoch 015:     34 / 139 loss=5.932, nll_loss=2.452, ppl=5.47, wps=2382, ups=0.35, wpb=6718.5, bsz=296, num_updates=1980, lr=2.376e-05, gnorm=1.196, train_wall=6, gb_free=10.5, wall=6302
2025-04-17 11:41:55 | INFO | train_inner | epoch 015:     36 / 139 loss=5.954, nll_loss=2.496, ppl=5.64, wps=2479.1, ups=0.36, wpb=6928.5, bsz=292, num_updates=1982, lr=2.3784e-05, gnorm=1.203, train_wall=6, gb_free=10.9, wall=6308
2025-04-17 11:42:00 | INFO | train_inner | epoch 015:     38 / 139 loss=6.078, nll_loss=2.656, ppl=6.3, wps=2482.7, ups=0.42, wpb=5975.5, bsz=184, num_updates=1984, lr=2.3808e-05, gnorm=1.362, train_wall=5, gb_free=13.7, wall=6313
2025-04-17 11:42:06 | INFO | train_inner | epoch 015:     40 / 139 loss=5.871, nll_loss=2.389, ppl=5.24, wps=2563.5, ups=0.38, wpb=6808, bsz=276, num_updates=1986, lr=2.3832e-05, gnorm=1.232, train_wall=5, gb_free=11.2, wall=6318
2025-04-17 11:42:11 | INFO | train_inner | epoch 015:     42 / 139 loss=5.936, nll_loss=2.452, ppl=5.47, wps=2228.5, ups=0.36, wpb=6113, bsz=208, num_updates=1988, lr=2.3856e-05, gnorm=1.206, train_wall=5, gb_free=11.5, wall=6324
2025-04-17 11:42:17 | INFO | train_inner | epoch 015:     44 / 139 loss=6.026, nll_loss=2.587, ppl=6.01, wps=2288.8, ups=0.35, wpb=6478, bsz=240, num_updates=1990, lr=2.388e-05, gnorm=1.243, train_wall=6, gb_free=12.7, wall=6329
2025-04-17 11:42:22 | INFO | train_inner | epoch 015:     46 / 139 loss=5.968, nll_loss=2.519, ppl=5.73, wps=2306.3, ups=0.36, wpb=6438.5, bsz=220, num_updates=1992, lr=2.3904e-05, gnorm=1.245, train_wall=6, gb_free=11, wall=6335
2025-04-17 11:42:27 | INFO | train_inner | epoch 015:     48 / 139 loss=5.942, nll_loss=2.495, ppl=5.64, wps=2465.5, ups=0.39, wpb=6316.5, bsz=212, num_updates=1994, lr=2.3928e-05, gnorm=1.25, train_wall=5, gb_free=11.3, wall=6340
2025-04-17 11:42:37 | INFO | train_inner | epoch 015:     50 / 139 loss=6.073, nll_loss=2.639, ppl=6.23, wps=1042.1, ups=0.2, wpb=5218, bsz=172, num_updates=1996, lr=2.3952e-05, gnorm=1.25, train_wall=10, gb_free=13.5, wall=6350
2025-04-17 11:42:43 | INFO | train_inner | epoch 015:     52 / 139 loss=6.028, nll_loss=2.587, ppl=6.01, wps=2086.6, ups=0.38, wpb=5471, bsz=212, num_updates=1998, lr=2.3976e-05, gnorm=1.338, train_wall=5, gb_free=12.9, wall=6355
2025-04-17 11:42:48 | INFO | train_inner | epoch 015:     54 / 139 loss=5.875, nll_loss=2.395, ppl=5.26, wps=2248.3, ups=0.39, wpb=5813.5, bsz=232, num_updates=2000, lr=2.4e-05, gnorm=1.169, train_wall=5, gb_free=12.9, wall=6360
2025-04-17 11:42:53 | INFO | train_inner | epoch 015:     56 / 139 loss=6.011, nll_loss=2.565, ppl=5.92, wps=2177.8, ups=0.39, wpb=5620, bsz=160, num_updates=2002, lr=2.4024e-05, gnorm=1.254, train_wall=5, gb_free=13.8, wall=6366
2025-04-17 11:42:58 | INFO | train_inner | epoch 015:     58 / 139 loss=5.914, nll_loss=2.445, ppl=5.44, wps=2399.2, ups=0.38, wpb=6332.5, bsz=240, num_updates=2004, lr=2.4048e-05, gnorm=1.139, train_wall=5, gb_free=11.4, wall=6371
2025-04-17 11:43:03 | INFO | train_inner | epoch 015:     60 / 139 loss=5.976, nll_loss=2.523, ppl=5.75, wps=2184.8, ups=0.4, wpb=5470, bsz=224, num_updates=2006, lr=2.4072e-05, gnorm=1.399, train_wall=5, gb_free=10.9, wall=6376
2025-04-17 11:43:09 | INFO | train_inner | epoch 015:     62 / 139 loss=5.876, nll_loss=2.382, ppl=5.21, wps=2445.9, ups=0.35, wpb=6978, bsz=304, num_updates=2008, lr=2.4096e-05, gnorm=1.144, train_wall=6, gb_free=10.1, wall=6382
2025-04-17 11:43:14 | INFO | train_inner | epoch 015:     64 / 139 loss=5.892, nll_loss=2.408, ppl=5.31, wps=2247.1, ups=0.37, wpb=6006, bsz=260, num_updates=2010, lr=2.412e-05, gnorm=1.139, train_wall=5, gb_free=12.1, wall=6387
2025-04-17 11:43:19 | INFO | train_inner | epoch 015:     66 / 139 loss=5.907, nll_loss=2.446, ppl=5.45, wps=2083.8, ups=0.4, wpb=5234.5, bsz=200, num_updates=2012, lr=2.4144e-05, gnorm=1.304, train_wall=5, gb_free=12.2, wall=6392
2025-04-17 11:43:25 | INFO | train_inner | epoch 015:     68 / 139 loss=5.865, nll_loss=2.39, ppl=5.24, wps=2457.3, ups=0.37, wpb=6728, bsz=276, num_updates=2014, lr=2.4168e-05, gnorm=1.135, train_wall=5, gb_free=11.4, wall=6397
2025-04-17 11:43:30 | INFO | train_inner | epoch 015:     70 / 139 loss=5.955, nll_loss=2.483, ppl=5.59, wps=2357.2, ups=0.37, wpb=6344.5, bsz=228, num_updates=2016, lr=2.4192e-05, gnorm=1.29, train_wall=5, gb_free=9.7, wall=6403
2025-04-17 11:43:36 | INFO | train_inner | epoch 015:     72 / 139 loss=5.795, nll_loss=2.28, ppl=4.86, wps=2365.8, ups=0.36, wpb=6529, bsz=292, num_updates=2018, lr=2.4216e-05, gnorm=1.116, train_wall=6, gb_free=12.5, wall=6408
2025-04-17 11:43:41 | INFO | train_inner | epoch 015:     74 / 139 loss=6.006, nll_loss=2.557, ppl=5.89, wps=2360.3, ups=0.39, wpb=6046, bsz=172, num_updates=2020, lr=2.424e-05, gnorm=1.477, train_wall=5, gb_free=12.4, wall=6413
2025-04-17 11:43:46 | INFO | train_inner | epoch 015:     76 / 139 loss=6.15, nll_loss=2.756, ppl=6.76, wps=2164.7, ups=0.37, wpb=5856.5, bsz=280, num_updates=2022, lr=2.4264e-05, gnorm=1.605, train_wall=5, gb_free=13.4, wall=6419
2025-04-17 11:43:52 | INFO | train_inner | epoch 015:     78 / 139 loss=5.888, nll_loss=2.416, ppl=5.34, wps=2170.4, ups=0.36, wpb=6079, bsz=352, num_updates=2024, lr=2.4288e-05, gnorm=1.261, train_wall=6, gb_free=10.3, wall=6424
2025-04-17 11:43:58 | INFO | train_inner | epoch 015:     80 / 139 loss=5.895, nll_loss=2.402, ppl=5.29, wps=2295.1, ups=0.35, wpb=6508.5, bsz=252, num_updates=2026, lr=2.4312e-05, gnorm=1.239, train_wall=6, gb_free=10.4, wall=6430
2025-04-17 11:44:03 | INFO | train_inner | epoch 015:     82 / 139 loss=5.996, nll_loss=2.532, ppl=5.78, wps=2065, ups=0.4, wpb=5128, bsz=180, num_updates=2028, lr=2.4336e-05, gnorm=1.441, train_wall=5, gb_free=14, wall=6435
2025-04-17 11:44:08 | INFO | train_inner | epoch 015:     84 / 139 loss=6.068, nll_loss=2.643, ppl=6.25, wps=2302, ups=0.39, wpb=5882.5, bsz=180, num_updates=2030, lr=2.436e-05, gnorm=1.301, train_wall=5, gb_free=11.9, wall=6440
2025-04-17 11:44:13 | INFO | train_inner | epoch 015:     86 / 139 loss=6.064, nll_loss=2.631, ppl=6.19, wps=1882.5, ups=0.4, wpb=4762, bsz=96, num_updates=2032, lr=2.4384e-05, gnorm=1.416, train_wall=5, gb_free=12.6, wall=6445
2025-04-17 11:44:18 | INFO | train_inner | epoch 015:     88 / 139 loss=5.933, nll_loss=2.475, ppl=5.56, wps=2070.9, ups=0.36, wpb=5683.5, bsz=248, num_updates=2034, lr=2.4408e-05, gnorm=1.413, train_wall=5, gb_free=9.5, wall=6451
2025-04-17 11:44:23 | INFO | train_inner | epoch 015:     90 / 139 loss=5.936, nll_loss=2.465, ppl=5.52, wps=2060.5, ups=0.38, wpb=5404, bsz=220, num_updates=2036, lr=2.4432e-05, gnorm=1.352, train_wall=5, gb_free=9.8, wall=6456
2025-04-17 11:44:29 | INFO | train_inner | epoch 015:     92 / 139 loss=6.084, nll_loss=2.637, ppl=6.22, wps=2022.2, ups=0.37, wpb=5468, bsz=112, num_updates=2038, lr=2.4456e-05, gnorm=1.396, train_wall=5, gb_free=10.6, wall=6461
2025-04-17 11:44:35 | INFO | train_inner | epoch 015:     94 / 139 loss=5.892, nll_loss=2.422, ppl=5.36, wps=2342.8, ups=0.35, wpb=6747, bsz=324, num_updates=2040, lr=2.448e-05, gnorm=1.261, train_wall=6, gb_free=10.2, wall=6467
2025-04-17 11:44:39 | INFO | train_inner | epoch 015:     96 / 139 loss=5.873, nll_loss=2.401, ppl=5.28, wps=2307.7, ups=0.43, wpb=5354, bsz=272.5, num_updates=2042, lr=2.4504e-05, gnorm=1.334, train_wall=5, gb_free=11.5, wall=6472
2025-04-17 11:44:45 | INFO | train_inner | epoch 015:     98 / 139 loss=5.905, nll_loss=2.414, ppl=5.33, wps=2221.7, ups=0.37, wpb=6039, bsz=160, num_updates=2044, lr=2.4528e-05, gnorm=1.238, train_wall=5, gb_free=11, wall=6477
2025-04-17 11:44:50 | INFO | train_inner | epoch 015:    100 / 139 loss=5.81, nll_loss=2.327, ppl=5.02, wps=2384.7, ups=0.38, wpb=6279, bsz=216, num_updates=2046, lr=2.4552e-05, gnorm=1.129, train_wall=5, gb_free=10.6, wall=6482
2025-04-17 11:44:55 | INFO | train_inner | epoch 015:    102 / 139 loss=5.945, nll_loss=2.484, ppl=5.59, wps=2274.3, ups=0.39, wpb=5821.5, bsz=180, num_updates=2048, lr=2.4576e-05, gnorm=1.339, train_wall=5, gb_free=12.3, wall=6488
2025-04-17 11:45:00 | INFO | train_inner | epoch 015:    104 / 139 loss=5.908, nll_loss=2.449, ppl=5.46, wps=2366.7, ups=0.38, wpb=6196, bsz=244, num_updates=2050, lr=2.46e-05, gnorm=1.184, train_wall=5, gb_free=12, wall=6493
2025-04-17 11:45:06 | INFO | train_inner | epoch 015:    106 / 139 loss=5.798, nll_loss=2.298, ppl=4.92, wps=2239.8, ups=0.36, wpb=6217.5, bsz=344, num_updates=2052, lr=2.4624e-05, gnorm=1.537, train_wall=6, gb_free=11, wall=6498
2025-04-17 11:45:11 | INFO | train_inner | epoch 015:    108 / 139 loss=5.984, nll_loss=2.527, ppl=5.77, wps=2603.1, ups=0.38, wpb=6800, bsz=252, num_updates=2054, lr=2.4648e-05, gnorm=1.169, train_wall=5, gb_free=13, wall=6504
2025-04-17 11:45:16 | INFO | train_inner | epoch 015:    110 / 139 loss=5.925, nll_loss=2.458, ppl=5.49, wps=2438.2, ups=0.4, wpb=6111.5, bsz=184, num_updates=2056, lr=2.4672e-05, gnorm=1.312, train_wall=5, gb_free=12.2, wall=6509
2025-04-17 11:45:21 | INFO | train_inner | epoch 015:    112 / 139 loss=5.868, nll_loss=2.395, ppl=5.26, wps=2323, ups=0.38, wpb=6100, bsz=204, num_updates=2058, lr=2.4696e-05, gnorm=1.194, train_wall=5, gb_free=14.5, wall=6514
2025-04-17 11:45:27 | INFO | train_inner | epoch 015:    114 / 139 loss=5.866, nll_loss=2.391, ppl=5.24, wps=2534.8, ups=0.38, wpb=6674, bsz=244, num_updates=2060, lr=2.472e-05, gnorm=1.097, train_wall=5, gb_free=12.1, wall=6519
2025-04-17 11:45:32 | INFO | train_inner | epoch 015:    116 / 139 loss=5.852, nll_loss=2.37, ppl=5.17, wps=2472, ups=0.36, wpb=6945.5, bsz=372, num_updates=2062, lr=2.4744e-05, gnorm=1.168, train_wall=6, gb_free=11, wall=6525
2025-04-17 11:45:37 | INFO | train_inner | epoch 015:    118 / 139 loss=5.83, nll_loss=2.344, ppl=5.08, wps=2578, ups=0.39, wpb=6692, bsz=260, num_updates=2064, lr=2.4768e-05, gnorm=1.146, train_wall=5, gb_free=11.3, wall=6530
2025-04-17 11:45:43 | INFO | train_inner | epoch 015:    120 / 139 loss=6.012, nll_loss=2.57, ppl=5.94, wps=2184.3, ups=0.39, wpb=5669, bsz=220, num_updates=2066, lr=2.4792e-05, gnorm=1.258, train_wall=5, gb_free=13.6, wall=6535
2025-04-17 11:45:48 | INFO | train_inner | epoch 015:    122 / 139 loss=5.894, nll_loss=2.424, ppl=5.37, wps=2282.6, ups=0.37, wpb=6114.5, bsz=236, num_updates=2068, lr=2.4816e-05, gnorm=1.355, train_wall=5, gb_free=9.3, wall=6540
2025-04-17 11:45:54 | INFO | train_inner | epoch 015:    124 / 139 loss=5.925, nll_loss=2.45, ppl=5.46, wps=2064.1, ups=0.35, wpb=5947.5, bsz=232, num_updates=2070, lr=2.484e-05, gnorm=1.242, train_wall=6, gb_free=9.6, wall=6546
2025-04-17 11:45:59 | INFO | train_inner | epoch 015:    126 / 139 loss=6.011, nll_loss=2.563, ppl=5.91, wps=2284.5, ups=0.38, wpb=6007, bsz=148, num_updates=2072, lr=2.4864e-05, gnorm=1.249, train_wall=5, gb_free=10.2, wall=6552
2025-04-17 11:46:05 | INFO | train_inner | epoch 015:    128 / 139 loss=5.953, nll_loss=2.502, ppl=5.67, wps=2254.6, ups=0.36, wpb=6216.5, bsz=304, num_updates=2074, lr=2.4888e-05, gnorm=1.303, train_wall=6, gb_free=11.9, wall=6557
2025-04-17 11:46:10 | INFO | train_inner | epoch 015:    130 / 139 loss=5.936, nll_loss=2.48, ppl=5.58, wps=2446.8, ups=0.38, wpb=6393, bsz=216, num_updates=2076, lr=2.4912e-05, gnorm=1.123, train_wall=5, gb_free=12.1, wall=6562
2025-04-17 11:46:15 | INFO | train_inner | epoch 015:    132 / 139 loss=5.996, nll_loss=2.54, ppl=5.82, wps=2126.3, ups=0.4, wpb=5295, bsz=168, num_updates=2078, lr=2.4936e-05, gnorm=1.305, train_wall=5, gb_free=13.5, wall=6567
2025-04-17 11:46:20 | INFO | train_inner | epoch 015:    134 / 139 loss=5.953, nll_loss=2.488, ppl=5.61, wps=2313, ups=0.35, wpb=6574, bsz=288, num_updates=2080, lr=2.496e-05, gnorm=1.163, train_wall=6, gb_free=11.9, wall=6573
2025-04-17 11:46:25 | INFO | train_inner | epoch 015:    136 / 139 loss=5.963, nll_loss=2.51, ppl=5.7, wps=2156.9, ups=0.42, wpb=5183.5, bsz=156, num_updates=2082, lr=2.4984e-05, gnorm=1.356, train_wall=5, gb_free=14.6, wall=6578
2025-04-17 11:46:31 | INFO | train_inner | epoch 015:    138 / 139 loss=5.92, nll_loss=2.464, ppl=5.52, wps=2222.1, ups=0.35, wpb=6303.5, bsz=268, num_updates=2084, lr=2.5008e-05, gnorm=1.261, train_wall=6, gb_free=9.4, wall=6583
2025-04-17 11:46:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-17 11:46:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=15284.36328125Mb; avail=239797.7890625Mb
2025-04-17 11:46:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000633
2025-04-17 11:46:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15284.36328125Mb; avail=239797.7890625Mb
2025-04-17 11:46:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012842
2025-04-17 11:46:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15284.36328125Mb; avail=239797.7890625Mb
2025-04-17 11:46:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.011097
2025-04-17 11:46:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024907
2025-04-17 11:46:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15284.36328125Mb; avail=239797.7890625Mb
2025-04-17 11:46:47 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 6.052 | nll_loss 2.475 | ppl 5.56 | wps 5371.3 | wpb 2350.9 | bsz 94.7 | num_updates 2085 | best_loss 6.052
2025-04-17 11:46:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2085 updates
2025-04-17 11:46:47 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt
2025-04-17 11:47:25 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt
2025-04-17 11:47:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt (epoch 15 @ 2085 updates, score 6.052) (writing took 61.518340530004934 seconds)
2025-04-17 11:47:49 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2025-04-17 11:47:49 | INFO | train | epoch 015 | loss 5.944 | nll_loss 2.481 | ppl 5.58 | wps 1870.6 | ups 0.31 | wpb 6008.3 | bsz 229.1 | num_updates 2085 | lr 2.502e-05 | gnorm 1.293 | train_wall 369 | gb_free 18.2 | wall 6661
2025-04-17 11:47:49 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:hi-mr': 31849}; raw total size: 31849
2025-04-17 11:47:49 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:hi-mr': 31849}; resampled total size: 31849
2025-04-17 11:47:49 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:hi-mr': 1.0}
2025-04-17 11:47:49 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001066
2025-04-17 11:47:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=25412.52734375Mb; avail=229669.6015625Mb
2025-04-17 11:47:49 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000536
2025-04-17 11:47:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003289
2025-04-17 11:47:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=25412.52734375Mb; avail=229669.6015625Mb
2025-04-17 11:47:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000087
2025-04-17 11:47:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=25412.52734375Mb; avail=229669.6015625Mb
2025-04-17 11:47:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001170
2025-04-17 11:47:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.004838
2025-04-17 11:47:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=25412.52734375Mb; avail=229669.6015625Mb
2025-04-17 11:47:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 139
2025-04-17 11:47:49 | INFO | fairseq.trainer | begin training epoch 16
2025-04-17 11:47:49 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-17 11:47:52 | INFO | train_inner | epoch 016:      1 / 139 loss=5.898, nll_loss=2.416, ppl=5.34, wps=108.9, ups=0.02, wpb=4402.5, bsz=136, num_updates=2086, lr=2.5032e-05, gnorm=1.471, train_wall=4, gb_free=10, wall=6664
2025-04-17 11:47:57 | INFO | train_inner | epoch 016:      3 / 139 loss=5.816, nll_loss=2.324, ppl=5.01, wps=2416, ups=0.37, wpb=6547.5, bsz=280, num_updates=2088, lr=2.5056e-05, gnorm=1.12, train_wall=5, gb_free=11, wall=6670
2025-04-17 11:48:02 | INFO | train_inner | epoch 016:      5 / 139 loss=5.739, nll_loss=2.237, ppl=4.71, wps=2417.2, ups=0.38, wpb=6333.5, bsz=344, num_updates=2090, lr=2.508e-05, gnorm=1.097, train_wall=5, gb_free=12.1, wall=6675
2025-04-17 11:48:08 | INFO | train_inner | epoch 016:      7 / 139 loss=5.858, nll_loss=2.367, ppl=5.16, wps=2200.4, ups=0.38, wpb=5742, bsz=216, num_updates=2092, lr=2.5104e-05, gnorm=1.279, train_wall=5, gb_free=10.5, wall=6680
2025-04-17 11:48:13 | INFO | train_inner | epoch 016:      9 / 139 loss=5.939, nll_loss=2.481, ppl=5.58, wps=2460.9, ups=0.37, wpb=6683.5, bsz=228, num_updates=2094, lr=2.5128e-05, gnorm=1.175, train_wall=5, gb_free=11.2, wall=6686
2025-04-17 11:48:18 | INFO | train_inner | epoch 016:     11 / 139 loss=5.986, nll_loss=2.537, ppl=5.8, wps=2491.2, ups=0.37, wpb=6738.5, bsz=296, num_updates=2096, lr=2.5152e-05, gnorm=1.246, train_wall=5, gb_free=11.2, wall=6691
2025-04-17 11:48:24 | INFO | train_inner | epoch 016:     13 / 139 loss=5.792, nll_loss=2.276, ppl=4.84, wps=2387.7, ups=0.35, wpb=6796.5, bsz=292, num_updates=2098, lr=2.5176e-05, gnorm=1.031, train_wall=6, gb_free=10.3, wall=6697
2025-04-17 11:48:29 | INFO | train_inner | epoch 016:     15 / 139 loss=5.825, nll_loss=2.319, ppl=4.99, wps=2327.2, ups=0.38, wpb=6155, bsz=208, num_updates=2100, lr=2.52e-05, gnorm=1.166, train_wall=5, gb_free=10.2, wall=6702
2025-04-17 11:48:35 | INFO | train_inner | epoch 016:     17 / 139 loss=5.886, nll_loss=2.413, ppl=5.33, wps=2325.6, ups=0.37, wpb=6217, bsz=212, num_updates=2102, lr=2.5224e-05, gnorm=1.15, train_wall=5, gb_free=11, wall=6707
2025-04-17 11:48:40 | INFO | train_inner | epoch 016:     19 / 139 loss=5.825, nll_loss=2.337, ppl=5.05, wps=2570.5, ups=0.38, wpb=6729, bsz=248, num_updates=2104, lr=2.5248e-05, gnorm=1.092, train_wall=5, gb_free=12.2, wall=6713
2025-04-17 11:48:45 | INFO | train_inner | epoch 016:     21 / 139 loss=5.781, nll_loss=2.28, ppl=4.86, wps=2521.2, ups=0.39, wpb=6456.5, bsz=276, num_updates=2106, lr=2.5272e-05, gnorm=1.224, train_wall=5, gb_free=14.6, wall=6718
2025-04-17 11:48:51 | INFO | train_inner | epoch 016:     23 / 139 loss=5.858, nll_loss=2.36, ppl=5.13, wps=2004.2, ups=0.37, wpb=5423, bsz=220, num_updates=2108, lr=2.5296e-05, gnorm=1.33, train_wall=5, gb_free=11.6, wall=6723
2025-04-17 11:48:56 | INFO | train_inner | epoch 016:     25 / 139 loss=5.89, nll_loss=2.414, ppl=5.33, wps=2303.7, ups=0.39, wpb=5838.5, bsz=192, num_updates=2110, lr=2.532e-05, gnorm=1.323, train_wall=5, gb_free=12.5, wall=6728
2025-04-17 11:49:01 | INFO | train_inner | epoch 016:     27 / 139 loss=5.772, nll_loss=2.282, ppl=4.86, wps=2548, ups=0.37, wpb=6954, bsz=336, num_updates=2112, lr=2.5344e-05, gnorm=1.098, train_wall=5, gb_free=12.5, wall=6734
2025-04-17 11:49:06 | INFO | train_inner | epoch 016:     29 / 139 loss=5.815, nll_loss=2.297, ppl=4.91, wps=2237.1, ups=0.42, wpb=5358, bsz=180, num_updates=2114, lr=2.5368e-05, gnorm=1.523, train_wall=5, gb_free=11.2, wall=6738
2025-04-17 11:49:11 | INFO | train_inner | epoch 016:     31 / 139 loss=5.838, nll_loss=2.326, ppl=5.01, wps=2356, ups=0.41, wpb=5788, bsz=220, num_updates=2116, lr=2.5392e-05, gnorm=1.305, train_wall=5, gb_free=11.2, wall=6743
2025-04-17 11:49:16 | INFO | train_inner | epoch 016:     33 / 139 loss=5.853, nll_loss=2.386, ppl=5.23, wps=2555.8, ups=0.41, wpb=6259, bsz=244, num_updates=2118, lr=2.5416e-05, gnorm=1.274, train_wall=5, gb_free=12.4, wall=6748
2025-04-17 11:49:21 | INFO | train_inner | epoch 016:     35 / 139 loss=5.882, nll_loss=2.407, ppl=5.3, wps=2300, ups=0.41, wpb=5547, bsz=168, num_updates=2120, lr=2.544e-05, gnorm=1.375, train_wall=5, gb_free=14.3, wall=6753
2025-04-17 11:49:26 | INFO | train_inner | epoch 016:     37 / 139 loss=5.797, nll_loss=2.303, ppl=4.93, wps=2344.5, ups=0.38, wpb=6211.5, bsz=272, num_updates=2122, lr=2.5464e-05, gnorm=1.163, train_wall=5, gb_free=10.1, wall=6758
2025-04-17 11:49:31 | INFO | train_inner | epoch 016:     39 / 139 loss=6.051, nll_loss=2.615, ppl=6.13, wps=2073.2, ups=0.37, wpb=5609.5, bsz=240, num_updates=2124, lr=2.5488e-05, gnorm=1.47, train_wall=5, gb_free=11.3, wall=6764
2025-04-17 11:49:36 | INFO | train_inner | epoch 016:     41 / 139 loss=6.09, nll_loss=2.666, ppl=6.35, wps=1663.9, ups=0.44, wpb=3801, bsz=112, num_updates=2126, lr=2.5512e-05, gnorm=1.653, train_wall=5, gb_free=13.4, wall=6768
2025-04-17 11:49:41 | INFO | train_inner | epoch 016:     43 / 139 loss=5.812, nll_loss=2.322, ppl=5, wps=2463.1, ups=0.36, wpb=6829.5, bsz=300, num_updates=2128, lr=2.5536e-05, gnorm=1.218, train_wall=6, gb_free=11, wall=6774
2025-04-17 11:49:47 | INFO | train_inner | epoch 016:     45 / 139 loss=5.929, nll_loss=2.46, ppl=5.5, wps=2252.8, ups=0.37, wpb=6146, bsz=264, num_updates=2130, lr=2.556e-05, gnorm=1.179, train_wall=5, gb_free=10.5, wall=6779
2025-04-17 11:49:52 | INFO | train_inner | epoch 016:     47 / 139 loss=5.956, nll_loss=2.486, ppl=5.6, wps=2401.8, ups=0.38, wpb=6242, bsz=220, num_updates=2132, lr=2.5584e-05, gnorm=1.262, train_wall=5, gb_free=11.9, wall=6785
2025-04-17 11:49:57 | INFO | train_inner | epoch 016:     49 / 139 loss=5.872, nll_loss=2.392, ppl=5.25, wps=2518.1, ups=0.39, wpb=6532.5, bsz=232, num_updates=2134, lr=2.5608e-05, gnorm=1.197, train_wall=5, gb_free=12.1, wall=6790
2025-04-17 11:50:02 | INFO | train_inner | epoch 016:     51 / 139 loss=5.846, nll_loss=2.367, ppl=5.16, wps=2216.6, ups=0.39, wpb=5723, bsz=272, num_updates=2136, lr=2.5632e-05, gnorm=1.322, train_wall=5, gb_free=13.5, wall=6795
2025-04-17 11:50:08 | INFO | train_inner | epoch 016:     53 / 139 loss=6.085, nll_loss=2.658, ppl=6.31, wps=2036.3, ups=0.39, wpb=5275.5, bsz=152, num_updates=2138, lr=2.5656e-05, gnorm=1.529, train_wall=5, gb_free=12, wall=6800
2025-04-17 11:50:13 | INFO | train_inner | epoch 016:     55 / 139 loss=5.911, nll_loss=2.447, ppl=5.45, wps=2241.6, ups=0.39, wpb=5675, bsz=236, num_updates=2140, lr=2.568e-05, gnorm=1.36, train_wall=5, gb_free=12.2, wall=6805
2025-04-17 11:50:18 | INFO | train_inner | epoch 016:     57 / 139 loss=5.826, nll_loss=2.341, ppl=5.07, wps=2354.8, ups=0.35, wpb=6736.5, bsz=348, num_updates=2142, lr=2.5704e-05, gnorm=1.3, train_wall=6, gb_free=10.1, wall=6811
2025-04-17 11:50:24 | INFO | train_inner | epoch 016:     59 / 139 loss=5.834, nll_loss=2.341, ppl=5.07, wps=2352.3, ups=0.37, wpb=6385.5, bsz=240, num_updates=2144, lr=2.5728e-05, gnorm=1.187, train_wall=5, gb_free=13, wall=6816
2025-04-17 11:50:29 | INFO | train_inner | epoch 016:     61 / 139 loss=5.943, nll_loss=2.465, ppl=5.52, wps=2080.6, ups=0.37, wpb=5681.5, bsz=204, num_updates=2146, lr=2.5752e-05, gnorm=1.273, train_wall=5, gb_free=11.3, wall=6822
2025-04-17 11:50:34 | INFO | train_inner | epoch 016:     63 / 139 loss=5.861, nll_loss=2.372, ppl=5.18, wps=2379.6, ups=0.39, wpb=6032, bsz=176, num_updates=2148, lr=2.5776e-05, gnorm=1.224, train_wall=5, gb_free=13.4, wall=6827
2025-04-17 11:50:40 | INFO | train_inner | epoch 016:     65 / 139 loss=5.796, nll_loss=2.295, ppl=4.91, wps=2334.4, ups=0.37, wpb=6368.5, bsz=324, num_updates=2150, lr=2.58e-05, gnorm=1.184, train_wall=5, gb_free=9.4, wall=6832
2025-04-17 11:50:45 | INFO | train_inner | epoch 016:     67 / 139 loss=5.804, nll_loss=2.297, ppl=4.92, wps=2423.3, ups=0.35, wpb=6886.5, bsz=300, num_updates=2152, lr=2.5824e-05, gnorm=1.081, train_wall=6, gb_free=10.7, wall=6838
2025-04-17 11:50:51 | INFO | train_inner | epoch 016:     69 / 139 loss=5.818, nll_loss=2.311, ppl=4.96, wps=2390.6, ups=0.36, wpb=6682.5, bsz=340, num_updates=2154, lr=2.5848e-05, gnorm=1.175, train_wall=6, gb_free=10.1, wall=6844
2025-04-17 11:50:56 | INFO | train_inner | epoch 016:     71 / 139 loss=5.929, nll_loss=2.461, ppl=5.51, wps=2441.6, ups=0.42, wpb=5833.5, bsz=160, num_updates=2156, lr=2.5872e-05, gnorm=1.348, train_wall=5, gb_free=11.1, wall=6848
2025-04-17 11:51:01 | INFO | train_inner | epoch 016:     73 / 139 loss=5.948, nll_loss=2.478, ppl=5.57, wps=2221.6, ups=0.38, wpb=5813.5, bsz=188, num_updates=2158, lr=2.5896e-05, gnorm=1.231, train_wall=5, gb_free=10.7, wall=6854
2025-04-17 11:51:06 | INFO | train_inner | epoch 016:     75 / 139 loss=5.873, nll_loss=2.386, ppl=5.23, wps=2242.6, ups=0.37, wpb=6015.5, bsz=256, num_updates=2160, lr=2.592e-05, gnorm=1.232, train_wall=5, gb_free=11.5, wall=6859
2025-04-17 11:51:11 | INFO | train_inner | epoch 016:     77 / 139 loss=5.966, nll_loss=2.508, ppl=5.69, wps=2043.8, ups=0.4, wpb=5059.5, bsz=140, num_updates=2162, lr=2.5944e-05, gnorm=1.349, train_wall=5, gb_free=12.9, wall=6864
2025-04-17 11:51:17 | INFO | train_inner | epoch 016:     79 / 139 loss=5.861, nll_loss=2.363, ppl=5.14, wps=2311, ups=0.37, wpb=6192.5, bsz=164, num_updates=2164, lr=2.5968e-05, gnorm=1.251, train_wall=5, gb_free=12, wall=6869
2025-04-17 11:51:22 | INFO | train_inner | epoch 016:     81 / 139 loss=5.983, nll_loss=2.526, ppl=5.76, wps=2289.2, ups=0.4, wpb=5713.5, bsz=136, num_updates=2166, lr=2.5992e-05, gnorm=1.365, train_wall=5, gb_free=12.6, wall=6874
2025-04-17 11:51:32 | INFO | train_inner | epoch 016:     83 / 139 loss=5.973, nll_loss=2.521, ppl=5.74, wps=1146.2, ups=0.2, wpb=5836, bsz=248, num_updates=2168, lr=2.6016e-05, gnorm=1.348, train_wall=10, gb_free=13.8, wall=6884
2025-04-17 11:51:37 | INFO | train_inner | epoch 016:     85 / 139 loss=6.001, nll_loss=2.562, ppl=5.9, wps=2358.8, ups=0.37, wpb=6394.5, bsz=212, num_updates=2170, lr=2.604e-05, gnorm=1.318, train_wall=5, gb_free=12.7, wall=6890
2025-04-17 11:51:43 | INFO | train_inner | epoch 016:     87 / 139 loss=5.963, nll_loss=2.508, ppl=5.69, wps=2446, ups=0.38, wpb=6354.5, bsz=200, num_updates=2172, lr=2.6064e-05, gnorm=1.333, train_wall=5, gb_free=10.8, wall=6895
2025-04-17 11:51:48 | INFO | train_inner | epoch 016:     89 / 139 loss=5.852, nll_loss=2.355, ppl=5.11, wps=2247, ups=0.37, wpb=5993.5, bsz=196, num_updates=2174, lr=2.6088e-05, gnorm=1.308, train_wall=5, gb_free=11.8, wall=6900
2025-04-17 11:51:53 | INFO | train_inner | epoch 016:     91 / 139 loss=5.961, nll_loss=2.5, ppl=5.66, wps=2510.9, ups=0.38, wpb=6578.5, bsz=236, num_updates=2176, lr=2.6112e-05, gnorm=1.219, train_wall=5, gb_free=12.3, wall=6906
2025-04-17 11:51:57 | INFO | train_inner | epoch 016:     93 / 139 loss=5.948, nll_loss=2.494, ppl=5.63, wps=2326.6, ups=0.45, wpb=5113.5, bsz=136.5, num_updates=2178, lr=2.6136e-05, gnorm=1.526, train_wall=4, gb_free=11.4, wall=6910
2025-04-17 11:52:03 | INFO | train_inner | epoch 016:     95 / 139 loss=5.912, nll_loss=2.442, ppl=5.44, wps=2309, ups=0.37, wpb=6174, bsz=236, num_updates=2180, lr=2.616e-05, gnorm=1.163, train_wall=5, gb_free=12, wall=6915
2025-04-17 11:52:08 | INFO | train_inner | epoch 016:     97 / 139 loss=5.906, nll_loss=2.432, ppl=5.4, wps=2474.7, ups=0.39, wpb=6369, bsz=184, num_updates=2182, lr=2.6184e-05, gnorm=1.224, train_wall=5, gb_free=11.3, wall=6920
2025-04-17 11:52:13 | INFO | train_inner | epoch 016:     99 / 139 loss=5.86, nll_loss=2.384, ppl=5.22, wps=2272.6, ups=0.37, wpb=6126, bsz=228, num_updates=2184, lr=2.6208e-05, gnorm=1.284, train_wall=5, gb_free=14, wall=6926
2025-04-17 11:52:19 | INFO | train_inner | epoch 016:    101 / 139 loss=5.809, nll_loss=2.311, ppl=4.96, wps=2416.5, ups=0.35, wpb=6935.5, bsz=296, num_updates=2186, lr=2.6232e-05, gnorm=1.217, train_wall=6, gb_free=10.1, wall=6932
2025-04-17 11:52:25 | INFO | train_inner | epoch 016:    103 / 139 loss=5.822, nll_loss=2.336, ppl=5.05, wps=2226, ups=0.37, wpb=6045, bsz=336, num_updates=2188, lr=2.6256e-05, gnorm=1.264, train_wall=5, gb_free=11.2, wall=6937
2025-04-17 11:52:30 | INFO | train_inner | epoch 016:    105 / 139 loss=5.812, nll_loss=2.308, ppl=4.95, wps=2221.3, ups=0.37, wpb=6008, bsz=168, num_updates=2190, lr=2.628e-05, gnorm=1.32, train_wall=5, gb_free=12.4, wall=6942
2025-04-17 11:52:35 | INFO | train_inner | epoch 016:    107 / 139 loss=5.853, nll_loss=2.362, ppl=5.14, wps=2239, ups=0.39, wpb=5734, bsz=168, num_updates=2192, lr=2.6304e-05, gnorm=1.358, train_wall=5, gb_free=14.3, wall=6948
2025-04-17 11:52:40 | INFO | train_inner | epoch 016:    109 / 139 loss=5.922, nll_loss=2.46, ppl=5.5, wps=2045, ups=0.4, wpb=5161, bsz=256, num_updates=2194, lr=2.6328e-05, gnorm=1.298, train_wall=5, gb_free=10.9, wall=6953
2025-04-17 11:52:45 | INFO | train_inner | epoch 016:    111 / 139 loss=5.831, nll_loss=2.344, ppl=5.08, wps=2150.2, ups=0.39, wpb=5502, bsz=204, num_updates=2196, lr=2.6352e-05, gnorm=1.362, train_wall=5, gb_free=11.6, wall=6958
2025-04-17 11:52:50 | INFO | train_inner | epoch 016:    113 / 139 loss=5.756, nll_loss=2.245, ppl=4.74, wps=2305.6, ups=0.4, wpb=5730, bsz=240, num_updates=2198, lr=2.6376e-05, gnorm=2.276, train_wall=5, gb_free=15.1, wall=6963
2025-04-17 11:52:55 | INFO | train_inner | epoch 016:    115 / 139 loss=5.871, nll_loss=2.389, ppl=5.24, wps=2124.7, ups=0.39, wpb=5413, bsz=240, num_updates=2200, lr=2.64e-05, gnorm=1.477, train_wall=5, gb_free=10.4, wall=6968
2025-04-17 11:53:00 | INFO | train_inner | epoch 016:    117 / 139 loss=5.848, nll_loss=2.353, ppl=5.11, wps=2073.2, ups=0.41, wpb=5058.5, bsz=216, num_updates=2202, lr=2.6424e-05, gnorm=1.378, train_wall=5, gb_free=11.8, wall=6973
2025-04-17 11:53:05 | INFO | train_inner | epoch 016:    119 / 139 loss=5.847, nll_loss=2.358, ppl=5.13, wps=2507.1, ups=0.38, wpb=6567, bsz=216, num_updates=2204, lr=2.6448e-05, gnorm=1.216, train_wall=5, gb_free=11.8, wall=6978
2025-04-17 11:53:11 | INFO | train_inner | epoch 016:    121 / 139 loss=5.942, nll_loss=2.488, ppl=5.61, wps=2376.5, ups=0.35, wpb=6705, bsz=236, num_updates=2206, lr=2.6472e-05, gnorm=1.236, train_wall=6, gb_free=11.6, wall=6984
2025-04-17 11:53:16 | INFO | train_inner | epoch 016:    123 / 139 loss=6.005, nll_loss=2.561, ppl=5.9, wps=2291, ups=0.4, wpb=5786.5, bsz=164, num_updates=2208, lr=2.6496e-05, gnorm=1.323, train_wall=5, gb_free=12.7, wall=6989
2025-04-17 11:53:21 | INFO | train_inner | epoch 016:    125 / 139 loss=5.81, nll_loss=2.306, ppl=4.94, wps=2102.8, ups=0.37, wpb=5648, bsz=276, num_updates=2210, lr=2.652e-05, gnorm=1.489, train_wall=5, gb_free=12.5, wall=6994
2025-04-17 11:53:27 | INFO | train_inner | epoch 016:    127 / 139 loss=5.782, nll_loss=2.279, ppl=4.85, wps=2335.4, ups=0.34, wpb=6944, bsz=328, num_updates=2212, lr=2.6544e-05, gnorm=1.146, train_wall=6, gb_free=9.3, wall=7000
2025-04-17 11:53:33 | INFO | train_inner | epoch 016:    129 / 139 loss=5.891, nll_loss=2.425, ppl=5.37, wps=2284.2, ups=0.38, wpb=6084, bsz=212, num_updates=2214, lr=2.6568e-05, gnorm=1.423, train_wall=5, gb_free=11.1, wall=7005
2025-04-17 11:53:38 | INFO | train_inner | epoch 016:    131 / 139 loss=5.836, nll_loss=2.357, ppl=5.12, wps=2252.5, ups=0.37, wpb=6062, bsz=288, num_updates=2216, lr=2.6592e-05, gnorm=1.23, train_wall=5, gb_free=10.8, wall=7011
2025-04-17 11:53:43 | INFO | train_inner | epoch 016:    133 / 139 loss=5.945, nll_loss=2.475, ppl=5.56, wps=2296.6, ups=0.43, wpb=5392.5, bsz=164, num_updates=2218, lr=2.6616e-05, gnorm=1.258, train_wall=5, gb_free=12.1, wall=7015
2025-04-17 11:53:48 | INFO | train_inner | epoch 016:    135 / 139 loss=5.923, nll_loss=2.44, ppl=5.43, wps=1945.3, ups=0.42, wpb=4631.5, bsz=100, num_updates=2220, lr=2.664e-05, gnorm=1.431, train_wall=5, gb_free=13, wall=7020
2025-04-17 11:53:53 | INFO | train_inner | epoch 016:    137 / 139 loss=5.877, nll_loss=2.418, ppl=5.34, wps=2413.8, ups=0.38, wpb=6275.5, bsz=228, num_updates=2222, lr=2.6664e-05, gnorm=1.198, train_wall=5, gb_free=11.7, wall=7025
2025-04-17 11:53:56 | INFO | train_inner | epoch 016:    139 / 139 loss=6.006, nll_loss=2.59, ppl=6.02, wps=2590.2, ups=0.54, wpb=4763, bsz=156, num_updates=2224, lr=2.6688e-05, gnorm=1.558, train_wall=4, gb_free=17.5, wall=7029
2025-04-17 11:53:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-17 11:53:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=15272.60546875Mb; avail=239809.5078125Mb
2025-04-17 11:53:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000634
2025-04-17 11:53:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15272.60546875Mb; avail=239809.5078125Mb
2025-04-17 11:53:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012696
2025-04-17 11:53:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15272.60546875Mb; avail=239809.5078125Mb
2025-04-17 11:53:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.011137
2025-04-17 11:53:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024815
2025-04-17 11:53:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15272.60546875Mb; avail=239809.5078125Mb
2025-04-17 11:54:12 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 6.025 | nll_loss 2.429 | ppl 5.38 | wps 5367.4 | wpb 2350.9 | bsz 94.7 | num_updates 2224 | best_loss 6.025
2025-04-17 11:54:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2224 updates
2025-04-17 11:54:12 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt
2025-04-17 11:54:49 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt
2025-04-17 11:55:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt (epoch 16 @ 2224 updates, score 6.025) (writing took 61.59451774001354 seconds)
2025-04-17 11:55:13 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2025-04-17 11:55:13 | INFO | train | epoch 016 | loss 5.879 | nll_loss 2.399 | ppl 5.28 | wps 1879.4 | ups 0.31 | wpb 6008.3 | bsz 229.1 | num_updates 2224 | lr 2.6688e-05 | gnorm 1.296 | train_wall 367 | gb_free 17.5 | wall 7106
2025-04-17 11:55:13 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:hi-mr': 31849}; raw total size: 31849
2025-04-17 11:55:13 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:hi-mr': 31849}; resampled total size: 31849
2025-04-17 11:55:13 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:hi-mr': 1.0}
2025-04-17 11:55:13 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001210
2025-04-17 11:55:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=25400.0Mb; avail=229682.109375Mb
2025-04-17 11:55:13 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000568
2025-04-17 11:55:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003323
2025-04-17 11:55:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=25400.0Mb; avail=229682.109375Mb
2025-04-17 11:55:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000094
2025-04-17 11:55:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=25400.0Mb; avail=229682.109375Mb
2025-04-17 11:55:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001195
2025-04-17 11:55:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.004921
2025-04-17 11:55:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=25400.0Mb; avail=229682.109375Mb
2025-04-17 11:55:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 139
2025-04-17 11:55:13 | INFO | fairseq.trainer | begin training epoch 17
2025-04-17 11:55:13 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-17 11:55:23 | INFO | train_inner | epoch 017:      2 / 139 loss=5.725, nll_loss=2.191, ppl=4.57, wps=139.2, ups=0.02, wpb=6050, bsz=248, num_updates=2226, lr=2.6712e-05, gnorm=1.231, train_wall=10, gb_free=11.4, wall=7116
2025-04-17 11:55:28 | INFO | train_inner | epoch 017:      4 / 139 loss=5.874, nll_loss=2.38, ppl=5.2, wps=2019, ups=0.41, wpb=4913.5, bsz=208, num_updates=2228, lr=2.6736e-05, gnorm=1.316, train_wall=5, gb_free=11.9, wall=7121
2025-04-17 11:55:34 | INFO | train_inner | epoch 017:      6 / 139 loss=5.81, nll_loss=2.313, ppl=4.97, wps=2354.4, ups=0.38, wpb=6145.5, bsz=244, num_updates=2230, lr=2.676e-05, gnorm=1.222, train_wall=5, gb_free=11, wall=7126
2025-04-17 11:55:39 | INFO | train_inner | epoch 017:      8 / 139 loss=5.743, nll_loss=2.246, ppl=4.74, wps=2538, ups=0.38, wpb=6670.5, bsz=264, num_updates=2232, lr=2.6784e-05, gnorm=1.303, train_wall=5, gb_free=12.1, wall=7131
2025-04-17 11:55:44 | INFO | train_inner | epoch 017:     10 / 139 loss=5.622, nll_loss=2.083, ppl=4.24, wps=2532.7, ups=0.38, wpb=6700.5, bsz=312, num_updates=2234, lr=2.6808e-05, gnorm=1.101, train_wall=5, gb_free=11.8, wall=7137
2025-04-17 11:55:49 | INFO | train_inner | epoch 017:     12 / 139 loss=5.764, nll_loss=2.231, ppl=4.7, wps=2494.4, ups=0.42, wpb=5962.5, bsz=252, num_updates=2236, lr=2.6832e-05, gnorm=1.149, train_wall=5, gb_free=16.1, wall=7141
2025-04-17 11:55:55 | INFO | train_inner | epoch 017:     14 / 139 loss=5.799, nll_loss=2.289, ppl=4.89, wps=2419.9, ups=0.35, wpb=6873.5, bsz=284, num_updates=2238, lr=2.6856e-05, gnorm=1.144, train_wall=6, gb_free=10.6, wall=7147
2025-04-17 11:56:00 | INFO | train_inner | epoch 017:     16 / 139 loss=5.831, nll_loss=2.351, ppl=5.1, wps=2409.8, ups=0.39, wpb=6227.5, bsz=164, num_updates=2240, lr=2.688e-05, gnorm=1.181, train_wall=5, gb_free=11.5, wall=7152
2025-04-17 11:56:05 | INFO | train_inner | epoch 017:     18 / 139 loss=5.827, nll_loss=2.335, ppl=5.05, wps=2108.1, ups=0.39, wpb=5398, bsz=172, num_updates=2242, lr=2.6904e-05, gnorm=1.308, train_wall=5, gb_free=14.4, wall=7157
2025-04-17 11:56:11 | INFO | train_inner | epoch 017:     20 / 139 loss=5.703, nll_loss=2.17, ppl=4.5, wps=2403.9, ups=0.35, wpb=6825, bsz=356, num_updates=2244, lr=2.6928e-05, gnorm=1.154, train_wall=6, gb_free=11, wall=7163
2025-04-17 11:56:16 | INFO | train_inner | epoch 017:     22 / 139 loss=5.962, nll_loss=2.491, ppl=5.62, wps=2119.7, ups=0.35, wpb=6019, bsz=312, num_updates=2246, lr=2.6952e-05, gnorm=1.246, train_wall=6, gb_free=12, wall=7169
2025-04-17 11:56:21 | INFO | train_inner | epoch 017:     24 / 139 loss=5.725, nll_loss=2.232, ppl=4.7, wps=2397, ups=0.38, wpb=6284.5, bsz=296, num_updates=2248, lr=2.6976e-05, gnorm=1.209, train_wall=5, gb_free=10.3, wall=7174
2025-04-17 11:56:26 | INFO | train_inner | epoch 017:     26 / 139 loss=5.895, nll_loss=2.42, ppl=5.35, wps=2141.6, ups=0.4, wpb=5385, bsz=168, num_updates=2250, lr=2.7e-05, gnorm=1.432, train_wall=5, gb_free=12.9, wall=7179
2025-04-17 11:56:31 | INFO | train_inner | epoch 017:     28 / 139 loss=5.843, nll_loss=2.334, ppl=5.04, wps=2444.3, ups=0.43, wpb=5691, bsz=144, num_updates=2252, lr=2.7024e-05, gnorm=1.225, train_wall=5, gb_free=15.1, wall=7184
2025-04-17 11:56:37 | INFO | train_inner | epoch 017:     30 / 139 loss=5.777, nll_loss=2.251, ppl=4.76, wps=2534.1, ups=0.37, wpb=6861, bsz=308, num_updates=2254, lr=2.7048e-05, gnorm=1.199, train_wall=5, gb_free=10.6, wall=7189
2025-04-17 11:56:42 | INFO | train_inner | epoch 017:     32 / 139 loss=5.824, nll_loss=2.326, ppl=5.02, wps=2004.9, ups=0.4, wpb=5030, bsz=264, num_updates=2256, lr=2.7072e-05, gnorm=1.968, train_wall=5, gb_free=16, wall=7194
2025-04-17 11:56:47 | INFO | train_inner | epoch 017:     34 / 139 loss=5.826, nll_loss=2.339, ppl=5.06, wps=2405.2, ups=0.39, wpb=6175, bsz=204, num_updates=2258, lr=2.7096e-05, gnorm=1.27, train_wall=5, gb_free=12.2, wall=7199
2025-04-17 11:56:52 | INFO | train_inner | epoch 017:     36 / 139 loss=5.866, nll_loss=2.381, ppl=5.21, wps=2097.3, ups=0.39, wpb=5410.5, bsz=204, num_updates=2260, lr=2.712e-05, gnorm=1.449, train_wall=5, gb_free=10.8, wall=7204
2025-04-17 11:56:57 | INFO | train_inner | epoch 017:     38 / 139 loss=5.867, nll_loss=2.379, ppl=5.2, wps=2361.6, ups=0.37, wpb=6426, bsz=264, num_updates=2262, lr=2.7144e-05, gnorm=1.41, train_wall=5, gb_free=10.7, wall=7210
2025-04-17 11:57:01 | INFO | train_inner | epoch 017:     40 / 139 loss=5.928, nll_loss=2.455, ppl=5.48, wps=2087.1, ups=0.5, wpb=4213.5, bsz=100.5, num_updates=2264, lr=2.7168e-05, gnorm=1.665, train_wall=4, gb_free=13.3, wall=7214
2025-04-17 11:57:07 | INFO | train_inner | epoch 017:     42 / 139 loss=5.901, nll_loss=2.423, ppl=5.36, wps=2338.9, ups=0.36, wpb=6446.5, bsz=204, num_updates=2266, lr=2.7192e-05, gnorm=1.212, train_wall=6, gb_free=11.5, wall=7219
2025-04-17 11:57:12 | INFO | train_inner | epoch 017:     44 / 139 loss=5.929, nll_loss=2.45, ppl=5.46, wps=2053.8, ups=0.41, wpb=5042.5, bsz=108, num_updates=2268, lr=2.7216e-05, gnorm=1.465, train_wall=5, gb_free=12.7, wall=7224
2025-04-17 11:57:17 | INFO | train_inner | epoch 017:     46 / 139 loss=5.835, nll_loss=2.339, ppl=5.06, wps=2210.6, ups=0.37, wpb=5927, bsz=176, num_updates=2270, lr=2.724e-05, gnorm=1.181, train_wall=5, gb_free=12.2, wall=7230
2025-04-17 11:57:22 | INFO | train_inner | epoch 017:     48 / 139 loss=5.859, nll_loss=2.377, ppl=5.2, wps=2142.5, ups=0.37, wpb=5752, bsz=132, num_updates=2272, lr=2.7264e-05, gnorm=1.203, train_wall=5, gb_free=10.6, wall=7235
2025-04-17 11:57:28 | INFO | train_inner | epoch 017:     50 / 139 loss=5.886, nll_loss=2.428, ppl=5.38, wps=2513.6, ups=0.38, wpb=6552, bsz=228, num_updates=2274, lr=2.7288e-05, gnorm=1.251, train_wall=5, gb_free=12.3, wall=7240
2025-04-17 11:57:33 | INFO | train_inner | epoch 017:     52 / 139 loss=5.724, nll_loss=2.193, ppl=4.57, wps=2303, ups=0.36, wpb=6460.5, bsz=312, num_updates=2276, lr=2.7312e-05, gnorm=1.111, train_wall=6, gb_free=12, wall=7246
2025-04-17 11:57:38 | INFO | train_inner | epoch 017:     54 / 139 loss=5.836, nll_loss=2.33, ppl=5.03, wps=2477.2, ups=0.39, wpb=6434, bsz=260, num_updates=2278, lr=2.7336e-05, gnorm=1.225, train_wall=5, gb_free=10.6, wall=7251
2025-04-17 11:57:44 | INFO | train_inner | epoch 017:     56 / 139 loss=5.821, nll_loss=2.334, ppl=5.04, wps=2249.9, ups=0.37, wpb=6163.5, bsz=292, num_updates=2280, lr=2.736e-05, gnorm=1.174, train_wall=5, gb_free=11.4, wall=7256
2025-04-17 11:57:49 | INFO | train_inner | epoch 017:     58 / 139 loss=5.833, nll_loss=2.358, ppl=5.13, wps=2324.8, ups=0.38, wpb=6145.5, bsz=184, num_updates=2282, lr=2.7384e-05, gnorm=1.238, train_wall=5, gb_free=11, wall=7262
2025-04-17 11:57:55 | INFO | train_inner | epoch 017:     60 / 139 loss=5.854, nll_loss=2.363, ppl=5.14, wps=2001, ups=0.37, wpb=5450, bsz=232, num_updates=2284, lr=2.7408e-05, gnorm=1.292, train_wall=5, gb_free=8.9, wall=7267
2025-04-17 11:58:00 | INFO | train_inner | epoch 017:     62 / 139 loss=5.773, nll_loss=2.271, ppl=4.83, wps=2342.7, ups=0.38, wpb=6183.5, bsz=260, num_updates=2286, lr=2.7432e-05, gnorm=1.154, train_wall=5, gb_free=11.4, wall=7272
2025-04-17 11:58:05 | INFO | train_inner | epoch 017:     64 / 139 loss=5.767, nll_loss=2.271, ppl=4.83, wps=2381.8, ups=0.38, wpb=6338.5, bsz=264, num_updates=2288, lr=2.7456e-05, gnorm=1.182, train_wall=5, gb_free=11.6, wall=7278
2025-04-17 11:58:11 | INFO | train_inner | epoch 017:     66 / 139 loss=5.78, nll_loss=2.273, ppl=4.83, wps=2294.2, ups=0.38, wpb=5998, bsz=196, num_updates=2290, lr=2.748e-05, gnorm=1.17, train_wall=5, gb_free=13.8, wall=7283
2025-04-17 11:58:16 | INFO | train_inner | epoch 017:     68 / 139 loss=5.727, nll_loss=2.197, ppl=4.59, wps=2185.3, ups=0.38, wpb=5795.5, bsz=208, num_updates=2292, lr=2.7504e-05, gnorm=1.237, train_wall=5, gb_free=10.8, wall=7288
2025-04-17 11:58:21 | INFO | train_inner | epoch 017:     70 / 139 loss=5.805, nll_loss=2.301, ppl=4.93, wps=2368.9, ups=0.4, wpb=5855.5, bsz=208, num_updates=2294, lr=2.7528e-05, gnorm=1.217, train_wall=5, gb_free=13.9, wall=7293
2025-04-17 11:58:26 | INFO | train_inner | epoch 017:     72 / 139 loss=5.784, nll_loss=2.289, ppl=4.89, wps=2481.7, ups=0.36, wpb=6815.5, bsz=260, num_updates=2296, lr=2.7552e-05, gnorm=1.16, train_wall=5, gb_free=12.4, wall=7299
2025-04-17 11:58:32 | INFO | train_inner | epoch 017:     74 / 139 loss=5.803, nll_loss=2.317, ppl=4.98, wps=2238.1, ups=0.37, wpb=6027.5, bsz=272, num_updates=2298, lr=2.7576e-05, gnorm=1.251, train_wall=5, gb_free=13.3, wall=7304
2025-04-17 11:58:37 | INFO | train_inner | epoch 017:     76 / 139 loss=5.824, nll_loss=2.325, ppl=5.01, wps=2109.9, ups=0.4, wpb=5317.5, bsz=184, num_updates=2300, lr=2.76e-05, gnorm=1.243, train_wall=5, gb_free=12.4, wall=7309
2025-04-17 11:58:42 | INFO | train_inner | epoch 017:     78 / 139 loss=5.86, nll_loss=2.372, ppl=5.18, wps=2198.1, ups=0.36, wpb=6032.5, bsz=212, num_updates=2302, lr=2.7624e-05, gnorm=1.187, train_wall=5, gb_free=13.5, wall=7315
2025-04-17 11:58:47 | INFO | train_inner | epoch 017:     80 / 139 loss=5.935, nll_loss=2.466, ppl=5.53, wps=2353.9, ups=0.43, wpb=5419, bsz=124, num_updates=2304, lr=2.7648e-05, gnorm=1.516, train_wall=5, gb_free=12.9, wall=7319
2025-04-17 11:58:52 | INFO | train_inner | epoch 017:     82 / 139 loss=5.696, nll_loss=2.167, ppl=4.49, wps=2419.1, ups=0.38, wpb=6428, bsz=276, num_updates=2306, lr=2.7672e-05, gnorm=1.139, train_wall=5, gb_free=12.6, wall=7325
2025-04-17 11:58:58 | INFO | train_inner | epoch 017:     84 / 139 loss=5.831, nll_loss=2.328, ppl=5.02, wps=2458.4, ups=0.37, wpb=6708.5, bsz=224, num_updates=2308, lr=2.7696e-05, gnorm=1.171, train_wall=5, gb_free=11.9, wall=7330
2025-04-17 11:59:02 | INFO | train_inner | epoch 017:     86 / 139 loss=5.899, nll_loss=2.413, ppl=5.33, wps=2087.3, ups=0.42, wpb=4998.5, bsz=124, num_updates=2310, lr=2.772e-05, gnorm=1.639, train_wall=5, gb_free=12.6, wall=7335
2025-04-17 11:59:07 | INFO | train_inner | epoch 017:     88 / 139 loss=5.793, nll_loss=2.297, ppl=4.92, wps=1950, ups=0.42, wpb=4647.5, bsz=156, num_updates=2312, lr=2.7744e-05, gnorm=1.423, train_wall=5, gb_free=13.1, wall=7340
2025-04-17 11:59:12 | INFO | train_inner | epoch 017:     90 / 139 loss=5.836, nll_loss=2.364, ppl=5.15, wps=2196.3, ups=0.39, wpb=5591.5, bsz=228, num_updates=2314, lr=2.7768e-05, gnorm=1.364, train_wall=5, gb_free=12.4, wall=7345
2025-04-17 11:59:18 | INFO | train_inner | epoch 017:     92 / 139 loss=5.804, nll_loss=2.295, ppl=4.91, wps=2187.4, ups=0.35, wpb=6261, bsz=280, num_updates=2316, lr=2.7792e-05, gnorm=1.143, train_wall=6, gb_free=10.6, wall=7350
2025-04-17 11:59:23 | INFO | train_inner | epoch 017:     94 / 139 loss=5.838, nll_loss=2.351, ppl=5.1, wps=2204.9, ups=0.38, wpb=5796.5, bsz=292, num_updates=2318, lr=2.7816e-05, gnorm=1.389, train_wall=5, gb_free=12.2, wall=7356
2025-04-17 11:59:28 | INFO | train_inner | epoch 017:     96 / 139 loss=5.829, nll_loss=2.33, ppl=5.03, wps=2392.1, ups=0.39, wpb=6107.5, bsz=188, num_updates=2320, lr=2.784e-05, gnorm=1.218, train_wall=5, gb_free=14.4, wall=7361
2025-04-17 11:59:33 | INFO | train_inner | epoch 017:     98 / 139 loss=5.854, nll_loss=2.373, ppl=5.18, wps=2130.5, ups=0.42, wpb=5065.5, bsz=164, num_updates=2322, lr=2.7864e-05, gnorm=1.31, train_wall=5, gb_free=12.7, wall=7366
2025-04-17 11:59:39 | INFO | train_inner | epoch 017:    100 / 139 loss=5.866, nll_loss=2.379, ppl=5.2, wps=2227.3, ups=0.36, wpb=6205, bsz=224, num_updates=2324, lr=2.7888e-05, gnorm=1.269, train_wall=6, gb_free=12.5, wall=7371
2025-04-17 11:59:44 | INFO | train_inner | epoch 017:    102 / 139 loss=5.764, nll_loss=2.264, ppl=4.8, wps=2125.5, ups=0.4, wpb=5299, bsz=180, num_updates=2326, lr=2.7912e-05, gnorm=1.492, train_wall=5, gb_free=11.9, wall=7376
2025-04-17 11:59:49 | INFO | train_inner | epoch 017:    104 / 139 loss=5.681, nll_loss=2.154, ppl=4.45, wps=2370.7, ups=0.37, wpb=6397, bsz=216, num_updates=2328, lr=2.7936e-05, gnorm=1.126, train_wall=5, gb_free=13.5, wall=7382
2025-04-17 11:59:55 | INFO | train_inner | epoch 017:    106 / 139 loss=5.707, nll_loss=2.181, ppl=4.53, wps=2489.2, ups=0.36, wpb=6923, bsz=324, num_updates=2330, lr=2.796e-05, gnorm=1.046, train_wall=6, gb_free=10.2, wall=7387
2025-04-17 12:00:01 | INFO | train_inner | epoch 017:    108 / 139 loss=5.902, nll_loss=2.422, ppl=5.36, wps=2272, ups=0.33, wpb=6847.5, bsz=340, num_updates=2332, lr=2.7984e-05, gnorm=1.214, train_wall=6, gb_free=11.1, wall=7393
2025-04-17 12:00:06 | INFO | train_inner | epoch 017:    110 / 139 loss=5.865, nll_loss=2.397, ppl=5.27, wps=2415.7, ups=0.39, wpb=6127.5, bsz=188, num_updates=2334, lr=2.8008e-05, gnorm=1.333, train_wall=5, gb_free=11.7, wall=7398
2025-04-17 12:00:11 | INFO | train_inner | epoch 017:    112 / 139 loss=5.816, nll_loss=2.329, ppl=5.02, wps=2331.6, ups=0.39, wpb=6054.5, bsz=168, num_updates=2336, lr=2.8032e-05, gnorm=1.138, train_wall=5, gb_free=13.2, wall=7403
2025-04-17 12:00:16 | INFO | train_inner | epoch 017:    114 / 139 loss=5.765, nll_loss=2.261, ppl=4.79, wps=2156.5, ups=0.42, wpb=5119.5, bsz=216, num_updates=2338, lr=2.8056e-05, gnorm=1.266, train_wall=5, gb_free=12.9, wall=7408
2025-04-17 12:00:21 | INFO | train_inner | epoch 017:    116 / 139 loss=5.823, nll_loss=2.319, ppl=4.99, wps=2366.2, ups=0.36, wpb=6498, bsz=264, num_updates=2340, lr=2.808e-05, gnorm=1.181, train_wall=5, gb_free=12.7, wall=7414
2025-04-17 12:00:26 | INFO | train_inner | epoch 017:    118 / 139 loss=5.762, nll_loss=2.257, ppl=4.78, wps=2256.3, ups=0.37, wpb=6022, bsz=228, num_updates=2342, lr=2.8104e-05, gnorm=1.2, train_wall=5, gb_free=10.2, wall=7419
2025-04-17 12:00:32 | INFO | train_inner | epoch 017:    120 / 139 loss=5.809, nll_loss=2.327, ppl=5.02, wps=2345.8, ups=0.37, wpb=6346.5, bsz=224, num_updates=2344, lr=2.8128e-05, gnorm=1.169, train_wall=5, gb_free=13.1, wall=7424
2025-04-17 12:00:37 | INFO | train_inner | epoch 017:    122 / 139 loss=5.794, nll_loss=2.288, ppl=4.88, wps=2417.4, ups=0.38, wpb=6388, bsz=188, num_updates=2346, lr=2.8152e-05, gnorm=1.184, train_wall=5, gb_free=11.2, wall=7430
2025-04-17 12:00:43 | INFO | train_inner | epoch 017:    124 / 139 loss=5.786, nll_loss=2.272, ppl=4.83, wps=2292.9, ups=0.36, wpb=6358.5, bsz=272, num_updates=2348, lr=2.8176e-05, gnorm=1.135, train_wall=6, gb_free=10.8, wall=7435
2025-04-17 12:00:48 | INFO | train_inner | epoch 017:    126 / 139 loss=5.81, nll_loss=2.306, ppl=4.95, wps=2361.6, ups=0.38, wpb=6202.5, bsz=256, num_updates=2350, lr=2.82e-05, gnorm=1.149, train_wall=5, gb_free=13.8, wall=7440
2025-04-17 12:00:53 | INFO | train_inner | epoch 017:    128 / 139 loss=5.7, nll_loss=2.197, ppl=4.58, wps=2472.4, ups=0.37, wpb=6643, bsz=324, num_updates=2352, lr=2.8224e-05, gnorm=1.068, train_wall=5, gb_free=10.1, wall=7446
2025-04-17 12:00:59 | INFO | train_inner | epoch 017:    130 / 139 loss=5.744, nll_loss=2.239, ppl=4.72, wps=2445.1, ups=0.38, wpb=6425.5, bsz=236, num_updates=2354, lr=2.8248e-05, gnorm=1.081, train_wall=5, gb_free=11.6, wall=7451
2025-04-17 12:01:04 | INFO | train_inner | epoch 017:    132 / 139 loss=5.803, nll_loss=2.301, ppl=4.93, wps=2299.8, ups=0.37, wpb=6235, bsz=240, num_updates=2356, lr=2.8272e-05, gnorm=1.208, train_wall=5, gb_free=11.6, wall=7456
2025-04-17 12:01:10 | INFO | train_inner | epoch 017:    134 / 139 loss=5.868, nll_loss=2.381, ppl=5.21, wps=2387.8, ups=0.36, wpb=6673.5, bsz=260, num_updates=2358, lr=2.8296e-05, gnorm=1.12, train_wall=6, gb_free=11.8, wall=7462
2025-04-17 12:01:14 | INFO | train_inner | epoch 017:    136 / 139 loss=5.901, nll_loss=2.427, ppl=5.38, wps=2109.5, ups=0.41, wpb=5137.5, bsz=136, num_updates=2360, lr=2.832e-05, gnorm=1.373, train_wall=5, gb_free=14.3, wall=7467
2025-04-17 12:01:20 | INFO | train_inner | epoch 017:    138 / 139 loss=5.664, nll_loss=2.138, ppl=4.4, wps=2372.6, ups=0.34, wpb=6963.5, bsz=348, num_updates=2362, lr=2.8344e-05, gnorm=1.007, train_wall=6, gb_free=9.9, wall=7473
2025-04-17 12:01:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-17 12:01:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=15276.64453125Mb; avail=239805.50390625Mb
2025-04-17 12:01:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000640
2025-04-17 12:01:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15276.64453125Mb; avail=239805.50390625Mb
2025-04-17 12:01:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012688
2025-04-17 12:01:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15276.64453125Mb; avail=239805.50390625Mb
2025-04-17 12:01:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.011315
2025-04-17 12:01:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.025002
2025-04-17 12:01:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15276.890625Mb; avail=239805.2578125Mb
2025-04-17 12:01:37 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 5.98 | nll_loss 2.391 | ppl 5.25 | wps 5375.4 | wpb 2350.9 | bsz 94.7 | num_updates 2363 | best_loss 5.98
2025-04-17 12:01:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2363 updates
2025-04-17 12:01:37 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt
2025-04-17 12:02:15 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt
2025-04-17 12:02:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt (epoch 17 @ 2363 updates, score 5.98) (writing took 62.419379940009094 seconds)
2025-04-17 12:02:39 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2025-04-17 12:02:39 | INFO | train | epoch 017 | loss 5.807 | nll_loss 2.309 | ppl 4.95 | wps 1872.3 | ups 0.31 | wpb 6008.3 | bsz 229.1 | num_updates 2363 | lr 2.8356e-05 | gnorm 1.253 | train_wall 368 | gb_free 16.3 | wall 7552
2025-04-17 12:02:39 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:hi-mr': 31849}; raw total size: 31849
2025-04-17 12:02:39 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:hi-mr': 31849}; resampled total size: 31849
2025-04-17 12:02:39 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:hi-mr': 1.0}
2025-04-17 12:02:39 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001085
2025-04-17 12:02:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=25390.95703125Mb; avail=229691.20703125Mb
2025-04-17 12:02:39 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000568
2025-04-17 12:02:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003371
2025-04-17 12:02:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=25391.44921875Mb; avail=229690.71484375Mb
2025-04-17 12:02:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000090
2025-04-17 12:02:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=25391.44921875Mb; avail=229690.71484375Mb
2025-04-17 12:02:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001161
2025-04-17 12:02:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.004933
2025-04-17 12:02:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=25391.44921875Mb; avail=229690.71484375Mb
2025-04-17 12:02:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 139
2025-04-17 12:02:39 | INFO | fairseq.trainer | begin training epoch 18
2025-04-17 12:02:39 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-17 12:02:42 | INFO | train_inner | epoch 018:      1 / 139 loss=5.733, nll_loss=2.221, ppl=4.66, wps=103.6, ups=0.02, wpb=4221, bsz=120, num_updates=2364, lr=2.8368e-05, gnorm=1.3, train_wall=4, gb_free=13.6, wall=7554
2025-04-17 12:02:47 | INFO | train_inner | epoch 018:      3 / 139 loss=5.75, nll_loss=2.241, ppl=4.73, wps=2323.6, ups=0.39, wpb=5994.5, bsz=232, num_updates=2366, lr=2.8392e-05, gnorm=1.218, train_wall=5, gb_free=12.1, wall=7559
2025-04-17 12:02:53 | INFO | train_inner | epoch 018:      5 / 139 loss=5.631, nll_loss=2.096, ppl=4.28, wps=2488.7, ups=0.36, wpb=6918.5, bsz=356, num_updates=2368, lr=2.8416e-05, gnorm=1.053, train_wall=6, gb_free=10.5, wall=7565
2025-04-17 12:02:58 | INFO | train_inner | epoch 018:      7 / 139 loss=5.736, nll_loss=2.205, ppl=4.61, wps=2486.7, ups=0.37, wpb=6674, bsz=228, num_updates=2370, lr=2.844e-05, gnorm=1.136, train_wall=5, gb_free=11.4, wall=7570
2025-04-17 12:03:03 | INFO | train_inner | epoch 018:      9 / 139 loss=5.699, nll_loss=2.178, ppl=4.53, wps=2375.1, ups=0.37, wpb=6466, bsz=272, num_updates=2372, lr=2.8464e-05, gnorm=1.101, train_wall=5, gb_free=11.8, wall=7576
2025-04-17 12:03:09 | INFO | train_inner | epoch 018:     11 / 139 loss=5.702, nll_loss=2.191, ppl=4.57, wps=2600.6, ups=0.39, wpb=6739.5, bsz=316, num_updates=2374, lr=2.8488e-05, gnorm=1.132, train_wall=5, gb_free=12.7, wall=7581
2025-04-17 12:03:13 | INFO | train_inner | epoch 018:     13 / 139 loss=5.793, nll_loss=2.281, ppl=4.86, wps=2113.1, ups=0.42, wpb=5022.5, bsz=120, num_updates=2376, lr=2.8512e-05, gnorm=1.359, train_wall=5, gb_free=12.1, wall=7586
2025-04-17 12:03:19 | INFO | train_inner | epoch 018:     15 / 139 loss=5.724, nll_loss=2.198, ppl=4.59, wps=2422.8, ups=0.35, wpb=6950, bsz=312, num_updates=2378, lr=2.8536e-05, gnorm=1.244, train_wall=6, gb_free=10.5, wall=7591
2025-04-17 12:03:23 | INFO | train_inner | epoch 018:     17 / 139 loss=5.796, nll_loss=2.296, ppl=4.91, wps=2348.8, ups=0.47, wpb=5011.5, bsz=184.5, num_updates=2380, lr=2.856e-05, gnorm=1.407, train_wall=4, gb_free=11.8, wall=7596
2025-04-17 12:03:28 | INFO | train_inner | epoch 018:     19 / 139 loss=5.74, nll_loss=2.23, ppl=4.69, wps=1974, ups=0.4, wpb=4947.5, bsz=180, num_updates=2382, lr=2.8584e-05, gnorm=1.241, train_wall=5, gb_free=12.4, wall=7601
2025-04-17 12:03:34 | INFO | train_inner | epoch 018:     21 / 139 loss=5.726, nll_loss=2.217, ppl=4.65, wps=2248.3, ups=0.37, wpb=6040, bsz=276, num_updates=2384, lr=2.8608e-05, gnorm=1.234, train_wall=5, gb_free=13.2, wall=7606
2025-04-17 12:03:39 | INFO | train_inner | epoch 018:     23 / 139 loss=5.705, nll_loss=2.171, ppl=4.5, wps=2362.9, ups=0.37, wpb=6433.5, bsz=212, num_updates=2386, lr=2.8632e-05, gnorm=1.173, train_wall=5, gb_free=10.5, wall=7612
2025-04-17 12:03:45 | INFO | train_inner | epoch 018:     25 / 139 loss=5.736, nll_loss=2.211, ppl=4.63, wps=2277.1, ups=0.37, wpb=6147.5, bsz=276, num_updates=2388, lr=2.8656e-05, gnorm=1.165, train_wall=5, gb_free=11, wall=7617
2025-04-17 12:03:55 | INFO | train_inner | epoch 018:     27 / 139 loss=5.813, nll_loss=2.313, ppl=4.97, wps=1095.3, ups=0.2, wpb=5537, bsz=172, num_updates=2390, lr=2.868e-05, gnorm=1.284, train_wall=10, gb_free=11.5, wall=7627
2025-04-17 12:04:00 | INFO | train_inner | epoch 018:     29 / 139 loss=5.785, nll_loss=2.275, ppl=4.84, wps=2469, ups=0.4, wpb=6196, bsz=156, num_updates=2392, lr=2.8704e-05, gnorm=1.189, train_wall=5, gb_free=11.4, wall=7632
2025-04-17 12:04:05 | INFO | train_inner | epoch 018:     31 / 139 loss=5.717, nll_loss=2.2, ppl=4.59, wps=2446.8, ups=0.36, wpb=6882.5, bsz=348, num_updates=2394, lr=2.8728e-05, gnorm=1.306, train_wall=6, gb_free=11.5, wall=7638
2025-04-17 12:04:11 | INFO | train_inner | epoch 018:     33 / 139 loss=5.718, nll_loss=2.199, ppl=4.59, wps=2267.3, ups=0.36, wpb=6325, bsz=308, num_updates=2396, lr=2.8752e-05, gnorm=1.091, train_wall=6, gb_free=11.4, wall=7643
2025-04-17 12:04:16 | INFO | train_inner | epoch 018:     35 / 139 loss=5.712, nll_loss=2.187, ppl=4.55, wps=2345.8, ups=0.37, wpb=6383, bsz=284, num_updates=2398, lr=2.8776e-05, gnorm=1.162, train_wall=5, gb_free=12, wall=7649
2025-04-17 12:04:21 | INFO | train_inner | epoch 018:     37 / 139 loss=5.744, nll_loss=2.229, ppl=4.69, wps=2333.8, ups=0.4, wpb=5838.5, bsz=152, num_updates=2400, lr=2.88e-05, gnorm=1.23, train_wall=5, gb_free=11.7, wall=7654
2025-04-17 12:04:26 | INFO | train_inner | epoch 018:     39 / 139 loss=5.763, nll_loss=2.254, ppl=4.77, wps=2212.5, ups=0.39, wpb=5646.5, bsz=224, num_updates=2402, lr=2.8824e-05, gnorm=1.248, train_wall=5, gb_free=11.9, wall=7659
2025-04-17 12:04:31 | INFO | train_inner | epoch 018:     41 / 139 loss=5.68, nll_loss=2.146, ppl=4.43, wps=1828.7, ups=0.39, wpb=4639.5, bsz=228, num_updates=2404, lr=2.8848e-05, gnorm=1.537, train_wall=5, gb_free=13.1, wall=7664
2025-04-17 12:04:37 | INFO | train_inner | epoch 018:     43 / 139 loss=5.819, nll_loss=2.324, ppl=5.01, wps=2413.4, ups=0.38, wpb=6349, bsz=184, num_updates=2406, lr=2.8872e-05, gnorm=1.222, train_wall=5, gb_free=11.6, wall=7669
2025-04-17 12:04:42 | INFO | train_inner | epoch 018:     45 / 139 loss=5.74, nll_loss=2.228, ppl=4.68, wps=2108.4, ups=0.41, wpb=5153, bsz=164, num_updates=2408, lr=2.8896e-05, gnorm=1.255, train_wall=5, gb_free=11.9, wall=7674
2025-04-17 12:04:47 | INFO | train_inner | epoch 018:     47 / 139 loss=5.66, nll_loss=2.118, ppl=4.34, wps=2187.3, ups=0.4, wpb=5494, bsz=172, num_updates=2410, lr=2.892e-05, gnorm=1.26, train_wall=5, gb_free=13.9, wall=7679
2025-04-17 12:04:52 | INFO | train_inner | epoch 018:     49 / 139 loss=5.685, nll_loss=2.152, ppl=4.45, wps=2391.9, ups=0.35, wpb=6851, bsz=276, num_updates=2412, lr=2.8944e-05, gnorm=2.085, train_wall=6, gb_free=10.9, wall=7685
2025-04-17 12:04:58 | INFO | train_inner | epoch 018:     51 / 139 loss=5.784, nll_loss=2.28, ppl=4.86, wps=2481.9, ups=0.39, wpb=6440, bsz=200, num_updates=2414, lr=2.8968e-05, gnorm=1.127, train_wall=5, gb_free=11.6, wall=7690
2025-04-17 12:05:03 | INFO | train_inner | epoch 018:     53 / 139 loss=5.627, nll_loss=2.087, ppl=4.25, wps=2468.3, ups=0.36, wpb=6818, bsz=312, num_updates=2416, lr=2.8992e-05, gnorm=1.117, train_wall=6, gb_free=11.1, wall=7696
2025-04-17 12:05:08 | INFO | train_inner | epoch 018:     55 / 139 loss=5.697, nll_loss=2.169, ppl=4.5, wps=2323.6, ups=0.39, wpb=6022.5, bsz=192, num_updates=2418, lr=2.9016e-05, gnorm=1.107, train_wall=5, gb_free=11.4, wall=7701
2025-04-17 12:05:14 | INFO | train_inner | epoch 018:     57 / 139 loss=5.742, nll_loss=2.234, ppl=4.71, wps=2263.9, ups=0.37, wpb=6054, bsz=216, num_updates=2420, lr=2.904e-05, gnorm=1.113, train_wall=5, gb_free=11.4, wall=7706
2025-04-17 12:05:19 | INFO | train_inner | epoch 018:     59 / 139 loss=5.728, nll_loss=2.208, ppl=4.62, wps=2391, ups=0.39, wpb=6167.5, bsz=224, num_updates=2422, lr=2.9064e-05, gnorm=1.151, train_wall=5, gb_free=14, wall=7711
2025-04-17 12:05:24 | INFO | train_inner | epoch 018:     61 / 139 loss=5.695, nll_loss=2.177, ppl=4.52, wps=2527.1, ups=0.37, wpb=6808.5, bsz=284, num_updates=2424, lr=2.9088e-05, gnorm=1.102, train_wall=5, gb_free=12.1, wall=7717
2025-04-17 12:05:30 | INFO | train_inner | epoch 018:     63 / 139 loss=5.783, nll_loss=2.279, ppl=4.85, wps=2228.4, ups=0.37, wpb=5963, bsz=196, num_updates=2426, lr=2.9112e-05, gnorm=1.285, train_wall=5, gb_free=10.6, wall=7722
2025-04-17 12:05:35 | INFO | train_inner | epoch 018:     65 / 139 loss=5.753, nll_loss=2.239, ppl=4.72, wps=2471.7, ups=0.36, wpb=6772, bsz=288, num_updates=2428, lr=2.9136e-05, gnorm=1.128, train_wall=5, gb_free=11.3, wall=7727
2025-04-17 12:05:40 | INFO | train_inner | epoch 018:     67 / 139 loss=5.871, nll_loss=2.37, ppl=5.17, wps=2227.3, ups=0.36, wpb=6104, bsz=168, num_updates=2430, lr=2.916e-05, gnorm=1.237, train_wall=5, gb_free=10.7, wall=7733
2025-04-17 12:05:46 | INFO | train_inner | epoch 018:     69 / 139 loss=5.701, nll_loss=2.195, ppl=4.58, wps=2244.1, ups=0.39, wpb=5718, bsz=212, num_updates=2432, lr=2.9184e-05, gnorm=1.211, train_wall=5, gb_free=12.7, wall=7738
2025-04-17 12:05:51 | INFO | train_inner | epoch 018:     71 / 139 loss=5.712, nll_loss=2.206, ppl=4.61, wps=2508, ups=0.39, wpb=6424.5, bsz=208, num_updates=2434, lr=2.9208e-05, gnorm=1.203, train_wall=5, gb_free=13, wall=7743
2025-04-17 12:05:56 | INFO | train_inner | epoch 018:     73 / 139 loss=5.833, nll_loss=2.328, ppl=5.02, wps=2256.7, ups=0.41, wpb=5564.5, bsz=144, num_updates=2436, lr=2.9232e-05, gnorm=1.391, train_wall=5, gb_free=12.2, wall=7748
2025-04-17 12:06:01 | INFO | train_inner | epoch 018:     75 / 139 loss=5.795, nll_loss=2.279, ppl=4.85, wps=2151.4, ups=0.4, wpb=5438.5, bsz=180, num_updates=2438, lr=2.9256e-05, gnorm=1.405, train_wall=5, gb_free=11, wall=7753
2025-04-17 12:06:06 | INFO | train_inner | epoch 018:     77 / 139 loss=5.632, nll_loss=2.102, ppl=4.29, wps=2170, ups=0.36, wpb=6087, bsz=372, num_updates=2440, lr=2.928e-05, gnorm=1.187, train_wall=6, gb_free=11.3, wall=7759
2025-04-17 12:06:12 | INFO | train_inner | epoch 018:     79 / 139 loss=5.712, nll_loss=2.21, ppl=4.63, wps=1753.4, ups=0.38, wpb=4635.5, bsz=300, num_updates=2442, lr=2.9304e-05, gnorm=1.429, train_wall=5, gb_free=9.6, wall=7764
2025-04-17 12:06:16 | INFO | train_inner | epoch 018:     81 / 139 loss=5.912, nll_loss=2.443, ppl=5.44, wps=2358.8, ups=0.41, wpb=5701.5, bsz=120, num_updates=2444, lr=2.9328e-05, gnorm=1.864, train_wall=5, gb_free=14.5, wall=7769
2025-04-17 12:06:22 | INFO | train_inner | epoch 018:     83 / 139 loss=5.772, nll_loss=2.25, ppl=4.76, wps=2409.7, ups=0.36, wpb=6720.5, bsz=292, num_updates=2446, lr=2.9352e-05, gnorm=1.127, train_wall=6, gb_free=12.1, wall=7774
2025-04-17 12:06:27 | INFO | train_inner | epoch 018:     85 / 139 loss=5.782, nll_loss=2.254, ppl=4.77, wps=2146.4, ups=0.41, wpb=5213, bsz=140, num_updates=2448, lr=2.9376e-05, gnorm=1.449, train_wall=5, gb_free=12.1, wall=7779
2025-04-17 12:06:32 | INFO | train_inner | epoch 018:     87 / 139 loss=5.864, nll_loss=2.394, ppl=5.26, wps=2083.2, ups=0.39, wpb=5338, bsz=248, num_updates=2450, lr=2.94e-05, gnorm=1.537, train_wall=5, gb_free=10.7, wall=7784
2025-04-17 12:06:37 | INFO | train_inner | epoch 018:     89 / 139 loss=5.755, nll_loss=2.255, ppl=4.77, wps=2396, ups=0.38, wpb=6384, bsz=232, num_updates=2452, lr=2.9424e-05, gnorm=1.21, train_wall=5, gb_free=11.2, wall=7790
2025-04-17 12:06:43 | INFO | train_inner | epoch 018:     91 / 139 loss=5.773, nll_loss=2.278, ppl=4.85, wps=2421, ups=0.35, wpb=6848, bsz=348, num_updates=2454, lr=2.9448e-05, gnorm=1.104, train_wall=6, gb_free=10.9, wall=7795
2025-04-17 12:06:48 | INFO | train_inner | epoch 018:     93 / 139 loss=5.724, nll_loss=2.19, ppl=4.56, wps=2484, ups=0.43, wpb=5821, bsz=168, num_updates=2456, lr=2.9472e-05, gnorm=1.414, train_wall=5, gb_free=12.7, wall=7800
2025-04-17 12:06:53 | INFO | train_inner | epoch 018:     95 / 139 loss=5.731, nll_loss=2.185, ppl=4.55, wps=2236.8, ups=0.37, wpb=6068.5, bsz=216, num_updates=2458, lr=2.9496e-05, gnorm=1.217, train_wall=5, gb_free=9.2, wall=7806
2025-04-17 12:06:58 | INFO | train_inner | epoch 018:     97 / 139 loss=5.751, nll_loss=2.241, ppl=4.73, wps=2268.2, ups=0.42, wpb=5411, bsz=200, num_updates=2460, lr=2.952e-05, gnorm=1.26, train_wall=5, gb_free=10.8, wall=7810
2025-04-17 12:07:03 | INFO | train_inner | epoch 018:     99 / 139 loss=5.773, nll_loss=2.291, ppl=4.89, wps=2548.9, ups=0.38, wpb=6639.5, bsz=240, num_updates=2462, lr=2.9544e-05, gnorm=1.228, train_wall=5, gb_free=11.6, wall=7816
2025-04-17 12:07:08 | INFO | train_inner | epoch 018:    101 / 139 loss=5.857, nll_loss=2.378, ppl=5.2, wps=2230.6, ups=0.37, wpb=5952, bsz=232, num_updates=2464, lr=2.9568e-05, gnorm=1.377, train_wall=5, gb_free=12.6, wall=7821
2025-04-17 12:07:14 | INFO | train_inner | epoch 018:    103 / 139 loss=5.816, nll_loss=2.307, ppl=4.95, wps=2193.1, ups=0.38, wpb=5704.5, bsz=172, num_updates=2466, lr=2.9592e-05, gnorm=1.232, train_wall=5, gb_free=13.6, wall=7826
2025-04-17 12:07:19 | INFO | train_inner | epoch 018:    105 / 139 loss=5.852, nll_loss=2.362, ppl=5.14, wps=2266.3, ups=0.37, wpb=6189.5, bsz=200, num_updates=2468, lr=2.9616e-05, gnorm=1.318, train_wall=5, gb_free=10.5, wall=7832
2025-04-17 12:07:24 | INFO | train_inner | epoch 018:    107 / 139 loss=5.771, nll_loss=2.286, ppl=4.88, wps=2470.2, ups=0.37, wpb=6610.5, bsz=340, num_updates=2470, lr=2.964e-05, gnorm=1.267, train_wall=5, gb_free=11.9, wall=7837
2025-04-17 12:07:30 | INFO | train_inner | epoch 018:    109 / 139 loss=5.853, nll_loss=2.334, ppl=5.04, wps=2237.3, ups=0.35, wpb=6384.5, bsz=264, num_updates=2472, lr=2.9664e-05, gnorm=1.287, train_wall=6, gb_free=11.3, wall=7843
2025-04-17 12:07:36 | INFO | train_inner | epoch 018:    111 / 139 loss=5.818, nll_loss=2.303, ppl=4.94, wps=2360.6, ups=0.37, wpb=6386.5, bsz=228, num_updates=2474, lr=2.9688e-05, gnorm=1.316, train_wall=5, gb_free=9.8, wall=7848
2025-04-17 12:07:41 | INFO | train_inner | epoch 018:    113 / 139 loss=5.712, nll_loss=2.212, ppl=4.63, wps=2397.7, ups=0.38, wpb=6308.5, bsz=264, num_updates=2476, lr=2.9712e-05, gnorm=1.161, train_wall=5, gb_free=11.9, wall=7853
2025-04-17 12:07:46 | INFO | train_inner | epoch 018:    115 / 139 loss=5.689, nll_loss=2.159, ppl=4.47, wps=2203.2, ups=0.39, wpb=5610.5, bsz=168, num_updates=2478, lr=2.9736e-05, gnorm=1.213, train_wall=5, gb_free=11, wall=7858
2025-04-17 12:07:51 | INFO | train_inner | epoch 018:    117 / 139 loss=5.653, nll_loss=2.125, ppl=4.36, wps=2261.2, ups=0.37, wpb=6059.5, bsz=288, num_updates=2480, lr=2.976e-05, gnorm=2.106, train_wall=5, gb_free=11.4, wall=7864
2025-04-17 12:07:56 | INFO | train_inner | epoch 018:    119 / 139 loss=5.812, nll_loss=2.308, ppl=4.95, wps=2205.9, ups=0.41, wpb=5417.5, bsz=160, num_updates=2482, lr=2.9784e-05, gnorm=1.326, train_wall=5, gb_free=11.9, wall=7869
2025-04-17 12:08:01 | INFO | train_inner | epoch 018:    121 / 139 loss=5.673, nll_loss=2.125, ppl=4.36, wps=2257.9, ups=0.41, wpb=5462.5, bsz=232, num_updates=2484, lr=2.9808e-05, gnorm=1.473, train_wall=5, gb_free=14.1, wall=7873
2025-04-17 12:08:06 | INFO | train_inner | epoch 018:    123 / 139 loss=5.814, nll_loss=2.329, ppl=5.02, wps=2262.1, ups=0.42, wpb=5376.5, bsz=116, num_updates=2486, lr=2.9832e-05, gnorm=1.219, train_wall=5, gb_free=14.1, wall=7878
2025-04-17 12:08:11 | INFO | train_inner | epoch 018:    125 / 139 loss=5.794, nll_loss=2.293, ppl=4.9, wps=2138.4, ups=0.37, wpb=5731, bsz=168, num_updates=2488, lr=2.9856e-05, gnorm=1.284, train_wall=5, gb_free=12.2, wall=7884
2025-04-17 12:08:17 | INFO | train_inner | epoch 018:    127 / 139 loss=5.737, nll_loss=2.209, ppl=4.62, wps=2437.3, ups=0.36, wpb=6821, bsz=304, num_updates=2490, lr=2.988e-05, gnorm=1.117, train_wall=6, gb_free=12, wall=7889
2025-04-17 12:08:22 | INFO | train_inner | epoch 018:    129 / 139 loss=5.684, nll_loss=2.156, ppl=4.46, wps=2418, ups=0.38, wpb=6399, bsz=252, num_updates=2492, lr=2.9904e-05, gnorm=1.192, train_wall=5, gb_free=10.6, wall=7894
2025-04-17 12:08:27 | INFO | train_inner | epoch 018:    131 / 139 loss=5.747, nll_loss=2.235, ppl=4.71, wps=2307.9, ups=0.39, wpb=5924, bsz=196, num_updates=2494, lr=2.9928e-05, gnorm=1.197, train_wall=5, gb_free=13.8, wall=7900
2025-04-17 12:08:32 | INFO | train_inner | epoch 018:    133 / 139 loss=5.654, nll_loss=2.118, ppl=4.34, wps=2378, ups=0.39, wpb=6116.5, bsz=328, num_updates=2496, lr=2.9952e-05, gnorm=1.42, train_wall=5, gb_free=10.8, wall=7905
2025-04-17 12:08:38 | INFO | train_inner | epoch 018:    135 / 139 loss=5.588, nll_loss=2.033, ppl=4.09, wps=2323.3, ups=0.37, wpb=6339, bsz=276, num_updates=2498, lr=2.9976e-05, gnorm=1.025, train_wall=5, gb_free=10.4, wall=7910
2025-04-17 12:08:43 | INFO | train_inner | epoch 018:    137 / 139 loss=5.776, nll_loss=2.281, ppl=4.86, wps=2072.5, ups=0.39, wpb=5277, bsz=160, num_updates=2500, lr=3e-05, gnorm=1.14, train_wall=5, gb_free=12.2, wall=7915
2025-04-17 12:08:47 | INFO | train_inner | epoch 018:    139 / 139 loss=5.746, nll_loss=2.245, ppl=4.74, wps=2458.5, ups=0.48, wpb=5170, bsz=200, num_updates=2502, lr=2.9988e-05, gnorm=1.326, train_wall=4, gb_free=17.2, wall=7920
2025-04-17 12:08:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2025-04-17 12:08:47 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=15281.0859375Mb; avail=239801.0625Mb
2025-04-17 12:08:47 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.000629
2025-04-17 12:08:47 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15281.0859375Mb; avail=239801.0625Mb
2025-04-17 12:08:47 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.012734
2025-04-17 12:08:47 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15281.0859375Mb; avail=239801.0625Mb
2025-04-17 12:08:47 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.011056
2025-04-17 12:08:47 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.024776
2025-04-17 12:08:47 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15281.0859375Mb; avail=239801.0625Mb
2025-04-17 12:09:02 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 5.934 | nll_loss 2.342 | ppl 5.07 | wps 5366.8 | wpb 2350.9 | bsz 94.7 | num_updates 2502 | best_loss 5.934
2025-04-17 12:09:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2502 updates
2025-04-17 12:09:02 | INFO | fairseq.trainer | Saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt
2025-04-17 12:09:40 | INFO | fairseq.trainer | Finished saving checkpoint to /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt
2025-04-17 12:10:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/krish/content/old_files/Version3/checkpoint1.2B/checkpoint_best.pt (epoch 18 @ 2502 updates, score 5.934) (writing took 62.18181339799776 seconds)
2025-04-17 12:10:04 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2025-04-17 12:10:04 | INFO | train | epoch 018 | loss 5.746 | nll_loss 2.232 | ppl 4.7 | wps 1876.4 | ups 0.31 | wpb 6008.3 | bsz 229.1 | num_updates 2502 | lr 2.9988e-05 | gnorm 1.274 | train_wall 367 | gb_free 17.2 | wall 7997
2025-04-17 12:10:04 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:hi-mr': 31849}; raw total size: 31849
2025-04-17 12:10:04 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:hi-mr': 31849}; resampled total size: 31849
2025-04-17 12:10:04 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:hi-mr': 1.0}
2025-04-17 12:10:04 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.001119
2025-04-17 12:10:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=25404.703125Mb; avail=229677.40625Mb
2025-04-17 12:10:04 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000461
2025-04-17 12:10:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.003743
2025-04-17 12:10:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=25404.703125Mb; avail=229677.40625Mb
2025-04-17 12:10:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000130
2025-04-17 12:10:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=25404.703125Mb; avail=229677.40625Mb
2025-04-17 12:10:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001200
2025-04-17 12:10:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.005430
2025-04-17 12:10:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=25404.703125Mb; avail=229677.40625Mb
2025-04-17 12:10:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 139
2025-04-17 12:10:05 | INFO | fairseq.trainer | begin training epoch 19
2025-04-17 12:10:05 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-17 12:10:10 | INFO | train_inner | epoch 019:      2 / 139 loss=5.741, nll_loss=2.219, ppl=4.66, wps=156.8, ups=0.02, wpb=6478, bsz=196, num_updates=2504, lr=2.9976e-05, gnorm=1.164, train_wall=5, gb_free=12.7, wall=8002
2025-04-17 12:10:14 | INFO | train_inner | epoch 019:      4 / 139 loss=5.814, nll_loss=2.318, ppl=4.99, wps=2243.7, ups=0.42, wpb=5299.5, bsz=132, num_updates=2506, lr=2.99641e-05, gnorm=1.239, train_wall=5, gb_free=11.8, wall=8007
2025-04-17 12:10:20 | INFO | train_inner | epoch 019:      6 / 139 loss=5.518, nll_loss=1.943, ppl=3.85, wps=2433.9, ups=0.38, wpb=6424, bsz=340, num_updates=2508, lr=2.99521e-05, gnorm=1.043, train_wall=5, gb_free=10.9, wall=8012
2025-04-17 12:10:25 | INFO | train_inner | epoch 019:      8 / 139 loss=5.722, nll_loss=2.204, ppl=4.61, wps=2379.7, ups=0.37, wpb=6405, bsz=312, num_updates=2510, lr=2.99402e-05, gnorm=1.22, train_wall=5, gb_free=10.7, wall=8018
2025-04-17 12:10:30 | INFO | train_inner | epoch 019:     10 / 139 loss=5.749, nll_loss=2.244, ppl=4.74, wps=2365, ups=0.39, wpb=6114.5, bsz=216, num_updates=2512, lr=2.99283e-05, gnorm=1.562, train_wall=5, gb_free=10.2, wall=8023
2025-04-17 12:10:35 | INFO | train_inner | epoch 019:     12 / 139 loss=5.722, nll_loss=2.184, ppl=4.54, wps=2160.1, ups=0.42, wpb=5088.5, bsz=144, num_updates=2514, lr=2.99164e-05, gnorm=1.461, train_wall=5, gb_free=14.3, wall=8027
2025-04-17 12:10:40 | INFO | train_inner | epoch 019:     14 / 139 loss=5.618, nll_loss=2.054, ppl=4.15, wps=2269.1, ups=0.42, wpb=5439, bsz=196, num_updates=2516, lr=2.99045e-05, gnorm=1.241, train_wall=5, gb_free=11.5, wall=8032
2025-04-17 12:10:45 | INFO | train_inner | epoch 019:     16 / 139 loss=5.621, nll_loss=2.07, ppl=4.2, wps=2216.9, ups=0.36, wpb=6200.5, bsz=304, num_updates=2518, lr=2.98926e-05, gnorm=1.265, train_wall=6, gb_free=10.6, wall=8038
2025-04-17 12:10:51 | INFO | train_inner | epoch 019:     18 / 139 loss=5.68, nll_loss=2.163, ppl=4.48, wps=2316.6, ups=0.38, wpb=6159.5, bsz=220, num_updates=2520, lr=2.98807e-05, gnorm=1.199, train_wall=5, gb_free=10.9, wall=8043
2025-04-17 12:10:56 | INFO | train_inner | epoch 019:     20 / 139 loss=5.636, nll_loss=2.096, ppl=4.27, wps=2356.8, ups=0.38, wpb=6198.5, bsz=192, num_updates=2522, lr=2.98689e-05, gnorm=1.136, train_wall=5, gb_free=10.6, wall=8048
2025-04-17 12:11:01 | INFO | train_inner | epoch 019:     22 / 139 loss=5.764, nll_loss=2.237, ppl=4.71, wps=2425, ups=0.38, wpb=6435, bsz=192, num_updates=2524, lr=2.9857e-05, gnorm=1.195, train_wall=5, gb_free=11.4, wall=8054
2025-04-17 12:11:06 | INFO | train_inner | epoch 019:     24 / 139 loss=5.733, nll_loss=2.197, ppl=4.59, wps=2526.1, ups=0.41, wpb=6222, bsz=196, num_updates=2526, lr=2.98452e-05, gnorm=1.317, train_wall=5, gb_free=15.1, wall=8059
2025-04-17 12:11:12 | INFO | train_inner | epoch 019:     26 / 139 loss=5.633, nll_loss=2.08, ppl=4.23, wps=2309.3, ups=0.37, wpb=6305, bsz=240, num_updates=2528, lr=2.98334e-05, gnorm=1.198, train_wall=5, gb_free=12.6, wall=8064
2025-04-17 12:11:17 | INFO | train_inner | epoch 019:     28 / 139 loss=5.616, nll_loss=2.078, ppl=4.22, wps=2350.6, ups=0.38, wpb=6248.5, bsz=264, num_updates=2530, lr=2.98216e-05, gnorm=1.127, train_wall=5, gb_free=12, wall=8069
2025-04-17 12:11:22 | INFO | train_inner | epoch 019:     30 / 139 loss=5.521, nll_loss=1.955, ppl=3.88, wps=2229, ups=0.38, wpb=5884.5, bsz=312, num_updates=2532, lr=2.98098e-05, gnorm=1.168, train_wall=5, gb_free=11.2, wall=8075
2025-04-17 12:11:27 | INFO | train_inner | epoch 019:     32 / 139 loss=5.7, nll_loss=2.174, ppl=4.51, wps=2463.6, ups=0.43, wpb=5774, bsz=200, num_updates=2534, lr=2.97981e-05, gnorm=1.328, train_wall=5, gb_free=16.6, wall=8079
2025-04-17 12:11:32 | INFO | train_inner | epoch 019:     34 / 139 loss=5.601, nll_loss=2.051, ppl=4.14, wps=2233.8, ups=0.4, wpb=5613, bsz=172, num_updates=2536, lr=2.97863e-05, gnorm=1.157, train_wall=5, gb_free=11.7, wall=8084
2025-04-17 12:11:37 | INFO | train_inner | epoch 019:     36 / 139 loss=5.728, nll_loss=2.204, ppl=4.61, wps=1993.5, ups=0.4, wpb=4972.5, bsz=172, num_updates=2538, lr=2.97746e-05, gnorm=1.276, train_wall=5, gb_free=11.5, wall=8089
2025-04-17 12:11:42 | INFO | train_inner | epoch 019:     38 / 139 loss=5.704, nll_loss=2.172, ppl=4.51, wps=2279, ups=0.4, wpb=5661, bsz=184, num_updates=2540, lr=2.97628e-05, gnorm=1.806, train_wall=5, gb_free=13.6, wall=8094
2025-04-17 12:11:47 | INFO | train_inner | epoch 019:     40 / 139 loss=5.694, nll_loss=2.166, ppl=4.49, wps=2062.9, ups=0.4, wpb=5096, bsz=160, num_updates=2542, lr=2.97511e-05, gnorm=1.244, train_wall=5, gb_free=11.8, wall=8099
2025-04-17 12:11:52 | INFO | train_inner | epoch 019:     42 / 139 loss=5.508, nll_loss=1.937, ppl=3.83, wps=2501.1, ups=0.37, wpb=6836.5, bsz=284, num_updates=2544, lr=2.97394e-05, gnorm=1, train_wall=5, gb_free=10.7, wall=8105
2025-04-17 12:11:57 | INFO | train_inner | epoch 019:     44 / 139 loss=5.637, nll_loss=2.098, ppl=4.28, wps=2307.4, ups=0.4, wpb=5737, bsz=236, num_updates=2546, lr=2.97278e-05, gnorm=1.151, train_wall=5, gb_free=13.8, wall=8110
2025-04-17 12:12:03 | INFO | train_inner | epoch 019:     46 / 139 loss=5.579, nll_loss=2.015, ppl=4.04, wps=2213.6, ups=0.36, wpb=6150, bsz=252, num_updates=2548, lr=2.97161e-05, gnorm=1.1, train_wall=6, gb_free=11.6, wall=8115
2025-04-17 12:12:08 | INFO | train_inner | epoch 019:     48 / 139 loss=5.713, nll_loss=2.188, ppl=4.56, wps=2313, ups=0.37, wpb=6204.5, bsz=232, num_updates=2550, lr=2.97044e-05, gnorm=1.158, train_wall=5, gb_free=10.8, wall=8121
2025-04-17 12:12:13 | INFO | train_inner | epoch 019:     50 / 139 loss=5.703, nll_loss=2.179, ppl=4.53, wps=2362.9, ups=0.38, wpb=6228.5, bsz=196, num_updates=2552, lr=2.96928e-05, gnorm=1.19, train_wall=5, gb_free=11.8, wall=8126
2025-04-17 12:12:19 | INFO | train_inner | epoch 019:     52 / 139 loss=5.785, nll_loss=2.29, ppl=4.89, wps=2219.6, ups=0.34, wpb=6625.5, bsz=372, num_updates=2554, lr=2.96812e-05, gnorm=1.231, train_wall=6, gb_free=9.8, wall=8132
2025-04-17 12:12:30 | INFO | train_inner | epoch 019:     54 / 139 loss=5.695, nll_loss=2.171, ppl=4.5, wps=1209.3, ups=0.19, wpb=6332, bsz=264, num_updates=2556, lr=2.96695e-05, gnorm=1.234, train_wall=10, gb_free=11.2, wall=8142
2025-04-17 12:12:34 | INFO | train_inner | epoch 019:     56 / 139 loss=5.608, nll_loss=2.047, ppl=4.13, wps=2340.1, ups=0.45, wpb=5203.5, bsz=144, num_updates=2558, lr=2.96579e-05, gnorm=1.186, train_wall=4, gb_free=17.8, wall=8147
2025-04-17 12:12:39 | INFO | train_inner | epoch 019:     58 / 139 loss=5.791, nll_loss=2.284, ppl=4.87, wps=2052.7, ups=0.39, wpb=5198.5, bsz=136, num_updates=2560, lr=2.96464e-05, gnorm=1.34, train_wall=5, gb_free=14.2, wall=8152
2025-04-17 12:12:45 | INFO | train_inner | epoch 019:     60 / 139 loss=5.607, nll_loss=2.057, ppl=4.16, wps=2431.5, ups=0.36, wpb=6733.5, bsz=324, num_updates=2562, lr=2.96348e-05, gnorm=1.2, train_wall=6, gb_free=12, wall=8157
2025-04-17 12:12:50 | INFO | train_inner | epoch 019:     62 / 139 loss=5.637, nll_loss=2.088, ppl=4.25, wps=2430.9, ups=0.37, wpb=6635.5, bsz=308, num_updates=2564, lr=2.96232e-05, gnorm=1.097, train_wall=5, gb_free=10.4, wall=8163
