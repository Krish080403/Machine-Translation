2025-04-01 06:21:54 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 2, 'log_format': 'simple', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 222, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 3600, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 3600, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 40000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [2], 'lr': [3e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/home/krish/content/old_files/Version3/checkpoint1.2B', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': '/home/krish/content/1.2B_last_checkpoint.pt', 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 5000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': 10, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=2, log_format='simple', log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=222, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', scoring='bleu', task='translation_multi_simple_epoch', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=3600, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=3600, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='transformer_wmt_en_de_big', max_epoch=0, max_update=40000, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[2], lr=[3e-05], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='/home/krish/content/old_files/Version3/checkpoint1.2B', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model='/home/krish/content/1.2B_last_checkpoint.pt', reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=5000, keep_interval_updates=10, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=10, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, source_lang=None, target_lang=None, lang_pairs='hi-mr', keep_inference_langtok=False, sampling_method='temperature', sampling_temperature=1.5, data='/home/krish/content/old_files/Version3/wmt22_spm/wmt22_bin', langs=['hi', 'mr'], lang_dict=None, source_dict=None, target_dict=None, lang_tok_style='multilingual', load_alignments=False, left_pad_source='True', left_pad_target='False', upsample_primary=1, truncate_source=False, encoder_langtok='src', decoder_langtok=True, lang_tok_replacing_bos_eos=False, enable_lang_ids=False, enable_reservsed_directions_shared_datasets=False, extra_data=None, extra_lang_pairs=None, fixed_dictionary=None, langtoks_specs=['main'], langtoks=None, sampling_weights_from_file=None, sampling_weights=None, virtual_epoch_size=None, virtual_data_size=None, label_smoothing=0.2, report_accuracy=False, ignore_prefix_size=0, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.0, use_old_adam=False, fp16_adam_stats=False, warmup_updates=2500, warmup_init_lr=-1, pad=1, eos=2, unk=3, encoder_normalize_before=True, decoder_normalize_before=True, dropout=0.3, attention_dropout=0.1, encoder_layers=24, decoder_layers=24, encoder_ffn_embed_dim=8192, decoder_ffn_embed_dim=8192, encoder_layerdrop=0.05, decoder_layerdrop=0.05, share_decoder_input_output_embed=True, share_all_embeddings=True, no_seed_provided=False, encoder_embed_dim=1024, encoder_attention_heads=16, decoder_embed_dim=1024, decoder_attention_heads=16, encoder_embed_path=None, encoder_learned_pos=False, decoder_embed_path=None, decoder_learned_pos=False, activation_dropout=0.0, activation_fn='relu', adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, no_token_positional_embeddings=False, adaptive_input=False, no_cross_attention=False, cross_self_attention=False, decoder_output_dim=1024, decoder_input_dim=1024, no_scale_embedding=False, layernorm_embedding=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, _name='transformer_wmt_en_de_big'), 'task': Namespace(no_progress_bar=False, log_interval=2, log_format='simple', log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=222, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', scoring='bleu', task='translation_multi_simple_epoch', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=3600, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=3600, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='transformer_wmt_en_de_big', max_epoch=0, max_update=40000, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[2], lr=[3e-05], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='/home/krish/content/old_files/Version3/checkpoint1.2B', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model='/home/krish/content/1.2B_last_checkpoint.pt', reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=5000, keep_interval_updates=10, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=10, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, source_lang=None, target_lang=None, lang_pairs='hi-mr', keep_inference_langtok=False, sampling_method='temperature', sampling_temperature=1.5, data='/home/krish/content/old_files/Version3/wmt22_spm/wmt22_bin', langs=['hi', 'mr'], lang_dict=None, source_dict=None, target_dict=None, lang_tok_style='multilingual', load_alignments=False, left_pad_source='True', left_pad_target='False', upsample_primary=1, truncate_source=False, encoder_langtok='src', decoder_langtok=True, lang_tok_replacing_bos_eos=False, enable_lang_ids=False, enable_reservsed_directions_shared_datasets=False, extra_data=None, extra_lang_pairs=None, fixed_dictionary=None, langtoks_specs=['main'], langtoks=None, sampling_weights_from_file=None, sampling_weights=None, virtual_epoch_size=None, virtual_data_size=None, label_smoothing=0.2, report_accuracy=False, ignore_prefix_size=0, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.0, use_old_adam=False, fp16_adam_stats=False, warmup_updates=2500, warmup_init_lr=-1, pad=1, eos=2, unk=3, encoder_normalize_before=True, decoder_normalize_before=True, dropout=0.3, attention_dropout=0.1, encoder_layers=24, decoder_layers=24, encoder_ffn_embed_dim=8192, decoder_ffn_embed_dim=8192, encoder_layerdrop=0.05, decoder_layerdrop=0.05, share_decoder_input_output_embed=True, share_all_embeddings=True, no_seed_provided=False, encoder_embed_dim=1024, encoder_attention_heads=16, decoder_embed_dim=1024, decoder_attention_heads=16, encoder_embed_path=None, encoder_learned_pos=False, decoder_embed_path=None, decoder_learned_pos=False, activation_dropout=0.0, activation_fn='relu', adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, no_token_positional_embeddings=False, adaptive_input=False, no_cross_attention=False, cross_self_attention=False, decoder_output_dim=1024, decoder_input_dim=1024, no_scale_embedding=False, layernorm_embedding=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, max_source_positions=1024, max_target_positions=1024, _name='translation_multi_simple_epoch'), 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.2, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [3e-05]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 2500, 'warmup_init_lr': -1.0, 'lr': [3e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2025-04-01 06:21:54 | INFO | fairseq.data.multilingual.multilingual_data_manager | parsed the language list as they are ordered in the option: ['hi', 'mr']
2025-04-03 11:31:26 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 2, 'log_format': 'simple', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 222, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 3600, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 3600, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 40000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [2], 'lr': [3e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/home/krish/content/old_files/Version3/checkpoint1.2B', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': '/home/krish/content/1.2B_last_checkpoint.pt', 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 5000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': 10, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=2, log_format='simple', log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=222, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', scoring='bleu', task='translation_multi_simple_epoch', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=3600, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=3600, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='transformer_wmt_en_de_big', max_epoch=0, max_update=40000, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[2], lr=[3e-05], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='/home/krish/content/old_files/Version3/checkpoint1.2B', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model='/home/krish/content/1.2B_last_checkpoint.pt', reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=5000, keep_interval_updates=10, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=10, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, source_lang=None, target_lang=None, lang_pairs='hi-mr', keep_inference_langtok=False, sampling_method='temperature', sampling_temperature=1.5, data='/home/krish/content/old_files/Version3/wmt22_spm/wmt22_bin', langs=['hi', 'mr'], lang_dict=None, source_dict=None, target_dict=None, lang_tok_style='multilingual', load_alignments=False, left_pad_source='True', left_pad_target='False', upsample_primary=1, truncate_source=False, encoder_langtok='src', decoder_langtok=True, lang_tok_replacing_bos_eos=False, enable_lang_ids=False, enable_reservsed_directions_shared_datasets=False, extra_data=None, extra_lang_pairs=None, fixed_dictionary=None, langtoks_specs=['main'], langtoks=None, sampling_weights_from_file=None, sampling_weights=None, virtual_epoch_size=None, virtual_data_size=None, label_smoothing=0.2, report_accuracy=False, ignore_prefix_size=0, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.0, use_old_adam=False, fp16_adam_stats=False, warmup_updates=2500, warmup_init_lr=-1, pad=1, eos=2, unk=3, encoder_normalize_before=True, decoder_normalize_before=True, dropout=0.3, attention_dropout=0.1, encoder_layers=24, decoder_layers=24, encoder_ffn_embed_dim=8192, decoder_ffn_embed_dim=8192, encoder_layerdrop=0.05, decoder_layerdrop=0.05, share_decoder_input_output_embed=True, share_all_embeddings=True, no_seed_provided=False, encoder_embed_dim=1024, encoder_attention_heads=16, decoder_embed_dim=1024, decoder_attention_heads=16, encoder_embed_path=None, encoder_learned_pos=False, decoder_embed_path=None, decoder_learned_pos=False, activation_dropout=0.0, activation_fn='relu', adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, no_token_positional_embeddings=False, adaptive_input=False, no_cross_attention=False, cross_self_attention=False, decoder_output_dim=1024, decoder_input_dim=1024, no_scale_embedding=False, layernorm_embedding=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, _name='transformer_wmt_en_de_big'), 'task': Namespace(no_progress_bar=False, log_interval=2, log_format='simple', log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=222, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', scoring='bleu', task='translation_multi_simple_epoch', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=3600, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=3600, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='transformer_wmt_en_de_big', max_epoch=0, max_update=40000, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[2], lr=[3e-05], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='/home/krish/content/old_files/Version3/checkpoint1.2B', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model='/home/krish/content/1.2B_last_checkpoint.pt', reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=5000, keep_interval_updates=10, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=10, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, source_lang=None, target_lang=None, lang_pairs='hi-mr', keep_inference_langtok=False, sampling_method='temperature', sampling_temperature=1.5, data='/home/krish/content/old_files/Version3/wmt22_spm/wmt22_bin', langs=['hi', 'mr'], lang_dict=None, source_dict=None, target_dict=None, lang_tok_style='multilingual', load_alignments=False, left_pad_source='True', left_pad_target='False', upsample_primary=1, truncate_source=False, encoder_langtok='src', decoder_langtok=True, lang_tok_replacing_bos_eos=False, enable_lang_ids=False, enable_reservsed_directions_shared_datasets=False, extra_data=None, extra_lang_pairs=None, fixed_dictionary=None, langtoks_specs=['main'], langtoks=None, sampling_weights_from_file=None, sampling_weights=None, virtual_epoch_size=None, virtual_data_size=None, label_smoothing=0.2, report_accuracy=False, ignore_prefix_size=0, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.0, use_old_adam=False, fp16_adam_stats=False, warmup_updates=2500, warmup_init_lr=-1, pad=1, eos=2, unk=3, encoder_normalize_before=True, decoder_normalize_before=True, dropout=0.3, attention_dropout=0.1, encoder_layers=24, decoder_layers=24, encoder_ffn_embed_dim=8192, decoder_ffn_embed_dim=8192, encoder_layerdrop=0.05, decoder_layerdrop=0.05, share_decoder_input_output_embed=True, share_all_embeddings=True, no_seed_provided=False, encoder_embed_dim=1024, encoder_attention_heads=16, decoder_embed_dim=1024, decoder_attention_heads=16, encoder_embed_path=None, encoder_learned_pos=False, decoder_embed_path=None, decoder_learned_pos=False, activation_dropout=0.0, activation_fn='relu', adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, no_token_positional_embeddings=False, adaptive_input=False, no_cross_attention=False, cross_self_attention=False, decoder_output_dim=1024, decoder_input_dim=1024, no_scale_embedding=False, layernorm_embedding=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, max_source_positions=1024, max_target_positions=1024, _name='translation_multi_simple_epoch'), 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.2, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [3e-05]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 2500, 'warmup_init_lr': -1.0, 'lr': [3e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2025-04-03 11:31:26 | INFO | fairseq.data.multilingual.multilingual_data_manager | parsed the language list as they are ordered in the option: ['hi', 'mr']
2025-04-03 11:31:26 | INFO | fairseq.data.multilingual.multilingual_data_manager | [hi] dictionary: 128112 types
2025-04-03 11:31:26 | INFO | fairseq.data.multilingual.multilingual_data_manager | [mr] dictionary: 128112 types
2025-04-03 11:31:35 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(128112, 1024, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): LayerDropModuleList(
      (0-22): 23 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=8192, bias=True)
        (fc2): Linear(in_features=8192, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(128112, 1024, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): LayerDropModuleList(
      (0-20): 21 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=8192, bias=True)
        (fc2): Linear(in_features=8192, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=1024, out_features=128112, bias=False)
  )
)
2025-04-03 11:31:35 | INFO | fairseq_cli.train | task: TranslationMultiSimpleEpochTask
2025-04-03 11:31:35 | INFO | fairseq_cli.train | model: TransformerModel
2025-04-03 11:31:35 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2025-04-03 11:31:35 | INFO | fairseq_cli.train | num. shared model params: 1,743,106,048 (num. trained: 1,743,106,048)
2025-04-03 11:31:35 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2025-04-03 11:31:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | loading data for valid epoch=1/None
2025-04-03 11:31:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=10676.4140625Mb; avail=244424.8203125Mb
2025-04-03 11:31:35 | INFO | fairseq.data.multilingual.multilingual_data_manager | langtoks settings: {'main': ('src', 'tgt')}
2025-04-03 11:31:35 | INFO | fairseq.data.multilingual.multilingual_data_manager | [valid] num of shards: {'main:hi-mr': 1}
2025-04-03 11:31:35 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:hi-mr src_langtok: 128036; tgt_langtok: 128063
2025-04-03 11:31:35 | INFO | fairseq.data.data_utils | loaded 3,313 examples from: /home/krish/content/old_files/Version3/wmt22_spm/wmt22_bin/valid.hi-mr.hi
2025-04-03 11:31:35 | INFO | fairseq.data.data_utils | loaded 3,313 examples from: /home/krish/content/old_files/Version3/wmt22_spm/wmt22_bin/valid.hi-mr.mr
2025-04-03 11:31:35 | INFO | fairseq.data.multilingual.multilingual_data_manager | /home/krish/content/old_files/Version3/wmt22_spm/wmt22_bin valid hi-mr 3313 examples
2025-04-03 11:31:36 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2025-04-03 11:31:36 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2025-04-03 11:31:36 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2025-04-03 11:31:36 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
2025-04-03 11:31:36 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2025-04-03 11:31:36 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2025-04-03 11:31:36 | INFO | fairseq_cli.train | max tokens per device = 3600 and max sentences per device = None
2025-04-03 11:31:36 | INFO | fairseq.checkpoint_utils | loading pretrained model from /home/krish/content/1.2B_last_checkpoint.pt: optimizer, lr scheduler, meters, dataloader will be reset
2025-04-03 11:31:36 | INFO | fairseq.trainer | Preparing to load checkpoint /home/krish/content/1.2B_last_checkpoint.pt
2025-04-03 11:31:43 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2025-04-03 11:31:44 | INFO | fairseq.trainer | Loaded checkpoint /home/krish/content/1.2B_last_checkpoint.pt (epoch 81 @ 0 updates)
2025-04-03 11:31:44 | INFO | fairseq.trainer | loading train data for epoch 1
2025-04-03 11:31:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | loading data for train epoch=1/None
2025-04-03 11:31:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=7037.765625Mb; avail=248055.46484375Mb
2025-04-03 11:31:44 | INFO | fairseq.data.multilingual.multilingual_data_manager | langtoks settings: {'main': ('src', 'tgt')}
2025-04-03 11:31:44 | INFO | fairseq.data.multilingual.multilingual_data_manager | [train] num of shards: {'main:hi-mr': 1}
2025-04-03 11:31:44 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:hi-mr src_langtok: 128036; tgt_langtok: 128063
2025-04-03 11:31:44 | INFO | fairseq.data.data_utils | loaded 31,849 examples from: /home/krish/content/old_files/Version3/wmt22_spm/wmt22_bin/train.hi-mr.hi
2025-04-03 11:31:44 | INFO | fairseq.data.data_utils | loaded 31,849 examples from: /home/krish/content/old_files/Version3/wmt22_spm/wmt22_bin/train.hi-mr.mr
2025-04-03 11:31:44 | INFO | fairseq.data.multilingual.multilingual_data_manager | /home/krish/content/old_files/Version3/wmt22_spm/wmt22_bin train hi-mr 31849 examples
2025-04-03 11:31:44 | INFO | fairseq.data.multilingual.multilingual_data_manager | estimated total data sizes of all shards used in sampling ratios: [('main:hi-mr', 31849)]. Note that if the data a shard has not been loaded yet, use the max known data size to approximate
2025-04-03 11:31:44 | INFO | fairseq.data.multilingual.sampling_method | selected sampler: temperature
2025-04-03 11:31:44 | INFO | fairseq.data.multilingual.multilingual_data_manager | | Upsample ratios: [('main:hi-mr', 1.0)]
2025-04-03 11:31:44 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:hi-mr': 31849}; raw total size: 31849
2025-04-03 11:31:44 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:hi-mr': 31849}; resampled total size: 31849
2025-04-03 11:31:44 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Upsampling ratios: {'main:hi-mr': 1.0}
2025-04-03 11:31:44 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.000788
2025-04-03 11:31:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=7037.765625Mb; avail=248055.46484375Mb
2025-04-03 11:31:44 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.000295
2025-04-03 11:31:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.002958
2025-04-03 11:31:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=7037.765625Mb; avail=248055.46484375Mb
2025-04-03 11:31:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.000100
2025-04-03 11:31:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=7037.765625Mb; avail=248055.46484375Mb
2025-04-03 11:31:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.001531
2025-04-03 11:31:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:00.004937
2025-04-03 11:31:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=7037.765625Mb; avail=248055.46484375Mb
2025-04-03 11:31:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 139
2025-04-03 11:31:44 | INFO | fairseq.trainer | begin training epoch 1
2025-04-03 11:31:44 | INFO | fairseq_cli.train | Start iterating over samples
2025-04-03 11:31:50 | INFO | train_inner | epoch 001:      2 / 139 loss=11.88, nll_loss=9.81, ppl=897.61, wps=2671.2, ups=0.4, wpb=6812, bsz=260, num_updates=2, lr=2.4e-08, gnorm=14.219, train_wall=6, gb_free=12.2, wall=14
2025-04-03 11:31:54 | INFO | train_inner | epoch 001:      4 / 139 loss=11.894, nll_loss=9.826, ppl=907.67, wps=2100.4, ups=0.45, wpb=4627.5, bsz=156, num_updates=4, lr=4.8e-08, gnorm=13.139, train_wall=4, gb_free=12.7, wall=19
2025-04-03 11:32:00 | INFO | train_inner | epoch 001:      6 / 139 loss=11.627, nll_loss=9.483, ppl=715.52, wps=2324.3, ups=0.37, wpb=6237.5, bsz=324, num_updates=6, lr=7.2e-08, gnorm=12.546, train_wall=5, gb_free=11.3, wall=24
2025-04-03 11:32:04 | INFO | train_inner | epoch 001:      8 / 139 loss=11.734, nll_loss=9.622, ppl=787.82, wps=2221.7, ups=0.44, wpb=5095.5, bsz=104, num_updates=8, lr=9.6e-08, gnorm=13.879, train_wall=5, gb_free=13.6, wall=29
2025-04-03 11:32:09 | INFO | train_inner | epoch 001:     10 / 139 loss=11.629, nll_loss=9.486, ppl=717.23, wps=2447.6, ups=0.39, wpb=6320, bsz=188, num_updates=10, lr=1.2e-07, gnorm=13.794, train_wall=5, gb_free=11.3, wall=34
2025-04-03 11:32:14 | INFO | train_inner | epoch 001:     12 / 139 loss=11.696, nll_loss=9.573, ppl=761.55, wps=2437.2, ups=0.4, wpb=6062, bsz=176, num_updates=12, lr=1.44e-07, gnorm=14.101, train_wall=5, gb_free=9.7, wall=39
2025-04-03 11:32:19 | INFO | train_inner | epoch 001:     14 / 139 loss=11.502, nll_loss=9.331, ppl=643.9, wps=2099.6, ups=0.41, wpb=5073, bsz=168, num_updates=14, lr=1.68e-07, gnorm=12.544, train_wall=5, gb_free=12.5, wall=44
2025-04-03 11:32:24 | INFO | train_inner | epoch 001:     16 / 139 loss=11.808, nll_loss=9.715, ppl=840.38, wps=2521.5, ups=0.43, wpb=5891.5, bsz=172, num_updates=16, lr=1.92e-07, gnorm=13.419, train_wall=5, gb_free=11.7, wall=48
2025-04-03 11:32:29 | INFO | train_inner | epoch 001:     18 / 139 loss=11.635, nll_loss=9.493, ppl=720.57, wps=2227.1, ups=0.4, wpb=5499, bsz=152, num_updates=18, lr=2.16e-07, gnorm=12.099, train_wall=5, gb_free=12.6, wall=53
2025-04-03 11:32:34 | INFO | train_inner | epoch 001:     20 / 139 loss=11.733, nll_loss=9.615, ppl=784.04, wps=2424.5, ups=0.39, wpb=6186, bsz=284, num_updates=20, lr=2.4e-07, gnorm=13.25, train_wall=5, gb_free=14.1, wall=58
2025-04-03 11:32:39 | INFO | train_inner | epoch 001:     22 / 139 loss=11.548, nll_loss=9.389, ppl=670.49, wps=2318, ups=0.39, wpb=5904, bsz=220, num_updates=22, lr=2.64e-07, gnorm=11.713, train_wall=5, gb_free=14.4, wall=64
2025-04-03 11:32:44 | INFO | train_inner | epoch 001:     24 / 139 loss=11.691, nll_loss=9.565, ppl=757.71, wps=2461.3, ups=0.39, wpb=6265, bsz=180, num_updates=24, lr=2.88e-07, gnorm=12.662, train_wall=5, gb_free=12, wall=69
2025-04-03 11:32:49 | INFO | train_inner | epoch 001:     26 / 139 loss=11.444, nll_loss=9.263, ppl=614.19, wps=1936.8, ups=0.41, wpb=4727.5, bsz=176, num_updates=26, lr=3.12e-07, gnorm=11.003, train_wall=5, gb_free=13.2, wall=73
2025-04-03 11:32:54 | INFO | train_inner | epoch 001:     28 / 139 loss=11.471, nll_loss=9.292, ppl=626.79, wps=2461, ups=0.37, wpb=6571, bsz=256, num_updates=28, lr=3.36e-07, gnorm=11.612, train_wall=5, gb_free=11.9, wall=79
2025-04-03 11:33:00 | INFO | train_inner | epoch 001:     30 / 139 loss=11.307, nll_loss=9.081, ppl=541.58, wps=2293.8, ups=0.38, wpb=6013.5, bsz=204, num_updates=30, lr=3.6e-07, gnorm=10.322, train_wall=5, gb_free=11.1, wall=84
2025-04-03 11:33:05 | INFO | train_inner | epoch 001:     32 / 139 loss=11.488, nll_loss=9.312, ppl=635.7, wps=2506, ups=0.37, wpb=6795.5, bsz=292, num_updates=32, lr=3.84e-07, gnorm=12.131, train_wall=5, gb_free=12.1, wall=90
2025-04-03 11:33:10 | INFO | train_inner | epoch 001:     34 / 139 loss=11.146, nll_loss=8.883, ppl=472.26, wps=2278.7, ups=0.39, wpb=5884, bsz=220, num_updates=34, lr=4.08e-07, gnorm=10.423, train_wall=5, gb_free=10.8, wall=95
2025-04-03 11:33:16 | INFO | train_inner | epoch 001:     36 / 139 loss=11.093, nll_loss=8.818, ppl=451.17, wps=2332.2, ups=0.36, wpb=6488.5, bsz=232, num_updates=36, lr=4.32e-07, gnorm=9.589, train_wall=6, gb_free=10.3, wall=100
2025-04-03 11:33:21 | INFO | train_inner | epoch 001:     38 / 139 loss=11.186, nll_loss=8.935, ppl=489.59, wps=2239.2, ups=0.4, wpb=5659, bsz=176, num_updates=38, lr=4.56e-07, gnorm=9.125, train_wall=5, gb_free=12.9, wall=105
2025-04-03 11:33:26 | INFO | train_inner | epoch 001:     40 / 139 loss=11.27, nll_loss=9.045, ppl=528.13, wps=2586.6, ups=0.38, wpb=6758.5, bsz=248, num_updates=40, lr=4.8e-07, gnorm=9.551, train_wall=5, gb_free=12.1, wall=111
2025-04-03 11:33:31 | INFO | train_inner | epoch 001:     42 / 139 loss=11.054, nll_loss=8.767, ppl=435.52, wps=2212.6, ups=0.39, wpb=5639, bsz=260, num_updates=42, lr=5.04e-07, gnorm=8.414, train_wall=5, gb_free=12, wall=116
2025-04-03 11:33:37 | INFO | train_inner | epoch 001:     44 / 139 loss=11.215, nll_loss=8.975, ppl=503.38, wps=2508.6, ups=0.37, wpb=6794.5, bsz=296, num_updates=44, lr=5.28e-07, gnorm=9.225, train_wall=5, gb_free=10.8, wall=121
2025-04-03 11:33:42 | INFO | train_inner | epoch 001:     46 / 139 loss=11.155, nll_loss=8.9, ppl=477.87, wps=2414.2, ups=0.38, wpb=6351, bsz=272, num_updates=46, lr=5.52e-07, gnorm=8.943, train_wall=5, gb_free=10.4, wall=126
2025-04-03 11:33:47 | INFO | train_inner | epoch 001:     48 / 139 loss=11.064, nll_loss=8.787, ppl=441.62, wps=2045.5, ups=0.4, wpb=5131, bsz=204, num_updates=48, lr=5.76e-07, gnorm=8.181, train_wall=5, gb_free=12.2, wall=131
2025-04-03 11:33:52 | INFO | train_inner | epoch 001:     50 / 139 loss=11.022, nll_loss=8.734, ppl=425.77, wps=2116.7, ups=0.38, wpb=5571, bsz=180, num_updates=50, lr=6e-07, gnorm=6.928, train_wall=5, gb_free=11.4, wall=137
2025-04-03 11:33:57 | INFO | train_inner | epoch 001:     52 / 139 loss=10.889, nll_loss=8.57, ppl=380.12, wps=2555.5, ups=0.38, wpb=6804.5, bsz=268, num_updates=52, lr=6.24e-07, gnorm=7.419, train_wall=5, gb_free=10, wall=142
2025-04-03 11:34:03 | INFO | train_inner | epoch 001:     54 / 139 loss=10.84, nll_loss=8.514, ppl=365.66, wps=2257.1, ups=0.37, wpb=6045.5, bsz=300, num_updates=54, lr=6.48e-07, gnorm=7.169, train_wall=5, gb_free=10.3, wall=147
2025-04-03 11:34:08 | INFO | train_inner | epoch 001:     56 / 139 loss=10.627, nll_loss=8.249, ppl=304.18, wps=2261.2, ups=0.38, wpb=5983, bsz=180, num_updates=56, lr=6.72e-07, gnorm=5.704, train_wall=5, gb_free=9.5, wall=153
2025-04-03 11:34:13 | INFO | train_inner | epoch 001:     58 / 139 loss=10.712, nll_loss=8.356, ppl=327.56, wps=2262.4, ups=0.38, wpb=5933.5, bsz=240, num_updates=58, lr=6.96e-07, gnorm=6.312, train_wall=5, gb_free=13.5, wall=158
2025-04-03 11:34:19 | INFO | train_inner | epoch 001:     60 / 139 loss=10.69, nll_loss=8.326, ppl=320.87, wps=2271.2, ups=0.38, wpb=6044.5, bsz=248, num_updates=60, lr=7.2e-07, gnorm=5.792, train_wall=5, gb_free=11.4, wall=163
2025-04-03 11:34:24 | INFO | train_inner | epoch 001:     62 / 139 loss=10.728, nll_loss=8.381, ppl=333.4, wps=2460.4, ups=0.37, wpb=6655, bsz=232, num_updates=62, lr=7.44e-07, gnorm=5.35, train_wall=5, gb_free=10.1, wall=169
2025-04-03 11:34:29 | INFO | train_inner | epoch 001:     64 / 139 loss=10.67, nll_loss=8.306, ppl=316.55, wps=2260.9, ups=0.38, wpb=6016, bsz=280, num_updates=64, lr=7.68e-07, gnorm=5.92, train_wall=5, gb_free=11, wall=174
2025-04-03 11:34:35 | INFO | train_inner | epoch 001:     66 / 139 loss=10.521, nll_loss=8.124, ppl=278.99, wps=2293.1, ups=0.37, wpb=6238, bsz=224, num_updates=66, lr=7.92e-07, gnorm=4.838, train_wall=5, gb_free=12.1, wall=179
2025-04-03 11:34:40 | INFO | train_inner | epoch 001:     68 / 139 loss=10.463, nll_loss=8.06, ppl=266.93, wps=2330.9, ups=0.37, wpb=6300.5, bsz=240, num_updates=68, lr=8.16e-07, gnorm=4.878, train_wall=5, gb_free=12.3, wall=185
2025-04-03 11:34:46 | INFO | train_inner | epoch 001:     70 / 139 loss=10.224, nll_loss=7.742, ppl=214.09, wps=2211.3, ups=0.36, wpb=6099, bsz=336, num_updates=70, lr=8.4e-07, gnorm=5.075, train_wall=6, gb_free=12.8, wall=190
2025-04-03 11:34:51 | INFO | train_inner | epoch 001:     72 / 139 loss=10.259, nll_loss=7.798, ppl=222.56, wps=2244.5, ups=0.35, wpb=6325, bsz=280, num_updates=72, lr=8.64e-07, gnorm=4.406, train_wall=6, gb_free=10.2, wall=196
2025-04-03 11:34:56 | INFO | train_inner | epoch 001:     74 / 139 loss=10.564, nll_loss=8.194, ppl=292.78, wps=2443.3, ups=0.41, wpb=6014, bsz=192, num_updates=74, lr=8.88e-07, gnorm=4.611, train_wall=5, gb_free=12.2, wall=201
2025-04-03 11:35:02 | INFO | train_inner | epoch 001:     76 / 139 loss=10.239, nll_loss=7.777, ppl=219.27, wps=2277.9, ups=0.37, wpb=6136, bsz=248, num_updates=76, lr=9.12e-07, gnorm=4.246, train_wall=5, gb_free=12.5, wall=206
2025-04-03 11:35:07 | INFO | train_inner | epoch 001:     78 / 139 loss=10.233, nll_loss=7.772, ppl=218.6, wps=2402.2, ups=0.37, wpb=6487.5, bsz=284, num_updates=78, lr=9.36e-07, gnorm=4.013, train_wall=5, gb_free=11.1, wall=212
2025-04-03 11:35:12 | INFO | train_inner | epoch 001:     80 / 139 loss=10.278, nll_loss=7.831, ppl=227.63, wps=2057.2, ups=0.4, wpb=5141.5, bsz=164, num_updates=80, lr=9.6e-07, gnorm=3.847, train_wall=5, gb_free=10, wall=217
2025-04-03 11:35:17 | INFO | train_inner | epoch 001:     82 / 139 loss=10.219, nll_loss=7.753, ppl=215.73, wps=2231.2, ups=0.39, wpb=5703.5, bsz=272, num_updates=82, lr=9.84e-07, gnorm=4.228, train_wall=5, gb_free=13.5, wall=222
2025-04-03 11:35:22 | INFO | train_inner | epoch 001:     84 / 139 loss=10.372, nll_loss=7.961, ppl=249.19, wps=2317.2, ups=0.39, wpb=5939.5, bsz=148, num_updates=84, lr=1.008e-06, gnorm=3.787, train_wall=5, gb_free=12.6, wall=227
2025-04-03 11:35:27 | INFO | train_inner | epoch 001:     86 / 139 loss=10.287, nll_loss=7.845, ppl=229.9, wps=2144.7, ups=0.42, wpb=5121.5, bsz=160, num_updates=86, lr=1.032e-06, gnorm=3.633, train_wall=5, gb_free=13.7, wall=232
2025-04-03 11:35:32 | INFO | train_inner | epoch 001:     88 / 139 loss=10.315, nll_loss=7.896, ppl=238.26, wps=2369.5, ups=0.42, wpb=5583.5, bsz=204, num_updates=88, lr=1.056e-06, gnorm=3.642, train_wall=5, gb_free=12.3, wall=236
2025-04-03 11:35:37 | INFO | train_inner | epoch 001:     90 / 139 loss=10.16, nll_loss=7.695, ppl=207.24, wps=2518.3, ups=0.36, wpb=7011, bsz=332, num_updates=90, lr=1.08e-06, gnorm=3.708, train_wall=6, gb_free=10.9, wall=242
2025-04-03 11:35:43 | INFO | train_inner | epoch 001:     92 / 139 loss=10.013, nll_loss=7.506, ppl=181.73, wps=2387, ups=0.35, wpb=6874.5, bsz=284, num_updates=92, lr=1.104e-06, gnorm=3.295, train_wall=6, gb_free=10.7, wall=248
2025-04-03 11:35:49 | INFO | train_inner | epoch 001:     94 / 139 loss=10.078, nll_loss=7.601, ppl=194.09, wps=2182.6, ups=0.36, wpb=6004, bsz=152, num_updates=94, lr=1.128e-06, gnorm=3.193, train_wall=5, gb_free=10.8, wall=253
2025-04-03 11:35:54 | INFO | train_inner | epoch 001:     96 / 139 loss=9.854, nll_loss=7.294, ppl=156.9, wps=2188.5, ups=0.36, wpb=6002, bsz=300, num_updates=96, lr=1.152e-06, gnorm=3.732, train_wall=5, gb_free=13.4, wall=259
2025-04-03 11:35:59 | INFO | train_inner | epoch 001:     98 / 139 loss=10.016, nll_loss=7.523, ppl=183.98, wps=2256.7, ups=0.43, wpb=5264.5, bsz=192, num_updates=98, lr=1.176e-06, gnorm=3.115, train_wall=5, gb_free=11.5, wall=263
2025-04-03 11:36:04 | INFO | train_inner | epoch 001:    100 / 139 loss=9.993, nll_loss=7.497, ppl=180.7, wps=2543.5, ups=0.38, wpb=6754.5, bsz=252, num_updates=100, lr=1.2e-06, gnorm=3.284, train_wall=5, gb_free=12.1, wall=269
2025-04-03 11:36:10 | INFO | train_inner | epoch 001:    102 / 139 loss=9.904, nll_loss=7.377, ppl=166.18, wps=2325, ups=0.37, wpb=6328, bsz=240, num_updates=102, lr=1.224e-06, gnorm=2.793, train_wall=5, gb_free=11.1, wall=274
2025-04-03 11:36:15 | INFO | train_inner | epoch 001:    104 / 139 loss=9.946, nll_loss=7.436, ppl=173.19, wps=2275.8, ups=0.38, wpb=6039.5, bsz=244, num_updates=104, lr=1.248e-06, gnorm=2.767, train_wall=5, gb_free=10.1, wall=279
2025-04-03 11:36:20 | INFO | train_inner | epoch 001:    106 / 139 loss=9.912, nll_loss=7.395, ppl=168.33, wps=2387, ups=0.37, wpb=6534, bsz=240, num_updates=106, lr=1.272e-06, gnorm=2.791, train_wall=5, gb_free=10.4, wall=285
2025-04-03 11:36:26 | INFO | train_inner | epoch 001:    108 / 139 loss=9.692, nll_loss=7.112, ppl=138.32, wps=2249.5, ups=0.35, wpb=6460, bsz=276, num_updates=108, lr=1.296e-06, gnorm=2.763, train_wall=6, gb_free=10.7, wall=291
2025-04-03 11:36:31 | INFO | train_inner | epoch 001:    110 / 139 loss=10.025, nll_loss=7.546, ppl=186.89, wps=2409.5, ups=0.38, wpb=6307.5, bsz=204, num_updates=110, lr=1.32e-06, gnorm=2.678, train_wall=5, gb_free=11.7, wall=296
2025-04-03 11:36:37 | INFO | train_inner | epoch 001:    112 / 139 loss=9.856, nll_loss=7.325, ppl=160.29, wps=2320.8, ups=0.37, wpb=6254, bsz=252, num_updates=112, lr=1.344e-06, gnorm=2.646, train_wall=5, gb_free=10.7, wall=301
2025-04-03 11:36:42 | INFO | train_inner | epoch 001:    114 / 139 loss=9.972, nll_loss=7.476, ppl=178, wps=2476.9, ups=0.39, wpb=6321.5, bsz=204, num_updates=114, lr=1.368e-06, gnorm=2.907, train_wall=5, gb_free=12, wall=306
2025-04-03 11:36:47 | INFO | train_inner | epoch 001:    116 / 139 loss=9.731, nll_loss=7.172, ppl=144.24, wps=2284.6, ups=0.39, wpb=5905, bsz=224, num_updates=116, lr=1.392e-06, gnorm=2.752, train_wall=5, gb_free=13.9, wall=311
2025-04-03 11:36:52 | INFO | train_inner | epoch 001:    118 / 139 loss=9.591, nll_loss=6.997, ppl=127.75, wps=2218, ups=0.36, wpb=6129.5, bsz=248, num_updates=118, lr=1.416e-06, gnorm=2.409, train_wall=6, gb_free=10.8, wall=317
2025-04-03 11:36:58 | INFO | train_inner | epoch 001:    120 / 139 loss=9.722, nll_loss=7.176, ppl=144.6, wps=2208.4, ups=0.38, wpb=5835, bsz=168, num_updates=120, lr=1.44e-06, gnorm=2.931, train_wall=5, gb_free=12.3, wall=322
2025-04-03 11:37:03 | INFO | train_inner | epoch 001:    122 / 139 loss=9.602, nll_loss=7.013, ppl=129.17, wps=2366.5, ups=0.37, wpb=6462.5, bsz=248, num_updates=122, lr=1.464e-06, gnorm=2.569, train_wall=5, gb_free=11.4, wall=328
2025-04-03 11:37:08 | INFO | train_inner | epoch 001:    124 / 139 loss=9.697, nll_loss=7.138, ppl=140.89, wps=2084.6, ups=0.44, wpb=4767.5, bsz=184.5, num_updates=124, lr=1.488e-06, gnorm=3.061, train_wall=5, gb_free=9.4, wall=332
2025-04-03 11:37:13 | INFO | train_inner | epoch 001:    126 / 139 loss=9.612, nll_loss=7.039, ppl=131.54, wps=2251.6, ups=0.38, wpb=5858.5, bsz=196, num_updates=126, lr=1.512e-06, gnorm=2.23, train_wall=5, gb_free=13, wall=337
2025-04-03 11:37:18 | INFO | train_inner | epoch 001:    128 / 139 loss=9.653, nll_loss=7.075, ppl=134.8, wps=2388.5, ups=0.39, wpb=6054.5, bsz=320, num_updates=128, lr=1.536e-06, gnorm=2.58, train_wall=5, gb_free=10.6, wall=343
2025-04-03 11:37:23 | INFO | train_inner | epoch 001:    130 / 139 loss=9.641, nll_loss=7.084, ppl=135.65, wps=2181.9, ups=0.38, wpb=5784.5, bsz=168, num_updates=130, lr=1.56e-06, gnorm=2.363, train_wall=5, gb_free=10.4, wall=348
